{
  "identifier": "selfie_segmenter_landscape_19.onnx",
  "format": "ONNX v4",
  "producer": "tf2onnx 1.8.5",
  "version": "0",
  "functions": [],
  "imports": [
    "ai.onnx v19"
  ],
  "metadata": [],
  "graph": [
    {
      "name": "tf2onnx",
      "inputs": [
        {
          "name": "input",
          "value": [
            {
              "name": "input",
              "type": {
                "dataType": "float32",
                "shape": {
                  "dimensions": [
                    1,
                    144,
                    256,
                    3
                  ]
                }
              }
            }
          ]
        }
      ],
      "outputs": [
        {
          "name": "segment_back",
          "value": [
            {
              "name": "segment_back",
              "type": {
                "dataType": "float32",
                "shape": {
                  "dimensions": [
                    1,
                    144,
                    256,
                    1
                  ]
                }
              }
            }
          ]
        }
      ],
      "nodes": [
        {
          "name": "Conv2D__6",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "data",
              "value": [
                {
                  "name": "input",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        144,
                        256,
                        3
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "transposed",
              "value": [
                {
                  "name": "Conv2D__6:0",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        3,
                        144,
                        256
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [
            {
              "name": "perm",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "0",
                  "3",
                  "1",
                  "2"
                ]
              }
            }
          ],
          "type": {
            "name": "Transpose",
            "module": "ai.onnx",
            "version": 13,
            "description": "Transpose the input tensor similar to numpy.transpose. For example, when\nperm=(1, 0, 2), given an input tensor of shape (1, 2, 3), the output shape\nwill be (2, 1, 3).\n",
            "attributes": [
              {
                "name": "perm",
                "type": "int64[]",
                "required": false,
                "description": "A list of integers. By default, reverse the dimensions, otherwise permute the axes according to the values given."
              }
            ],
            "inputs": [
              {
                "name": "data",
                "type": "T",
                "description": "An input tensor."
              }
            ],
            "min_input": 1,
            "max_input": 1,
            "outputs": [
              {
                "name": "transposed",
                "type": "T",
                "description": "Transposed output."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "type_constraints": [
              {
                "description": "Constrain input and output types to all tensor types.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(uint8)",
                  "tensor(uint16)",
                  "tensor(uint32)",
                  "tensor(uint64)",
                  "tensor(int8)",
                  "tensor(int16)",
                  "tensor(int32)",
                  "tensor(int64)",
                  "tensor(bfloat16)",
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)",
                  "tensor(string)",
                  "tensor(bool)",
                  "tensor(complex64)",
                  "tensor(complex128)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "all_permutations",
                "code": "shape = (2, 3, 4)\ndata = np.random.random_sample(shape).astype(np.float32)\npermutations = list(itertools.permutations(np.arange(len(shape))))\n\nfor i, permutation in enumerate(permutations):\n    node = onnx.helper.make_node(\n        \"Transpose\",\n        inputs=[\"data\"],\n        outputs=[\"transposed\"],\n        perm=permutation,\n    )\n    transposed = np.transpose(data, permutation)\n    expect(\n        node,\n        inputs=[data],\n        outputs=[transposed],\n        name=f\"test_transpose_all_permutations_{i}\",\n    )"
              },
              {
                "summary": "default",
                "code": "shape = (2, 3, 4)\ndata = np.random.random_sample(shape).astype(np.float32)\n\nnode = onnx.helper.make_node(\n    \"Transpose\", inputs=[\"data\"], outputs=[\"transposed\"]\n)\n\ntransposed = np.transpose(data)\nexpect(node, inputs=[data], outputs=[transposed], name=\"test_transpose_default\")"
              }
            ],
            "category": "Transform"
          }
        },
        {
          "name": "Conv__158",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "X",
              "value": [
                {
                  "name": "Conv2D__6:0",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        3,
                        144,
                        256
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "W",
              "value": [
                {
                  "name": "Conv2D/filter:0",
                  "initializer": {
                    "name": "Conv2D/filter:0",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float32",
                      "shape": {
                        "dimensions": [
                          16,
                          3,
                          3,
                          3
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        16,
                        3,
                        3,
                        3
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "B",
              "value": [
                {
                  "name": "conv2d_1/y:0",
                  "initializer": {
                    "name": "conv2d_1/y:0",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float32",
                      "shape": {
                        "dimensions": [
                          16
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        16
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "Y",
              "value": [
                {
                  "name": "Conv__158:0",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        16,
                        72,
                        128
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [
            {
              "name": "dilations",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "strides",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "2",
                  "2"
                ]
              }
            },
            {
              "name": "kernel_shape",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "3",
                  "3"
                ]
              }
            },
            {
              "name": "pads",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "0",
                  "0",
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "group",
              "type": "int64",
              "value": {
                "type": "bigint",
                "value": "1"
              }
            }
          ],
          "type": {
            "name": "Conv",
            "module": "ai.onnx",
            "version": 11,
            "description": "The convolution operator consumes an input tensor and a filter, and\ncomputes the output.",
            "attributes": [
              {
                "name": "auto_pad",
                "type": "string",
                "required": false,
                "default": "NOTSET",
                "description": "auto_pad must be either NOTSET, SAME_UPPER, SAME_LOWER or VALID. Where default value is NOTSET, which means explicit padding is used. SAME_UPPER or SAME_LOWER mean pad the input so that `output_shape[i] = ceil(input_shape[i] / strides[i])` for each axis `i`. The padding is split between the two sides equally or almost equally (depending on whether it is even or odd). In case the padding is an odd number, the extra padding is added at the end for SAME_UPPER and at the beginning for SAME_LOWER."
              },
              {
                "name": "dilations",
                "type": "int64[]",
                "required": false,
                "description": "dilation value along each spatial axis of the filter. If not present, the dilation defaults is 1 along each spatial axis."
              },
              {
                "name": "group",
                "type": "int64",
                "required": false,
                "default": 1,
                "description": "number of groups input channels and output channels are divided into."
              },
              {
                "name": "kernel_shape",
                "type": "int64[]",
                "required": false,
                "description": "The shape of the convolution kernel. If not present, should be inferred from input W."
              },
              {
                "name": "pads",
                "type": "int64[]",
                "required": false,
                "description": "Padding for the beginning and ending along each spatial axis, it can take any value greater than or equal to 0. The value represent the number of pixels added to the beginning and end part of the corresponding axis. `pads` format should be as follow [x1_begin, x2_begin...x1_end, x2_end,...], where xi_begin the number of pixels added at the beginning of axis `i` and xi_end, the number of pixels added at the end of axis `i`. This attribute cannot be used simultaneously with auto_pad attribute. If not present, the padding defaults to 0 along start and end of each spatial axis."
              },
              {
                "name": "strides",
                "type": "int64[]",
                "required": false,
                "description": "Stride along each spatial axis. If not present, the stride defaults is 1 along each spatial axis."
              }
            ],
            "inputs": [
              {
                "name": "X",
                "type": "T",
                "description": "Input data tensor from previous layer; has size (N x C x H x W), where N is the batch size, C is the number of channels, and H and W are the height and width. Note that this is for the 2D image. Otherwise the size is (N x C x D1 x D2 ... x Dn). Optionally, if dimension denotation is in effect, the operation expects input data tensor to arrive with the dimension denotation of [DATA_BATCH, DATA_CHANNEL, DATA_FEATURE, DATA_FEATURE ...]."
              },
              {
                "name": "W",
                "type": "T",
                "description": "The weight tensor that will be used in the convolutions; has size (M x C/group x kH x kW), where C is the number of channels, and kH and kW are the height and width of the kernel, and M is the number of feature maps. For more than 2 dimensions, the kernel shape will be (M x C/group x k1 x k2 x ... x kn), where (k1 x k2 x ... kn) is the dimension of the kernel. Optionally, if dimension denotation is in effect, the operation expects the weight tensor to arrive with the dimension denotation of [FILTER_OUT_CHANNEL, FILTER_IN_CHANNEL, FILTER_SPATIAL, FILTER_SPATIAL ...]. Assuming zero based indices for the shape array, X.shape[1] == (W.shape[1] * group) == C and W.shape[0] mod G == 0. Or in other words FILTER_IN_CHANNEL multiplied by the number of groups should be equal to DATA_CHANNEL and the number of feature maps M should be a multiple of the number of groups G."
              },
              {
                "name": "B",
                "type": "T",
                "option": "optional",
                "description": "Optional 1D bias to be added to the convolution, has size of M."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "Y",
                "type": "T",
                "description": "Output data tensor that contains the result of the convolution. The output dimensions are functions of the kernel size, stride size, and pad lengths."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain input and output types to float tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "conv",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[1, 1, 1, 1],\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 21.0, 27.0, 33.0, 24.0],  # (1, 1, 5, 5) output tensor\n                [33.0, 54.0, 63.0, 72.0, 51.0],\n                [63.0, 99.0, 108.0, 117.0, 81.0],\n                [93.0, 144.0, 153.0, 162.0, 111.0],\n                [72.0, 111.0, 117.0, 123.0, 84.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_basic_conv_with_padding\",\n)\n\n# Convolution without padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[0, 0, 0, 0],\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 63.0, 72.0],  # (1, 1, 3, 3) output tensor\n                [99.0, 108.0, 117.0],\n                [144.0, 153.0, 162.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_basic_conv_without_padding\",\n)"
              },
              {
                "summary": "conv_with_autopad_same",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with auto_pad='SAME_LOWER' and strides=2\nnode = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    auto_pad=\"SAME_LOWER\",\n    kernel_shape=[3, 3],\n    strides=[2, 2],\n)\ny = np.array(\n    [[[[12.0, 27.0, 24.0], [63.0, 108.0, 81.0], [72.0, 117.0, 84.0]]]]\n).astype(np.float32)\nexpect(node, inputs=[x, W], outputs=[y], name=\"test_conv_with_autopad_same\")"
              },
              {
                "summary": "conv_with_strides",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 7, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n                [25.0, 26.0, 27.0, 28.0, 29.0],\n                [30.0, 31.0, 32.0, 33.0, 34.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with strides=2 and padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 1, 1, 1],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 27.0, 24.0],  # (1, 1, 4, 3) output tensor\n                [63.0, 108.0, 81.0],\n                [123.0, 198.0, 141.0],\n                [112.0, 177.0, 124.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_conv_with_strides_padding\",\n)\n\n# Convolution with strides=2 and no padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[0, 0, 0, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 72.0],  # (1, 1, 3, 2) output tensor\n                [144.0, 162.0],\n                [234.0, 252.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_conv_with_strides_no_padding\",\n)\n\n# Convolution with strides=2 and padding only along one dimension (the H dimension in NxCxHxW tensor)\nnode_with_asymmetric_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 0, 1, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_asymmetric_padding = np.array(\n    [\n        [\n            [\n                [21.0, 33.0],  # (1, 1, 4, 2) output tensor\n                [99.0, 117.0],\n                [189.0, 207.0],\n                [171.0, 183.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_asymmetric_padding,\n    inputs=[x, W],\n    outputs=[y_with_asymmetric_padding],\n    name=\"test_conv_with_strides_and_asymmetric_padding\",\n)"
              }
            ],
            "category": "Layer"
          }
        },
        {
          "name": "add",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "A",
              "value": [
                {
                  "name": "Conv__158:0",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        16,
                        72,
                        128
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "B",
              "value": [
                {
                  "name": "const_fold_opt__408",
                  "initializer": {
                    "name": "const_fold_opt__408",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float32",
                      "shape": {
                        "dimensions": [
                          1,
                          1,
                          1,
                          1
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        1,
                        1,
                        1
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "C",
              "value": [
                {
                  "name": "add:0",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        16,
                        72,
                        128
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "Add",
            "module": "ai.onnx",
            "version": 14,
            "description": "Performs element-wise binary addition (with Numpy-style broadcasting support).\n\nThis operator supports **multidirectional (i.e., Numpy-style) broadcasting**; for more details please check [the doc](https://github.com/onnx/onnx/blob/master/docs/Broadcasting.md).\n\n(Opset 14 change): Extend supported types to include uint8, int8, uint16, and int16.\n",
            "inputs": [
              {
                "name": "A",
                "type": "T",
                "description": "First operand."
              },
              {
                "name": "B",
                "type": "T",
                "description": "Second operand."
              }
            ],
            "min_input": 2,
            "max_input": 2,
            "outputs": [
              {
                "name": "C",
                "type": "T",
                "description": "Result, has same element type as two inputs"
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "type_constraints": [
              {
                "description": "Constrain input and output types to all numeric tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(uint8)",
                  "tensor(uint16)",
                  "tensor(uint32)",
                  "tensor(uint64)",
                  "tensor(int8)",
                  "tensor(int16)",
                  "tensor(int32)",
                  "tensor(int64)",
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)",
                  "tensor(bfloat16)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "add",
                "code": "node = onnx.helper.make_node(\n    \"Add\",\n    inputs=[\"x\", \"y\"],\n    outputs=[\"sum\"],\n)\n\nx = np.random.randn(3, 4, 5).astype(np.float32)\ny = np.random.randn(3, 4, 5).astype(np.float32)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add\")\n\nx = np.random.randint(24, size=(3, 4, 5), dtype=np.int8)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.int8)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add_int8\")\n\nx = np.random.randint(24, size=(3, 4, 5), dtype=np.int16)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.int16)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add_int16\")\n\nx = np.random.randint(24, size=(3, 4, 5), dtype=np.uint8)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.uint8)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add_uint8\")\n\nx = np.random.randint(24, size=(3, 4, 5), dtype=np.uint16)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.uint16)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add_uint16\")\n\nx = np.random.randint(24, size=(3, 4, 5), dtype=np.uint32)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.uint32)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add_uint32\")\n\nx = np.random.randint(24, size=(3, 4, 5), dtype=np.uint64)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.uint64)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add_uint64\")"
              },
              {
                "summary": "add_broadcast",
                "code": "node = onnx.helper.make_node(\n    \"Add\",\n    inputs=[\"x\", \"y\"],\n    outputs=[\"sum\"],\n)\n\nx = np.random.randn(3, 4, 5).astype(np.float32)\ny = np.random.randn(5).astype(np.float32)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add_bcast\")"
              }
            ]
          }
        },
        {
          "name": "Relu6",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "input",
              "value": [
                {
                  "name": "add:0",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        16,
                        72,
                        128
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "min",
              "value": [
                {
                  "name": "292",
                  "initializer": {
                    "category": "Constant",
                    "encoding": "|",
                    "values": {
                      "0": 0
                    },
                    "type": {
                      "dataType": "float32",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            },
            {
              "name": "max",
              "value": [
                {
                  "name": "293",
                  "initializer": {
                    "category": "Constant",
                    "encoding": "|",
                    "values": {
                      "0": 6
                    },
                    "type": {
                      "dataType": "float32",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "output",
              "value": [
                {
                  "name": "Relu6:0",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        16,
                        72,
                        128
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "Clip",
            "module": "ai.onnx",
            "version": 13,
            "description": "Clip operator limits the given input within an interval. The interval is\nspecified by the inputs 'min' and 'max'. They default to\nnumeric_limits::lowest() and numeric_limits::max(), respectively.\nWhen 'min' is greater than 'max', the clip operator sets all the 'input' values to\nthe value of 'max'. Thus, this is equivalent to 'Min(max, Max(input, min))'.\n",
            "inputs": [
              {
                "name": "input",
                "type": "T",
                "description": "Input tensor whose elements to be clipped"
              },
              {
                "name": "min",
                "type": "T",
                "option": "optional",
                "description": "Minimum value, under which element is replaced by min. It must be a scalar(tensor of empty shape)."
              },
              {
                "name": "max",
                "type": "T",
                "option": "optional",
                "description": "Maximum value, above which element is replaced by max. It must be a scalar(tensor of empty shape)."
              }
            ],
            "min_input": 1,
            "max_input": 3,
            "outputs": [
              {
                "name": "output",
                "type": "T",
                "description": "Output tensor with clipped input elements"
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "1 - 3",
            "type_constraints": [
              {
                "description": "Constrain input and output types to all numeric tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(uint8)",
                  "tensor(uint16)",
                  "tensor(uint32)",
                  "tensor(uint64)",
                  "tensor(int8)",
                  "tensor(int16)",
                  "tensor(int32)",
                  "tensor(int64)",
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)",
                  "tensor(bfloat16)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "clip",
                "code": "node = onnx.helper.make_node(\n    \"Clip\",\n    inputs=[\"x\", \"min\", \"max\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([-2, 0, 2]).astype(np.float32)\nmin_val = np.float32(-1)\nmax_val = np.float32(1)\ny = np.clip(x, min_val, max_val)  # expected output [-1., 0., 1.]\nexpect(\n    node, inputs=[x, min_val, max_val], outputs=[y], name=\"test_clip_example\"\n)\n\nx = np.random.randn(3, 4, 5).astype(np.float32)\ny = np.clip(x, min_val, max_val)\nexpect(node, inputs=[x, min_val, max_val], outputs=[y], name=\"test_clip\")\nnode = onnx.helper.make_node(\n    \"Clip\",\n    inputs=[\"x\", \"min\", \"max\"],\n    outputs=[\"y\"],\n)\n\nmin_val = np.float32(-5)\nmax_val = np.float32(5)\n\nx = np.array([-1, 0, 1]).astype(np.float32)\ny = np.array([-1, 0, 1]).astype(np.float32)\nexpect(\n    node, inputs=[x, min_val, max_val], outputs=[y], name=\"test_clip_inbounds\"\n)\n\nx = np.array([-6, 0, 6]).astype(np.float32)\ny = np.array([-5, 0, 5]).astype(np.float32)\nexpect(\n    node, inputs=[x, min_val, max_val], outputs=[y], name=\"test_clip_outbounds\"\n)\n\nx = np.array([-1, 0, 6]).astype(np.float32)\ny = np.array([-1, 0, 5]).astype(np.float32)\nexpect(\n    node,\n    inputs=[x, min_val, max_val],\n    outputs=[y],\n    name=\"test_clip_splitbounds\",\n)\n\nx = np.array([-2, 0, 6]).astype(np.float32)\ny = np.array([1, 1, 1]).astype(np.float32)\nmin_val = np.float32(2)\nmax_val = np.float32(1)\nexpect(\n    node,\n    inputs=[x, min_val, max_val],\n    outputs=[y],\n    name=\"test_clip_min_greater_than_max\",\n)"
              },
              {
                "summary": "clip_default",
                "code": "node = onnx.helper.make_node(\n    \"Clip\",\n    inputs=[\"x\", \"min\"],\n    outputs=[\"y\"],\n)\nmin_val = np.float32(0)\nx = np.random.randn(3, 4, 5).astype(np.float32)\ny = np.clip(x, min_val, np.inf)\nexpect(node, inputs=[x, min_val], outputs=[y], name=\"test_clip_default_min\")\n\nno_min = \"\"  # optional input, not supplied\nnode = onnx.helper.make_node(\n    \"Clip\",\n    inputs=[\"x\", no_min, \"max\"],\n    outputs=[\"y\"],\n)\nmax_val = np.float32(0)\nx = np.random.randn(3, 4, 5).astype(np.float32)\ny = np.clip(x, -np.inf, max_val)\nexpect(node, inputs=[x, max_val], outputs=[y], name=\"test_clip_default_max\")\n\nno_max = \"\"  # optional input, not supplied\nnode = onnx.helper.make_node(\n    \"Clip\",\n    inputs=[\"x\", no_min, no_max],\n    outputs=[\"y\"],\n)\n\nx = np.array([-1, 0, 1]).astype(np.float32)\ny = np.array([-1, 0, 1]).astype(np.float32)\nexpect(node, inputs=[x], outputs=[y], name=\"test_clip_default_inbounds\")"
              },
              {
                "summary": "clip_default_int8",
                "code": "node = onnx.helper.make_node(\n    \"Clip\",\n    inputs=[\"x\", \"min\"],\n    outputs=[\"y\"],\n)\nmin_val = np.int8(0)\nx = np.random.randn(3, 4, 5).astype(np.int8)\ny = np.clip(x, min_val, np.iinfo(np.int8).max)\nexpect(\n    node, inputs=[x, min_val], outputs=[y], name=\"test_clip_default_int8_min\"\n)\n\nno_min = \"\"  # optional input, not supplied\nnode = onnx.helper.make_node(\n    \"Clip\",\n    inputs=[\"x\", no_min, \"max\"],\n    outputs=[\"y\"],\n)\nmax_val = np.int8(0)\nx = np.random.randn(3, 4, 5).astype(np.int8)\ny = np.clip(x, np.iinfo(np.int8).min, max_val)\nexpect(\n    node, inputs=[x, max_val], outputs=[y], name=\"test_clip_default_int8_max\"\n)\n\nno_max = \"\"  # optional input, not supplied\nnode = onnx.helper.make_node(\n    \"Clip\",\n    inputs=[\"x\", no_min, no_max],\n    outputs=[\"y\"],\n)\n\nx = np.array([-1, 0, 1]).astype(np.int8)\ny = np.array([-1, 0, 1]).astype(np.int8)\nexpect(node, inputs=[x], outputs=[y], name=\"test_clip_default_int8_inbounds\")"
              }
            ],
            "category": "Activation"
          }
        },
        {
          "name": "mul",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "A",
              "value": [
                {
                  "name": "mul_3/y:0",
                  "initializer": {
                    "name": "mul_3/y:0",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float32",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            },
            {
              "name": "B",
              "value": [
                {
                  "name": "Relu6:0",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        16,
                        72,
                        128
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "C",
              "value": [
                {
                  "name": "mul:0",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        16,
                        72,
                        128
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "Mul",
            "module": "ai.onnx",
            "version": 14,
            "description": "Performs element-wise binary multiplication (with Numpy-style broadcasting support).\n\nThis operator supports **multidirectional (i.e., Numpy-style) broadcasting**; for more details please check [the doc](https://github.com/onnx/onnx/blob/master/docs/Broadcasting.md).\n\n(Opset 14 change): Extend supported types to include uint8, int8, uint16, and int16.\n",
            "inputs": [
              {
                "name": "A",
                "type": "T",
                "description": "First operand."
              },
              {
                "name": "B",
                "type": "T",
                "description": "Second operand."
              }
            ],
            "min_input": 2,
            "max_input": 2,
            "outputs": [
              {
                "name": "C",
                "type": "T",
                "description": "Result, has same element type as two inputs"
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "type_constraints": [
              {
                "description": "Constrain input and output types to all numeric tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(uint8)",
                  "tensor(uint16)",
                  "tensor(uint32)",
                  "tensor(uint64)",
                  "tensor(int8)",
                  "tensor(int16)",
                  "tensor(int32)",
                  "tensor(int64)",
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)",
                  "tensor(bfloat16)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "mul",
                "code": "node = onnx.helper.make_node(\n    \"Mul\",\n    inputs=[\"x\", \"y\"],\n    outputs=[\"z\"],\n)\n\nx = np.array([1, 2, 3]).astype(np.float32)\ny = np.array([4, 5, 6]).astype(np.float32)\nz = x * y  # expected output [4., 10., 18.]\nexpect(node, inputs=[x, y], outputs=[z], name=\"test_mul_example\")\n\nx = np.random.randn(3, 4, 5).astype(np.float32)\ny = np.random.randn(3, 4, 5).astype(np.float32)\nz = x * y\nexpect(node, inputs=[x, y], outputs=[z], name=\"test_mul\")\n\nx = np.random.randint(4, size=(3, 4, 5), dtype=np.int8)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.int8)\nz = x * y\nexpect(node, inputs=[x, y], outputs=[z], name=\"test_mul_int8\")\n\nx = np.random.randint(4, size=(3, 4, 5), dtype=np.int16)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.int16)\nz = x * y\nexpect(node, inputs=[x, y], outputs=[z], name=\"test_mul_int16\")\n\nx = np.random.randint(4, size=(3, 4, 5), dtype=np.uint8)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.uint8)\nz = x * y\nexpect(node, inputs=[x, y], outputs=[z], name=\"test_mul_uint8\")\n\nx = np.random.randint(4, size=(3, 4, 5), dtype=np.uint16)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.uint16)\nz = x * y\nexpect(node, inputs=[x, y], outputs=[z], name=\"test_mul_uint16\")\n\nx = np.random.randint(4, size=(3, 4, 5), dtype=np.uint32)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.uint32)\nz = x * y\nexpect(node, inputs=[x, y], outputs=[z], name=\"test_mul_uint32\")\n\nx = np.random.randint(4, size=(3, 4, 5), dtype=np.uint64)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.uint64)\nz = x * y\nexpect(node, inputs=[x, y], outputs=[z], name=\"test_mul_uint64\")"
              },
              {
                "summary": "mul_broadcast",
                "code": "node = onnx.helper.make_node(\n    \"Mul\",\n    inputs=[\"x\", \"y\"],\n    outputs=[\"z\"],\n)\n\nx = np.random.randn(3, 4, 5).astype(np.float32)\ny = np.random.randn(5).astype(np.float32)\nz = x * y\nexpect(node, inputs=[x, y], outputs=[z], name=\"test_mul_bcast\")"
              }
            ]
          }
        },
        {
          "name": "mul_1",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "A",
              "value": [
                {
                  "name": "Conv__158:0",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        16,
                        72,
                        128
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "B",
              "value": [
                {
                  "name": "mul:0",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        16,
                        72,
                        128
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "C",
              "value": [
                {
                  "name": "mul_1:0",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        16,
                        72,
                        128
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "Mul",
            "module": "ai.onnx",
            "version": 14,
            "description": "Performs element-wise binary multiplication (with Numpy-style broadcasting support).\n\nThis operator supports **multidirectional (i.e., Numpy-style) broadcasting**; for more details please check [the doc](https://github.com/onnx/onnx/blob/master/docs/Broadcasting.md).\n\n(Opset 14 change): Extend supported types to include uint8, int8, uint16, and int16.\n",
            "inputs": [
              {
                "name": "A",
                "type": "T",
                "description": "First operand."
              },
              {
                "name": "B",
                "type": "T",
                "description": "Second operand."
              }
            ],
            "min_input": 2,
            "max_input": 2,
            "outputs": [
              {
                "name": "C",
                "type": "T",
                "description": "Result, has same element type as two inputs"
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "type_constraints": [
              {
                "description": "Constrain input and output types to all numeric tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(uint8)",
                  "tensor(uint16)",
                  "tensor(uint32)",
                  "tensor(uint64)",
                  "tensor(int8)",
                  "tensor(int16)",
                  "tensor(int32)",
                  "tensor(int64)",
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)",
                  "tensor(bfloat16)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "mul",
                "code": "node = onnx.helper.make_node(\n    \"Mul\",\n    inputs=[\"x\", \"y\"],\n    outputs=[\"z\"],\n)\n\nx = np.array([1, 2, 3]).astype(np.float32)\ny = np.array([4, 5, 6]).astype(np.float32)\nz = x * y  # expected output [4., 10., 18.]\nexpect(node, inputs=[x, y], outputs=[z], name=\"test_mul_example\")\n\nx = np.random.randn(3, 4, 5).astype(np.float32)\ny = np.random.randn(3, 4, 5).astype(np.float32)\nz = x * y\nexpect(node, inputs=[x, y], outputs=[z], name=\"test_mul\")\n\nx = np.random.randint(4, size=(3, 4, 5), dtype=np.int8)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.int8)\nz = x * y\nexpect(node, inputs=[x, y], outputs=[z], name=\"test_mul_int8\")\n\nx = np.random.randint(4, size=(3, 4, 5), dtype=np.int16)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.int16)\nz = x * y\nexpect(node, inputs=[x, y], outputs=[z], name=\"test_mul_int16\")\n\nx = np.random.randint(4, size=(3, 4, 5), dtype=np.uint8)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.uint8)\nz = x * y\nexpect(node, inputs=[x, y], outputs=[z], name=\"test_mul_uint8\")\n\nx = np.random.randint(4, size=(3, 4, 5), dtype=np.uint16)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.uint16)\nz = x * y\nexpect(node, inputs=[x, y], outputs=[z], name=\"test_mul_uint16\")\n\nx = np.random.randint(4, size=(3, 4, 5), dtype=np.uint32)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.uint32)\nz = x * y\nexpect(node, inputs=[x, y], outputs=[z], name=\"test_mul_uint32\")\n\nx = np.random.randint(4, size=(3, 4, 5), dtype=np.uint64)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.uint64)\nz = x * y\nexpect(node, inputs=[x, y], outputs=[z], name=\"test_mul_uint64\")"
              },
              {
                "summary": "mul_broadcast",
                "code": "node = onnx.helper.make_node(\n    \"Mul\",\n    inputs=[\"x\", \"y\"],\n    outputs=[\"z\"],\n)\n\nx = np.random.randn(3, 4, 5).astype(np.float32)\ny = np.random.randn(5).astype(np.float32)\nz = x * y\nexpect(node, inputs=[x, y], outputs=[z], name=\"test_mul_bcast\")"
              }
            ]
          }
        },
        {
          "name": "Conv__161",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "X",
              "value": [
                {
                  "name": "mul_1:0",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        16,
                        72,
                        128
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "W",
              "value": [
                {
                  "name": "Conv2D_2/filter:0",
                  "initializer": {
                    "name": "Conv2D_2/filter:0",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float32",
                      "shape": {
                        "dimensions": [
                          16,
                          16,
                          1,
                          1
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        16,
                        16,
                        1,
                        1
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "B",
              "value": [
                {
                  "name": "conv2d_1_1/y:0",
                  "initializer": {
                    "name": "conv2d_1_1/y:0",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float32",
                      "shape": {
                        "dimensions": [
                          16
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        16
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "Y",
              "value": [
                {
                  "name": "Conv__161:0",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        16,
                        72,
                        128
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [
            {
              "name": "dilations",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "strides",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "kernel_shape",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "pads",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "0",
                  "0",
                  "0",
                  "0"
                ]
              }
            },
            {
              "name": "group",
              "type": "int64",
              "value": {
                "type": "bigint",
                "value": "1"
              }
            }
          ],
          "type": {
            "name": "Conv",
            "module": "ai.onnx",
            "version": 11,
            "description": "The convolution operator consumes an input tensor and a filter, and\ncomputes the output.",
            "attributes": [
              {
                "name": "auto_pad",
                "type": "string",
                "required": false,
                "default": "NOTSET",
                "description": "auto_pad must be either NOTSET, SAME_UPPER, SAME_LOWER or VALID. Where default value is NOTSET, which means explicit padding is used. SAME_UPPER or SAME_LOWER mean pad the input so that `output_shape[i] = ceil(input_shape[i] / strides[i])` for each axis `i`. The padding is split between the two sides equally or almost equally (depending on whether it is even or odd). In case the padding is an odd number, the extra padding is added at the end for SAME_UPPER and at the beginning for SAME_LOWER."
              },
              {
                "name": "dilations",
                "type": "int64[]",
                "required": false,
                "description": "dilation value along each spatial axis of the filter. If not present, the dilation defaults is 1 along each spatial axis."
              },
              {
                "name": "group",
                "type": "int64",
                "required": false,
                "default": 1,
                "description": "number of groups input channels and output channels are divided into."
              },
              {
                "name": "kernel_shape",
                "type": "int64[]",
                "required": false,
                "description": "The shape of the convolution kernel. If not present, should be inferred from input W."
              },
              {
                "name": "pads",
                "type": "int64[]",
                "required": false,
                "description": "Padding for the beginning and ending along each spatial axis, it can take any value greater than or equal to 0. The value represent the number of pixels added to the beginning and end part of the corresponding axis. `pads` format should be as follow [x1_begin, x2_begin...x1_end, x2_end,...], where xi_begin the number of pixels added at the beginning of axis `i` and xi_end, the number of pixels added at the end of axis `i`. This attribute cannot be used simultaneously with auto_pad attribute. If not present, the padding defaults to 0 along start and end of each spatial axis."
              },
              {
                "name": "strides",
                "type": "int64[]",
                "required": false,
                "description": "Stride along each spatial axis. If not present, the stride defaults is 1 along each spatial axis."
              }
            ],
            "inputs": [
              {
                "name": "X",
                "type": "T",
                "description": "Input data tensor from previous layer; has size (N x C x H x W), where N is the batch size, C is the number of channels, and H and W are the height and width. Note that this is for the 2D image. Otherwise the size is (N x C x D1 x D2 ... x Dn). Optionally, if dimension denotation is in effect, the operation expects input data tensor to arrive with the dimension denotation of [DATA_BATCH, DATA_CHANNEL, DATA_FEATURE, DATA_FEATURE ...]."
              },
              {
                "name": "W",
                "type": "T",
                "description": "The weight tensor that will be used in the convolutions; has size (M x C/group x kH x kW), where C is the number of channels, and kH and kW are the height and width of the kernel, and M is the number of feature maps. For more than 2 dimensions, the kernel shape will be (M x C/group x k1 x k2 x ... x kn), where (k1 x k2 x ... kn) is the dimension of the kernel. Optionally, if dimension denotation is in effect, the operation expects the weight tensor to arrive with the dimension denotation of [FILTER_OUT_CHANNEL, FILTER_IN_CHANNEL, FILTER_SPATIAL, FILTER_SPATIAL ...]. Assuming zero based indices for the shape array, X.shape[1] == (W.shape[1] * group) == C and W.shape[0] mod G == 0. Or in other words FILTER_IN_CHANNEL multiplied by the number of groups should be equal to DATA_CHANNEL and the number of feature maps M should be a multiple of the number of groups G."
              },
              {
                "name": "B",
                "type": "T",
                "option": "optional",
                "description": "Optional 1D bias to be added to the convolution, has size of M."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "Y",
                "type": "T",
                "description": "Output data tensor that contains the result of the convolution. The output dimensions are functions of the kernel size, stride size, and pad lengths."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain input and output types to float tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "conv",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[1, 1, 1, 1],\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 21.0, 27.0, 33.0, 24.0],  # (1, 1, 5, 5) output tensor\n                [33.0, 54.0, 63.0, 72.0, 51.0],\n                [63.0, 99.0, 108.0, 117.0, 81.0],\n                [93.0, 144.0, 153.0, 162.0, 111.0],\n                [72.0, 111.0, 117.0, 123.0, 84.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_basic_conv_with_padding\",\n)\n\n# Convolution without padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[0, 0, 0, 0],\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 63.0, 72.0],  # (1, 1, 3, 3) output tensor\n                [99.0, 108.0, 117.0],\n                [144.0, 153.0, 162.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_basic_conv_without_padding\",\n)"
              },
              {
                "summary": "conv_with_autopad_same",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with auto_pad='SAME_LOWER' and strides=2\nnode = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    auto_pad=\"SAME_LOWER\",\n    kernel_shape=[3, 3],\n    strides=[2, 2],\n)\ny = np.array(\n    [[[[12.0, 27.0, 24.0], [63.0, 108.0, 81.0], [72.0, 117.0, 84.0]]]]\n).astype(np.float32)\nexpect(node, inputs=[x, W], outputs=[y], name=\"test_conv_with_autopad_same\")"
              },
              {
                "summary": "conv_with_strides",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 7, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n                [25.0, 26.0, 27.0, 28.0, 29.0],\n                [30.0, 31.0, 32.0, 33.0, 34.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with strides=2 and padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 1, 1, 1],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 27.0, 24.0],  # (1, 1, 4, 3) output tensor\n                [63.0, 108.0, 81.0],\n                [123.0, 198.0, 141.0],\n                [112.0, 177.0, 124.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_conv_with_strides_padding\",\n)\n\n# Convolution with strides=2 and no padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[0, 0, 0, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 72.0],  # (1, 1, 3, 2) output tensor\n                [144.0, 162.0],\n                [234.0, 252.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_conv_with_strides_no_padding\",\n)\n\n# Convolution with strides=2 and padding only along one dimension (the H dimension in NxCxHxW tensor)\nnode_with_asymmetric_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 0, 1, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_asymmetric_padding = np.array(\n    [\n        [\n            [\n                [21.0, 33.0],  # (1, 1, 4, 2) output tensor\n                [99.0, 117.0],\n                [189.0, 207.0],\n                [171.0, 183.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_asymmetric_padding,\n    inputs=[x, W],\n    outputs=[y_with_asymmetric_padding],\n    name=\"test_conv_with_strides_and_asymmetric_padding\",\n)"
              }
            ],
            "category": "Layer"
          }
        },
        {
          "name": "re_lu",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "X",
              "value": [
                {
                  "name": "Conv__161:0",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        16,
                        72,
                        128
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "Y",
              "value": [
                {
                  "name": "re_lu:0",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        16,
                        72,
                        128
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "Relu",
            "module": "ai.onnx",
            "version": 14,
            "description": "Relu takes one input data (Tensor<T>) and produces one output data\n(Tensor<T>) where the rectified linear function, y = max(0, x), is applied to\nthe tensor elementwise.\n",
            "inputs": [
              {
                "name": "X",
                "type": "T",
                "description": "Input tensor"
              }
            ],
            "min_input": 1,
            "max_input": 1,
            "outputs": [
              {
                "name": "Y",
                "type": "T",
                "description": "Output tensor"
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "type_constraints": [
              {
                "description": "Constrain input and output types to signed numeric tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(float)",
                  "tensor(int32)",
                  "tensor(int8)",
                  "tensor(int16)",
                  "tensor(int64)",
                  "tensor(float16)",
                  "tensor(double)",
                  "tensor(bfloat16)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "relu",
                "code": "node = onnx.helper.make_node(\n    \"Relu\",\n    inputs=[\"x\"],\n    outputs=[\"y\"],\n)\nx = np.random.randn(3, 4, 5).astype(np.float32)\ny = np.clip(x, 0, np.inf)\n\nexpect(node, inputs=[x], outputs=[y], name=\"test_relu\")"
              }
            ],
            "category": "Activation"
          }
        },
        {
          "name": "Conv__162",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "X",
              "value": [
                {
                  "name": "re_lu:0",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        16,
                        72,
                        128
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "W",
              "value": [
                {
                  "name": "const_fold_opt__377",
                  "initializer": {
                    "name": "const_fold_opt__377",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float32",
                      "shape": {
                        "dimensions": [
                          16,
                          1,
                          3,
                          3
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        16,
                        1,
                        3,
                        3
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "B",
              "value": [
                {
                  "name": "depthwise_conv2d/y:0",
                  "initializer": {
                    "name": "depthwise_conv2d/y:0",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float32",
                      "shape": {
                        "dimensions": [
                          16
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        16
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "Y",
              "value": [
                {
                  "name": "Conv__162:0",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        16,
                        36,
                        64
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [
            {
              "name": "dilations",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "strides",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "2",
                  "2"
                ]
              }
            },
            {
              "name": "kernel_shape",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "3",
                  "3"
                ]
              }
            },
            {
              "name": "group",
              "type": "int64",
              "value": {
                "type": "bigint",
                "value": "16"
              }
            },
            {
              "name": "pads",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "0",
                  "0",
                  "1",
                  "1"
                ]
              }
            }
          ],
          "type": {
            "name": "Conv",
            "module": "ai.onnx",
            "version": 11,
            "description": "The convolution operator consumes an input tensor and a filter, and\ncomputes the output.",
            "attributes": [
              {
                "name": "auto_pad",
                "type": "string",
                "required": false,
                "default": "NOTSET",
                "description": "auto_pad must be either NOTSET, SAME_UPPER, SAME_LOWER or VALID. Where default value is NOTSET, which means explicit padding is used. SAME_UPPER or SAME_LOWER mean pad the input so that `output_shape[i] = ceil(input_shape[i] / strides[i])` for each axis `i`. The padding is split between the two sides equally or almost equally (depending on whether it is even or odd). In case the padding is an odd number, the extra padding is added at the end for SAME_UPPER and at the beginning for SAME_LOWER."
              },
              {
                "name": "dilations",
                "type": "int64[]",
                "required": false,
                "description": "dilation value along each spatial axis of the filter. If not present, the dilation defaults is 1 along each spatial axis."
              },
              {
                "name": "group",
                "type": "int64",
                "required": false,
                "default": 1,
                "description": "number of groups input channels and output channels are divided into."
              },
              {
                "name": "kernel_shape",
                "type": "int64[]",
                "required": false,
                "description": "The shape of the convolution kernel. If not present, should be inferred from input W."
              },
              {
                "name": "pads",
                "type": "int64[]",
                "required": false,
                "description": "Padding for the beginning and ending along each spatial axis, it can take any value greater than or equal to 0. The value represent the number of pixels added to the beginning and end part of the corresponding axis. `pads` format should be as follow [x1_begin, x2_begin...x1_end, x2_end,...], where xi_begin the number of pixels added at the beginning of axis `i` and xi_end, the number of pixels added at the end of axis `i`. This attribute cannot be used simultaneously with auto_pad attribute. If not present, the padding defaults to 0 along start and end of each spatial axis."
              },
              {
                "name": "strides",
                "type": "int64[]",
                "required": false,
                "description": "Stride along each spatial axis. If not present, the stride defaults is 1 along each spatial axis."
              }
            ],
            "inputs": [
              {
                "name": "X",
                "type": "T",
                "description": "Input data tensor from previous layer; has size (N x C x H x W), where N is the batch size, C is the number of channels, and H and W are the height and width. Note that this is for the 2D image. Otherwise the size is (N x C x D1 x D2 ... x Dn). Optionally, if dimension denotation is in effect, the operation expects input data tensor to arrive with the dimension denotation of [DATA_BATCH, DATA_CHANNEL, DATA_FEATURE, DATA_FEATURE ...]."
              },
              {
                "name": "W",
                "type": "T",
                "description": "The weight tensor that will be used in the convolutions; has size (M x C/group x kH x kW), where C is the number of channels, and kH and kW are the height and width of the kernel, and M is the number of feature maps. For more than 2 dimensions, the kernel shape will be (M x C/group x k1 x k2 x ... x kn), where (k1 x k2 x ... kn) is the dimension of the kernel. Optionally, if dimension denotation is in effect, the operation expects the weight tensor to arrive with the dimension denotation of [FILTER_OUT_CHANNEL, FILTER_IN_CHANNEL, FILTER_SPATIAL, FILTER_SPATIAL ...]. Assuming zero based indices for the shape array, X.shape[1] == (W.shape[1] * group) == C and W.shape[0] mod G == 0. Or in other words FILTER_IN_CHANNEL multiplied by the number of groups should be equal to DATA_CHANNEL and the number of feature maps M should be a multiple of the number of groups G."
              },
              {
                "name": "B",
                "type": "T",
                "option": "optional",
                "description": "Optional 1D bias to be added to the convolution, has size of M."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "Y",
                "type": "T",
                "description": "Output data tensor that contains the result of the convolution. The output dimensions are functions of the kernel size, stride size, and pad lengths."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain input and output types to float tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "conv",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[1, 1, 1, 1],\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 21.0, 27.0, 33.0, 24.0],  # (1, 1, 5, 5) output tensor\n                [33.0, 54.0, 63.0, 72.0, 51.0],\n                [63.0, 99.0, 108.0, 117.0, 81.0],\n                [93.0, 144.0, 153.0, 162.0, 111.0],\n                [72.0, 111.0, 117.0, 123.0, 84.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_basic_conv_with_padding\",\n)\n\n# Convolution without padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[0, 0, 0, 0],\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 63.0, 72.0],  # (1, 1, 3, 3) output tensor\n                [99.0, 108.0, 117.0],\n                [144.0, 153.0, 162.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_basic_conv_without_padding\",\n)"
              },
              {
                "summary": "conv_with_autopad_same",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with auto_pad='SAME_LOWER' and strides=2\nnode = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    auto_pad=\"SAME_LOWER\",\n    kernel_shape=[3, 3],\n    strides=[2, 2],\n)\ny = np.array(\n    [[[[12.0, 27.0, 24.0], [63.0, 108.0, 81.0], [72.0, 117.0, 84.0]]]]\n).astype(np.float32)\nexpect(node, inputs=[x, W], outputs=[y], name=\"test_conv_with_autopad_same\")"
              },
              {
                "summary": "conv_with_strides",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 7, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n                [25.0, 26.0, 27.0, 28.0, 29.0],\n                [30.0, 31.0, 32.0, 33.0, 34.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with strides=2 and padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 1, 1, 1],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 27.0, 24.0],  # (1, 1, 4, 3) output tensor\n                [63.0, 108.0, 81.0],\n                [123.0, 198.0, 141.0],\n                [112.0, 177.0, 124.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_conv_with_strides_padding\",\n)\n\n# Convolution with strides=2 and no padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[0, 0, 0, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 72.0],  # (1, 1, 3, 2) output tensor\n                [144.0, 162.0],\n                [234.0, 252.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_conv_with_strides_no_padding\",\n)\n\n# Convolution with strides=2 and padding only along one dimension (the H dimension in NxCxHxW tensor)\nnode_with_asymmetric_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 0, 1, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_asymmetric_padding = np.array(\n    [\n        [\n            [\n                [21.0, 33.0],  # (1, 1, 4, 2) output tensor\n                [99.0, 117.0],\n                [189.0, 207.0],\n                [171.0, 183.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_asymmetric_padding,\n    inputs=[x, W],\n    outputs=[y_with_asymmetric_padding],\n    name=\"test_conv_with_strides_and_asymmetric_padding\",\n)"
              }
            ],
            "category": "Layer"
          }
        },
        {
          "name": "re_lu_1",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "X",
              "value": [
                {
                  "name": "Conv__162:0",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        16,
                        36,
                        64
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "Y",
              "value": [
                {
                  "name": "re_lu_1:0",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        16,
                        36,
                        64
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "Relu",
            "module": "ai.onnx",
            "version": 14,
            "description": "Relu takes one input data (Tensor<T>) and produces one output data\n(Tensor<T>) where the rectified linear function, y = max(0, x), is applied to\nthe tensor elementwise.\n",
            "inputs": [
              {
                "name": "X",
                "type": "T",
                "description": "Input tensor"
              }
            ],
            "min_input": 1,
            "max_input": 1,
            "outputs": [
              {
                "name": "Y",
                "type": "T",
                "description": "Output tensor"
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "type_constraints": [
              {
                "description": "Constrain input and output types to signed numeric tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(float)",
                  "tensor(int32)",
                  "tensor(int8)",
                  "tensor(int16)",
                  "tensor(int64)",
                  "tensor(float16)",
                  "tensor(double)",
                  "tensor(bfloat16)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "relu",
                "code": "node = onnx.helper.make_node(\n    \"Relu\",\n    inputs=[\"x\"],\n    outputs=[\"y\"],\n)\nx = np.random.randn(3, 4, 5).astype(np.float32)\ny = np.clip(x, 0, np.inf)\n\nexpect(node, inputs=[x], outputs=[y], name=\"test_relu\")"
              }
            ],
            "category": "Activation"
          }
        },
        {
          "name": "global_average_pooling2d",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "X",
              "value": [
                {
                  "name": "re_lu_1:0",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        16,
                        36,
                        64
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "Y",
              "value": [
                {
                  "name": "global_average_pooling2d:0",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        16,
                        1,
                        1
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "GlobalAveragePool",
            "module": "ai.onnx",
            "version": 1,
            "description": "GlobalAveragePool consumes an input tensor X and applies average pooling across\n the values in the same channel. This is equivalent to AveragePool with kernel size\n equal to the spatial dimension of input tensor.",
            "inputs": [
              {
                "name": "X",
                "type": "T",
                "description": "Input data tensor from the previous operator; dimensions for image case are (N x C x H x W), where N is the batch size, C is the number of channels, and H and W are the height and the width of the data. For non image case, the dimensions are in the form of (N x C x D1 x D2 ... Dn), where N is the batch size."
              }
            ],
            "min_input": 1,
            "max_input": 1,
            "outputs": [
              {
                "name": "Y",
                "type": "T",
                "description": "Output data tensor from pooling across the input tensor. The output tensor has the same rank as the input. The first two dimensions of output shape are the same as the input (N x C), while the other dimensions are all 1."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "type_constraints": [
              {
                "description": "Constrain input and output types to float tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "globalaveragepool",
                "code": "node = onnx.helper.make_node(\n    \"GlobalAveragePool\",\n    inputs=[\"x\"],\n    outputs=[\"y\"],\n)\nx = np.random.randn(1, 3, 5, 5).astype(np.float32)\ny = np.mean(x, axis=tuple(range(2, np.ndim(x))), keepdims=True)\nexpect(node, inputs=[x], outputs=[y], name=\"test_globalaveragepool\")"
              },
              {
                "summary": "globalaveragepool_precomputed",
                "code": "node = onnx.helper.make_node(\n    \"GlobalAveragePool\",\n    inputs=[\"x\"],\n    outputs=[\"y\"],\n)\nx = np.array(\n    [\n        [\n            [\n                [1, 2, 3],\n                [4, 5, 6],\n                [7, 8, 9],\n            ]\n        ]\n    ]\n).astype(np.float32)\ny = np.array([[[[5]]]]).astype(np.float32)\nexpect(node, inputs=[x], outputs=[y], name=\"test_globalaveragepool_precomputed\")"
              }
            ],
            "category": "Pool"
          }
        },
        {
          "name": "Conv__165",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "X",
              "value": [
                {
                  "name": "global_average_pooling2d:0",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        16,
                        1,
                        1
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "W",
              "value": [
                {
                  "name": "Conv2D_3/filter:0",
                  "initializer": {
                    "name": "Conv2D_3/filter:0",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float32",
                      "shape": {
                        "dimensions": [
                          8,
                          16,
                          1,
                          1
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        8,
                        16,
                        1,
                        1
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "B",
              "value": [
                {
                  "name": "conv2d_2_1/y:0",
                  "initializer": {
                    "name": "conv2d_2_1/y:0",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float32",
                      "shape": {
                        "dimensions": [
                          8
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        8
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "Y",
              "value": [
                {
                  "name": "Conv__165:0",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        8,
                        1,
                        1
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [
            {
              "name": "dilations",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "strides",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "kernel_shape",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "group",
              "type": "int64",
              "value": {
                "type": "bigint",
                "value": "1"
              }
            }
          ],
          "type": {
            "name": "Conv",
            "module": "ai.onnx",
            "version": 11,
            "description": "The convolution operator consumes an input tensor and a filter, and\ncomputes the output.",
            "attributes": [
              {
                "name": "auto_pad",
                "type": "string",
                "required": false,
                "default": "NOTSET",
                "description": "auto_pad must be either NOTSET, SAME_UPPER, SAME_LOWER or VALID. Where default value is NOTSET, which means explicit padding is used. SAME_UPPER or SAME_LOWER mean pad the input so that `output_shape[i] = ceil(input_shape[i] / strides[i])` for each axis `i`. The padding is split between the two sides equally or almost equally (depending on whether it is even or odd). In case the padding is an odd number, the extra padding is added at the end for SAME_UPPER and at the beginning for SAME_LOWER."
              },
              {
                "name": "dilations",
                "type": "int64[]",
                "required": false,
                "description": "dilation value along each spatial axis of the filter. If not present, the dilation defaults is 1 along each spatial axis."
              },
              {
                "name": "group",
                "type": "int64",
                "required": false,
                "default": 1,
                "description": "number of groups input channels and output channels are divided into."
              },
              {
                "name": "kernel_shape",
                "type": "int64[]",
                "required": false,
                "description": "The shape of the convolution kernel. If not present, should be inferred from input W."
              },
              {
                "name": "pads",
                "type": "int64[]",
                "required": false,
                "description": "Padding for the beginning and ending along each spatial axis, it can take any value greater than or equal to 0. The value represent the number of pixels added to the beginning and end part of the corresponding axis. `pads` format should be as follow [x1_begin, x2_begin...x1_end, x2_end,...], where xi_begin the number of pixels added at the beginning of axis `i` and xi_end, the number of pixels added at the end of axis `i`. This attribute cannot be used simultaneously with auto_pad attribute. If not present, the padding defaults to 0 along start and end of each spatial axis."
              },
              {
                "name": "strides",
                "type": "int64[]",
                "required": false,
                "description": "Stride along each spatial axis. If not present, the stride defaults is 1 along each spatial axis."
              }
            ],
            "inputs": [
              {
                "name": "X",
                "type": "T",
                "description": "Input data tensor from previous layer; has size (N x C x H x W), where N is the batch size, C is the number of channels, and H and W are the height and width. Note that this is for the 2D image. Otherwise the size is (N x C x D1 x D2 ... x Dn). Optionally, if dimension denotation is in effect, the operation expects input data tensor to arrive with the dimension denotation of [DATA_BATCH, DATA_CHANNEL, DATA_FEATURE, DATA_FEATURE ...]."
              },
              {
                "name": "W",
                "type": "T",
                "description": "The weight tensor that will be used in the convolutions; has size (M x C/group x kH x kW), where C is the number of channels, and kH and kW are the height and width of the kernel, and M is the number of feature maps. For more than 2 dimensions, the kernel shape will be (M x C/group x k1 x k2 x ... x kn), where (k1 x k2 x ... kn) is the dimension of the kernel. Optionally, if dimension denotation is in effect, the operation expects the weight tensor to arrive with the dimension denotation of [FILTER_OUT_CHANNEL, FILTER_IN_CHANNEL, FILTER_SPATIAL, FILTER_SPATIAL ...]. Assuming zero based indices for the shape array, X.shape[1] == (W.shape[1] * group) == C and W.shape[0] mod G == 0. Or in other words FILTER_IN_CHANNEL multiplied by the number of groups should be equal to DATA_CHANNEL and the number of feature maps M should be a multiple of the number of groups G."
              },
              {
                "name": "B",
                "type": "T",
                "option": "optional",
                "description": "Optional 1D bias to be added to the convolution, has size of M."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "Y",
                "type": "T",
                "description": "Output data tensor that contains the result of the convolution. The output dimensions are functions of the kernel size, stride size, and pad lengths."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain input and output types to float tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "conv",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[1, 1, 1, 1],\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 21.0, 27.0, 33.0, 24.0],  # (1, 1, 5, 5) output tensor\n                [33.0, 54.0, 63.0, 72.0, 51.0],\n                [63.0, 99.0, 108.0, 117.0, 81.0],\n                [93.0, 144.0, 153.0, 162.0, 111.0],\n                [72.0, 111.0, 117.0, 123.0, 84.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_basic_conv_with_padding\",\n)\n\n# Convolution without padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[0, 0, 0, 0],\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 63.0, 72.0],  # (1, 1, 3, 3) output tensor\n                [99.0, 108.0, 117.0],\n                [144.0, 153.0, 162.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_basic_conv_without_padding\",\n)"
              },
              {
                "summary": "conv_with_autopad_same",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with auto_pad='SAME_LOWER' and strides=2\nnode = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    auto_pad=\"SAME_LOWER\",\n    kernel_shape=[3, 3],\n    strides=[2, 2],\n)\ny = np.array(\n    [[[[12.0, 27.0, 24.0], [63.0, 108.0, 81.0], [72.0, 117.0, 84.0]]]]\n).astype(np.float32)\nexpect(node, inputs=[x, W], outputs=[y], name=\"test_conv_with_autopad_same\")"
              },
              {
                "summary": "conv_with_strides",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 7, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n                [25.0, 26.0, 27.0, 28.0, 29.0],\n                [30.0, 31.0, 32.0, 33.0, 34.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with strides=2 and padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 1, 1, 1],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 27.0, 24.0],  # (1, 1, 4, 3) output tensor\n                [63.0, 108.0, 81.0],\n                [123.0, 198.0, 141.0],\n                [112.0, 177.0, 124.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_conv_with_strides_padding\",\n)\n\n# Convolution with strides=2 and no padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[0, 0, 0, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 72.0],  # (1, 1, 3, 2) output tensor\n                [144.0, 162.0],\n                [234.0, 252.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_conv_with_strides_no_padding\",\n)\n\n# Convolution with strides=2 and padding only along one dimension (the H dimension in NxCxHxW tensor)\nnode_with_asymmetric_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 0, 1, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_asymmetric_padding = np.array(\n    [\n        [\n            [\n                [21.0, 33.0],  # (1, 1, 4, 2) output tensor\n                [99.0, 117.0],\n                [189.0, 207.0],\n                [171.0, 183.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_asymmetric_padding,\n    inputs=[x, W],\n    outputs=[y_with_asymmetric_padding],\n    name=\"test_conv_with_strides_and_asymmetric_padding\",\n)"
              }
            ],
            "category": "Layer"
          }
        },
        {
          "name": "re_lu_2",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "X",
              "value": [
                {
                  "name": "Conv__165:0",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        8,
                        1,
                        1
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "Y",
              "value": [
                {
                  "name": "re_lu_2:0",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        8,
                        1,
                        1
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "Relu",
            "module": "ai.onnx",
            "version": 14,
            "description": "Relu takes one input data (Tensor<T>) and produces one output data\n(Tensor<T>) where the rectified linear function, y = max(0, x), is applied to\nthe tensor elementwise.\n",
            "inputs": [
              {
                "name": "X",
                "type": "T",
                "description": "Input tensor"
              }
            ],
            "min_input": 1,
            "max_input": 1,
            "outputs": [
              {
                "name": "Y",
                "type": "T",
                "description": "Output tensor"
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "type_constraints": [
              {
                "description": "Constrain input and output types to signed numeric tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(float)",
                  "tensor(int32)",
                  "tensor(int8)",
                  "tensor(int16)",
                  "tensor(int64)",
                  "tensor(float16)",
                  "tensor(double)",
                  "tensor(bfloat16)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "relu",
                "code": "node = onnx.helper.make_node(\n    \"Relu\",\n    inputs=[\"x\"],\n    outputs=[\"y\"],\n)\nx = np.random.randn(3, 4, 5).astype(np.float32)\ny = np.clip(x, 0, np.inf)\n\nexpect(node, inputs=[x], outputs=[y], name=\"test_relu\")"
              }
            ],
            "category": "Activation"
          }
        },
        {
          "name": "Conv__166",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "X",
              "value": [
                {
                  "name": "re_lu_2:0",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        8,
                        1,
                        1
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "W",
              "value": [
                {
                  "name": "Conv2D_4/filter:0",
                  "initializer": {
                    "name": "Conv2D_4/filter:0",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float32",
                      "shape": {
                        "dimensions": [
                          16,
                          8,
                          1,
                          1
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        16,
                        8,
                        1,
                        1
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "B",
              "value": [
                {
                  "name": "conv2d_3_1/y:0",
                  "initializer": {
                    "name": "conv2d_3_1/y:0",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float32",
                      "shape": {
                        "dimensions": [
                          16
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        16
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "Y",
              "value": [
                {
                  "name": "Conv__166:0",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        16,
                        1,
                        1
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [
            {
              "name": "dilations",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "strides",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "kernel_shape",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "group",
              "type": "int64",
              "value": {
                "type": "bigint",
                "value": "1"
              }
            }
          ],
          "type": {
            "name": "Conv",
            "module": "ai.onnx",
            "version": 11,
            "description": "The convolution operator consumes an input tensor and a filter, and\ncomputes the output.",
            "attributes": [
              {
                "name": "auto_pad",
                "type": "string",
                "required": false,
                "default": "NOTSET",
                "description": "auto_pad must be either NOTSET, SAME_UPPER, SAME_LOWER or VALID. Where default value is NOTSET, which means explicit padding is used. SAME_UPPER or SAME_LOWER mean pad the input so that `output_shape[i] = ceil(input_shape[i] / strides[i])` for each axis `i`. The padding is split between the two sides equally or almost equally (depending on whether it is even or odd). In case the padding is an odd number, the extra padding is added at the end for SAME_UPPER and at the beginning for SAME_LOWER."
              },
              {
                "name": "dilations",
                "type": "int64[]",
                "required": false,
                "description": "dilation value along each spatial axis of the filter. If not present, the dilation defaults is 1 along each spatial axis."
              },
              {
                "name": "group",
                "type": "int64",
                "required": false,
                "default": 1,
                "description": "number of groups input channels and output channels are divided into."
              },
              {
                "name": "kernel_shape",
                "type": "int64[]",
                "required": false,
                "description": "The shape of the convolution kernel. If not present, should be inferred from input W."
              },
              {
                "name": "pads",
                "type": "int64[]",
                "required": false,
                "description": "Padding for the beginning and ending along each spatial axis, it can take any value greater than or equal to 0. The value represent the number of pixels added to the beginning and end part of the corresponding axis. `pads` format should be as follow [x1_begin, x2_begin...x1_end, x2_end,...], where xi_begin the number of pixels added at the beginning of axis `i` and xi_end, the number of pixels added at the end of axis `i`. This attribute cannot be used simultaneously with auto_pad attribute. If not present, the padding defaults to 0 along start and end of each spatial axis."
              },
              {
                "name": "strides",
                "type": "int64[]",
                "required": false,
                "description": "Stride along each spatial axis. If not present, the stride defaults is 1 along each spatial axis."
              }
            ],
            "inputs": [
              {
                "name": "X",
                "type": "T",
                "description": "Input data tensor from previous layer; has size (N x C x H x W), where N is the batch size, C is the number of channels, and H and W are the height and width. Note that this is for the 2D image. Otherwise the size is (N x C x D1 x D2 ... x Dn). Optionally, if dimension denotation is in effect, the operation expects input data tensor to arrive with the dimension denotation of [DATA_BATCH, DATA_CHANNEL, DATA_FEATURE, DATA_FEATURE ...]."
              },
              {
                "name": "W",
                "type": "T",
                "description": "The weight tensor that will be used in the convolutions; has size (M x C/group x kH x kW), where C is the number of channels, and kH and kW are the height and width of the kernel, and M is the number of feature maps. For more than 2 dimensions, the kernel shape will be (M x C/group x k1 x k2 x ... x kn), where (k1 x k2 x ... kn) is the dimension of the kernel. Optionally, if dimension denotation is in effect, the operation expects the weight tensor to arrive with the dimension denotation of [FILTER_OUT_CHANNEL, FILTER_IN_CHANNEL, FILTER_SPATIAL, FILTER_SPATIAL ...]. Assuming zero based indices for the shape array, X.shape[1] == (W.shape[1] * group) == C and W.shape[0] mod G == 0. Or in other words FILTER_IN_CHANNEL multiplied by the number of groups should be equal to DATA_CHANNEL and the number of feature maps M should be a multiple of the number of groups G."
              },
              {
                "name": "B",
                "type": "T",
                "option": "optional",
                "description": "Optional 1D bias to be added to the convolution, has size of M."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "Y",
                "type": "T",
                "description": "Output data tensor that contains the result of the convolution. The output dimensions are functions of the kernel size, stride size, and pad lengths."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain input and output types to float tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "conv",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[1, 1, 1, 1],\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 21.0, 27.0, 33.0, 24.0],  # (1, 1, 5, 5) output tensor\n                [33.0, 54.0, 63.0, 72.0, 51.0],\n                [63.0, 99.0, 108.0, 117.0, 81.0],\n                [93.0, 144.0, 153.0, 162.0, 111.0],\n                [72.0, 111.0, 117.0, 123.0, 84.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_basic_conv_with_padding\",\n)\n\n# Convolution without padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[0, 0, 0, 0],\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 63.0, 72.0],  # (1, 1, 3, 3) output tensor\n                [99.0, 108.0, 117.0],\n                [144.0, 153.0, 162.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_basic_conv_without_padding\",\n)"
              },
              {
                "summary": "conv_with_autopad_same",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with auto_pad='SAME_LOWER' and strides=2\nnode = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    auto_pad=\"SAME_LOWER\",\n    kernel_shape=[3, 3],\n    strides=[2, 2],\n)\ny = np.array(\n    [[[[12.0, 27.0, 24.0], [63.0, 108.0, 81.0], [72.0, 117.0, 84.0]]]]\n).astype(np.float32)\nexpect(node, inputs=[x, W], outputs=[y], name=\"test_conv_with_autopad_same\")"
              },
              {
                "summary": "conv_with_strides",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 7, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n                [25.0, 26.0, 27.0, 28.0, 29.0],\n                [30.0, 31.0, 32.0, 33.0, 34.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with strides=2 and padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 1, 1, 1],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 27.0, 24.0],  # (1, 1, 4, 3) output tensor\n                [63.0, 108.0, 81.0],\n                [123.0, 198.0, 141.0],\n                [112.0, 177.0, 124.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_conv_with_strides_padding\",\n)\n\n# Convolution with strides=2 and no padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[0, 0, 0, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 72.0],  # (1, 1, 3, 2) output tensor\n                [144.0, 162.0],\n                [234.0, 252.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_conv_with_strides_no_padding\",\n)\n\n# Convolution with strides=2 and padding only along one dimension (the H dimension in NxCxHxW tensor)\nnode_with_asymmetric_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 0, 1, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_asymmetric_padding = np.array(\n    [\n        [\n            [\n                [21.0, 33.0],  # (1, 1, 4, 2) output tensor\n                [99.0, 117.0],\n                [189.0, 207.0],\n                [171.0, 183.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_asymmetric_padding,\n    inputs=[x, W],\n    outputs=[y_with_asymmetric_padding],\n    name=\"test_conv_with_strides_and_asymmetric_padding\",\n)"
              }
            ],
            "category": "Layer"
          }
        },
        {
          "name": "activation",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "X",
              "value": [
                {
                  "name": "Conv__166:0",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        16,
                        1,
                        1
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "Y",
              "value": [
                {
                  "name": "activation:0",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        16,
                        1,
                        1
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "Sigmoid",
            "module": "ai.onnx",
            "version": 13,
            "description": "Sigmoid takes one input data (Tensor<T>) and produces one output data\n(Tensor<T>) where the sigmoid function, y = 1 / (1 + exp(-x)), is applied to the\ntensor elementwise.\n",
            "inputs": [
              {
                "name": "X",
                "type": "T",
                "description": "Input tensor"
              }
            ],
            "min_input": 1,
            "max_input": 1,
            "outputs": [
              {
                "name": "Y",
                "type": "T",
                "description": "Output tensor"
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "type_constraints": [
              {
                "description": "Constrain input and output types to float tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)",
                  "tensor(bfloat16)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "sigmoid",
                "code": "node = onnx.helper.make_node(\n    \"Sigmoid\",\n    inputs=[\"x\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([-1, 0, 1]).astype(np.float32)\ny = 1.0 / (\n    1.0 + np.exp(np.negative(x))\n)  # expected output [0.26894143, 0.5, 0.7310586]\nexpect(node, inputs=[x], outputs=[y], name=\"test_sigmoid_example\")\n\nx = np.random.randn(3, 4, 5).astype(np.float32)\ny = 1.0 / (1.0 + np.exp(np.negative(x)))\nexpect(node, inputs=[x], outputs=[y], name=\"test_sigmoid\")"
              }
            ],
            "category": "Activation"
          }
        },
        {
          "name": "multiply",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "A",
              "value": [
                {
                  "name": "re_lu_1:0",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        16,
                        36,
                        64
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "B",
              "value": [
                {
                  "name": "activation:0",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        16,
                        1,
                        1
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "C",
              "value": [
                {
                  "name": "multiply:0",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        16,
                        36,
                        64
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "Mul",
            "module": "ai.onnx",
            "version": 14,
            "description": "Performs element-wise binary multiplication (with Numpy-style broadcasting support).\n\nThis operator supports **multidirectional (i.e., Numpy-style) broadcasting**; for more details please check [the doc](https://github.com/onnx/onnx/blob/master/docs/Broadcasting.md).\n\n(Opset 14 change): Extend supported types to include uint8, int8, uint16, and int16.\n",
            "inputs": [
              {
                "name": "A",
                "type": "T",
                "description": "First operand."
              },
              {
                "name": "B",
                "type": "T",
                "description": "Second operand."
              }
            ],
            "min_input": 2,
            "max_input": 2,
            "outputs": [
              {
                "name": "C",
                "type": "T",
                "description": "Result, has same element type as two inputs"
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "type_constraints": [
              {
                "description": "Constrain input and output types to all numeric tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(uint8)",
                  "tensor(uint16)",
                  "tensor(uint32)",
                  "tensor(uint64)",
                  "tensor(int8)",
                  "tensor(int16)",
                  "tensor(int32)",
                  "tensor(int64)",
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)",
                  "tensor(bfloat16)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "mul",
                "code": "node = onnx.helper.make_node(\n    \"Mul\",\n    inputs=[\"x\", \"y\"],\n    outputs=[\"z\"],\n)\n\nx = np.array([1, 2, 3]).astype(np.float32)\ny = np.array([4, 5, 6]).astype(np.float32)\nz = x * y  # expected output [4., 10., 18.]\nexpect(node, inputs=[x, y], outputs=[z], name=\"test_mul_example\")\n\nx = np.random.randn(3, 4, 5).astype(np.float32)\ny = np.random.randn(3, 4, 5).astype(np.float32)\nz = x * y\nexpect(node, inputs=[x, y], outputs=[z], name=\"test_mul\")\n\nx = np.random.randint(4, size=(3, 4, 5), dtype=np.int8)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.int8)\nz = x * y\nexpect(node, inputs=[x, y], outputs=[z], name=\"test_mul_int8\")\n\nx = np.random.randint(4, size=(3, 4, 5), dtype=np.int16)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.int16)\nz = x * y\nexpect(node, inputs=[x, y], outputs=[z], name=\"test_mul_int16\")\n\nx = np.random.randint(4, size=(3, 4, 5), dtype=np.uint8)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.uint8)\nz = x * y\nexpect(node, inputs=[x, y], outputs=[z], name=\"test_mul_uint8\")\n\nx = np.random.randint(4, size=(3, 4, 5), dtype=np.uint16)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.uint16)\nz = x * y\nexpect(node, inputs=[x, y], outputs=[z], name=\"test_mul_uint16\")\n\nx = np.random.randint(4, size=(3, 4, 5), dtype=np.uint32)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.uint32)\nz = x * y\nexpect(node, inputs=[x, y], outputs=[z], name=\"test_mul_uint32\")\n\nx = np.random.randint(4, size=(3, 4, 5), dtype=np.uint64)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.uint64)\nz = x * y\nexpect(node, inputs=[x, y], outputs=[z], name=\"test_mul_uint64\")"
              },
              {
                "summary": "mul_broadcast",
                "code": "node = onnx.helper.make_node(\n    \"Mul\",\n    inputs=[\"x\", \"y\"],\n    outputs=[\"z\"],\n)\n\nx = np.random.randn(3, 4, 5).astype(np.float32)\ny = np.random.randn(5).astype(np.float32)\nz = x * y\nexpect(node, inputs=[x, y], outputs=[z], name=\"test_mul_bcast\")"
              }
            ]
          }
        },
        {
          "name": "Conv__167",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "X",
              "value": [
                {
                  "name": "multiply:0",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        16,
                        36,
                        64
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "W",
              "value": [
                {
                  "name": "Conv2D_5/filter:0",
                  "initializer": {
                    "name": "Conv2D_5/filter:0",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float32",
                      "shape": {
                        "dimensions": [
                          16,
                          16,
                          1,
                          1
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        16,
                        16,
                        1,
                        1
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "B",
              "value": [
                {
                  "name": "conv2d_4_1/y:0",
                  "initializer": {
                    "name": "conv2d_4_1/y:0",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float32",
                      "shape": {
                        "dimensions": [
                          16
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        16
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "Y",
              "value": [
                {
                  "name": "Conv__167:0",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        16,
                        36,
                        64
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [
            {
              "name": "dilations",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "strides",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "kernel_shape",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "pads",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "0",
                  "0",
                  "0",
                  "0"
                ]
              }
            },
            {
              "name": "group",
              "type": "int64",
              "value": {
                "type": "bigint",
                "value": "1"
              }
            }
          ],
          "type": {
            "name": "Conv",
            "module": "ai.onnx",
            "version": 11,
            "description": "The convolution operator consumes an input tensor and a filter, and\ncomputes the output.",
            "attributes": [
              {
                "name": "auto_pad",
                "type": "string",
                "required": false,
                "default": "NOTSET",
                "description": "auto_pad must be either NOTSET, SAME_UPPER, SAME_LOWER or VALID. Where default value is NOTSET, which means explicit padding is used. SAME_UPPER or SAME_LOWER mean pad the input so that `output_shape[i] = ceil(input_shape[i] / strides[i])` for each axis `i`. The padding is split between the two sides equally or almost equally (depending on whether it is even or odd). In case the padding is an odd number, the extra padding is added at the end for SAME_UPPER and at the beginning for SAME_LOWER."
              },
              {
                "name": "dilations",
                "type": "int64[]",
                "required": false,
                "description": "dilation value along each spatial axis of the filter. If not present, the dilation defaults is 1 along each spatial axis."
              },
              {
                "name": "group",
                "type": "int64",
                "required": false,
                "default": 1,
                "description": "number of groups input channels and output channels are divided into."
              },
              {
                "name": "kernel_shape",
                "type": "int64[]",
                "required": false,
                "description": "The shape of the convolution kernel. If not present, should be inferred from input W."
              },
              {
                "name": "pads",
                "type": "int64[]",
                "required": false,
                "description": "Padding for the beginning and ending along each spatial axis, it can take any value greater than or equal to 0. The value represent the number of pixels added to the beginning and end part of the corresponding axis. `pads` format should be as follow [x1_begin, x2_begin...x1_end, x2_end,...], where xi_begin the number of pixels added at the beginning of axis `i` and xi_end, the number of pixels added at the end of axis `i`. This attribute cannot be used simultaneously with auto_pad attribute. If not present, the padding defaults to 0 along start and end of each spatial axis."
              },
              {
                "name": "strides",
                "type": "int64[]",
                "required": false,
                "description": "Stride along each spatial axis. If not present, the stride defaults is 1 along each spatial axis."
              }
            ],
            "inputs": [
              {
                "name": "X",
                "type": "T",
                "description": "Input data tensor from previous layer; has size (N x C x H x W), where N is the batch size, C is the number of channels, and H and W are the height and width. Note that this is for the 2D image. Otherwise the size is (N x C x D1 x D2 ... x Dn). Optionally, if dimension denotation is in effect, the operation expects input data tensor to arrive with the dimension denotation of [DATA_BATCH, DATA_CHANNEL, DATA_FEATURE, DATA_FEATURE ...]."
              },
              {
                "name": "W",
                "type": "T",
                "description": "The weight tensor that will be used in the convolutions; has size (M x C/group x kH x kW), where C is the number of channels, and kH and kW are the height and width of the kernel, and M is the number of feature maps. For more than 2 dimensions, the kernel shape will be (M x C/group x k1 x k2 x ... x kn), where (k1 x k2 x ... kn) is the dimension of the kernel. Optionally, if dimension denotation is in effect, the operation expects the weight tensor to arrive with the dimension denotation of [FILTER_OUT_CHANNEL, FILTER_IN_CHANNEL, FILTER_SPATIAL, FILTER_SPATIAL ...]. Assuming zero based indices for the shape array, X.shape[1] == (W.shape[1] * group) == C and W.shape[0] mod G == 0. Or in other words FILTER_IN_CHANNEL multiplied by the number of groups should be equal to DATA_CHANNEL and the number of feature maps M should be a multiple of the number of groups G."
              },
              {
                "name": "B",
                "type": "T",
                "option": "optional",
                "description": "Optional 1D bias to be added to the convolution, has size of M."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "Y",
                "type": "T",
                "description": "Output data tensor that contains the result of the convolution. The output dimensions are functions of the kernel size, stride size, and pad lengths."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain input and output types to float tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "conv",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[1, 1, 1, 1],\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 21.0, 27.0, 33.0, 24.0],  # (1, 1, 5, 5) output tensor\n                [33.0, 54.0, 63.0, 72.0, 51.0],\n                [63.0, 99.0, 108.0, 117.0, 81.0],\n                [93.0, 144.0, 153.0, 162.0, 111.0],\n                [72.0, 111.0, 117.0, 123.0, 84.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_basic_conv_with_padding\",\n)\n\n# Convolution without padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[0, 0, 0, 0],\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 63.0, 72.0],  # (1, 1, 3, 3) output tensor\n                [99.0, 108.0, 117.0],\n                [144.0, 153.0, 162.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_basic_conv_without_padding\",\n)"
              },
              {
                "summary": "conv_with_autopad_same",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with auto_pad='SAME_LOWER' and strides=2\nnode = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    auto_pad=\"SAME_LOWER\",\n    kernel_shape=[3, 3],\n    strides=[2, 2],\n)\ny = np.array(\n    [[[[12.0, 27.0, 24.0], [63.0, 108.0, 81.0], [72.0, 117.0, 84.0]]]]\n).astype(np.float32)\nexpect(node, inputs=[x, W], outputs=[y], name=\"test_conv_with_autopad_same\")"
              },
              {
                "summary": "conv_with_strides",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 7, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n                [25.0, 26.0, 27.0, 28.0, 29.0],\n                [30.0, 31.0, 32.0, 33.0, 34.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with strides=2 and padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 1, 1, 1],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 27.0, 24.0],  # (1, 1, 4, 3) output tensor\n                [63.0, 108.0, 81.0],\n                [123.0, 198.0, 141.0],\n                [112.0, 177.0, 124.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_conv_with_strides_padding\",\n)\n\n# Convolution with strides=2 and no padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[0, 0, 0, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 72.0],  # (1, 1, 3, 2) output tensor\n                [144.0, 162.0],\n                [234.0, 252.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_conv_with_strides_no_padding\",\n)\n\n# Convolution with strides=2 and padding only along one dimension (the H dimension in NxCxHxW tensor)\nnode_with_asymmetric_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 0, 1, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_asymmetric_padding = np.array(\n    [\n        [\n            [\n                [21.0, 33.0],  # (1, 1, 4, 2) output tensor\n                [99.0, 117.0],\n                [189.0, 207.0],\n                [171.0, 183.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_asymmetric_padding,\n    inputs=[x, W],\n    outputs=[y_with_asymmetric_padding],\n    name=\"test_conv_with_strides_and_asymmetric_padding\",\n)"
              }
            ],
            "category": "Layer"
          }
        },
        {
          "name": "Conv__171",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "X",
              "value": [
                {
                  "name": "Conv__167:0",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        16,
                        36,
                        64
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "W",
              "value": [
                {
                  "name": "Conv2D_6/filter:0",
                  "initializer": {
                    "name": "Conv2D_6/filter:0",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float32",
                      "shape": {
                        "dimensions": [
                          72,
                          16,
                          1,
                          1
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        72,
                        16,
                        1,
                        1
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "B",
              "value": [
                {
                  "name": "conv2d_5_1/y:0",
                  "initializer": {
                    "name": "conv2d_5_1/y:0",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float32",
                      "shape": {
                        "dimensions": [
                          72
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        72
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "Y",
              "value": [
                {
                  "name": "Conv__171:0",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        72,
                        36,
                        64
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [
            {
              "name": "dilations",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "strides",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "kernel_shape",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "pads",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "0",
                  "0",
                  "0",
                  "0"
                ]
              }
            },
            {
              "name": "group",
              "type": "int64",
              "value": {
                "type": "bigint",
                "value": "1"
              }
            }
          ],
          "type": {
            "name": "Conv",
            "module": "ai.onnx",
            "version": 11,
            "description": "The convolution operator consumes an input tensor and a filter, and\ncomputes the output.",
            "attributes": [
              {
                "name": "auto_pad",
                "type": "string",
                "required": false,
                "default": "NOTSET",
                "description": "auto_pad must be either NOTSET, SAME_UPPER, SAME_LOWER or VALID. Where default value is NOTSET, which means explicit padding is used. SAME_UPPER or SAME_LOWER mean pad the input so that `output_shape[i] = ceil(input_shape[i] / strides[i])` for each axis `i`. The padding is split between the two sides equally or almost equally (depending on whether it is even or odd). In case the padding is an odd number, the extra padding is added at the end for SAME_UPPER and at the beginning for SAME_LOWER."
              },
              {
                "name": "dilations",
                "type": "int64[]",
                "required": false,
                "description": "dilation value along each spatial axis of the filter. If not present, the dilation defaults is 1 along each spatial axis."
              },
              {
                "name": "group",
                "type": "int64",
                "required": false,
                "default": 1,
                "description": "number of groups input channels and output channels are divided into."
              },
              {
                "name": "kernel_shape",
                "type": "int64[]",
                "required": false,
                "description": "The shape of the convolution kernel. If not present, should be inferred from input W."
              },
              {
                "name": "pads",
                "type": "int64[]",
                "required": false,
                "description": "Padding for the beginning and ending along each spatial axis, it can take any value greater than or equal to 0. The value represent the number of pixels added to the beginning and end part of the corresponding axis. `pads` format should be as follow [x1_begin, x2_begin...x1_end, x2_end,...], where xi_begin the number of pixels added at the beginning of axis `i` and xi_end, the number of pixels added at the end of axis `i`. This attribute cannot be used simultaneously with auto_pad attribute. If not present, the padding defaults to 0 along start and end of each spatial axis."
              },
              {
                "name": "strides",
                "type": "int64[]",
                "required": false,
                "description": "Stride along each spatial axis. If not present, the stride defaults is 1 along each spatial axis."
              }
            ],
            "inputs": [
              {
                "name": "X",
                "type": "T",
                "description": "Input data tensor from previous layer; has size (N x C x H x W), where N is the batch size, C is the number of channels, and H and W are the height and width. Note that this is for the 2D image. Otherwise the size is (N x C x D1 x D2 ... x Dn). Optionally, if dimension denotation is in effect, the operation expects input data tensor to arrive with the dimension denotation of [DATA_BATCH, DATA_CHANNEL, DATA_FEATURE, DATA_FEATURE ...]."
              },
              {
                "name": "W",
                "type": "T",
                "description": "The weight tensor that will be used in the convolutions; has size (M x C/group x kH x kW), where C is the number of channels, and kH and kW are the height and width of the kernel, and M is the number of feature maps. For more than 2 dimensions, the kernel shape will be (M x C/group x k1 x k2 x ... x kn), where (k1 x k2 x ... kn) is the dimension of the kernel. Optionally, if dimension denotation is in effect, the operation expects the weight tensor to arrive with the dimension denotation of [FILTER_OUT_CHANNEL, FILTER_IN_CHANNEL, FILTER_SPATIAL, FILTER_SPATIAL ...]. Assuming zero based indices for the shape array, X.shape[1] == (W.shape[1] * group) == C and W.shape[0] mod G == 0. Or in other words FILTER_IN_CHANNEL multiplied by the number of groups should be equal to DATA_CHANNEL and the number of feature maps M should be a multiple of the number of groups G."
              },
              {
                "name": "B",
                "type": "T",
                "option": "optional",
                "description": "Optional 1D bias to be added to the convolution, has size of M."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "Y",
                "type": "T",
                "description": "Output data tensor that contains the result of the convolution. The output dimensions are functions of the kernel size, stride size, and pad lengths."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain input and output types to float tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "conv",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[1, 1, 1, 1],\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 21.0, 27.0, 33.0, 24.0],  # (1, 1, 5, 5) output tensor\n                [33.0, 54.0, 63.0, 72.0, 51.0],\n                [63.0, 99.0, 108.0, 117.0, 81.0],\n                [93.0, 144.0, 153.0, 162.0, 111.0],\n                [72.0, 111.0, 117.0, 123.0, 84.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_basic_conv_with_padding\",\n)\n\n# Convolution without padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[0, 0, 0, 0],\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 63.0, 72.0],  # (1, 1, 3, 3) output tensor\n                [99.0, 108.0, 117.0],\n                [144.0, 153.0, 162.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_basic_conv_without_padding\",\n)"
              },
              {
                "summary": "conv_with_autopad_same",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with auto_pad='SAME_LOWER' and strides=2\nnode = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    auto_pad=\"SAME_LOWER\",\n    kernel_shape=[3, 3],\n    strides=[2, 2],\n)\ny = np.array(\n    [[[[12.0, 27.0, 24.0], [63.0, 108.0, 81.0], [72.0, 117.0, 84.0]]]]\n).astype(np.float32)\nexpect(node, inputs=[x, W], outputs=[y], name=\"test_conv_with_autopad_same\")"
              },
              {
                "summary": "conv_with_strides",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 7, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n                [25.0, 26.0, 27.0, 28.0, 29.0],\n                [30.0, 31.0, 32.0, 33.0, 34.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with strides=2 and padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 1, 1, 1],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 27.0, 24.0],  # (1, 1, 4, 3) output tensor\n                [63.0, 108.0, 81.0],\n                [123.0, 198.0, 141.0],\n                [112.0, 177.0, 124.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_conv_with_strides_padding\",\n)\n\n# Convolution with strides=2 and no padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[0, 0, 0, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 72.0],  # (1, 1, 3, 2) output tensor\n                [144.0, 162.0],\n                [234.0, 252.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_conv_with_strides_no_padding\",\n)\n\n# Convolution with strides=2 and padding only along one dimension (the H dimension in NxCxHxW tensor)\nnode_with_asymmetric_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 0, 1, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_asymmetric_padding = np.array(\n    [\n        [\n            [\n                [21.0, 33.0],  # (1, 1, 4, 2) output tensor\n                [99.0, 117.0],\n                [189.0, 207.0],\n                [171.0, 183.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_asymmetric_padding,\n    inputs=[x, W],\n    outputs=[y_with_asymmetric_padding],\n    name=\"test_conv_with_strides_and_asymmetric_padding\",\n)"
              }
            ],
            "category": "Layer"
          }
        },
        {
          "name": "re_lu_3",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "X",
              "value": [
                {
                  "name": "Conv__171:0",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        72,
                        36,
                        64
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "Y",
              "value": [
                {
                  "name": "re_lu_3:0",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        72,
                        36,
                        64
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "Relu",
            "module": "ai.onnx",
            "version": 14,
            "description": "Relu takes one input data (Tensor<T>) and produces one output data\n(Tensor<T>) where the rectified linear function, y = max(0, x), is applied to\nthe tensor elementwise.\n",
            "inputs": [
              {
                "name": "X",
                "type": "T",
                "description": "Input tensor"
              }
            ],
            "min_input": 1,
            "max_input": 1,
            "outputs": [
              {
                "name": "Y",
                "type": "T",
                "description": "Output tensor"
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "type_constraints": [
              {
                "description": "Constrain input and output types to signed numeric tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(float)",
                  "tensor(int32)",
                  "tensor(int8)",
                  "tensor(int16)",
                  "tensor(int64)",
                  "tensor(float16)",
                  "tensor(double)",
                  "tensor(bfloat16)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "relu",
                "code": "node = onnx.helper.make_node(\n    \"Relu\",\n    inputs=[\"x\"],\n    outputs=[\"y\"],\n)\nx = np.random.randn(3, 4, 5).astype(np.float32)\ny = np.clip(x, 0, np.inf)\n\nexpect(node, inputs=[x], outputs=[y], name=\"test_relu\")"
              }
            ],
            "category": "Activation"
          }
        },
        {
          "name": "Conv__172",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "X",
              "value": [
                {
                  "name": "re_lu_3:0",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        72,
                        36,
                        64
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "W",
              "value": [
                {
                  "name": "const_fold_opt__387",
                  "initializer": {
                    "name": "const_fold_opt__387",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float32",
                      "shape": {
                        "dimensions": [
                          72,
                          1,
                          3,
                          3
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        72,
                        1,
                        3,
                        3
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "B",
              "value": [
                {
                  "name": "depthwise_conv2d_1/y:0",
                  "initializer": {
                    "name": "depthwise_conv2d_1/y:0",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float32",
                      "shape": {
                        "dimensions": [
                          72
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        72
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "Y",
              "value": [
                {
                  "name": "Conv__172:0",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        72,
                        18,
                        32
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [
            {
              "name": "dilations",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "strides",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "2",
                  "2"
                ]
              }
            },
            {
              "name": "kernel_shape",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "3",
                  "3"
                ]
              }
            },
            {
              "name": "group",
              "type": "int64",
              "value": {
                "type": "bigint",
                "value": "72"
              }
            },
            {
              "name": "pads",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "0",
                  "0",
                  "1",
                  "1"
                ]
              }
            }
          ],
          "type": {
            "name": "Conv",
            "module": "ai.onnx",
            "version": 11,
            "description": "The convolution operator consumes an input tensor and a filter, and\ncomputes the output.",
            "attributes": [
              {
                "name": "auto_pad",
                "type": "string",
                "required": false,
                "default": "NOTSET",
                "description": "auto_pad must be either NOTSET, SAME_UPPER, SAME_LOWER or VALID. Where default value is NOTSET, which means explicit padding is used. SAME_UPPER or SAME_LOWER mean pad the input so that `output_shape[i] = ceil(input_shape[i] / strides[i])` for each axis `i`. The padding is split between the two sides equally or almost equally (depending on whether it is even or odd). In case the padding is an odd number, the extra padding is added at the end for SAME_UPPER and at the beginning for SAME_LOWER."
              },
              {
                "name": "dilations",
                "type": "int64[]",
                "required": false,
                "description": "dilation value along each spatial axis of the filter. If not present, the dilation defaults is 1 along each spatial axis."
              },
              {
                "name": "group",
                "type": "int64",
                "required": false,
                "default": 1,
                "description": "number of groups input channels and output channels are divided into."
              },
              {
                "name": "kernel_shape",
                "type": "int64[]",
                "required": false,
                "description": "The shape of the convolution kernel. If not present, should be inferred from input W."
              },
              {
                "name": "pads",
                "type": "int64[]",
                "required": false,
                "description": "Padding for the beginning and ending along each spatial axis, it can take any value greater than or equal to 0. The value represent the number of pixels added to the beginning and end part of the corresponding axis. `pads` format should be as follow [x1_begin, x2_begin...x1_end, x2_end,...], where xi_begin the number of pixels added at the beginning of axis `i` and xi_end, the number of pixels added at the end of axis `i`. This attribute cannot be used simultaneously with auto_pad attribute. If not present, the padding defaults to 0 along start and end of each spatial axis."
              },
              {
                "name": "strides",
                "type": "int64[]",
                "required": false,
                "description": "Stride along each spatial axis. If not present, the stride defaults is 1 along each spatial axis."
              }
            ],
            "inputs": [
              {
                "name": "X",
                "type": "T",
                "description": "Input data tensor from previous layer; has size (N x C x H x W), where N is the batch size, C is the number of channels, and H and W are the height and width. Note that this is for the 2D image. Otherwise the size is (N x C x D1 x D2 ... x Dn). Optionally, if dimension denotation is in effect, the operation expects input data tensor to arrive with the dimension denotation of [DATA_BATCH, DATA_CHANNEL, DATA_FEATURE, DATA_FEATURE ...]."
              },
              {
                "name": "W",
                "type": "T",
                "description": "The weight tensor that will be used in the convolutions; has size (M x C/group x kH x kW), where C is the number of channels, and kH and kW are the height and width of the kernel, and M is the number of feature maps. For more than 2 dimensions, the kernel shape will be (M x C/group x k1 x k2 x ... x kn), where (k1 x k2 x ... kn) is the dimension of the kernel. Optionally, if dimension denotation is in effect, the operation expects the weight tensor to arrive with the dimension denotation of [FILTER_OUT_CHANNEL, FILTER_IN_CHANNEL, FILTER_SPATIAL, FILTER_SPATIAL ...]. Assuming zero based indices for the shape array, X.shape[1] == (W.shape[1] * group) == C and W.shape[0] mod G == 0. Or in other words FILTER_IN_CHANNEL multiplied by the number of groups should be equal to DATA_CHANNEL and the number of feature maps M should be a multiple of the number of groups G."
              },
              {
                "name": "B",
                "type": "T",
                "option": "optional",
                "description": "Optional 1D bias to be added to the convolution, has size of M."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "Y",
                "type": "T",
                "description": "Output data tensor that contains the result of the convolution. The output dimensions are functions of the kernel size, stride size, and pad lengths."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain input and output types to float tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "conv",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[1, 1, 1, 1],\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 21.0, 27.0, 33.0, 24.0],  # (1, 1, 5, 5) output tensor\n                [33.0, 54.0, 63.0, 72.0, 51.0],\n                [63.0, 99.0, 108.0, 117.0, 81.0],\n                [93.0, 144.0, 153.0, 162.0, 111.0],\n                [72.0, 111.0, 117.0, 123.0, 84.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_basic_conv_with_padding\",\n)\n\n# Convolution without padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[0, 0, 0, 0],\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 63.0, 72.0],  # (1, 1, 3, 3) output tensor\n                [99.0, 108.0, 117.0],\n                [144.0, 153.0, 162.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_basic_conv_without_padding\",\n)"
              },
              {
                "summary": "conv_with_autopad_same",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with auto_pad='SAME_LOWER' and strides=2\nnode = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    auto_pad=\"SAME_LOWER\",\n    kernel_shape=[3, 3],\n    strides=[2, 2],\n)\ny = np.array(\n    [[[[12.0, 27.0, 24.0], [63.0, 108.0, 81.0], [72.0, 117.0, 84.0]]]]\n).astype(np.float32)\nexpect(node, inputs=[x, W], outputs=[y], name=\"test_conv_with_autopad_same\")"
              },
              {
                "summary": "conv_with_strides",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 7, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n                [25.0, 26.0, 27.0, 28.0, 29.0],\n                [30.0, 31.0, 32.0, 33.0, 34.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with strides=2 and padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 1, 1, 1],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 27.0, 24.0],  # (1, 1, 4, 3) output tensor\n                [63.0, 108.0, 81.0],\n                [123.0, 198.0, 141.0],\n                [112.0, 177.0, 124.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_conv_with_strides_padding\",\n)\n\n# Convolution with strides=2 and no padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[0, 0, 0, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 72.0],  # (1, 1, 3, 2) output tensor\n                [144.0, 162.0],\n                [234.0, 252.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_conv_with_strides_no_padding\",\n)\n\n# Convolution with strides=2 and padding only along one dimension (the H dimension in NxCxHxW tensor)\nnode_with_asymmetric_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 0, 1, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_asymmetric_padding = np.array(\n    [\n        [\n            [\n                [21.0, 33.0],  # (1, 1, 4, 2) output tensor\n                [99.0, 117.0],\n                [189.0, 207.0],\n                [171.0, 183.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_asymmetric_padding,\n    inputs=[x, W],\n    outputs=[y_with_asymmetric_padding],\n    name=\"test_conv_with_strides_and_asymmetric_padding\",\n)"
              }
            ],
            "category": "Layer"
          }
        },
        {
          "name": "re_lu_4",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "X",
              "value": [
                {
                  "name": "Conv__172:0",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        72,
                        18,
                        32
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "Y",
              "value": [
                {
                  "name": "re_lu_4:0",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        72,
                        18,
                        32
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "Relu",
            "module": "ai.onnx",
            "version": 14,
            "description": "Relu takes one input data (Tensor<T>) and produces one output data\n(Tensor<T>) where the rectified linear function, y = max(0, x), is applied to\nthe tensor elementwise.\n",
            "inputs": [
              {
                "name": "X",
                "type": "T",
                "description": "Input tensor"
              }
            ],
            "min_input": 1,
            "max_input": 1,
            "outputs": [
              {
                "name": "Y",
                "type": "T",
                "description": "Output tensor"
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "type_constraints": [
              {
                "description": "Constrain input and output types to signed numeric tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(float)",
                  "tensor(int32)",
                  "tensor(int8)",
                  "tensor(int16)",
                  "tensor(int64)",
                  "tensor(float16)",
                  "tensor(double)",
                  "tensor(bfloat16)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "relu",
                "code": "node = onnx.helper.make_node(\n    \"Relu\",\n    inputs=[\"x\"],\n    outputs=[\"y\"],\n)\nx = np.random.randn(3, 4, 5).astype(np.float32)\ny = np.clip(x, 0, np.inf)\n\nexpect(node, inputs=[x], outputs=[y], name=\"test_relu\")"
              }
            ],
            "category": "Activation"
          }
        },
        {
          "name": "Conv__173",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "X",
              "value": [
                {
                  "name": "re_lu_4:0",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        72,
                        18,
                        32
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "W",
              "value": [
                {
                  "name": "Conv2D_7/filter:0",
                  "initializer": {
                    "name": "Conv2D_7/filter:0",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float32",
                      "shape": {
                        "dimensions": [
                          24,
                          72,
                          1,
                          1
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        24,
                        72,
                        1,
                        1
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "B",
              "value": [
                {
                  "name": "conv2d_6_1/y:0",
                  "initializer": {
                    "name": "conv2d_6_1/y:0",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float32",
                      "shape": {
                        "dimensions": [
                          24
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        24
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "Y",
              "value": [
                {
                  "name": "Conv__173:0",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        24,
                        18,
                        32
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [
            {
              "name": "dilations",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "strides",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "kernel_shape",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "pads",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "0",
                  "0",
                  "0",
                  "0"
                ]
              }
            },
            {
              "name": "group",
              "type": "int64",
              "value": {
                "type": "bigint",
                "value": "1"
              }
            }
          ],
          "type": {
            "name": "Conv",
            "module": "ai.onnx",
            "version": 11,
            "description": "The convolution operator consumes an input tensor and a filter, and\ncomputes the output.",
            "attributes": [
              {
                "name": "auto_pad",
                "type": "string",
                "required": false,
                "default": "NOTSET",
                "description": "auto_pad must be either NOTSET, SAME_UPPER, SAME_LOWER or VALID. Where default value is NOTSET, which means explicit padding is used. SAME_UPPER or SAME_LOWER mean pad the input so that `output_shape[i] = ceil(input_shape[i] / strides[i])` for each axis `i`. The padding is split between the two sides equally or almost equally (depending on whether it is even or odd). In case the padding is an odd number, the extra padding is added at the end for SAME_UPPER and at the beginning for SAME_LOWER."
              },
              {
                "name": "dilations",
                "type": "int64[]",
                "required": false,
                "description": "dilation value along each spatial axis of the filter. If not present, the dilation defaults is 1 along each spatial axis."
              },
              {
                "name": "group",
                "type": "int64",
                "required": false,
                "default": 1,
                "description": "number of groups input channels and output channels are divided into."
              },
              {
                "name": "kernel_shape",
                "type": "int64[]",
                "required": false,
                "description": "The shape of the convolution kernel. If not present, should be inferred from input W."
              },
              {
                "name": "pads",
                "type": "int64[]",
                "required": false,
                "description": "Padding for the beginning and ending along each spatial axis, it can take any value greater than or equal to 0. The value represent the number of pixels added to the beginning and end part of the corresponding axis. `pads` format should be as follow [x1_begin, x2_begin...x1_end, x2_end,...], where xi_begin the number of pixels added at the beginning of axis `i` and xi_end, the number of pixels added at the end of axis `i`. This attribute cannot be used simultaneously with auto_pad attribute. If not present, the padding defaults to 0 along start and end of each spatial axis."
              },
              {
                "name": "strides",
                "type": "int64[]",
                "required": false,
                "description": "Stride along each spatial axis. If not present, the stride defaults is 1 along each spatial axis."
              }
            ],
            "inputs": [
              {
                "name": "X",
                "type": "T",
                "description": "Input data tensor from previous layer; has size (N x C x H x W), where N is the batch size, C is the number of channels, and H and W are the height and width. Note that this is for the 2D image. Otherwise the size is (N x C x D1 x D2 ... x Dn). Optionally, if dimension denotation is in effect, the operation expects input data tensor to arrive with the dimension denotation of [DATA_BATCH, DATA_CHANNEL, DATA_FEATURE, DATA_FEATURE ...]."
              },
              {
                "name": "W",
                "type": "T",
                "description": "The weight tensor that will be used in the convolutions; has size (M x C/group x kH x kW), where C is the number of channels, and kH and kW are the height and width of the kernel, and M is the number of feature maps. For more than 2 dimensions, the kernel shape will be (M x C/group x k1 x k2 x ... x kn), where (k1 x k2 x ... kn) is the dimension of the kernel. Optionally, if dimension denotation is in effect, the operation expects the weight tensor to arrive with the dimension denotation of [FILTER_OUT_CHANNEL, FILTER_IN_CHANNEL, FILTER_SPATIAL, FILTER_SPATIAL ...]. Assuming zero based indices for the shape array, X.shape[1] == (W.shape[1] * group) == C and W.shape[0] mod G == 0. Or in other words FILTER_IN_CHANNEL multiplied by the number of groups should be equal to DATA_CHANNEL and the number of feature maps M should be a multiple of the number of groups G."
              },
              {
                "name": "B",
                "type": "T",
                "option": "optional",
                "description": "Optional 1D bias to be added to the convolution, has size of M."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "Y",
                "type": "T",
                "description": "Output data tensor that contains the result of the convolution. The output dimensions are functions of the kernel size, stride size, and pad lengths."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain input and output types to float tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "conv",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[1, 1, 1, 1],\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 21.0, 27.0, 33.0, 24.0],  # (1, 1, 5, 5) output tensor\n                [33.0, 54.0, 63.0, 72.0, 51.0],\n                [63.0, 99.0, 108.0, 117.0, 81.0],\n                [93.0, 144.0, 153.0, 162.0, 111.0],\n                [72.0, 111.0, 117.0, 123.0, 84.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_basic_conv_with_padding\",\n)\n\n# Convolution without padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[0, 0, 0, 0],\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 63.0, 72.0],  # (1, 1, 3, 3) output tensor\n                [99.0, 108.0, 117.0],\n                [144.0, 153.0, 162.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_basic_conv_without_padding\",\n)"
              },
              {
                "summary": "conv_with_autopad_same",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with auto_pad='SAME_LOWER' and strides=2\nnode = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    auto_pad=\"SAME_LOWER\",\n    kernel_shape=[3, 3],\n    strides=[2, 2],\n)\ny = np.array(\n    [[[[12.0, 27.0, 24.0], [63.0, 108.0, 81.0], [72.0, 117.0, 84.0]]]]\n).astype(np.float32)\nexpect(node, inputs=[x, W], outputs=[y], name=\"test_conv_with_autopad_same\")"
              },
              {
                "summary": "conv_with_strides",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 7, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n                [25.0, 26.0, 27.0, 28.0, 29.0],\n                [30.0, 31.0, 32.0, 33.0, 34.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with strides=2 and padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 1, 1, 1],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 27.0, 24.0],  # (1, 1, 4, 3) output tensor\n                [63.0, 108.0, 81.0],\n                [123.0, 198.0, 141.0],\n                [112.0, 177.0, 124.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_conv_with_strides_padding\",\n)\n\n# Convolution with strides=2 and no padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[0, 0, 0, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 72.0],  # (1, 1, 3, 2) output tensor\n                [144.0, 162.0],\n                [234.0, 252.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_conv_with_strides_no_padding\",\n)\n\n# Convolution with strides=2 and padding only along one dimension (the H dimension in NxCxHxW tensor)\nnode_with_asymmetric_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 0, 1, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_asymmetric_padding = np.array(\n    [\n        [\n            [\n                [21.0, 33.0],  # (1, 1, 4, 2) output tensor\n                [99.0, 117.0],\n                [189.0, 207.0],\n                [171.0, 183.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_asymmetric_padding,\n    inputs=[x, W],\n    outputs=[y_with_asymmetric_padding],\n    name=\"test_conv_with_strides_and_asymmetric_padding\",\n)"
              }
            ],
            "category": "Layer"
          }
        },
        {
          "name": "Conv__176",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "X",
              "value": [
                {
                  "name": "Conv__173:0",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        24,
                        18,
                        32
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "W",
              "value": [
                {
                  "name": "Conv2D_8/filter:0",
                  "initializer": {
                    "name": "Conv2D_8/filter:0",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float32",
                      "shape": {
                        "dimensions": [
                          88,
                          24,
                          1,
                          1
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        88,
                        24,
                        1,
                        1
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "B",
              "value": [
                {
                  "name": "conv2d_7_1/y:0",
                  "initializer": {
                    "name": "conv2d_7_1/y:0",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float32",
                      "shape": {
                        "dimensions": [
                          88
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        88
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "Y",
              "value": [
                {
                  "name": "Conv__176:0",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        88,
                        18,
                        32
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [
            {
              "name": "dilations",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "strides",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "kernel_shape",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "pads",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "0",
                  "0",
                  "0",
                  "0"
                ]
              }
            },
            {
              "name": "group",
              "type": "int64",
              "value": {
                "type": "bigint",
                "value": "1"
              }
            }
          ],
          "type": {
            "name": "Conv",
            "module": "ai.onnx",
            "version": 11,
            "description": "The convolution operator consumes an input tensor and a filter, and\ncomputes the output.",
            "attributes": [
              {
                "name": "auto_pad",
                "type": "string",
                "required": false,
                "default": "NOTSET",
                "description": "auto_pad must be either NOTSET, SAME_UPPER, SAME_LOWER or VALID. Where default value is NOTSET, which means explicit padding is used. SAME_UPPER or SAME_LOWER mean pad the input so that `output_shape[i] = ceil(input_shape[i] / strides[i])` for each axis `i`. The padding is split between the two sides equally or almost equally (depending on whether it is even or odd). In case the padding is an odd number, the extra padding is added at the end for SAME_UPPER and at the beginning for SAME_LOWER."
              },
              {
                "name": "dilations",
                "type": "int64[]",
                "required": false,
                "description": "dilation value along each spatial axis of the filter. If not present, the dilation defaults is 1 along each spatial axis."
              },
              {
                "name": "group",
                "type": "int64",
                "required": false,
                "default": 1,
                "description": "number of groups input channels and output channels are divided into."
              },
              {
                "name": "kernel_shape",
                "type": "int64[]",
                "required": false,
                "description": "The shape of the convolution kernel. If not present, should be inferred from input W."
              },
              {
                "name": "pads",
                "type": "int64[]",
                "required": false,
                "description": "Padding for the beginning and ending along each spatial axis, it can take any value greater than or equal to 0. The value represent the number of pixels added to the beginning and end part of the corresponding axis. `pads` format should be as follow [x1_begin, x2_begin...x1_end, x2_end,...], where xi_begin the number of pixels added at the beginning of axis `i` and xi_end, the number of pixels added at the end of axis `i`. This attribute cannot be used simultaneously with auto_pad attribute. If not present, the padding defaults to 0 along start and end of each spatial axis."
              },
              {
                "name": "strides",
                "type": "int64[]",
                "required": false,
                "description": "Stride along each spatial axis. If not present, the stride defaults is 1 along each spatial axis."
              }
            ],
            "inputs": [
              {
                "name": "X",
                "type": "T",
                "description": "Input data tensor from previous layer; has size (N x C x H x W), where N is the batch size, C is the number of channels, and H and W are the height and width. Note that this is for the 2D image. Otherwise the size is (N x C x D1 x D2 ... x Dn). Optionally, if dimension denotation is in effect, the operation expects input data tensor to arrive with the dimension denotation of [DATA_BATCH, DATA_CHANNEL, DATA_FEATURE, DATA_FEATURE ...]."
              },
              {
                "name": "W",
                "type": "T",
                "description": "The weight tensor that will be used in the convolutions; has size (M x C/group x kH x kW), where C is the number of channels, and kH and kW are the height and width of the kernel, and M is the number of feature maps. For more than 2 dimensions, the kernel shape will be (M x C/group x k1 x k2 x ... x kn), where (k1 x k2 x ... kn) is the dimension of the kernel. Optionally, if dimension denotation is in effect, the operation expects the weight tensor to arrive with the dimension denotation of [FILTER_OUT_CHANNEL, FILTER_IN_CHANNEL, FILTER_SPATIAL, FILTER_SPATIAL ...]. Assuming zero based indices for the shape array, X.shape[1] == (W.shape[1] * group) == C and W.shape[0] mod G == 0. Or in other words FILTER_IN_CHANNEL multiplied by the number of groups should be equal to DATA_CHANNEL and the number of feature maps M should be a multiple of the number of groups G."
              },
              {
                "name": "B",
                "type": "T",
                "option": "optional",
                "description": "Optional 1D bias to be added to the convolution, has size of M."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "Y",
                "type": "T",
                "description": "Output data tensor that contains the result of the convolution. The output dimensions are functions of the kernel size, stride size, and pad lengths."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain input and output types to float tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "conv",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[1, 1, 1, 1],\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 21.0, 27.0, 33.0, 24.0],  # (1, 1, 5, 5) output tensor\n                [33.0, 54.0, 63.0, 72.0, 51.0],\n                [63.0, 99.0, 108.0, 117.0, 81.0],\n                [93.0, 144.0, 153.0, 162.0, 111.0],\n                [72.0, 111.0, 117.0, 123.0, 84.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_basic_conv_with_padding\",\n)\n\n# Convolution without padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[0, 0, 0, 0],\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 63.0, 72.0],  # (1, 1, 3, 3) output tensor\n                [99.0, 108.0, 117.0],\n                [144.0, 153.0, 162.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_basic_conv_without_padding\",\n)"
              },
              {
                "summary": "conv_with_autopad_same",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with auto_pad='SAME_LOWER' and strides=2\nnode = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    auto_pad=\"SAME_LOWER\",\n    kernel_shape=[3, 3],\n    strides=[2, 2],\n)\ny = np.array(\n    [[[[12.0, 27.0, 24.0], [63.0, 108.0, 81.0], [72.0, 117.0, 84.0]]]]\n).astype(np.float32)\nexpect(node, inputs=[x, W], outputs=[y], name=\"test_conv_with_autopad_same\")"
              },
              {
                "summary": "conv_with_strides",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 7, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n                [25.0, 26.0, 27.0, 28.0, 29.0],\n                [30.0, 31.0, 32.0, 33.0, 34.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with strides=2 and padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 1, 1, 1],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 27.0, 24.0],  # (1, 1, 4, 3) output tensor\n                [63.0, 108.0, 81.0],\n                [123.0, 198.0, 141.0],\n                [112.0, 177.0, 124.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_conv_with_strides_padding\",\n)\n\n# Convolution with strides=2 and no padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[0, 0, 0, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 72.0],  # (1, 1, 3, 2) output tensor\n                [144.0, 162.0],\n                [234.0, 252.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_conv_with_strides_no_padding\",\n)\n\n# Convolution with strides=2 and padding only along one dimension (the H dimension in NxCxHxW tensor)\nnode_with_asymmetric_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 0, 1, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_asymmetric_padding = np.array(\n    [\n        [\n            [\n                [21.0, 33.0],  # (1, 1, 4, 2) output tensor\n                [99.0, 117.0],\n                [189.0, 207.0],\n                [171.0, 183.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_asymmetric_padding,\n    inputs=[x, W],\n    outputs=[y_with_asymmetric_padding],\n    name=\"test_conv_with_strides_and_asymmetric_padding\",\n)"
              }
            ],
            "category": "Layer"
          }
        },
        {
          "name": "re_lu_5",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "X",
              "value": [
                {
                  "name": "Conv__176:0",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        88,
                        18,
                        32
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "Y",
              "value": [
                {
                  "name": "re_lu_5:0",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        88,
                        18,
                        32
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "Relu",
            "module": "ai.onnx",
            "version": 14,
            "description": "Relu takes one input data (Tensor<T>) and produces one output data\n(Tensor<T>) where the rectified linear function, y = max(0, x), is applied to\nthe tensor elementwise.\n",
            "inputs": [
              {
                "name": "X",
                "type": "T",
                "description": "Input tensor"
              }
            ],
            "min_input": 1,
            "max_input": 1,
            "outputs": [
              {
                "name": "Y",
                "type": "T",
                "description": "Output tensor"
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "type_constraints": [
              {
                "description": "Constrain input and output types to signed numeric tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(float)",
                  "tensor(int32)",
                  "tensor(int8)",
                  "tensor(int16)",
                  "tensor(int64)",
                  "tensor(float16)",
                  "tensor(double)",
                  "tensor(bfloat16)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "relu",
                "code": "node = onnx.helper.make_node(\n    \"Relu\",\n    inputs=[\"x\"],\n    outputs=[\"y\"],\n)\nx = np.random.randn(3, 4, 5).astype(np.float32)\ny = np.clip(x, 0, np.inf)\n\nexpect(node, inputs=[x], outputs=[y], name=\"test_relu\")"
              }
            ],
            "category": "Activation"
          }
        },
        {
          "name": "Conv__177",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "X",
              "value": [
                {
                  "name": "re_lu_5:0",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        88,
                        18,
                        32
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "W",
              "value": [
                {
                  "name": "const_fold_opt__385",
                  "initializer": {
                    "name": "const_fold_opt__385",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float32",
                      "shape": {
                        "dimensions": [
                          88,
                          1,
                          3,
                          3
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        88,
                        1,
                        3,
                        3
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "B",
              "value": [
                {
                  "name": "depthwise_conv2d_2/y:0",
                  "initializer": {
                    "name": "depthwise_conv2d_2/y:0",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float32",
                      "shape": {
                        "dimensions": [
                          88
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        88
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "Y",
              "value": [
                {
                  "name": "Conv__177:0",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        88,
                        18,
                        32
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [
            {
              "name": "dilations",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "strides",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "kernel_shape",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "3",
                  "3"
                ]
              }
            },
            {
              "name": "group",
              "type": "int64",
              "value": {
                "type": "bigint",
                "value": "88"
              }
            },
            {
              "name": "pads",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1",
                  "1",
                  "1"
                ]
              }
            }
          ],
          "type": {
            "name": "Conv",
            "module": "ai.onnx",
            "version": 11,
            "description": "The convolution operator consumes an input tensor and a filter, and\ncomputes the output.",
            "attributes": [
              {
                "name": "auto_pad",
                "type": "string",
                "required": false,
                "default": "NOTSET",
                "description": "auto_pad must be either NOTSET, SAME_UPPER, SAME_LOWER or VALID. Where default value is NOTSET, which means explicit padding is used. SAME_UPPER or SAME_LOWER mean pad the input so that `output_shape[i] = ceil(input_shape[i] / strides[i])` for each axis `i`. The padding is split between the two sides equally or almost equally (depending on whether it is even or odd). In case the padding is an odd number, the extra padding is added at the end for SAME_UPPER and at the beginning for SAME_LOWER."
              },
              {
                "name": "dilations",
                "type": "int64[]",
                "required": false,
                "description": "dilation value along each spatial axis of the filter. If not present, the dilation defaults is 1 along each spatial axis."
              },
              {
                "name": "group",
                "type": "int64",
                "required": false,
                "default": 1,
                "description": "number of groups input channels and output channels are divided into."
              },
              {
                "name": "kernel_shape",
                "type": "int64[]",
                "required": false,
                "description": "The shape of the convolution kernel. If not present, should be inferred from input W."
              },
              {
                "name": "pads",
                "type": "int64[]",
                "required": false,
                "description": "Padding for the beginning and ending along each spatial axis, it can take any value greater than or equal to 0. The value represent the number of pixels added to the beginning and end part of the corresponding axis. `pads` format should be as follow [x1_begin, x2_begin...x1_end, x2_end,...], where xi_begin the number of pixels added at the beginning of axis `i` and xi_end, the number of pixels added at the end of axis `i`. This attribute cannot be used simultaneously with auto_pad attribute. If not present, the padding defaults to 0 along start and end of each spatial axis."
              },
              {
                "name": "strides",
                "type": "int64[]",
                "required": false,
                "description": "Stride along each spatial axis. If not present, the stride defaults is 1 along each spatial axis."
              }
            ],
            "inputs": [
              {
                "name": "X",
                "type": "T",
                "description": "Input data tensor from previous layer; has size (N x C x H x W), where N is the batch size, C is the number of channels, and H and W are the height and width. Note that this is for the 2D image. Otherwise the size is (N x C x D1 x D2 ... x Dn). Optionally, if dimension denotation is in effect, the operation expects input data tensor to arrive with the dimension denotation of [DATA_BATCH, DATA_CHANNEL, DATA_FEATURE, DATA_FEATURE ...]."
              },
              {
                "name": "W",
                "type": "T",
                "description": "The weight tensor that will be used in the convolutions; has size (M x C/group x kH x kW), where C is the number of channels, and kH and kW are the height and width of the kernel, and M is the number of feature maps. For more than 2 dimensions, the kernel shape will be (M x C/group x k1 x k2 x ... x kn), where (k1 x k2 x ... kn) is the dimension of the kernel. Optionally, if dimension denotation is in effect, the operation expects the weight tensor to arrive with the dimension denotation of [FILTER_OUT_CHANNEL, FILTER_IN_CHANNEL, FILTER_SPATIAL, FILTER_SPATIAL ...]. Assuming zero based indices for the shape array, X.shape[1] == (W.shape[1] * group) == C and W.shape[0] mod G == 0. Or in other words FILTER_IN_CHANNEL multiplied by the number of groups should be equal to DATA_CHANNEL and the number of feature maps M should be a multiple of the number of groups G."
              },
              {
                "name": "B",
                "type": "T",
                "option": "optional",
                "description": "Optional 1D bias to be added to the convolution, has size of M."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "Y",
                "type": "T",
                "description": "Output data tensor that contains the result of the convolution. The output dimensions are functions of the kernel size, stride size, and pad lengths."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain input and output types to float tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "conv",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[1, 1, 1, 1],\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 21.0, 27.0, 33.0, 24.0],  # (1, 1, 5, 5) output tensor\n                [33.0, 54.0, 63.0, 72.0, 51.0],\n                [63.0, 99.0, 108.0, 117.0, 81.0],\n                [93.0, 144.0, 153.0, 162.0, 111.0],\n                [72.0, 111.0, 117.0, 123.0, 84.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_basic_conv_with_padding\",\n)\n\n# Convolution without padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[0, 0, 0, 0],\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 63.0, 72.0],  # (1, 1, 3, 3) output tensor\n                [99.0, 108.0, 117.0],\n                [144.0, 153.0, 162.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_basic_conv_without_padding\",\n)"
              },
              {
                "summary": "conv_with_autopad_same",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with auto_pad='SAME_LOWER' and strides=2\nnode = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    auto_pad=\"SAME_LOWER\",\n    kernel_shape=[3, 3],\n    strides=[2, 2],\n)\ny = np.array(\n    [[[[12.0, 27.0, 24.0], [63.0, 108.0, 81.0], [72.0, 117.0, 84.0]]]]\n).astype(np.float32)\nexpect(node, inputs=[x, W], outputs=[y], name=\"test_conv_with_autopad_same\")"
              },
              {
                "summary": "conv_with_strides",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 7, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n                [25.0, 26.0, 27.0, 28.0, 29.0],\n                [30.0, 31.0, 32.0, 33.0, 34.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with strides=2 and padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 1, 1, 1],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 27.0, 24.0],  # (1, 1, 4, 3) output tensor\n                [63.0, 108.0, 81.0],\n                [123.0, 198.0, 141.0],\n                [112.0, 177.0, 124.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_conv_with_strides_padding\",\n)\n\n# Convolution with strides=2 and no padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[0, 0, 0, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 72.0],  # (1, 1, 3, 2) output tensor\n                [144.0, 162.0],\n                [234.0, 252.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_conv_with_strides_no_padding\",\n)\n\n# Convolution with strides=2 and padding only along one dimension (the H dimension in NxCxHxW tensor)\nnode_with_asymmetric_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 0, 1, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_asymmetric_padding = np.array(\n    [\n        [\n            [\n                [21.0, 33.0],  # (1, 1, 4, 2) output tensor\n                [99.0, 117.0],\n                [189.0, 207.0],\n                [171.0, 183.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_asymmetric_padding,\n    inputs=[x, W],\n    outputs=[y_with_asymmetric_padding],\n    name=\"test_conv_with_strides_and_asymmetric_padding\",\n)"
              }
            ],
            "category": "Layer"
          }
        },
        {
          "name": "re_lu_6",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "X",
              "value": [
                {
                  "name": "Conv__177:0",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        88,
                        18,
                        32
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "Y",
              "value": [
                {
                  "name": "re_lu_6:0",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        88,
                        18,
                        32
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "Relu",
            "module": "ai.onnx",
            "version": 14,
            "description": "Relu takes one input data (Tensor<T>) and produces one output data\n(Tensor<T>) where the rectified linear function, y = max(0, x), is applied to\nthe tensor elementwise.\n",
            "inputs": [
              {
                "name": "X",
                "type": "T",
                "description": "Input tensor"
              }
            ],
            "min_input": 1,
            "max_input": 1,
            "outputs": [
              {
                "name": "Y",
                "type": "T",
                "description": "Output tensor"
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "type_constraints": [
              {
                "description": "Constrain input and output types to signed numeric tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(float)",
                  "tensor(int32)",
                  "tensor(int8)",
                  "tensor(int16)",
                  "tensor(int64)",
                  "tensor(float16)",
                  "tensor(double)",
                  "tensor(bfloat16)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "relu",
                "code": "node = onnx.helper.make_node(\n    \"Relu\",\n    inputs=[\"x\"],\n    outputs=[\"y\"],\n)\nx = np.random.randn(3, 4, 5).astype(np.float32)\ny = np.clip(x, 0, np.inf)\n\nexpect(node, inputs=[x], outputs=[y], name=\"test_relu\")"
              }
            ],
            "category": "Activation"
          }
        },
        {
          "name": "Conv__178",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "X",
              "value": [
                {
                  "name": "re_lu_6:0",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        88,
                        18,
                        32
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "W",
              "value": [
                {
                  "name": "Conv2D_9/filter:0",
                  "initializer": {
                    "name": "Conv2D_9/filter:0",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float32",
                      "shape": {
                        "dimensions": [
                          24,
                          88,
                          1,
                          1
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        24,
                        88,
                        1,
                        1
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "B",
              "value": [
                {
                  "name": "conv2d_8_1/y:0",
                  "initializer": {
                    "name": "conv2d_8_1/y:0",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float32",
                      "shape": {
                        "dimensions": [
                          24
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        24
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "Y",
              "value": [
                {
                  "name": "Conv__178:0",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        24,
                        18,
                        32
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [
            {
              "name": "dilations",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "strides",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "kernel_shape",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "pads",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "0",
                  "0",
                  "0",
                  "0"
                ]
              }
            },
            {
              "name": "group",
              "type": "int64",
              "value": {
                "type": "bigint",
                "value": "1"
              }
            }
          ],
          "type": {
            "name": "Conv",
            "module": "ai.onnx",
            "version": 11,
            "description": "The convolution operator consumes an input tensor and a filter, and\ncomputes the output.",
            "attributes": [
              {
                "name": "auto_pad",
                "type": "string",
                "required": false,
                "default": "NOTSET",
                "description": "auto_pad must be either NOTSET, SAME_UPPER, SAME_LOWER or VALID. Where default value is NOTSET, which means explicit padding is used. SAME_UPPER or SAME_LOWER mean pad the input so that `output_shape[i] = ceil(input_shape[i] / strides[i])` for each axis `i`. The padding is split between the two sides equally or almost equally (depending on whether it is even or odd). In case the padding is an odd number, the extra padding is added at the end for SAME_UPPER and at the beginning for SAME_LOWER."
              },
              {
                "name": "dilations",
                "type": "int64[]",
                "required": false,
                "description": "dilation value along each spatial axis of the filter. If not present, the dilation defaults is 1 along each spatial axis."
              },
              {
                "name": "group",
                "type": "int64",
                "required": false,
                "default": 1,
                "description": "number of groups input channels and output channels are divided into."
              },
              {
                "name": "kernel_shape",
                "type": "int64[]",
                "required": false,
                "description": "The shape of the convolution kernel. If not present, should be inferred from input W."
              },
              {
                "name": "pads",
                "type": "int64[]",
                "required": false,
                "description": "Padding for the beginning and ending along each spatial axis, it can take any value greater than or equal to 0. The value represent the number of pixels added to the beginning and end part of the corresponding axis. `pads` format should be as follow [x1_begin, x2_begin...x1_end, x2_end,...], where xi_begin the number of pixels added at the beginning of axis `i` and xi_end, the number of pixels added at the end of axis `i`. This attribute cannot be used simultaneously with auto_pad attribute. If not present, the padding defaults to 0 along start and end of each spatial axis."
              },
              {
                "name": "strides",
                "type": "int64[]",
                "required": false,
                "description": "Stride along each spatial axis. If not present, the stride defaults is 1 along each spatial axis."
              }
            ],
            "inputs": [
              {
                "name": "X",
                "type": "T",
                "description": "Input data tensor from previous layer; has size (N x C x H x W), where N is the batch size, C is the number of channels, and H and W are the height and width. Note that this is for the 2D image. Otherwise the size is (N x C x D1 x D2 ... x Dn). Optionally, if dimension denotation is in effect, the operation expects input data tensor to arrive with the dimension denotation of [DATA_BATCH, DATA_CHANNEL, DATA_FEATURE, DATA_FEATURE ...]."
              },
              {
                "name": "W",
                "type": "T",
                "description": "The weight tensor that will be used in the convolutions; has size (M x C/group x kH x kW), where C is the number of channels, and kH and kW are the height and width of the kernel, and M is the number of feature maps. For more than 2 dimensions, the kernel shape will be (M x C/group x k1 x k2 x ... x kn), where (k1 x k2 x ... kn) is the dimension of the kernel. Optionally, if dimension denotation is in effect, the operation expects the weight tensor to arrive with the dimension denotation of [FILTER_OUT_CHANNEL, FILTER_IN_CHANNEL, FILTER_SPATIAL, FILTER_SPATIAL ...]. Assuming zero based indices for the shape array, X.shape[1] == (W.shape[1] * group) == C and W.shape[0] mod G == 0. Or in other words FILTER_IN_CHANNEL multiplied by the number of groups should be equal to DATA_CHANNEL and the number of feature maps M should be a multiple of the number of groups G."
              },
              {
                "name": "B",
                "type": "T",
                "option": "optional",
                "description": "Optional 1D bias to be added to the convolution, has size of M."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "Y",
                "type": "T",
                "description": "Output data tensor that contains the result of the convolution. The output dimensions are functions of the kernel size, stride size, and pad lengths."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain input and output types to float tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "conv",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[1, 1, 1, 1],\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 21.0, 27.0, 33.0, 24.0],  # (1, 1, 5, 5) output tensor\n                [33.0, 54.0, 63.0, 72.0, 51.0],\n                [63.0, 99.0, 108.0, 117.0, 81.0],\n                [93.0, 144.0, 153.0, 162.0, 111.0],\n                [72.0, 111.0, 117.0, 123.0, 84.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_basic_conv_with_padding\",\n)\n\n# Convolution without padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[0, 0, 0, 0],\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 63.0, 72.0],  # (1, 1, 3, 3) output tensor\n                [99.0, 108.0, 117.0],\n                [144.0, 153.0, 162.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_basic_conv_without_padding\",\n)"
              },
              {
                "summary": "conv_with_autopad_same",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with auto_pad='SAME_LOWER' and strides=2\nnode = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    auto_pad=\"SAME_LOWER\",\n    kernel_shape=[3, 3],\n    strides=[2, 2],\n)\ny = np.array(\n    [[[[12.0, 27.0, 24.0], [63.0, 108.0, 81.0], [72.0, 117.0, 84.0]]]]\n).astype(np.float32)\nexpect(node, inputs=[x, W], outputs=[y], name=\"test_conv_with_autopad_same\")"
              },
              {
                "summary": "conv_with_strides",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 7, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n                [25.0, 26.0, 27.0, 28.0, 29.0],\n                [30.0, 31.0, 32.0, 33.0, 34.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with strides=2 and padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 1, 1, 1],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 27.0, 24.0],  # (1, 1, 4, 3) output tensor\n                [63.0, 108.0, 81.0],\n                [123.0, 198.0, 141.0],\n                [112.0, 177.0, 124.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_conv_with_strides_padding\",\n)\n\n# Convolution with strides=2 and no padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[0, 0, 0, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 72.0],  # (1, 1, 3, 2) output tensor\n                [144.0, 162.0],\n                [234.0, 252.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_conv_with_strides_no_padding\",\n)\n\n# Convolution with strides=2 and padding only along one dimension (the H dimension in NxCxHxW tensor)\nnode_with_asymmetric_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 0, 1, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_asymmetric_padding = np.array(\n    [\n        [\n            [\n                [21.0, 33.0],  # (1, 1, 4, 2) output tensor\n                [99.0, 117.0],\n                [189.0, 207.0],\n                [171.0, 183.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_asymmetric_padding,\n    inputs=[x, W],\n    outputs=[y_with_asymmetric_padding],\n    name=\"test_conv_with_strides_and_asymmetric_padding\",\n)"
              }
            ],
            "category": "Layer"
          }
        },
        {
          "name": "add__xeno_compat__1",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "A",
              "value": [
                {
                  "name": "Conv__178:0",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        24,
                        18,
                        32
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "B",
              "value": [
                {
                  "name": "Conv__173:0",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        24,
                        18,
                        32
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "C",
              "value": [
                {
                  "name": "add__xeno_compat__1:0",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        24,
                        18,
                        32
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "Add",
            "module": "ai.onnx",
            "version": 14,
            "description": "Performs element-wise binary addition (with Numpy-style broadcasting support).\n\nThis operator supports **multidirectional (i.e., Numpy-style) broadcasting**; for more details please check [the doc](https://github.com/onnx/onnx/blob/master/docs/Broadcasting.md).\n\n(Opset 14 change): Extend supported types to include uint8, int8, uint16, and int16.\n",
            "inputs": [
              {
                "name": "A",
                "type": "T",
                "description": "First operand."
              },
              {
                "name": "B",
                "type": "T",
                "description": "Second operand."
              }
            ],
            "min_input": 2,
            "max_input": 2,
            "outputs": [
              {
                "name": "C",
                "type": "T",
                "description": "Result, has same element type as two inputs"
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "type_constraints": [
              {
                "description": "Constrain input and output types to all numeric tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(uint8)",
                  "tensor(uint16)",
                  "tensor(uint32)",
                  "tensor(uint64)",
                  "tensor(int8)",
                  "tensor(int16)",
                  "tensor(int32)",
                  "tensor(int64)",
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)",
                  "tensor(bfloat16)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "add",
                "code": "node = onnx.helper.make_node(\n    \"Add\",\n    inputs=[\"x\", \"y\"],\n    outputs=[\"sum\"],\n)\n\nx = np.random.randn(3, 4, 5).astype(np.float32)\ny = np.random.randn(3, 4, 5).astype(np.float32)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add\")\n\nx = np.random.randint(24, size=(3, 4, 5), dtype=np.int8)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.int8)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add_int8\")\n\nx = np.random.randint(24, size=(3, 4, 5), dtype=np.int16)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.int16)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add_int16\")\n\nx = np.random.randint(24, size=(3, 4, 5), dtype=np.uint8)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.uint8)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add_uint8\")\n\nx = np.random.randint(24, size=(3, 4, 5), dtype=np.uint16)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.uint16)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add_uint16\")\n\nx = np.random.randint(24, size=(3, 4, 5), dtype=np.uint32)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.uint32)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add_uint32\")\n\nx = np.random.randint(24, size=(3, 4, 5), dtype=np.uint64)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.uint64)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add_uint64\")"
              },
              {
                "summary": "add_broadcast",
                "code": "node = onnx.helper.make_node(\n    \"Add\",\n    inputs=[\"x\", \"y\"],\n    outputs=[\"sum\"],\n)\n\nx = np.random.randn(3, 4, 5).astype(np.float32)\ny = np.random.randn(5).astype(np.float32)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add_bcast\")"
              }
            ]
          }
        },
        {
          "name": "Conv__183",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "X",
              "value": [
                {
                  "name": "add__xeno_compat__1:0",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        24,
                        18,
                        32
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "W",
              "value": [
                {
                  "name": "Conv2D_10/filter:0",
                  "initializer": {
                    "name": "Conv2D_10/filter:0",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float32",
                      "shape": {
                        "dimensions": [
                          96,
                          24,
                          1,
                          1
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        96,
                        24,
                        1,
                        1
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "B",
              "value": [
                {
                  "name": "conv2d_9_1/y:0",
                  "initializer": {
                    "name": "conv2d_9_1/y:0",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float32",
                      "shape": {
                        "dimensions": [
                          96
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        96
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "Y",
              "value": [
                {
                  "name": "Conv__183:0",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        96,
                        18,
                        32
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [
            {
              "name": "dilations",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "strides",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "kernel_shape",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "pads",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "0",
                  "0",
                  "0",
                  "0"
                ]
              }
            },
            {
              "name": "group",
              "type": "int64",
              "value": {
                "type": "bigint",
                "value": "1"
              }
            }
          ],
          "type": {
            "name": "Conv",
            "module": "ai.onnx",
            "version": 11,
            "description": "The convolution operator consumes an input tensor and a filter, and\ncomputes the output.",
            "attributes": [
              {
                "name": "auto_pad",
                "type": "string",
                "required": false,
                "default": "NOTSET",
                "description": "auto_pad must be either NOTSET, SAME_UPPER, SAME_LOWER or VALID. Where default value is NOTSET, which means explicit padding is used. SAME_UPPER or SAME_LOWER mean pad the input so that `output_shape[i] = ceil(input_shape[i] / strides[i])` for each axis `i`. The padding is split between the two sides equally or almost equally (depending on whether it is even or odd). In case the padding is an odd number, the extra padding is added at the end for SAME_UPPER and at the beginning for SAME_LOWER."
              },
              {
                "name": "dilations",
                "type": "int64[]",
                "required": false,
                "description": "dilation value along each spatial axis of the filter. If not present, the dilation defaults is 1 along each spatial axis."
              },
              {
                "name": "group",
                "type": "int64",
                "required": false,
                "default": 1,
                "description": "number of groups input channels and output channels are divided into."
              },
              {
                "name": "kernel_shape",
                "type": "int64[]",
                "required": false,
                "description": "The shape of the convolution kernel. If not present, should be inferred from input W."
              },
              {
                "name": "pads",
                "type": "int64[]",
                "required": false,
                "description": "Padding for the beginning and ending along each spatial axis, it can take any value greater than or equal to 0. The value represent the number of pixels added to the beginning and end part of the corresponding axis. `pads` format should be as follow [x1_begin, x2_begin...x1_end, x2_end,...], where xi_begin the number of pixels added at the beginning of axis `i` and xi_end, the number of pixels added at the end of axis `i`. This attribute cannot be used simultaneously with auto_pad attribute. If not present, the padding defaults to 0 along start and end of each spatial axis."
              },
              {
                "name": "strides",
                "type": "int64[]",
                "required": false,
                "description": "Stride along each spatial axis. If not present, the stride defaults is 1 along each spatial axis."
              }
            ],
            "inputs": [
              {
                "name": "X",
                "type": "T",
                "description": "Input data tensor from previous layer; has size (N x C x H x W), where N is the batch size, C is the number of channels, and H and W are the height and width. Note that this is for the 2D image. Otherwise the size is (N x C x D1 x D2 ... x Dn). Optionally, if dimension denotation is in effect, the operation expects input data tensor to arrive with the dimension denotation of [DATA_BATCH, DATA_CHANNEL, DATA_FEATURE, DATA_FEATURE ...]."
              },
              {
                "name": "W",
                "type": "T",
                "description": "The weight tensor that will be used in the convolutions; has size (M x C/group x kH x kW), where C is the number of channels, and kH and kW are the height and width of the kernel, and M is the number of feature maps. For more than 2 dimensions, the kernel shape will be (M x C/group x k1 x k2 x ... x kn), where (k1 x k2 x ... kn) is the dimension of the kernel. Optionally, if dimension denotation is in effect, the operation expects the weight tensor to arrive with the dimension denotation of [FILTER_OUT_CHANNEL, FILTER_IN_CHANNEL, FILTER_SPATIAL, FILTER_SPATIAL ...]. Assuming zero based indices for the shape array, X.shape[1] == (W.shape[1] * group) == C and W.shape[0] mod G == 0. Or in other words FILTER_IN_CHANNEL multiplied by the number of groups should be equal to DATA_CHANNEL and the number of feature maps M should be a multiple of the number of groups G."
              },
              {
                "name": "B",
                "type": "T",
                "option": "optional",
                "description": "Optional 1D bias to be added to the convolution, has size of M."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "Y",
                "type": "T",
                "description": "Output data tensor that contains the result of the convolution. The output dimensions are functions of the kernel size, stride size, and pad lengths."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain input and output types to float tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "conv",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[1, 1, 1, 1],\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 21.0, 27.0, 33.0, 24.0],  # (1, 1, 5, 5) output tensor\n                [33.0, 54.0, 63.0, 72.0, 51.0],\n                [63.0, 99.0, 108.0, 117.0, 81.0],\n                [93.0, 144.0, 153.0, 162.0, 111.0],\n                [72.0, 111.0, 117.0, 123.0, 84.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_basic_conv_with_padding\",\n)\n\n# Convolution without padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[0, 0, 0, 0],\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 63.0, 72.0],  # (1, 1, 3, 3) output tensor\n                [99.0, 108.0, 117.0],\n                [144.0, 153.0, 162.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_basic_conv_without_padding\",\n)"
              },
              {
                "summary": "conv_with_autopad_same",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with auto_pad='SAME_LOWER' and strides=2\nnode = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    auto_pad=\"SAME_LOWER\",\n    kernel_shape=[3, 3],\n    strides=[2, 2],\n)\ny = np.array(\n    [[[[12.0, 27.0, 24.0], [63.0, 108.0, 81.0], [72.0, 117.0, 84.0]]]]\n).astype(np.float32)\nexpect(node, inputs=[x, W], outputs=[y], name=\"test_conv_with_autopad_same\")"
              },
              {
                "summary": "conv_with_strides",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 7, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n                [25.0, 26.0, 27.0, 28.0, 29.0],\n                [30.0, 31.0, 32.0, 33.0, 34.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with strides=2 and padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 1, 1, 1],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 27.0, 24.0],  # (1, 1, 4, 3) output tensor\n                [63.0, 108.0, 81.0],\n                [123.0, 198.0, 141.0],\n                [112.0, 177.0, 124.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_conv_with_strides_padding\",\n)\n\n# Convolution with strides=2 and no padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[0, 0, 0, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 72.0],  # (1, 1, 3, 2) output tensor\n                [144.0, 162.0],\n                [234.0, 252.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_conv_with_strides_no_padding\",\n)\n\n# Convolution with strides=2 and padding only along one dimension (the H dimension in NxCxHxW tensor)\nnode_with_asymmetric_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 0, 1, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_asymmetric_padding = np.array(\n    [\n        [\n            [\n                [21.0, 33.0],  # (1, 1, 4, 2) output tensor\n                [99.0, 117.0],\n                [189.0, 207.0],\n                [171.0, 183.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_asymmetric_padding,\n    inputs=[x, W],\n    outputs=[y_with_asymmetric_padding],\n    name=\"test_conv_with_strides_and_asymmetric_padding\",\n)"
              }
            ],
            "category": "Layer"
          }
        },
        {
          "name": "add_1",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "A",
              "value": [
                {
                  "name": "Conv__183:0",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        96,
                        18,
                        32
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "B",
              "value": [
                {
                  "name": "const_fold_opt__408",
                  "initializer": {
                    "name": "const_fold_opt__408",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float32",
                      "shape": {
                        "dimensions": [
                          1,
                          1,
                          1,
                          1
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        1,
                        1,
                        1
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "C",
              "value": [
                {
                  "name": "add_1:0",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        96,
                        18,
                        32
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "Add",
            "module": "ai.onnx",
            "version": 14,
            "description": "Performs element-wise binary addition (with Numpy-style broadcasting support).\n\nThis operator supports **multidirectional (i.e., Numpy-style) broadcasting**; for more details please check [the doc](https://github.com/onnx/onnx/blob/master/docs/Broadcasting.md).\n\n(Opset 14 change): Extend supported types to include uint8, int8, uint16, and int16.\n",
            "inputs": [
              {
                "name": "A",
                "type": "T",
                "description": "First operand."
              },
              {
                "name": "B",
                "type": "T",
                "description": "Second operand."
              }
            ],
            "min_input": 2,
            "max_input": 2,
            "outputs": [
              {
                "name": "C",
                "type": "T",
                "description": "Result, has same element type as two inputs"
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "type_constraints": [
              {
                "description": "Constrain input and output types to all numeric tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(uint8)",
                  "tensor(uint16)",
                  "tensor(uint32)",
                  "tensor(uint64)",
                  "tensor(int8)",
                  "tensor(int16)",
                  "tensor(int32)",
                  "tensor(int64)",
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)",
                  "tensor(bfloat16)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "add",
                "code": "node = onnx.helper.make_node(\n    \"Add\",\n    inputs=[\"x\", \"y\"],\n    outputs=[\"sum\"],\n)\n\nx = np.random.randn(3, 4, 5).astype(np.float32)\ny = np.random.randn(3, 4, 5).astype(np.float32)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add\")\n\nx = np.random.randint(24, size=(3, 4, 5), dtype=np.int8)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.int8)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add_int8\")\n\nx = np.random.randint(24, size=(3, 4, 5), dtype=np.int16)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.int16)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add_int16\")\n\nx = np.random.randint(24, size=(3, 4, 5), dtype=np.uint8)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.uint8)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add_uint8\")\n\nx = np.random.randint(24, size=(3, 4, 5), dtype=np.uint16)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.uint16)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add_uint16\")\n\nx = np.random.randint(24, size=(3, 4, 5), dtype=np.uint32)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.uint32)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add_uint32\")\n\nx = np.random.randint(24, size=(3, 4, 5), dtype=np.uint64)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.uint64)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add_uint64\")"
              },
              {
                "summary": "add_broadcast",
                "code": "node = onnx.helper.make_node(\n    \"Add\",\n    inputs=[\"x\", \"y\"],\n    outputs=[\"sum\"],\n)\n\nx = np.random.randn(3, 4, 5).astype(np.float32)\ny = np.random.randn(5).astype(np.float32)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add_bcast\")"
              }
            ]
          }
        },
        {
          "name": "Relu6_1",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "input",
              "value": [
                {
                  "name": "add_1:0",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        96,
                        18,
                        32
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "min",
              "value": [
                {
                  "name": "294",
                  "initializer": {
                    "category": "Constant",
                    "encoding": "|",
                    "values": {
                      "0": 0
                    },
                    "type": {
                      "dataType": "float32",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            },
            {
              "name": "max",
              "value": [
                {
                  "name": "295",
                  "initializer": {
                    "category": "Constant",
                    "encoding": "|",
                    "values": {
                      "0": 6
                    },
                    "type": {
                      "dataType": "float32",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "output",
              "value": [
                {
                  "name": "Relu6_1:0",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        96,
                        18,
                        32
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "Clip",
            "module": "ai.onnx",
            "version": 13,
            "description": "Clip operator limits the given input within an interval. The interval is\nspecified by the inputs 'min' and 'max'. They default to\nnumeric_limits::lowest() and numeric_limits::max(), respectively.\nWhen 'min' is greater than 'max', the clip operator sets all the 'input' values to\nthe value of 'max'. Thus, this is equivalent to 'Min(max, Max(input, min))'.\n",
            "inputs": [
              {
                "name": "input",
                "type": "T",
                "description": "Input tensor whose elements to be clipped"
              },
              {
                "name": "min",
                "type": "T",
                "option": "optional",
                "description": "Minimum value, under which element is replaced by min. It must be a scalar(tensor of empty shape)."
              },
              {
                "name": "max",
                "type": "T",
                "option": "optional",
                "description": "Maximum value, above which element is replaced by max. It must be a scalar(tensor of empty shape)."
              }
            ],
            "min_input": 1,
            "max_input": 3,
            "outputs": [
              {
                "name": "output",
                "type": "T",
                "description": "Output tensor with clipped input elements"
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "1 - 3",
            "type_constraints": [
              {
                "description": "Constrain input and output types to all numeric tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(uint8)",
                  "tensor(uint16)",
                  "tensor(uint32)",
                  "tensor(uint64)",
                  "tensor(int8)",
                  "tensor(int16)",
                  "tensor(int32)",
                  "tensor(int64)",
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)",
                  "tensor(bfloat16)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "clip",
                "code": "node = onnx.helper.make_node(\n    \"Clip\",\n    inputs=[\"x\", \"min\", \"max\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([-2, 0, 2]).astype(np.float32)\nmin_val = np.float32(-1)\nmax_val = np.float32(1)\ny = np.clip(x, min_val, max_val)  # expected output [-1., 0., 1.]\nexpect(\n    node, inputs=[x, min_val, max_val], outputs=[y], name=\"test_clip_example\"\n)\n\nx = np.random.randn(3, 4, 5).astype(np.float32)\ny = np.clip(x, min_val, max_val)\nexpect(node, inputs=[x, min_val, max_val], outputs=[y], name=\"test_clip\")\nnode = onnx.helper.make_node(\n    \"Clip\",\n    inputs=[\"x\", \"min\", \"max\"],\n    outputs=[\"y\"],\n)\n\nmin_val = np.float32(-5)\nmax_val = np.float32(5)\n\nx = np.array([-1, 0, 1]).astype(np.float32)\ny = np.array([-1, 0, 1]).astype(np.float32)\nexpect(\n    node, inputs=[x, min_val, max_val], outputs=[y], name=\"test_clip_inbounds\"\n)\n\nx = np.array([-6, 0, 6]).astype(np.float32)\ny = np.array([-5, 0, 5]).astype(np.float32)\nexpect(\n    node, inputs=[x, min_val, max_val], outputs=[y], name=\"test_clip_outbounds\"\n)\n\nx = np.array([-1, 0, 6]).astype(np.float32)\ny = np.array([-1, 0, 5]).astype(np.float32)\nexpect(\n    node,\n    inputs=[x, min_val, max_val],\n    outputs=[y],\n    name=\"test_clip_splitbounds\",\n)\n\nx = np.array([-2, 0, 6]).astype(np.float32)\ny = np.array([1, 1, 1]).astype(np.float32)\nmin_val = np.float32(2)\nmax_val = np.float32(1)\nexpect(\n    node,\n    inputs=[x, min_val, max_val],\n    outputs=[y],\n    name=\"test_clip_min_greater_than_max\",\n)"
              },
              {
                "summary": "clip_default",
                "code": "node = onnx.helper.make_node(\n    \"Clip\",\n    inputs=[\"x\", \"min\"],\n    outputs=[\"y\"],\n)\nmin_val = np.float32(0)\nx = np.random.randn(3, 4, 5).astype(np.float32)\ny = np.clip(x, min_val, np.inf)\nexpect(node, inputs=[x, min_val], outputs=[y], name=\"test_clip_default_min\")\n\nno_min = \"\"  # optional input, not supplied\nnode = onnx.helper.make_node(\n    \"Clip\",\n    inputs=[\"x\", no_min, \"max\"],\n    outputs=[\"y\"],\n)\nmax_val = np.float32(0)\nx = np.random.randn(3, 4, 5).astype(np.float32)\ny = np.clip(x, -np.inf, max_val)\nexpect(node, inputs=[x, max_val], outputs=[y], name=\"test_clip_default_max\")\n\nno_max = \"\"  # optional input, not supplied\nnode = onnx.helper.make_node(\n    \"Clip\",\n    inputs=[\"x\", no_min, no_max],\n    outputs=[\"y\"],\n)\n\nx = np.array([-1, 0, 1]).astype(np.float32)\ny = np.array([-1, 0, 1]).astype(np.float32)\nexpect(node, inputs=[x], outputs=[y], name=\"test_clip_default_inbounds\")"
              },
              {
                "summary": "clip_default_int8",
                "code": "node = onnx.helper.make_node(\n    \"Clip\",\n    inputs=[\"x\", \"min\"],\n    outputs=[\"y\"],\n)\nmin_val = np.int8(0)\nx = np.random.randn(3, 4, 5).astype(np.int8)\ny = np.clip(x, min_val, np.iinfo(np.int8).max)\nexpect(\n    node, inputs=[x, min_val], outputs=[y], name=\"test_clip_default_int8_min\"\n)\n\nno_min = \"\"  # optional input, not supplied\nnode = onnx.helper.make_node(\n    \"Clip\",\n    inputs=[\"x\", no_min, \"max\"],\n    outputs=[\"y\"],\n)\nmax_val = np.int8(0)\nx = np.random.randn(3, 4, 5).astype(np.int8)\ny = np.clip(x, np.iinfo(np.int8).min, max_val)\nexpect(\n    node, inputs=[x, max_val], outputs=[y], name=\"test_clip_default_int8_max\"\n)\n\nno_max = \"\"  # optional input, not supplied\nnode = onnx.helper.make_node(\n    \"Clip\",\n    inputs=[\"x\", no_min, no_max],\n    outputs=[\"y\"],\n)\n\nx = np.array([-1, 0, 1]).astype(np.int8)\ny = np.array([-1, 0, 1]).astype(np.int8)\nexpect(node, inputs=[x], outputs=[y], name=\"test_clip_default_int8_inbounds\")"
              }
            ],
            "category": "Activation"
          }
        },
        {
          "name": "mul_2",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "A",
              "value": [
                {
                  "name": "mul_3/y:0",
                  "initializer": {
                    "name": "mul_3/y:0",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float32",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            },
            {
              "name": "B",
              "value": [
                {
                  "name": "Relu6_1:0",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        96,
                        18,
                        32
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "C",
              "value": [
                {
                  "name": "mul_2:0",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        96,
                        18,
                        32
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "Mul",
            "module": "ai.onnx",
            "version": 14,
            "description": "Performs element-wise binary multiplication (with Numpy-style broadcasting support).\n\nThis operator supports **multidirectional (i.e., Numpy-style) broadcasting**; for more details please check [the doc](https://github.com/onnx/onnx/blob/master/docs/Broadcasting.md).\n\n(Opset 14 change): Extend supported types to include uint8, int8, uint16, and int16.\n",
            "inputs": [
              {
                "name": "A",
                "type": "T",
                "description": "First operand."
              },
              {
                "name": "B",
                "type": "T",
                "description": "Second operand."
              }
            ],
            "min_input": 2,
            "max_input": 2,
            "outputs": [
              {
                "name": "C",
                "type": "T",
                "description": "Result, has same element type as two inputs"
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "type_constraints": [
              {
                "description": "Constrain input and output types to all numeric tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(uint8)",
                  "tensor(uint16)",
                  "tensor(uint32)",
                  "tensor(uint64)",
                  "tensor(int8)",
                  "tensor(int16)",
                  "tensor(int32)",
                  "tensor(int64)",
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)",
                  "tensor(bfloat16)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "mul",
                "code": "node = onnx.helper.make_node(\n    \"Mul\",\n    inputs=[\"x\", \"y\"],\n    outputs=[\"z\"],\n)\n\nx = np.array([1, 2, 3]).astype(np.float32)\ny = np.array([4, 5, 6]).astype(np.float32)\nz = x * y  # expected output [4., 10., 18.]\nexpect(node, inputs=[x, y], outputs=[z], name=\"test_mul_example\")\n\nx = np.random.randn(3, 4, 5).astype(np.float32)\ny = np.random.randn(3, 4, 5).astype(np.float32)\nz = x * y\nexpect(node, inputs=[x, y], outputs=[z], name=\"test_mul\")\n\nx = np.random.randint(4, size=(3, 4, 5), dtype=np.int8)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.int8)\nz = x * y\nexpect(node, inputs=[x, y], outputs=[z], name=\"test_mul_int8\")\n\nx = np.random.randint(4, size=(3, 4, 5), dtype=np.int16)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.int16)\nz = x * y\nexpect(node, inputs=[x, y], outputs=[z], name=\"test_mul_int16\")\n\nx = np.random.randint(4, size=(3, 4, 5), dtype=np.uint8)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.uint8)\nz = x * y\nexpect(node, inputs=[x, y], outputs=[z], name=\"test_mul_uint8\")\n\nx = np.random.randint(4, size=(3, 4, 5), dtype=np.uint16)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.uint16)\nz = x * y\nexpect(node, inputs=[x, y], outputs=[z], name=\"test_mul_uint16\")\n\nx = np.random.randint(4, size=(3, 4, 5), dtype=np.uint32)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.uint32)\nz = x * y\nexpect(node, inputs=[x, y], outputs=[z], name=\"test_mul_uint32\")\n\nx = np.random.randint(4, size=(3, 4, 5), dtype=np.uint64)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.uint64)\nz = x * y\nexpect(node, inputs=[x, y], outputs=[z], name=\"test_mul_uint64\")"
              },
              {
                "summary": "mul_broadcast",
                "code": "node = onnx.helper.make_node(\n    \"Mul\",\n    inputs=[\"x\", \"y\"],\n    outputs=[\"z\"],\n)\n\nx = np.random.randn(3, 4, 5).astype(np.float32)\ny = np.random.randn(5).astype(np.float32)\nz = x * y\nexpect(node, inputs=[x, y], outputs=[z], name=\"test_mul_bcast\")"
              }
            ]
          }
        },
        {
          "name": "mul_3",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "A",
              "value": [
                {
                  "name": "Conv__183:0",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        96,
                        18,
                        32
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "B",
              "value": [
                {
                  "name": "mul_2:0",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        96,
                        18,
                        32
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "C",
              "value": [
                {
                  "name": "mul_3:0",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        96,
                        18,
                        32
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "Mul",
            "module": "ai.onnx",
            "version": 14,
            "description": "Performs element-wise binary multiplication (with Numpy-style broadcasting support).\n\nThis operator supports **multidirectional (i.e., Numpy-style) broadcasting**; for more details please check [the doc](https://github.com/onnx/onnx/blob/master/docs/Broadcasting.md).\n\n(Opset 14 change): Extend supported types to include uint8, int8, uint16, and int16.\n",
            "inputs": [
              {
                "name": "A",
                "type": "T",
                "description": "First operand."
              },
              {
                "name": "B",
                "type": "T",
                "description": "Second operand."
              }
            ],
            "min_input": 2,
            "max_input": 2,
            "outputs": [
              {
                "name": "C",
                "type": "T",
                "description": "Result, has same element type as two inputs"
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "type_constraints": [
              {
                "description": "Constrain input and output types to all numeric tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(uint8)",
                  "tensor(uint16)",
                  "tensor(uint32)",
                  "tensor(uint64)",
                  "tensor(int8)",
                  "tensor(int16)",
                  "tensor(int32)",
                  "tensor(int64)",
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)",
                  "tensor(bfloat16)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "mul",
                "code": "node = onnx.helper.make_node(\n    \"Mul\",\n    inputs=[\"x\", \"y\"],\n    outputs=[\"z\"],\n)\n\nx = np.array([1, 2, 3]).astype(np.float32)\ny = np.array([4, 5, 6]).astype(np.float32)\nz = x * y  # expected output [4., 10., 18.]\nexpect(node, inputs=[x, y], outputs=[z], name=\"test_mul_example\")\n\nx = np.random.randn(3, 4, 5).astype(np.float32)\ny = np.random.randn(3, 4, 5).astype(np.float32)\nz = x * y\nexpect(node, inputs=[x, y], outputs=[z], name=\"test_mul\")\n\nx = np.random.randint(4, size=(3, 4, 5), dtype=np.int8)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.int8)\nz = x * y\nexpect(node, inputs=[x, y], outputs=[z], name=\"test_mul_int8\")\n\nx = np.random.randint(4, size=(3, 4, 5), dtype=np.int16)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.int16)\nz = x * y\nexpect(node, inputs=[x, y], outputs=[z], name=\"test_mul_int16\")\n\nx = np.random.randint(4, size=(3, 4, 5), dtype=np.uint8)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.uint8)\nz = x * y\nexpect(node, inputs=[x, y], outputs=[z], name=\"test_mul_uint8\")\n\nx = np.random.randint(4, size=(3, 4, 5), dtype=np.uint16)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.uint16)\nz = x * y\nexpect(node, inputs=[x, y], outputs=[z], name=\"test_mul_uint16\")\n\nx = np.random.randint(4, size=(3, 4, 5), dtype=np.uint32)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.uint32)\nz = x * y\nexpect(node, inputs=[x, y], outputs=[z], name=\"test_mul_uint32\")\n\nx = np.random.randint(4, size=(3, 4, 5), dtype=np.uint64)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.uint64)\nz = x * y\nexpect(node, inputs=[x, y], outputs=[z], name=\"test_mul_uint64\")"
              },
              {
                "summary": "mul_broadcast",
                "code": "node = onnx.helper.make_node(\n    \"Mul\",\n    inputs=[\"x\", \"y\"],\n    outputs=[\"z\"],\n)\n\nx = np.random.randn(3, 4, 5).astype(np.float32)\ny = np.random.randn(5).astype(np.float32)\nz = x * y\nexpect(node, inputs=[x, y], outputs=[z], name=\"test_mul_bcast\")"
              }
            ]
          }
        },
        {
          "name": "Conv__186",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "X",
              "value": [
                {
                  "name": "mul_3:0",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        96,
                        18,
                        32
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "W",
              "value": [
                {
                  "name": "const_fold_opt__383",
                  "initializer": {
                    "name": "const_fold_opt__383",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float32",
                      "shape": {
                        "dimensions": [
                          96,
                          1,
                          5,
                          5
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        96,
                        1,
                        5,
                        5
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "B",
              "value": [
                {
                  "name": "depthwise_conv2d_3/y:0",
                  "initializer": {
                    "name": "depthwise_conv2d_3/y:0",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float32",
                      "shape": {
                        "dimensions": [
                          96
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        96
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "Y",
              "value": [
                {
                  "name": "Conv__186:0",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        96,
                        9,
                        16
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [
            {
              "name": "dilations",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "strides",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "2",
                  "2"
                ]
              }
            },
            {
              "name": "kernel_shape",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "5",
                  "5"
                ]
              }
            },
            {
              "name": "group",
              "type": "int64",
              "value": {
                "type": "bigint",
                "value": "96"
              }
            },
            {
              "name": "pads",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1",
                  "2",
                  "2"
                ]
              }
            }
          ],
          "type": {
            "name": "Conv",
            "module": "ai.onnx",
            "version": 11,
            "description": "The convolution operator consumes an input tensor and a filter, and\ncomputes the output.",
            "attributes": [
              {
                "name": "auto_pad",
                "type": "string",
                "required": false,
                "default": "NOTSET",
                "description": "auto_pad must be either NOTSET, SAME_UPPER, SAME_LOWER or VALID. Where default value is NOTSET, which means explicit padding is used. SAME_UPPER or SAME_LOWER mean pad the input so that `output_shape[i] = ceil(input_shape[i] / strides[i])` for each axis `i`. The padding is split between the two sides equally or almost equally (depending on whether it is even or odd). In case the padding is an odd number, the extra padding is added at the end for SAME_UPPER and at the beginning for SAME_LOWER."
              },
              {
                "name": "dilations",
                "type": "int64[]",
                "required": false,
                "description": "dilation value along each spatial axis of the filter. If not present, the dilation defaults is 1 along each spatial axis."
              },
              {
                "name": "group",
                "type": "int64",
                "required": false,
                "default": 1,
                "description": "number of groups input channels and output channels are divided into."
              },
              {
                "name": "kernel_shape",
                "type": "int64[]",
                "required": false,
                "description": "The shape of the convolution kernel. If not present, should be inferred from input W."
              },
              {
                "name": "pads",
                "type": "int64[]",
                "required": false,
                "description": "Padding for the beginning and ending along each spatial axis, it can take any value greater than or equal to 0. The value represent the number of pixels added to the beginning and end part of the corresponding axis. `pads` format should be as follow [x1_begin, x2_begin...x1_end, x2_end,...], where xi_begin the number of pixels added at the beginning of axis `i` and xi_end, the number of pixels added at the end of axis `i`. This attribute cannot be used simultaneously with auto_pad attribute. If not present, the padding defaults to 0 along start and end of each spatial axis."
              },
              {
                "name": "strides",
                "type": "int64[]",
                "required": false,
                "description": "Stride along each spatial axis. If not present, the stride defaults is 1 along each spatial axis."
              }
            ],
            "inputs": [
              {
                "name": "X",
                "type": "T",
                "description": "Input data tensor from previous layer; has size (N x C x H x W), where N is the batch size, C is the number of channels, and H and W are the height and width. Note that this is for the 2D image. Otherwise the size is (N x C x D1 x D2 ... x Dn). Optionally, if dimension denotation is in effect, the operation expects input data tensor to arrive with the dimension denotation of [DATA_BATCH, DATA_CHANNEL, DATA_FEATURE, DATA_FEATURE ...]."
              },
              {
                "name": "W",
                "type": "T",
                "description": "The weight tensor that will be used in the convolutions; has size (M x C/group x kH x kW), where C is the number of channels, and kH and kW are the height and width of the kernel, and M is the number of feature maps. For more than 2 dimensions, the kernel shape will be (M x C/group x k1 x k2 x ... x kn), where (k1 x k2 x ... kn) is the dimension of the kernel. Optionally, if dimension denotation is in effect, the operation expects the weight tensor to arrive with the dimension denotation of [FILTER_OUT_CHANNEL, FILTER_IN_CHANNEL, FILTER_SPATIAL, FILTER_SPATIAL ...]. Assuming zero based indices for the shape array, X.shape[1] == (W.shape[1] * group) == C and W.shape[0] mod G == 0. Or in other words FILTER_IN_CHANNEL multiplied by the number of groups should be equal to DATA_CHANNEL and the number of feature maps M should be a multiple of the number of groups G."
              },
              {
                "name": "B",
                "type": "T",
                "option": "optional",
                "description": "Optional 1D bias to be added to the convolution, has size of M."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "Y",
                "type": "T",
                "description": "Output data tensor that contains the result of the convolution. The output dimensions are functions of the kernel size, stride size, and pad lengths."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain input and output types to float tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "conv",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[1, 1, 1, 1],\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 21.0, 27.0, 33.0, 24.0],  # (1, 1, 5, 5) output tensor\n                [33.0, 54.0, 63.0, 72.0, 51.0],\n                [63.0, 99.0, 108.0, 117.0, 81.0],\n                [93.0, 144.0, 153.0, 162.0, 111.0],\n                [72.0, 111.0, 117.0, 123.0, 84.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_basic_conv_with_padding\",\n)\n\n# Convolution without padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[0, 0, 0, 0],\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 63.0, 72.0],  # (1, 1, 3, 3) output tensor\n                [99.0, 108.0, 117.0],\n                [144.0, 153.0, 162.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_basic_conv_without_padding\",\n)"
              },
              {
                "summary": "conv_with_autopad_same",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with auto_pad='SAME_LOWER' and strides=2\nnode = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    auto_pad=\"SAME_LOWER\",\n    kernel_shape=[3, 3],\n    strides=[2, 2],\n)\ny = np.array(\n    [[[[12.0, 27.0, 24.0], [63.0, 108.0, 81.0], [72.0, 117.0, 84.0]]]]\n).astype(np.float32)\nexpect(node, inputs=[x, W], outputs=[y], name=\"test_conv_with_autopad_same\")"
              },
              {
                "summary": "conv_with_strides",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 7, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n                [25.0, 26.0, 27.0, 28.0, 29.0],\n                [30.0, 31.0, 32.0, 33.0, 34.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with strides=2 and padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 1, 1, 1],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 27.0, 24.0],  # (1, 1, 4, 3) output tensor\n                [63.0, 108.0, 81.0],\n                [123.0, 198.0, 141.0],\n                [112.0, 177.0, 124.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_conv_with_strides_padding\",\n)\n\n# Convolution with strides=2 and no padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[0, 0, 0, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 72.0],  # (1, 1, 3, 2) output tensor\n                [144.0, 162.0],\n                [234.0, 252.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_conv_with_strides_no_padding\",\n)\n\n# Convolution with strides=2 and padding only along one dimension (the H dimension in NxCxHxW tensor)\nnode_with_asymmetric_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 0, 1, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_asymmetric_padding = np.array(\n    [\n        [\n            [\n                [21.0, 33.0],  # (1, 1, 4, 2) output tensor\n                [99.0, 117.0],\n                [189.0, 207.0],\n                [171.0, 183.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_asymmetric_padding,\n    inputs=[x, W],\n    outputs=[y_with_asymmetric_padding],\n    name=\"test_conv_with_strides_and_asymmetric_padding\",\n)"
              }
            ],
            "category": "Layer"
          }
        },
        {
          "name": "add_2",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "A",
              "value": [
                {
                  "name": "Conv__186:0",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        96,
                        9,
                        16
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "B",
              "value": [
                {
                  "name": "const_fold_opt__408",
                  "initializer": {
                    "name": "const_fold_opt__408",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float32",
                      "shape": {
                        "dimensions": [
                          1,
                          1,
                          1,
                          1
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        1,
                        1,
                        1
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "C",
              "value": [
                {
                  "name": "add_2:0",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        96,
                        9,
                        16
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "Add",
            "module": "ai.onnx",
            "version": 14,
            "description": "Performs element-wise binary addition (with Numpy-style broadcasting support).\n\nThis operator supports **multidirectional (i.e., Numpy-style) broadcasting**; for more details please check [the doc](https://github.com/onnx/onnx/blob/master/docs/Broadcasting.md).\n\n(Opset 14 change): Extend supported types to include uint8, int8, uint16, and int16.\n",
            "inputs": [
              {
                "name": "A",
                "type": "T",
                "description": "First operand."
              },
              {
                "name": "B",
                "type": "T",
                "description": "Second operand."
              }
            ],
            "min_input": 2,
            "max_input": 2,
            "outputs": [
              {
                "name": "C",
                "type": "T",
                "description": "Result, has same element type as two inputs"
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "type_constraints": [
              {
                "description": "Constrain input and output types to all numeric tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(uint8)",
                  "tensor(uint16)",
                  "tensor(uint32)",
                  "tensor(uint64)",
                  "tensor(int8)",
                  "tensor(int16)",
                  "tensor(int32)",
                  "tensor(int64)",
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)",
                  "tensor(bfloat16)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "add",
                "code": "node = onnx.helper.make_node(\n    \"Add\",\n    inputs=[\"x\", \"y\"],\n    outputs=[\"sum\"],\n)\n\nx = np.random.randn(3, 4, 5).astype(np.float32)\ny = np.random.randn(3, 4, 5).astype(np.float32)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add\")\n\nx = np.random.randint(24, size=(3, 4, 5), dtype=np.int8)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.int8)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add_int8\")\n\nx = np.random.randint(24, size=(3, 4, 5), dtype=np.int16)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.int16)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add_int16\")\n\nx = np.random.randint(24, size=(3, 4, 5), dtype=np.uint8)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.uint8)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add_uint8\")\n\nx = np.random.randint(24, size=(3, 4, 5), dtype=np.uint16)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.uint16)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add_uint16\")\n\nx = np.random.randint(24, size=(3, 4, 5), dtype=np.uint32)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.uint32)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add_uint32\")\n\nx = np.random.randint(24, size=(3, 4, 5), dtype=np.uint64)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.uint64)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add_uint64\")"
              },
              {
                "summary": "add_broadcast",
                "code": "node = onnx.helper.make_node(\n    \"Add\",\n    inputs=[\"x\", \"y\"],\n    outputs=[\"sum\"],\n)\n\nx = np.random.randn(3, 4, 5).astype(np.float32)\ny = np.random.randn(5).astype(np.float32)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add_bcast\")"
              }
            ]
          }
        },
        {
          "name": "Relu6_2",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "input",
              "value": [
                {
                  "name": "add_2:0",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        96,
                        9,
                        16
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "min",
              "value": [
                {
                  "name": "296",
                  "initializer": {
                    "category": "Constant",
                    "encoding": "|",
                    "values": {
                      "0": 0
                    },
                    "type": {
                      "dataType": "float32",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            },
            {
              "name": "max",
              "value": [
                {
                  "name": "297",
                  "initializer": {
                    "category": "Constant",
                    "encoding": "|",
                    "values": {
                      "0": 6
                    },
                    "type": {
                      "dataType": "float32",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "output",
              "value": [
                {
                  "name": "Relu6_2:0",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        96,
                        9,
                        16
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "Clip",
            "module": "ai.onnx",
            "version": 13,
            "description": "Clip operator limits the given input within an interval. The interval is\nspecified by the inputs 'min' and 'max'. They default to\nnumeric_limits::lowest() and numeric_limits::max(), respectively.\nWhen 'min' is greater than 'max', the clip operator sets all the 'input' values to\nthe value of 'max'. Thus, this is equivalent to 'Min(max, Max(input, min))'.\n",
            "inputs": [
              {
                "name": "input",
                "type": "T",
                "description": "Input tensor whose elements to be clipped"
              },
              {
                "name": "min",
                "type": "T",
                "option": "optional",
                "description": "Minimum value, under which element is replaced by min. It must be a scalar(tensor of empty shape)."
              },
              {
                "name": "max",
                "type": "T",
                "option": "optional",
                "description": "Maximum value, above which element is replaced by max. It must be a scalar(tensor of empty shape)."
              }
            ],
            "min_input": 1,
            "max_input": 3,
            "outputs": [
              {
                "name": "output",
                "type": "T",
                "description": "Output tensor with clipped input elements"
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "1 - 3",
            "type_constraints": [
              {
                "description": "Constrain input and output types to all numeric tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(uint8)",
                  "tensor(uint16)",
                  "tensor(uint32)",
                  "tensor(uint64)",
                  "tensor(int8)",
                  "tensor(int16)",
                  "tensor(int32)",
                  "tensor(int64)",
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)",
                  "tensor(bfloat16)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "clip",
                "code": "node = onnx.helper.make_node(\n    \"Clip\",\n    inputs=[\"x\", \"min\", \"max\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([-2, 0, 2]).astype(np.float32)\nmin_val = np.float32(-1)\nmax_val = np.float32(1)\ny = np.clip(x, min_val, max_val)  # expected output [-1., 0., 1.]\nexpect(\n    node, inputs=[x, min_val, max_val], outputs=[y], name=\"test_clip_example\"\n)\n\nx = np.random.randn(3, 4, 5).astype(np.float32)\ny = np.clip(x, min_val, max_val)\nexpect(node, inputs=[x, min_val, max_val], outputs=[y], name=\"test_clip\")\nnode = onnx.helper.make_node(\n    \"Clip\",\n    inputs=[\"x\", \"min\", \"max\"],\n    outputs=[\"y\"],\n)\n\nmin_val = np.float32(-5)\nmax_val = np.float32(5)\n\nx = np.array([-1, 0, 1]).astype(np.float32)\ny = np.array([-1, 0, 1]).astype(np.float32)\nexpect(\n    node, inputs=[x, min_val, max_val], outputs=[y], name=\"test_clip_inbounds\"\n)\n\nx = np.array([-6, 0, 6]).astype(np.float32)\ny = np.array([-5, 0, 5]).astype(np.float32)\nexpect(\n    node, inputs=[x, min_val, max_val], outputs=[y], name=\"test_clip_outbounds\"\n)\n\nx = np.array([-1, 0, 6]).astype(np.float32)\ny = np.array([-1, 0, 5]).astype(np.float32)\nexpect(\n    node,\n    inputs=[x, min_val, max_val],\n    outputs=[y],\n    name=\"test_clip_splitbounds\",\n)\n\nx = np.array([-2, 0, 6]).astype(np.float32)\ny = np.array([1, 1, 1]).astype(np.float32)\nmin_val = np.float32(2)\nmax_val = np.float32(1)\nexpect(\n    node,\n    inputs=[x, min_val, max_val],\n    outputs=[y],\n    name=\"test_clip_min_greater_than_max\",\n)"
              },
              {
                "summary": "clip_default",
                "code": "node = onnx.helper.make_node(\n    \"Clip\",\n    inputs=[\"x\", \"min\"],\n    outputs=[\"y\"],\n)\nmin_val = np.float32(0)\nx = np.random.randn(3, 4, 5).astype(np.float32)\ny = np.clip(x, min_val, np.inf)\nexpect(node, inputs=[x, min_val], outputs=[y], name=\"test_clip_default_min\")\n\nno_min = \"\"  # optional input, not supplied\nnode = onnx.helper.make_node(\n    \"Clip\",\n    inputs=[\"x\", no_min, \"max\"],\n    outputs=[\"y\"],\n)\nmax_val = np.float32(0)\nx = np.random.randn(3, 4, 5).astype(np.float32)\ny = np.clip(x, -np.inf, max_val)\nexpect(node, inputs=[x, max_val], outputs=[y], name=\"test_clip_default_max\")\n\nno_max = \"\"  # optional input, not supplied\nnode = onnx.helper.make_node(\n    \"Clip\",\n    inputs=[\"x\", no_min, no_max],\n    outputs=[\"y\"],\n)\n\nx = np.array([-1, 0, 1]).astype(np.float32)\ny = np.array([-1, 0, 1]).astype(np.float32)\nexpect(node, inputs=[x], outputs=[y], name=\"test_clip_default_inbounds\")"
              },
              {
                "summary": "clip_default_int8",
                "code": "node = onnx.helper.make_node(\n    \"Clip\",\n    inputs=[\"x\", \"min\"],\n    outputs=[\"y\"],\n)\nmin_val = np.int8(0)\nx = np.random.randn(3, 4, 5).astype(np.int8)\ny = np.clip(x, min_val, np.iinfo(np.int8).max)\nexpect(\n    node, inputs=[x, min_val], outputs=[y], name=\"test_clip_default_int8_min\"\n)\n\nno_min = \"\"  # optional input, not supplied\nnode = onnx.helper.make_node(\n    \"Clip\",\n    inputs=[\"x\", no_min, \"max\"],\n    outputs=[\"y\"],\n)\nmax_val = np.int8(0)\nx = np.random.randn(3, 4, 5).astype(np.int8)\ny = np.clip(x, np.iinfo(np.int8).min, max_val)\nexpect(\n    node, inputs=[x, max_val], outputs=[y], name=\"test_clip_default_int8_max\"\n)\n\nno_max = \"\"  # optional input, not supplied\nnode = onnx.helper.make_node(\n    \"Clip\",\n    inputs=[\"x\", no_min, no_max],\n    outputs=[\"y\"],\n)\n\nx = np.array([-1, 0, 1]).astype(np.int8)\ny = np.array([-1, 0, 1]).astype(np.int8)\nexpect(node, inputs=[x], outputs=[y], name=\"test_clip_default_int8_inbounds\")"
              }
            ],
            "category": "Activation"
          }
        },
        {
          "name": "mul_4",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "A",
              "value": [
                {
                  "name": "mul_3/y:0",
                  "initializer": {
                    "name": "mul_3/y:0",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float32",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            },
            {
              "name": "B",
              "value": [
                {
                  "name": "Relu6_2:0",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        96,
                        9,
                        16
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "C",
              "value": [
                {
                  "name": "mul_4:0",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        96,
                        9,
                        16
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "Mul",
            "module": "ai.onnx",
            "version": 14,
            "description": "Performs element-wise binary multiplication (with Numpy-style broadcasting support).\n\nThis operator supports **multidirectional (i.e., Numpy-style) broadcasting**; for more details please check [the doc](https://github.com/onnx/onnx/blob/master/docs/Broadcasting.md).\n\n(Opset 14 change): Extend supported types to include uint8, int8, uint16, and int16.\n",
            "inputs": [
              {
                "name": "A",
                "type": "T",
                "description": "First operand."
              },
              {
                "name": "B",
                "type": "T",
                "description": "Second operand."
              }
            ],
            "min_input": 2,
            "max_input": 2,
            "outputs": [
              {
                "name": "C",
                "type": "T",
                "description": "Result, has same element type as two inputs"
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "type_constraints": [
              {
                "description": "Constrain input and output types to all numeric tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(uint8)",
                  "tensor(uint16)",
                  "tensor(uint32)",
                  "tensor(uint64)",
                  "tensor(int8)",
                  "tensor(int16)",
                  "tensor(int32)",
                  "tensor(int64)",
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)",
                  "tensor(bfloat16)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "mul",
                "code": "node = onnx.helper.make_node(\n    \"Mul\",\n    inputs=[\"x\", \"y\"],\n    outputs=[\"z\"],\n)\n\nx = np.array([1, 2, 3]).astype(np.float32)\ny = np.array([4, 5, 6]).astype(np.float32)\nz = x * y  # expected output [4., 10., 18.]\nexpect(node, inputs=[x, y], outputs=[z], name=\"test_mul_example\")\n\nx = np.random.randn(3, 4, 5).astype(np.float32)\ny = np.random.randn(3, 4, 5).astype(np.float32)\nz = x * y\nexpect(node, inputs=[x, y], outputs=[z], name=\"test_mul\")\n\nx = np.random.randint(4, size=(3, 4, 5), dtype=np.int8)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.int8)\nz = x * y\nexpect(node, inputs=[x, y], outputs=[z], name=\"test_mul_int8\")\n\nx = np.random.randint(4, size=(3, 4, 5), dtype=np.int16)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.int16)\nz = x * y\nexpect(node, inputs=[x, y], outputs=[z], name=\"test_mul_int16\")\n\nx = np.random.randint(4, size=(3, 4, 5), dtype=np.uint8)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.uint8)\nz = x * y\nexpect(node, inputs=[x, y], outputs=[z], name=\"test_mul_uint8\")\n\nx = np.random.randint(4, size=(3, 4, 5), dtype=np.uint16)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.uint16)\nz = x * y\nexpect(node, inputs=[x, y], outputs=[z], name=\"test_mul_uint16\")\n\nx = np.random.randint(4, size=(3, 4, 5), dtype=np.uint32)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.uint32)\nz = x * y\nexpect(node, inputs=[x, y], outputs=[z], name=\"test_mul_uint32\")\n\nx = np.random.randint(4, size=(3, 4, 5), dtype=np.uint64)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.uint64)\nz = x * y\nexpect(node, inputs=[x, y], outputs=[z], name=\"test_mul_uint64\")"
              },
              {
                "summary": "mul_broadcast",
                "code": "node = onnx.helper.make_node(\n    \"Mul\",\n    inputs=[\"x\", \"y\"],\n    outputs=[\"z\"],\n)\n\nx = np.random.randn(3, 4, 5).astype(np.float32)\ny = np.random.randn(5).astype(np.float32)\nz = x * y\nexpect(node, inputs=[x, y], outputs=[z], name=\"test_mul_bcast\")"
              }
            ]
          }
        },
        {
          "name": "mul_5",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "A",
              "value": [
                {
                  "name": "Conv__186:0",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        96,
                        9,
                        16
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "B",
              "value": [
                {
                  "name": "mul_4:0",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        96,
                        9,
                        16
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "C",
              "value": [
                {
                  "name": "mul_5:0",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        96,
                        9,
                        16
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "Mul",
            "module": "ai.onnx",
            "version": 14,
            "description": "Performs element-wise binary multiplication (with Numpy-style broadcasting support).\n\nThis operator supports **multidirectional (i.e., Numpy-style) broadcasting**; for more details please check [the doc](https://github.com/onnx/onnx/blob/master/docs/Broadcasting.md).\n\n(Opset 14 change): Extend supported types to include uint8, int8, uint16, and int16.\n",
            "inputs": [
              {
                "name": "A",
                "type": "T",
                "description": "First operand."
              },
              {
                "name": "B",
                "type": "T",
                "description": "Second operand."
              }
            ],
            "min_input": 2,
            "max_input": 2,
            "outputs": [
              {
                "name": "C",
                "type": "T",
                "description": "Result, has same element type as two inputs"
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "type_constraints": [
              {
                "description": "Constrain input and output types to all numeric tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(uint8)",
                  "tensor(uint16)",
                  "tensor(uint32)",
                  "tensor(uint64)",
                  "tensor(int8)",
                  "tensor(int16)",
                  "tensor(int32)",
                  "tensor(int64)",
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)",
                  "tensor(bfloat16)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "mul",
                "code": "node = onnx.helper.make_node(\n    \"Mul\",\n    inputs=[\"x\", \"y\"],\n    outputs=[\"z\"],\n)\n\nx = np.array([1, 2, 3]).astype(np.float32)\ny = np.array([4, 5, 6]).astype(np.float32)\nz = x * y  # expected output [4., 10., 18.]\nexpect(node, inputs=[x, y], outputs=[z], name=\"test_mul_example\")\n\nx = np.random.randn(3, 4, 5).astype(np.float32)\ny = np.random.randn(3, 4, 5).astype(np.float32)\nz = x * y\nexpect(node, inputs=[x, y], outputs=[z], name=\"test_mul\")\n\nx = np.random.randint(4, size=(3, 4, 5), dtype=np.int8)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.int8)\nz = x * y\nexpect(node, inputs=[x, y], outputs=[z], name=\"test_mul_int8\")\n\nx = np.random.randint(4, size=(3, 4, 5), dtype=np.int16)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.int16)\nz = x * y\nexpect(node, inputs=[x, y], outputs=[z], name=\"test_mul_int16\")\n\nx = np.random.randint(4, size=(3, 4, 5), dtype=np.uint8)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.uint8)\nz = x * y\nexpect(node, inputs=[x, y], outputs=[z], name=\"test_mul_uint8\")\n\nx = np.random.randint(4, size=(3, 4, 5), dtype=np.uint16)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.uint16)\nz = x * y\nexpect(node, inputs=[x, y], outputs=[z], name=\"test_mul_uint16\")\n\nx = np.random.randint(4, size=(3, 4, 5), dtype=np.uint32)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.uint32)\nz = x * y\nexpect(node, inputs=[x, y], outputs=[z], name=\"test_mul_uint32\")\n\nx = np.random.randint(4, size=(3, 4, 5), dtype=np.uint64)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.uint64)\nz = x * y\nexpect(node, inputs=[x, y], outputs=[z], name=\"test_mul_uint64\")"
              },
              {
                "summary": "mul_broadcast",
                "code": "node = onnx.helper.make_node(\n    \"Mul\",\n    inputs=[\"x\", \"y\"],\n    outputs=[\"z\"],\n)\n\nx = np.random.randn(3, 4, 5).astype(np.float32)\ny = np.random.randn(5).astype(np.float32)\nz = x * y\nexpect(node, inputs=[x, y], outputs=[z], name=\"test_mul_bcast\")"
              }
            ]
          }
        },
        {
          "name": "global_average_pooling2d_1",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "X",
              "value": [
                {
                  "name": "mul_5:0",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        96,
                        9,
                        16
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "Y",
              "value": [
                {
                  "name": "global_average_pooling2d_1:0",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        96,
                        1,
                        1
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "GlobalAveragePool",
            "module": "ai.onnx",
            "version": 1,
            "description": "GlobalAveragePool consumes an input tensor X and applies average pooling across\n the values in the same channel. This is equivalent to AveragePool with kernel size\n equal to the spatial dimension of input tensor.",
            "inputs": [
              {
                "name": "X",
                "type": "T",
                "description": "Input data tensor from the previous operator; dimensions for image case are (N x C x H x W), where N is the batch size, C is the number of channels, and H and W are the height and the width of the data. For non image case, the dimensions are in the form of (N x C x D1 x D2 ... Dn), where N is the batch size."
              }
            ],
            "min_input": 1,
            "max_input": 1,
            "outputs": [
              {
                "name": "Y",
                "type": "T",
                "description": "Output data tensor from pooling across the input tensor. The output tensor has the same rank as the input. The first two dimensions of output shape are the same as the input (N x C), while the other dimensions are all 1."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "type_constraints": [
              {
                "description": "Constrain input and output types to float tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "globalaveragepool",
                "code": "node = onnx.helper.make_node(\n    \"GlobalAveragePool\",\n    inputs=[\"x\"],\n    outputs=[\"y\"],\n)\nx = np.random.randn(1, 3, 5, 5).astype(np.float32)\ny = np.mean(x, axis=tuple(range(2, np.ndim(x))), keepdims=True)\nexpect(node, inputs=[x], outputs=[y], name=\"test_globalaveragepool\")"
              },
              {
                "summary": "globalaveragepool_precomputed",
                "code": "node = onnx.helper.make_node(\n    \"GlobalAveragePool\",\n    inputs=[\"x\"],\n    outputs=[\"y\"],\n)\nx = np.array(\n    [\n        [\n            [\n                [1, 2, 3],\n                [4, 5, 6],\n                [7, 8, 9],\n            ]\n        ]\n    ]\n).astype(np.float32)\ny = np.array([[[[5]]]]).astype(np.float32)\nexpect(node, inputs=[x], outputs=[y], name=\"test_globalaveragepool_precomputed\")"
              }
            ],
            "category": "Pool"
          }
        },
        {
          "name": "Conv__189",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "X",
              "value": [
                {
                  "name": "global_average_pooling2d_1:0",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        96,
                        1,
                        1
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "W",
              "value": [
                {
                  "name": "Conv2D_11/filter:0",
                  "initializer": {
                    "name": "Conv2D_11/filter:0",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float32",
                      "shape": {
                        "dimensions": [
                          24,
                          96,
                          1,
                          1
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        24,
                        96,
                        1,
                        1
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "B",
              "value": [
                {
                  "name": "conv2d_10_1/y:0",
                  "initializer": {
                    "name": "conv2d_10_1/y:0",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float32",
                      "shape": {
                        "dimensions": [
                          24
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        24
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "Y",
              "value": [
                {
                  "name": "Conv__189:0",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        24,
                        1,
                        1
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [
            {
              "name": "dilations",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "strides",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "kernel_shape",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "group",
              "type": "int64",
              "value": {
                "type": "bigint",
                "value": "1"
              }
            }
          ],
          "type": {
            "name": "Conv",
            "module": "ai.onnx",
            "version": 11,
            "description": "The convolution operator consumes an input tensor and a filter, and\ncomputes the output.",
            "attributes": [
              {
                "name": "auto_pad",
                "type": "string",
                "required": false,
                "default": "NOTSET",
                "description": "auto_pad must be either NOTSET, SAME_UPPER, SAME_LOWER or VALID. Where default value is NOTSET, which means explicit padding is used. SAME_UPPER or SAME_LOWER mean pad the input so that `output_shape[i] = ceil(input_shape[i] / strides[i])` for each axis `i`. The padding is split between the two sides equally or almost equally (depending on whether it is even or odd). In case the padding is an odd number, the extra padding is added at the end for SAME_UPPER and at the beginning for SAME_LOWER."
              },
              {
                "name": "dilations",
                "type": "int64[]",
                "required": false,
                "description": "dilation value along each spatial axis of the filter. If not present, the dilation defaults is 1 along each spatial axis."
              },
              {
                "name": "group",
                "type": "int64",
                "required": false,
                "default": 1,
                "description": "number of groups input channels and output channels are divided into."
              },
              {
                "name": "kernel_shape",
                "type": "int64[]",
                "required": false,
                "description": "The shape of the convolution kernel. If not present, should be inferred from input W."
              },
              {
                "name": "pads",
                "type": "int64[]",
                "required": false,
                "description": "Padding for the beginning and ending along each spatial axis, it can take any value greater than or equal to 0. The value represent the number of pixels added to the beginning and end part of the corresponding axis. `pads` format should be as follow [x1_begin, x2_begin...x1_end, x2_end,...], where xi_begin the number of pixels added at the beginning of axis `i` and xi_end, the number of pixels added at the end of axis `i`. This attribute cannot be used simultaneously with auto_pad attribute. If not present, the padding defaults to 0 along start and end of each spatial axis."
              },
              {
                "name": "strides",
                "type": "int64[]",
                "required": false,
                "description": "Stride along each spatial axis. If not present, the stride defaults is 1 along each spatial axis."
              }
            ],
            "inputs": [
              {
                "name": "X",
                "type": "T",
                "description": "Input data tensor from previous layer; has size (N x C x H x W), where N is the batch size, C is the number of channels, and H and W are the height and width. Note that this is for the 2D image. Otherwise the size is (N x C x D1 x D2 ... x Dn). Optionally, if dimension denotation is in effect, the operation expects input data tensor to arrive with the dimension denotation of [DATA_BATCH, DATA_CHANNEL, DATA_FEATURE, DATA_FEATURE ...]."
              },
              {
                "name": "W",
                "type": "T",
                "description": "The weight tensor that will be used in the convolutions; has size (M x C/group x kH x kW), where C is the number of channels, and kH and kW are the height and width of the kernel, and M is the number of feature maps. For more than 2 dimensions, the kernel shape will be (M x C/group x k1 x k2 x ... x kn), where (k1 x k2 x ... kn) is the dimension of the kernel. Optionally, if dimension denotation is in effect, the operation expects the weight tensor to arrive with the dimension denotation of [FILTER_OUT_CHANNEL, FILTER_IN_CHANNEL, FILTER_SPATIAL, FILTER_SPATIAL ...]. Assuming zero based indices for the shape array, X.shape[1] == (W.shape[1] * group) == C and W.shape[0] mod G == 0. Or in other words FILTER_IN_CHANNEL multiplied by the number of groups should be equal to DATA_CHANNEL and the number of feature maps M should be a multiple of the number of groups G."
              },
              {
                "name": "B",
                "type": "T",
                "option": "optional",
                "description": "Optional 1D bias to be added to the convolution, has size of M."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "Y",
                "type": "T",
                "description": "Output data tensor that contains the result of the convolution. The output dimensions are functions of the kernel size, stride size, and pad lengths."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain input and output types to float tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "conv",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[1, 1, 1, 1],\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 21.0, 27.0, 33.0, 24.0],  # (1, 1, 5, 5) output tensor\n                [33.0, 54.0, 63.0, 72.0, 51.0],\n                [63.0, 99.0, 108.0, 117.0, 81.0],\n                [93.0, 144.0, 153.0, 162.0, 111.0],\n                [72.0, 111.0, 117.0, 123.0, 84.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_basic_conv_with_padding\",\n)\n\n# Convolution without padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[0, 0, 0, 0],\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 63.0, 72.0],  # (1, 1, 3, 3) output tensor\n                [99.0, 108.0, 117.0],\n                [144.0, 153.0, 162.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_basic_conv_without_padding\",\n)"
              },
              {
                "summary": "conv_with_autopad_same",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with auto_pad='SAME_LOWER' and strides=2\nnode = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    auto_pad=\"SAME_LOWER\",\n    kernel_shape=[3, 3],\n    strides=[2, 2],\n)\ny = np.array(\n    [[[[12.0, 27.0, 24.0], [63.0, 108.0, 81.0], [72.0, 117.0, 84.0]]]]\n).astype(np.float32)\nexpect(node, inputs=[x, W], outputs=[y], name=\"test_conv_with_autopad_same\")"
              },
              {
                "summary": "conv_with_strides",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 7, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n                [25.0, 26.0, 27.0, 28.0, 29.0],\n                [30.0, 31.0, 32.0, 33.0, 34.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with strides=2 and padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 1, 1, 1],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 27.0, 24.0],  # (1, 1, 4, 3) output tensor\n                [63.0, 108.0, 81.0],\n                [123.0, 198.0, 141.0],\n                [112.0, 177.0, 124.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_conv_with_strides_padding\",\n)\n\n# Convolution with strides=2 and no padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[0, 0, 0, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 72.0],  # (1, 1, 3, 2) output tensor\n                [144.0, 162.0],\n                [234.0, 252.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_conv_with_strides_no_padding\",\n)\n\n# Convolution with strides=2 and padding only along one dimension (the H dimension in NxCxHxW tensor)\nnode_with_asymmetric_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 0, 1, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_asymmetric_padding = np.array(\n    [\n        [\n            [\n                [21.0, 33.0],  # (1, 1, 4, 2) output tensor\n                [99.0, 117.0],\n                [189.0, 207.0],\n                [171.0, 183.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_asymmetric_padding,\n    inputs=[x, W],\n    outputs=[y_with_asymmetric_padding],\n    name=\"test_conv_with_strides_and_asymmetric_padding\",\n)"
              }
            ],
            "category": "Layer"
          }
        },
        {
          "name": "re_lu_7",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "X",
              "value": [
                {
                  "name": "Conv__189:0",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        24,
                        1,
                        1
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "Y",
              "value": [
                {
                  "name": "re_lu_7:0",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        24,
                        1,
                        1
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "Relu",
            "module": "ai.onnx",
            "version": 14,
            "description": "Relu takes one input data (Tensor<T>) and produces one output data\n(Tensor<T>) where the rectified linear function, y = max(0, x), is applied to\nthe tensor elementwise.\n",
            "inputs": [
              {
                "name": "X",
                "type": "T",
                "description": "Input tensor"
              }
            ],
            "min_input": 1,
            "max_input": 1,
            "outputs": [
              {
                "name": "Y",
                "type": "T",
                "description": "Output tensor"
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "type_constraints": [
              {
                "description": "Constrain input and output types to signed numeric tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(float)",
                  "tensor(int32)",
                  "tensor(int8)",
                  "tensor(int16)",
                  "tensor(int64)",
                  "tensor(float16)",
                  "tensor(double)",
                  "tensor(bfloat16)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "relu",
                "code": "node = onnx.helper.make_node(\n    \"Relu\",\n    inputs=[\"x\"],\n    outputs=[\"y\"],\n)\nx = np.random.randn(3, 4, 5).astype(np.float32)\ny = np.clip(x, 0, np.inf)\n\nexpect(node, inputs=[x], outputs=[y], name=\"test_relu\")"
              }
            ],
            "category": "Activation"
          }
        },
        {
          "name": "Conv__190",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "X",
              "value": [
                {
                  "name": "re_lu_7:0",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        24,
                        1,
                        1
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "W",
              "value": [
                {
                  "name": "Conv2D_12/filter:0",
                  "initializer": {
                    "name": "Conv2D_12/filter:0",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float32",
                      "shape": {
                        "dimensions": [
                          96,
                          24,
                          1,
                          1
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        96,
                        24,
                        1,
                        1
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "B",
              "value": [
                {
                  "name": "conv2d_11_1/y:0",
                  "initializer": {
                    "name": "conv2d_11_1/y:0",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float32",
                      "shape": {
                        "dimensions": [
                          96
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        96
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "Y",
              "value": [
                {
                  "name": "Conv__190:0",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        96,
                        1,
                        1
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [
            {
              "name": "dilations",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "strides",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "kernel_shape",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "group",
              "type": "int64",
              "value": {
                "type": "bigint",
                "value": "1"
              }
            }
          ],
          "type": {
            "name": "Conv",
            "module": "ai.onnx",
            "version": 11,
            "description": "The convolution operator consumes an input tensor and a filter, and\ncomputes the output.",
            "attributes": [
              {
                "name": "auto_pad",
                "type": "string",
                "required": false,
                "default": "NOTSET",
                "description": "auto_pad must be either NOTSET, SAME_UPPER, SAME_LOWER or VALID. Where default value is NOTSET, which means explicit padding is used. SAME_UPPER or SAME_LOWER mean pad the input so that `output_shape[i] = ceil(input_shape[i] / strides[i])` for each axis `i`. The padding is split between the two sides equally or almost equally (depending on whether it is even or odd). In case the padding is an odd number, the extra padding is added at the end for SAME_UPPER and at the beginning for SAME_LOWER."
              },
              {
                "name": "dilations",
                "type": "int64[]",
                "required": false,
                "description": "dilation value along each spatial axis of the filter. If not present, the dilation defaults is 1 along each spatial axis."
              },
              {
                "name": "group",
                "type": "int64",
                "required": false,
                "default": 1,
                "description": "number of groups input channels and output channels are divided into."
              },
              {
                "name": "kernel_shape",
                "type": "int64[]",
                "required": false,
                "description": "The shape of the convolution kernel. If not present, should be inferred from input W."
              },
              {
                "name": "pads",
                "type": "int64[]",
                "required": false,
                "description": "Padding for the beginning and ending along each spatial axis, it can take any value greater than or equal to 0. The value represent the number of pixels added to the beginning and end part of the corresponding axis. `pads` format should be as follow [x1_begin, x2_begin...x1_end, x2_end,...], where xi_begin the number of pixels added at the beginning of axis `i` and xi_end, the number of pixels added at the end of axis `i`. This attribute cannot be used simultaneously with auto_pad attribute. If not present, the padding defaults to 0 along start and end of each spatial axis."
              },
              {
                "name": "strides",
                "type": "int64[]",
                "required": false,
                "description": "Stride along each spatial axis. If not present, the stride defaults is 1 along each spatial axis."
              }
            ],
            "inputs": [
              {
                "name": "X",
                "type": "T",
                "description": "Input data tensor from previous layer; has size (N x C x H x W), where N is the batch size, C is the number of channels, and H and W are the height and width. Note that this is for the 2D image. Otherwise the size is (N x C x D1 x D2 ... x Dn). Optionally, if dimension denotation is in effect, the operation expects input data tensor to arrive with the dimension denotation of [DATA_BATCH, DATA_CHANNEL, DATA_FEATURE, DATA_FEATURE ...]."
              },
              {
                "name": "W",
                "type": "T",
                "description": "The weight tensor that will be used in the convolutions; has size (M x C/group x kH x kW), where C is the number of channels, and kH and kW are the height and width of the kernel, and M is the number of feature maps. For more than 2 dimensions, the kernel shape will be (M x C/group x k1 x k2 x ... x kn), where (k1 x k2 x ... kn) is the dimension of the kernel. Optionally, if dimension denotation is in effect, the operation expects the weight tensor to arrive with the dimension denotation of [FILTER_OUT_CHANNEL, FILTER_IN_CHANNEL, FILTER_SPATIAL, FILTER_SPATIAL ...]. Assuming zero based indices for the shape array, X.shape[1] == (W.shape[1] * group) == C and W.shape[0] mod G == 0. Or in other words FILTER_IN_CHANNEL multiplied by the number of groups should be equal to DATA_CHANNEL and the number of feature maps M should be a multiple of the number of groups G."
              },
              {
                "name": "B",
                "type": "T",
                "option": "optional",
                "description": "Optional 1D bias to be added to the convolution, has size of M."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "Y",
                "type": "T",
                "description": "Output data tensor that contains the result of the convolution. The output dimensions are functions of the kernel size, stride size, and pad lengths."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain input and output types to float tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "conv",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[1, 1, 1, 1],\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 21.0, 27.0, 33.0, 24.0],  # (1, 1, 5, 5) output tensor\n                [33.0, 54.0, 63.0, 72.0, 51.0],\n                [63.0, 99.0, 108.0, 117.0, 81.0],\n                [93.0, 144.0, 153.0, 162.0, 111.0],\n                [72.0, 111.0, 117.0, 123.0, 84.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_basic_conv_with_padding\",\n)\n\n# Convolution without padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[0, 0, 0, 0],\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 63.0, 72.0],  # (1, 1, 3, 3) output tensor\n                [99.0, 108.0, 117.0],\n                [144.0, 153.0, 162.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_basic_conv_without_padding\",\n)"
              },
              {
                "summary": "conv_with_autopad_same",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with auto_pad='SAME_LOWER' and strides=2\nnode = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    auto_pad=\"SAME_LOWER\",\n    kernel_shape=[3, 3],\n    strides=[2, 2],\n)\ny = np.array(\n    [[[[12.0, 27.0, 24.0], [63.0, 108.0, 81.0], [72.0, 117.0, 84.0]]]]\n).astype(np.float32)\nexpect(node, inputs=[x, W], outputs=[y], name=\"test_conv_with_autopad_same\")"
              },
              {
                "summary": "conv_with_strides",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 7, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n                [25.0, 26.0, 27.0, 28.0, 29.0],\n                [30.0, 31.0, 32.0, 33.0, 34.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with strides=2 and padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 1, 1, 1],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 27.0, 24.0],  # (1, 1, 4, 3) output tensor\n                [63.0, 108.0, 81.0],\n                [123.0, 198.0, 141.0],\n                [112.0, 177.0, 124.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_conv_with_strides_padding\",\n)\n\n# Convolution with strides=2 and no padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[0, 0, 0, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 72.0],  # (1, 1, 3, 2) output tensor\n                [144.0, 162.0],\n                [234.0, 252.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_conv_with_strides_no_padding\",\n)\n\n# Convolution with strides=2 and padding only along one dimension (the H dimension in NxCxHxW tensor)\nnode_with_asymmetric_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 0, 1, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_asymmetric_padding = np.array(\n    [\n        [\n            [\n                [21.0, 33.0],  # (1, 1, 4, 2) output tensor\n                [99.0, 117.0],\n                [189.0, 207.0],\n                [171.0, 183.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_asymmetric_padding,\n    inputs=[x, W],\n    outputs=[y_with_asymmetric_padding],\n    name=\"test_conv_with_strides_and_asymmetric_padding\",\n)"
              }
            ],
            "category": "Layer"
          }
        },
        {
          "name": "activation_1",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "X",
              "value": [
                {
                  "name": "Conv__190:0",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        96,
                        1,
                        1
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "Y",
              "value": [
                {
                  "name": "activation_1:0",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        96,
                        1,
                        1
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "Sigmoid",
            "module": "ai.onnx",
            "version": 13,
            "description": "Sigmoid takes one input data (Tensor<T>) and produces one output data\n(Tensor<T>) where the sigmoid function, y = 1 / (1 + exp(-x)), is applied to the\ntensor elementwise.\n",
            "inputs": [
              {
                "name": "X",
                "type": "T",
                "description": "Input tensor"
              }
            ],
            "min_input": 1,
            "max_input": 1,
            "outputs": [
              {
                "name": "Y",
                "type": "T",
                "description": "Output tensor"
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "type_constraints": [
              {
                "description": "Constrain input and output types to float tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)",
                  "tensor(bfloat16)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "sigmoid",
                "code": "node = onnx.helper.make_node(\n    \"Sigmoid\",\n    inputs=[\"x\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([-1, 0, 1]).astype(np.float32)\ny = 1.0 / (\n    1.0 + np.exp(np.negative(x))\n)  # expected output [0.26894143, 0.5, 0.7310586]\nexpect(node, inputs=[x], outputs=[y], name=\"test_sigmoid_example\")\n\nx = np.random.randn(3, 4, 5).astype(np.float32)\ny = 1.0 / (1.0 + np.exp(np.negative(x)))\nexpect(node, inputs=[x], outputs=[y], name=\"test_sigmoid\")"
              }
            ],
            "category": "Activation"
          }
        },
        {
          "name": "multiply_1",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "A",
              "value": [
                {
                  "name": "mul_5:0",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        96,
                        9,
                        16
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "B",
              "value": [
                {
                  "name": "activation_1:0",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        96,
                        1,
                        1
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "C",
              "value": [
                {
                  "name": "multiply_1:0",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        96,
                        9,
                        16
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "Mul",
            "module": "ai.onnx",
            "version": 14,
            "description": "Performs element-wise binary multiplication (with Numpy-style broadcasting support).\n\nThis operator supports **multidirectional (i.e., Numpy-style) broadcasting**; for more details please check [the doc](https://github.com/onnx/onnx/blob/master/docs/Broadcasting.md).\n\n(Opset 14 change): Extend supported types to include uint8, int8, uint16, and int16.\n",
            "inputs": [
              {
                "name": "A",
                "type": "T",
                "description": "First operand."
              },
              {
                "name": "B",
                "type": "T",
                "description": "Second operand."
              }
            ],
            "min_input": 2,
            "max_input": 2,
            "outputs": [
              {
                "name": "C",
                "type": "T",
                "description": "Result, has same element type as two inputs"
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "type_constraints": [
              {
                "description": "Constrain input and output types to all numeric tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(uint8)",
                  "tensor(uint16)",
                  "tensor(uint32)",
                  "tensor(uint64)",
                  "tensor(int8)",
                  "tensor(int16)",
                  "tensor(int32)",
                  "tensor(int64)",
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)",
                  "tensor(bfloat16)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "mul",
                "code": "node = onnx.helper.make_node(\n    \"Mul\",\n    inputs=[\"x\", \"y\"],\n    outputs=[\"z\"],\n)\n\nx = np.array([1, 2, 3]).astype(np.float32)\ny = np.array([4, 5, 6]).astype(np.float32)\nz = x * y  # expected output [4., 10., 18.]\nexpect(node, inputs=[x, y], outputs=[z], name=\"test_mul_example\")\n\nx = np.random.randn(3, 4, 5).astype(np.float32)\ny = np.random.randn(3, 4, 5).astype(np.float32)\nz = x * y\nexpect(node, inputs=[x, y], outputs=[z], name=\"test_mul\")\n\nx = np.random.randint(4, size=(3, 4, 5), dtype=np.int8)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.int8)\nz = x * y\nexpect(node, inputs=[x, y], outputs=[z], name=\"test_mul_int8\")\n\nx = np.random.randint(4, size=(3, 4, 5), dtype=np.int16)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.int16)\nz = x * y\nexpect(node, inputs=[x, y], outputs=[z], name=\"test_mul_int16\")\n\nx = np.random.randint(4, size=(3, 4, 5), dtype=np.uint8)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.uint8)\nz = x * y\nexpect(node, inputs=[x, y], outputs=[z], name=\"test_mul_uint8\")\n\nx = np.random.randint(4, size=(3, 4, 5), dtype=np.uint16)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.uint16)\nz = x * y\nexpect(node, inputs=[x, y], outputs=[z], name=\"test_mul_uint16\")\n\nx = np.random.randint(4, size=(3, 4, 5), dtype=np.uint32)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.uint32)\nz = x * y\nexpect(node, inputs=[x, y], outputs=[z], name=\"test_mul_uint32\")\n\nx = np.random.randint(4, size=(3, 4, 5), dtype=np.uint64)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.uint64)\nz = x * y\nexpect(node, inputs=[x, y], outputs=[z], name=\"test_mul_uint64\")"
              },
              {
                "summary": "mul_broadcast",
                "code": "node = onnx.helper.make_node(\n    \"Mul\",\n    inputs=[\"x\", \"y\"],\n    outputs=[\"z\"],\n)\n\nx = np.random.randn(3, 4, 5).astype(np.float32)\ny = np.random.randn(5).astype(np.float32)\nz = x * y\nexpect(node, inputs=[x, y], outputs=[z], name=\"test_mul_bcast\")"
              }
            ]
          }
        },
        {
          "name": "Conv__191",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "X",
              "value": [
                {
                  "name": "multiply_1:0",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        96,
                        9,
                        16
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "W",
              "value": [
                {
                  "name": "Conv2D_13/filter:0",
                  "initializer": {
                    "name": "Conv2D_13/filter:0",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float32",
                      "shape": {
                        "dimensions": [
                          32,
                          96,
                          1,
                          1
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        32,
                        96,
                        1,
                        1
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "B",
              "value": [
                {
                  "name": "conv2d_12_1/y:0",
                  "initializer": {
                    "name": "conv2d_12_1/y:0",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float32",
                      "shape": {
                        "dimensions": [
                          32
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        32
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "Y",
              "value": [
                {
                  "name": "Conv__191:0",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        32,
                        9,
                        16
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [
            {
              "name": "dilations",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "strides",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "kernel_shape",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "pads",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "0",
                  "0",
                  "0",
                  "0"
                ]
              }
            },
            {
              "name": "group",
              "type": "int64",
              "value": {
                "type": "bigint",
                "value": "1"
              }
            }
          ],
          "type": {
            "name": "Conv",
            "module": "ai.onnx",
            "version": 11,
            "description": "The convolution operator consumes an input tensor and a filter, and\ncomputes the output.",
            "attributes": [
              {
                "name": "auto_pad",
                "type": "string",
                "required": false,
                "default": "NOTSET",
                "description": "auto_pad must be either NOTSET, SAME_UPPER, SAME_LOWER or VALID. Where default value is NOTSET, which means explicit padding is used. SAME_UPPER or SAME_LOWER mean pad the input so that `output_shape[i] = ceil(input_shape[i] / strides[i])` for each axis `i`. The padding is split between the two sides equally or almost equally (depending on whether it is even or odd). In case the padding is an odd number, the extra padding is added at the end for SAME_UPPER and at the beginning for SAME_LOWER."
              },
              {
                "name": "dilations",
                "type": "int64[]",
                "required": false,
                "description": "dilation value along each spatial axis of the filter. If not present, the dilation defaults is 1 along each spatial axis."
              },
              {
                "name": "group",
                "type": "int64",
                "required": false,
                "default": 1,
                "description": "number of groups input channels and output channels are divided into."
              },
              {
                "name": "kernel_shape",
                "type": "int64[]",
                "required": false,
                "description": "The shape of the convolution kernel. If not present, should be inferred from input W."
              },
              {
                "name": "pads",
                "type": "int64[]",
                "required": false,
                "description": "Padding for the beginning and ending along each spatial axis, it can take any value greater than or equal to 0. The value represent the number of pixels added to the beginning and end part of the corresponding axis. `pads` format should be as follow [x1_begin, x2_begin...x1_end, x2_end,...], where xi_begin the number of pixels added at the beginning of axis `i` and xi_end, the number of pixels added at the end of axis `i`. This attribute cannot be used simultaneously with auto_pad attribute. If not present, the padding defaults to 0 along start and end of each spatial axis."
              },
              {
                "name": "strides",
                "type": "int64[]",
                "required": false,
                "description": "Stride along each spatial axis. If not present, the stride defaults is 1 along each spatial axis."
              }
            ],
            "inputs": [
              {
                "name": "X",
                "type": "T",
                "description": "Input data tensor from previous layer; has size (N x C x H x W), where N is the batch size, C is the number of channels, and H and W are the height and width. Note that this is for the 2D image. Otherwise the size is (N x C x D1 x D2 ... x Dn). Optionally, if dimension denotation is in effect, the operation expects input data tensor to arrive with the dimension denotation of [DATA_BATCH, DATA_CHANNEL, DATA_FEATURE, DATA_FEATURE ...]."
              },
              {
                "name": "W",
                "type": "T",
                "description": "The weight tensor that will be used in the convolutions; has size (M x C/group x kH x kW), where C is the number of channels, and kH and kW are the height and width of the kernel, and M is the number of feature maps. For more than 2 dimensions, the kernel shape will be (M x C/group x k1 x k2 x ... x kn), where (k1 x k2 x ... kn) is the dimension of the kernel. Optionally, if dimension denotation is in effect, the operation expects the weight tensor to arrive with the dimension denotation of [FILTER_OUT_CHANNEL, FILTER_IN_CHANNEL, FILTER_SPATIAL, FILTER_SPATIAL ...]. Assuming zero based indices for the shape array, X.shape[1] == (W.shape[1] * group) == C and W.shape[0] mod G == 0. Or in other words FILTER_IN_CHANNEL multiplied by the number of groups should be equal to DATA_CHANNEL and the number of feature maps M should be a multiple of the number of groups G."
              },
              {
                "name": "B",
                "type": "T",
                "option": "optional",
                "description": "Optional 1D bias to be added to the convolution, has size of M."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "Y",
                "type": "T",
                "description": "Output data tensor that contains the result of the convolution. The output dimensions are functions of the kernel size, stride size, and pad lengths."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain input and output types to float tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "conv",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[1, 1, 1, 1],\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 21.0, 27.0, 33.0, 24.0],  # (1, 1, 5, 5) output tensor\n                [33.0, 54.0, 63.0, 72.0, 51.0],\n                [63.0, 99.0, 108.0, 117.0, 81.0],\n                [93.0, 144.0, 153.0, 162.0, 111.0],\n                [72.0, 111.0, 117.0, 123.0, 84.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_basic_conv_with_padding\",\n)\n\n# Convolution without padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[0, 0, 0, 0],\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 63.0, 72.0],  # (1, 1, 3, 3) output tensor\n                [99.0, 108.0, 117.0],\n                [144.0, 153.0, 162.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_basic_conv_without_padding\",\n)"
              },
              {
                "summary": "conv_with_autopad_same",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with auto_pad='SAME_LOWER' and strides=2\nnode = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    auto_pad=\"SAME_LOWER\",\n    kernel_shape=[3, 3],\n    strides=[2, 2],\n)\ny = np.array(\n    [[[[12.0, 27.0, 24.0], [63.0, 108.0, 81.0], [72.0, 117.0, 84.0]]]]\n).astype(np.float32)\nexpect(node, inputs=[x, W], outputs=[y], name=\"test_conv_with_autopad_same\")"
              },
              {
                "summary": "conv_with_strides",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 7, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n                [25.0, 26.0, 27.0, 28.0, 29.0],\n                [30.0, 31.0, 32.0, 33.0, 34.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with strides=2 and padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 1, 1, 1],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 27.0, 24.0],  # (1, 1, 4, 3) output tensor\n                [63.0, 108.0, 81.0],\n                [123.0, 198.0, 141.0],\n                [112.0, 177.0, 124.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_conv_with_strides_padding\",\n)\n\n# Convolution with strides=2 and no padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[0, 0, 0, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 72.0],  # (1, 1, 3, 2) output tensor\n                [144.0, 162.0],\n                [234.0, 252.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_conv_with_strides_no_padding\",\n)\n\n# Convolution with strides=2 and padding only along one dimension (the H dimension in NxCxHxW tensor)\nnode_with_asymmetric_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 0, 1, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_asymmetric_padding = np.array(\n    [\n        [\n            [\n                [21.0, 33.0],  # (1, 1, 4, 2) output tensor\n                [99.0, 117.0],\n                [189.0, 207.0],\n                [171.0, 183.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_asymmetric_padding,\n    inputs=[x, W],\n    outputs=[y_with_asymmetric_padding],\n    name=\"test_conv_with_strides_and_asymmetric_padding\",\n)"
              }
            ],
            "category": "Layer"
          }
        },
        {
          "name": "Conv__194",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "X",
              "value": [
                {
                  "name": "Conv__191:0",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        32,
                        9,
                        16
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "W",
              "value": [
                {
                  "name": "Conv2D_14/filter:0",
                  "initializer": {
                    "name": "Conv2D_14/filter:0",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float32",
                      "shape": {
                        "dimensions": [
                          128,
                          32,
                          1,
                          1
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        128,
                        32,
                        1,
                        1
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "B",
              "value": [
                {
                  "name": "conv2d_13_1/y:0",
                  "initializer": {
                    "name": "conv2d_13_1/y:0",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float32",
                      "shape": {
                        "dimensions": [
                          128
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        128
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "Y",
              "value": [
                {
                  "name": "Conv__194:0",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        128,
                        9,
                        16
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [
            {
              "name": "dilations",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "strides",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "kernel_shape",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "pads",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "0",
                  "0",
                  "0",
                  "0"
                ]
              }
            },
            {
              "name": "group",
              "type": "int64",
              "value": {
                "type": "bigint",
                "value": "1"
              }
            }
          ],
          "type": {
            "name": "Conv",
            "module": "ai.onnx",
            "version": 11,
            "description": "The convolution operator consumes an input tensor and a filter, and\ncomputes the output.",
            "attributes": [
              {
                "name": "auto_pad",
                "type": "string",
                "required": false,
                "default": "NOTSET",
                "description": "auto_pad must be either NOTSET, SAME_UPPER, SAME_LOWER or VALID. Where default value is NOTSET, which means explicit padding is used. SAME_UPPER or SAME_LOWER mean pad the input so that `output_shape[i] = ceil(input_shape[i] / strides[i])` for each axis `i`. The padding is split between the two sides equally or almost equally (depending on whether it is even or odd). In case the padding is an odd number, the extra padding is added at the end for SAME_UPPER and at the beginning for SAME_LOWER."
              },
              {
                "name": "dilations",
                "type": "int64[]",
                "required": false,
                "description": "dilation value along each spatial axis of the filter. If not present, the dilation defaults is 1 along each spatial axis."
              },
              {
                "name": "group",
                "type": "int64",
                "required": false,
                "default": 1,
                "description": "number of groups input channels and output channels are divided into."
              },
              {
                "name": "kernel_shape",
                "type": "int64[]",
                "required": false,
                "description": "The shape of the convolution kernel. If not present, should be inferred from input W."
              },
              {
                "name": "pads",
                "type": "int64[]",
                "required": false,
                "description": "Padding for the beginning and ending along each spatial axis, it can take any value greater than or equal to 0. The value represent the number of pixels added to the beginning and end part of the corresponding axis. `pads` format should be as follow [x1_begin, x2_begin...x1_end, x2_end,...], where xi_begin the number of pixels added at the beginning of axis `i` and xi_end, the number of pixels added at the end of axis `i`. This attribute cannot be used simultaneously with auto_pad attribute. If not present, the padding defaults to 0 along start and end of each spatial axis."
              },
              {
                "name": "strides",
                "type": "int64[]",
                "required": false,
                "description": "Stride along each spatial axis. If not present, the stride defaults is 1 along each spatial axis."
              }
            ],
            "inputs": [
              {
                "name": "X",
                "type": "T",
                "description": "Input data tensor from previous layer; has size (N x C x H x W), where N is the batch size, C is the number of channels, and H and W are the height and width. Note that this is for the 2D image. Otherwise the size is (N x C x D1 x D2 ... x Dn). Optionally, if dimension denotation is in effect, the operation expects input data tensor to arrive with the dimension denotation of [DATA_BATCH, DATA_CHANNEL, DATA_FEATURE, DATA_FEATURE ...]."
              },
              {
                "name": "W",
                "type": "T",
                "description": "The weight tensor that will be used in the convolutions; has size (M x C/group x kH x kW), where C is the number of channels, and kH and kW are the height and width of the kernel, and M is the number of feature maps. For more than 2 dimensions, the kernel shape will be (M x C/group x k1 x k2 x ... x kn), where (k1 x k2 x ... kn) is the dimension of the kernel. Optionally, if dimension denotation is in effect, the operation expects the weight tensor to arrive with the dimension denotation of [FILTER_OUT_CHANNEL, FILTER_IN_CHANNEL, FILTER_SPATIAL, FILTER_SPATIAL ...]. Assuming zero based indices for the shape array, X.shape[1] == (W.shape[1] * group) == C and W.shape[0] mod G == 0. Or in other words FILTER_IN_CHANNEL multiplied by the number of groups should be equal to DATA_CHANNEL and the number of feature maps M should be a multiple of the number of groups G."
              },
              {
                "name": "B",
                "type": "T",
                "option": "optional",
                "description": "Optional 1D bias to be added to the convolution, has size of M."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "Y",
                "type": "T",
                "description": "Output data tensor that contains the result of the convolution. The output dimensions are functions of the kernel size, stride size, and pad lengths."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain input and output types to float tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "conv",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[1, 1, 1, 1],\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 21.0, 27.0, 33.0, 24.0],  # (1, 1, 5, 5) output tensor\n                [33.0, 54.0, 63.0, 72.0, 51.0],\n                [63.0, 99.0, 108.0, 117.0, 81.0],\n                [93.0, 144.0, 153.0, 162.0, 111.0],\n                [72.0, 111.0, 117.0, 123.0, 84.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_basic_conv_with_padding\",\n)\n\n# Convolution without padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[0, 0, 0, 0],\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 63.0, 72.0],  # (1, 1, 3, 3) output tensor\n                [99.0, 108.0, 117.0],\n                [144.0, 153.0, 162.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_basic_conv_without_padding\",\n)"
              },
              {
                "summary": "conv_with_autopad_same",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with auto_pad='SAME_LOWER' and strides=2\nnode = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    auto_pad=\"SAME_LOWER\",\n    kernel_shape=[3, 3],\n    strides=[2, 2],\n)\ny = np.array(\n    [[[[12.0, 27.0, 24.0], [63.0, 108.0, 81.0], [72.0, 117.0, 84.0]]]]\n).astype(np.float32)\nexpect(node, inputs=[x, W], outputs=[y], name=\"test_conv_with_autopad_same\")"
              },
              {
                "summary": "conv_with_strides",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 7, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n                [25.0, 26.0, 27.0, 28.0, 29.0],\n                [30.0, 31.0, 32.0, 33.0, 34.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with strides=2 and padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 1, 1, 1],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 27.0, 24.0],  # (1, 1, 4, 3) output tensor\n                [63.0, 108.0, 81.0],\n                [123.0, 198.0, 141.0],\n                [112.0, 177.0, 124.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_conv_with_strides_padding\",\n)\n\n# Convolution with strides=2 and no padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[0, 0, 0, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 72.0],  # (1, 1, 3, 2) output tensor\n                [144.0, 162.0],\n                [234.0, 252.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_conv_with_strides_no_padding\",\n)\n\n# Convolution with strides=2 and padding only along one dimension (the H dimension in NxCxHxW tensor)\nnode_with_asymmetric_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 0, 1, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_asymmetric_padding = np.array(\n    [\n        [\n            [\n                [21.0, 33.0],  # (1, 1, 4, 2) output tensor\n                [99.0, 117.0],\n                [189.0, 207.0],\n                [171.0, 183.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_asymmetric_padding,\n    inputs=[x, W],\n    outputs=[y_with_asymmetric_padding],\n    name=\"test_conv_with_strides_and_asymmetric_padding\",\n)"
              }
            ],
            "category": "Layer"
          }
        },
        {
          "name": "add_3",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "A",
              "value": [
                {
                  "name": "Conv__194:0",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        128,
                        9,
                        16
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "B",
              "value": [
                {
                  "name": "const_fold_opt__408",
                  "initializer": {
                    "name": "const_fold_opt__408",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float32",
                      "shape": {
                        "dimensions": [
                          1,
                          1,
                          1,
                          1
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        1,
                        1,
                        1
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "C",
              "value": [
                {
                  "name": "add_3:0",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        128,
                        9,
                        16
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "Add",
            "module": "ai.onnx",
            "version": 14,
            "description": "Performs element-wise binary addition (with Numpy-style broadcasting support).\n\nThis operator supports **multidirectional (i.e., Numpy-style) broadcasting**; for more details please check [the doc](https://github.com/onnx/onnx/blob/master/docs/Broadcasting.md).\n\n(Opset 14 change): Extend supported types to include uint8, int8, uint16, and int16.\n",
            "inputs": [
              {
                "name": "A",
                "type": "T",
                "description": "First operand."
              },
              {
                "name": "B",
                "type": "T",
                "description": "Second operand."
              }
            ],
            "min_input": 2,
            "max_input": 2,
            "outputs": [
              {
                "name": "C",
                "type": "T",
                "description": "Result, has same element type as two inputs"
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "type_constraints": [
              {
                "description": "Constrain input and output types to all numeric tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(uint8)",
                  "tensor(uint16)",
                  "tensor(uint32)",
                  "tensor(uint64)",
                  "tensor(int8)",
                  "tensor(int16)",
                  "tensor(int32)",
                  "tensor(int64)",
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)",
                  "tensor(bfloat16)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "add",
                "code": "node = onnx.helper.make_node(\n    \"Add\",\n    inputs=[\"x\", \"y\"],\n    outputs=[\"sum\"],\n)\n\nx = np.random.randn(3, 4, 5).astype(np.float32)\ny = np.random.randn(3, 4, 5).astype(np.float32)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add\")\n\nx = np.random.randint(24, size=(3, 4, 5), dtype=np.int8)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.int8)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add_int8\")\n\nx = np.random.randint(24, size=(3, 4, 5), dtype=np.int16)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.int16)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add_int16\")\n\nx = np.random.randint(24, size=(3, 4, 5), dtype=np.uint8)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.uint8)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add_uint8\")\n\nx = np.random.randint(24, size=(3, 4, 5), dtype=np.uint16)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.uint16)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add_uint16\")\n\nx = np.random.randint(24, size=(3, 4, 5), dtype=np.uint32)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.uint32)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add_uint32\")\n\nx = np.random.randint(24, size=(3, 4, 5), dtype=np.uint64)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.uint64)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add_uint64\")"
              },
              {
                "summary": "add_broadcast",
                "code": "node = onnx.helper.make_node(\n    \"Add\",\n    inputs=[\"x\", \"y\"],\n    outputs=[\"sum\"],\n)\n\nx = np.random.randn(3, 4, 5).astype(np.float32)\ny = np.random.randn(5).astype(np.float32)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add_bcast\")"
              }
            ]
          }
        },
        {
          "name": "Relu6_3",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "input",
              "value": [
                {
                  "name": "add_3:0",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        128,
                        9,
                        16
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "min",
              "value": [
                {
                  "name": "298",
                  "initializer": {
                    "category": "Constant",
                    "encoding": "|",
                    "values": {
                      "0": 0
                    },
                    "type": {
                      "dataType": "float32",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            },
            {
              "name": "max",
              "value": [
                {
                  "name": "299",
                  "initializer": {
                    "category": "Constant",
                    "encoding": "|",
                    "values": {
                      "0": 6
                    },
                    "type": {
                      "dataType": "float32",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "output",
              "value": [
                {
                  "name": "Relu6_3:0",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        128,
                        9,
                        16
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "Clip",
            "module": "ai.onnx",
            "version": 13,
            "description": "Clip operator limits the given input within an interval. The interval is\nspecified by the inputs 'min' and 'max'. They default to\nnumeric_limits::lowest() and numeric_limits::max(), respectively.\nWhen 'min' is greater than 'max', the clip operator sets all the 'input' values to\nthe value of 'max'. Thus, this is equivalent to 'Min(max, Max(input, min))'.\n",
            "inputs": [
              {
                "name": "input",
                "type": "T",
                "description": "Input tensor whose elements to be clipped"
              },
              {
                "name": "min",
                "type": "T",
                "option": "optional",
                "description": "Minimum value, under which element is replaced by min. It must be a scalar(tensor of empty shape)."
              },
              {
                "name": "max",
                "type": "T",
                "option": "optional",
                "description": "Maximum value, above which element is replaced by max. It must be a scalar(tensor of empty shape)."
              }
            ],
            "min_input": 1,
            "max_input": 3,
            "outputs": [
              {
                "name": "output",
                "type": "T",
                "description": "Output tensor with clipped input elements"
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "1 - 3",
            "type_constraints": [
              {
                "description": "Constrain input and output types to all numeric tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(uint8)",
                  "tensor(uint16)",
                  "tensor(uint32)",
                  "tensor(uint64)",
                  "tensor(int8)",
                  "tensor(int16)",
                  "tensor(int32)",
                  "tensor(int64)",
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)",
                  "tensor(bfloat16)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "clip",
                "code": "node = onnx.helper.make_node(\n    \"Clip\",\n    inputs=[\"x\", \"min\", \"max\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([-2, 0, 2]).astype(np.float32)\nmin_val = np.float32(-1)\nmax_val = np.float32(1)\ny = np.clip(x, min_val, max_val)  # expected output [-1., 0., 1.]\nexpect(\n    node, inputs=[x, min_val, max_val], outputs=[y], name=\"test_clip_example\"\n)\n\nx = np.random.randn(3, 4, 5).astype(np.float32)\ny = np.clip(x, min_val, max_val)\nexpect(node, inputs=[x, min_val, max_val], outputs=[y], name=\"test_clip\")\nnode = onnx.helper.make_node(\n    \"Clip\",\n    inputs=[\"x\", \"min\", \"max\"],\n    outputs=[\"y\"],\n)\n\nmin_val = np.float32(-5)\nmax_val = np.float32(5)\n\nx = np.array([-1, 0, 1]).astype(np.float32)\ny = np.array([-1, 0, 1]).astype(np.float32)\nexpect(\n    node, inputs=[x, min_val, max_val], outputs=[y], name=\"test_clip_inbounds\"\n)\n\nx = np.array([-6, 0, 6]).astype(np.float32)\ny = np.array([-5, 0, 5]).astype(np.float32)\nexpect(\n    node, inputs=[x, min_val, max_val], outputs=[y], name=\"test_clip_outbounds\"\n)\n\nx = np.array([-1, 0, 6]).astype(np.float32)\ny = np.array([-1, 0, 5]).astype(np.float32)\nexpect(\n    node,\n    inputs=[x, min_val, max_val],\n    outputs=[y],\n    name=\"test_clip_splitbounds\",\n)\n\nx = np.array([-2, 0, 6]).astype(np.float32)\ny = np.array([1, 1, 1]).astype(np.float32)\nmin_val = np.float32(2)\nmax_val = np.float32(1)\nexpect(\n    node,\n    inputs=[x, min_val, max_val],\n    outputs=[y],\n    name=\"test_clip_min_greater_than_max\",\n)"
              },
              {
                "summary": "clip_default",
                "code": "node = onnx.helper.make_node(\n    \"Clip\",\n    inputs=[\"x\", \"min\"],\n    outputs=[\"y\"],\n)\nmin_val = np.float32(0)\nx = np.random.randn(3, 4, 5).astype(np.float32)\ny = np.clip(x, min_val, np.inf)\nexpect(node, inputs=[x, min_val], outputs=[y], name=\"test_clip_default_min\")\n\nno_min = \"\"  # optional input, not supplied\nnode = onnx.helper.make_node(\n    \"Clip\",\n    inputs=[\"x\", no_min, \"max\"],\n    outputs=[\"y\"],\n)\nmax_val = np.float32(0)\nx = np.random.randn(3, 4, 5).astype(np.float32)\ny = np.clip(x, -np.inf, max_val)\nexpect(node, inputs=[x, max_val], outputs=[y], name=\"test_clip_default_max\")\n\nno_max = \"\"  # optional input, not supplied\nnode = onnx.helper.make_node(\n    \"Clip\",\n    inputs=[\"x\", no_min, no_max],\n    outputs=[\"y\"],\n)\n\nx = np.array([-1, 0, 1]).astype(np.float32)\ny = np.array([-1, 0, 1]).astype(np.float32)\nexpect(node, inputs=[x], outputs=[y], name=\"test_clip_default_inbounds\")"
              },
              {
                "summary": "clip_default_int8",
                "code": "node = onnx.helper.make_node(\n    \"Clip\",\n    inputs=[\"x\", \"min\"],\n    outputs=[\"y\"],\n)\nmin_val = np.int8(0)\nx = np.random.randn(3, 4, 5).astype(np.int8)\ny = np.clip(x, min_val, np.iinfo(np.int8).max)\nexpect(\n    node, inputs=[x, min_val], outputs=[y], name=\"test_clip_default_int8_min\"\n)\n\nno_min = \"\"  # optional input, not supplied\nnode = onnx.helper.make_node(\n    \"Clip\",\n    inputs=[\"x\", no_min, \"max\"],\n    outputs=[\"y\"],\n)\nmax_val = np.int8(0)\nx = np.random.randn(3, 4, 5).astype(np.int8)\ny = np.clip(x, np.iinfo(np.int8).min, max_val)\nexpect(\n    node, inputs=[x, max_val], outputs=[y], name=\"test_clip_default_int8_max\"\n)\n\nno_max = \"\"  # optional input, not supplied\nnode = onnx.helper.make_node(\n    \"Clip\",\n    inputs=[\"x\", no_min, no_max],\n    outputs=[\"y\"],\n)\n\nx = np.array([-1, 0, 1]).astype(np.int8)\ny = np.array([-1, 0, 1]).astype(np.int8)\nexpect(node, inputs=[x], outputs=[y], name=\"test_clip_default_int8_inbounds\")"
              }
            ],
            "category": "Activation"
          }
        },
        {
          "name": "mul_6",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "A",
              "value": [
                {
                  "name": "mul_3/y:0",
                  "initializer": {
                    "name": "mul_3/y:0",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float32",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            },
            {
              "name": "B",
              "value": [
                {
                  "name": "Relu6_3:0",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        128,
                        9,
                        16
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "C",
              "value": [
                {
                  "name": "mul_6:0",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        128,
                        9,
                        16
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "Mul",
            "module": "ai.onnx",
            "version": 14,
            "description": "Performs element-wise binary multiplication (with Numpy-style broadcasting support).\n\nThis operator supports **multidirectional (i.e., Numpy-style) broadcasting**; for more details please check [the doc](https://github.com/onnx/onnx/blob/master/docs/Broadcasting.md).\n\n(Opset 14 change): Extend supported types to include uint8, int8, uint16, and int16.\n",
            "inputs": [
              {
                "name": "A",
                "type": "T",
                "description": "First operand."
              },
              {
                "name": "B",
                "type": "T",
                "description": "Second operand."
              }
            ],
            "min_input": 2,
            "max_input": 2,
            "outputs": [
              {
                "name": "C",
                "type": "T",
                "description": "Result, has same element type as two inputs"
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "type_constraints": [
              {
                "description": "Constrain input and output types to all numeric tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(uint8)",
                  "tensor(uint16)",
                  "tensor(uint32)",
                  "tensor(uint64)",
                  "tensor(int8)",
                  "tensor(int16)",
                  "tensor(int32)",
                  "tensor(int64)",
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)",
                  "tensor(bfloat16)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "mul",
                "code": "node = onnx.helper.make_node(\n    \"Mul\",\n    inputs=[\"x\", \"y\"],\n    outputs=[\"z\"],\n)\n\nx = np.array([1, 2, 3]).astype(np.float32)\ny = np.array([4, 5, 6]).astype(np.float32)\nz = x * y  # expected output [4., 10., 18.]\nexpect(node, inputs=[x, y], outputs=[z], name=\"test_mul_example\")\n\nx = np.random.randn(3, 4, 5).astype(np.float32)\ny = np.random.randn(3, 4, 5).astype(np.float32)\nz = x * y\nexpect(node, inputs=[x, y], outputs=[z], name=\"test_mul\")\n\nx = np.random.randint(4, size=(3, 4, 5), dtype=np.int8)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.int8)\nz = x * y\nexpect(node, inputs=[x, y], outputs=[z], name=\"test_mul_int8\")\n\nx = np.random.randint(4, size=(3, 4, 5), dtype=np.int16)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.int16)\nz = x * y\nexpect(node, inputs=[x, y], outputs=[z], name=\"test_mul_int16\")\n\nx = np.random.randint(4, size=(3, 4, 5), dtype=np.uint8)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.uint8)\nz = x * y\nexpect(node, inputs=[x, y], outputs=[z], name=\"test_mul_uint8\")\n\nx = np.random.randint(4, size=(3, 4, 5), dtype=np.uint16)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.uint16)\nz = x * y\nexpect(node, inputs=[x, y], outputs=[z], name=\"test_mul_uint16\")\n\nx = np.random.randint(4, size=(3, 4, 5), dtype=np.uint32)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.uint32)\nz = x * y\nexpect(node, inputs=[x, y], outputs=[z], name=\"test_mul_uint32\")\n\nx = np.random.randint(4, size=(3, 4, 5), dtype=np.uint64)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.uint64)\nz = x * y\nexpect(node, inputs=[x, y], outputs=[z], name=\"test_mul_uint64\")"
              },
              {
                "summary": "mul_broadcast",
                "code": "node = onnx.helper.make_node(\n    \"Mul\",\n    inputs=[\"x\", \"y\"],\n    outputs=[\"z\"],\n)\n\nx = np.random.randn(3, 4, 5).astype(np.float32)\ny = np.random.randn(5).astype(np.float32)\nz = x * y\nexpect(node, inputs=[x, y], outputs=[z], name=\"test_mul_bcast\")"
              }
            ]
          }
        },
        {
          "name": "mul_7",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "A",
              "value": [
                {
                  "name": "Conv__194:0",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        128,
                        9,
                        16
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "B",
              "value": [
                {
                  "name": "mul_6:0",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        128,
                        9,
                        16
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "C",
              "value": [
                {
                  "name": "mul_7:0",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        128,
                        9,
                        16
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "Mul",
            "module": "ai.onnx",
            "version": 14,
            "description": "Performs element-wise binary multiplication (with Numpy-style broadcasting support).\n\nThis operator supports **multidirectional (i.e., Numpy-style) broadcasting**; for more details please check [the doc](https://github.com/onnx/onnx/blob/master/docs/Broadcasting.md).\n\n(Opset 14 change): Extend supported types to include uint8, int8, uint16, and int16.\n",
            "inputs": [
              {
                "name": "A",
                "type": "T",
                "description": "First operand."
              },
              {
                "name": "B",
                "type": "T",
                "description": "Second operand."
              }
            ],
            "min_input": 2,
            "max_input": 2,
            "outputs": [
              {
                "name": "C",
                "type": "T",
                "description": "Result, has same element type as two inputs"
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "type_constraints": [
              {
                "description": "Constrain input and output types to all numeric tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(uint8)",
                  "tensor(uint16)",
                  "tensor(uint32)",
                  "tensor(uint64)",
                  "tensor(int8)",
                  "tensor(int16)",
                  "tensor(int32)",
                  "tensor(int64)",
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)",
                  "tensor(bfloat16)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "mul",
                "code": "node = onnx.helper.make_node(\n    \"Mul\",\n    inputs=[\"x\", \"y\"],\n    outputs=[\"z\"],\n)\n\nx = np.array([1, 2, 3]).astype(np.float32)\ny = np.array([4, 5, 6]).astype(np.float32)\nz = x * y  # expected output [4., 10., 18.]\nexpect(node, inputs=[x, y], outputs=[z], name=\"test_mul_example\")\n\nx = np.random.randn(3, 4, 5).astype(np.float32)\ny = np.random.randn(3, 4, 5).astype(np.float32)\nz = x * y\nexpect(node, inputs=[x, y], outputs=[z], name=\"test_mul\")\n\nx = np.random.randint(4, size=(3, 4, 5), dtype=np.int8)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.int8)\nz = x * y\nexpect(node, inputs=[x, y], outputs=[z], name=\"test_mul_int8\")\n\nx = np.random.randint(4, size=(3, 4, 5), dtype=np.int16)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.int16)\nz = x * y\nexpect(node, inputs=[x, y], outputs=[z], name=\"test_mul_int16\")\n\nx = np.random.randint(4, size=(3, 4, 5), dtype=np.uint8)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.uint8)\nz = x * y\nexpect(node, inputs=[x, y], outputs=[z], name=\"test_mul_uint8\")\n\nx = np.random.randint(4, size=(3, 4, 5), dtype=np.uint16)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.uint16)\nz = x * y\nexpect(node, inputs=[x, y], outputs=[z], name=\"test_mul_uint16\")\n\nx = np.random.randint(4, size=(3, 4, 5), dtype=np.uint32)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.uint32)\nz = x * y\nexpect(node, inputs=[x, y], outputs=[z], name=\"test_mul_uint32\")\n\nx = np.random.randint(4, size=(3, 4, 5), dtype=np.uint64)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.uint64)\nz = x * y\nexpect(node, inputs=[x, y], outputs=[z], name=\"test_mul_uint64\")"
              },
              {
                "summary": "mul_broadcast",
                "code": "node = onnx.helper.make_node(\n    \"Mul\",\n    inputs=[\"x\", \"y\"],\n    outputs=[\"z\"],\n)\n\nx = np.random.randn(3, 4, 5).astype(np.float32)\ny = np.random.randn(5).astype(np.float32)\nz = x * y\nexpect(node, inputs=[x, y], outputs=[z], name=\"test_mul_bcast\")"
              }
            ]
          }
        },
        {
          "name": "Conv__197",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "X",
              "value": [
                {
                  "name": "mul_7:0",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        128,
                        9,
                        16
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "W",
              "value": [
                {
                  "name": "const_fold_opt__381",
                  "initializer": {
                    "name": "const_fold_opt__381",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float32",
                      "shape": {
                        "dimensions": [
                          128,
                          1,
                          5,
                          5
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        128,
                        1,
                        5,
                        5
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "B",
              "value": [
                {
                  "name": "depthwise_conv2d_4/y:0",
                  "initializer": {
                    "name": "depthwise_conv2d_4/y:0",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float32",
                      "shape": {
                        "dimensions": [
                          128
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        128
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "Y",
              "value": [
                {
                  "name": "Conv__197:0",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        128,
                        9,
                        16
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [
            {
              "name": "dilations",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "strides",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "kernel_shape",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "5",
                  "5"
                ]
              }
            },
            {
              "name": "group",
              "type": "int64",
              "value": {
                "type": "bigint",
                "value": "128"
              }
            },
            {
              "name": "pads",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "2",
                  "2",
                  "2",
                  "2"
                ]
              }
            }
          ],
          "type": {
            "name": "Conv",
            "module": "ai.onnx",
            "version": 11,
            "description": "The convolution operator consumes an input tensor and a filter, and\ncomputes the output.",
            "attributes": [
              {
                "name": "auto_pad",
                "type": "string",
                "required": false,
                "default": "NOTSET",
                "description": "auto_pad must be either NOTSET, SAME_UPPER, SAME_LOWER or VALID. Where default value is NOTSET, which means explicit padding is used. SAME_UPPER or SAME_LOWER mean pad the input so that `output_shape[i] = ceil(input_shape[i] / strides[i])` for each axis `i`. The padding is split between the two sides equally or almost equally (depending on whether it is even or odd). In case the padding is an odd number, the extra padding is added at the end for SAME_UPPER and at the beginning for SAME_LOWER."
              },
              {
                "name": "dilations",
                "type": "int64[]",
                "required": false,
                "description": "dilation value along each spatial axis of the filter. If not present, the dilation defaults is 1 along each spatial axis."
              },
              {
                "name": "group",
                "type": "int64",
                "required": false,
                "default": 1,
                "description": "number of groups input channels and output channels are divided into."
              },
              {
                "name": "kernel_shape",
                "type": "int64[]",
                "required": false,
                "description": "The shape of the convolution kernel. If not present, should be inferred from input W."
              },
              {
                "name": "pads",
                "type": "int64[]",
                "required": false,
                "description": "Padding for the beginning and ending along each spatial axis, it can take any value greater than or equal to 0. The value represent the number of pixels added to the beginning and end part of the corresponding axis. `pads` format should be as follow [x1_begin, x2_begin...x1_end, x2_end,...], where xi_begin the number of pixels added at the beginning of axis `i` and xi_end, the number of pixels added at the end of axis `i`. This attribute cannot be used simultaneously with auto_pad attribute. If not present, the padding defaults to 0 along start and end of each spatial axis."
              },
              {
                "name": "strides",
                "type": "int64[]",
                "required": false,
                "description": "Stride along each spatial axis. If not present, the stride defaults is 1 along each spatial axis."
              }
            ],
            "inputs": [
              {
                "name": "X",
                "type": "T",
                "description": "Input data tensor from previous layer; has size (N x C x H x W), where N is the batch size, C is the number of channels, and H and W are the height and width. Note that this is for the 2D image. Otherwise the size is (N x C x D1 x D2 ... x Dn). Optionally, if dimension denotation is in effect, the operation expects input data tensor to arrive with the dimension denotation of [DATA_BATCH, DATA_CHANNEL, DATA_FEATURE, DATA_FEATURE ...]."
              },
              {
                "name": "W",
                "type": "T",
                "description": "The weight tensor that will be used in the convolutions; has size (M x C/group x kH x kW), where C is the number of channels, and kH and kW are the height and width of the kernel, and M is the number of feature maps. For more than 2 dimensions, the kernel shape will be (M x C/group x k1 x k2 x ... x kn), where (k1 x k2 x ... kn) is the dimension of the kernel. Optionally, if dimension denotation is in effect, the operation expects the weight tensor to arrive with the dimension denotation of [FILTER_OUT_CHANNEL, FILTER_IN_CHANNEL, FILTER_SPATIAL, FILTER_SPATIAL ...]. Assuming zero based indices for the shape array, X.shape[1] == (W.shape[1] * group) == C and W.shape[0] mod G == 0. Or in other words FILTER_IN_CHANNEL multiplied by the number of groups should be equal to DATA_CHANNEL and the number of feature maps M should be a multiple of the number of groups G."
              },
              {
                "name": "B",
                "type": "T",
                "option": "optional",
                "description": "Optional 1D bias to be added to the convolution, has size of M."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "Y",
                "type": "T",
                "description": "Output data tensor that contains the result of the convolution. The output dimensions are functions of the kernel size, stride size, and pad lengths."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain input and output types to float tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "conv",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[1, 1, 1, 1],\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 21.0, 27.0, 33.0, 24.0],  # (1, 1, 5, 5) output tensor\n                [33.0, 54.0, 63.0, 72.0, 51.0],\n                [63.0, 99.0, 108.0, 117.0, 81.0],\n                [93.0, 144.0, 153.0, 162.0, 111.0],\n                [72.0, 111.0, 117.0, 123.0, 84.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_basic_conv_with_padding\",\n)\n\n# Convolution without padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[0, 0, 0, 0],\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 63.0, 72.0],  # (1, 1, 3, 3) output tensor\n                [99.0, 108.0, 117.0],\n                [144.0, 153.0, 162.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_basic_conv_without_padding\",\n)"
              },
              {
                "summary": "conv_with_autopad_same",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with auto_pad='SAME_LOWER' and strides=2\nnode = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    auto_pad=\"SAME_LOWER\",\n    kernel_shape=[3, 3],\n    strides=[2, 2],\n)\ny = np.array(\n    [[[[12.0, 27.0, 24.0], [63.0, 108.0, 81.0], [72.0, 117.0, 84.0]]]]\n).astype(np.float32)\nexpect(node, inputs=[x, W], outputs=[y], name=\"test_conv_with_autopad_same\")"
              },
              {
                "summary": "conv_with_strides",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 7, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n                [25.0, 26.0, 27.0, 28.0, 29.0],\n                [30.0, 31.0, 32.0, 33.0, 34.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with strides=2 and padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 1, 1, 1],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 27.0, 24.0],  # (1, 1, 4, 3) output tensor\n                [63.0, 108.0, 81.0],\n                [123.0, 198.0, 141.0],\n                [112.0, 177.0, 124.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_conv_with_strides_padding\",\n)\n\n# Convolution with strides=2 and no padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[0, 0, 0, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 72.0],  # (1, 1, 3, 2) output tensor\n                [144.0, 162.0],\n                [234.0, 252.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_conv_with_strides_no_padding\",\n)\n\n# Convolution with strides=2 and padding only along one dimension (the H dimension in NxCxHxW tensor)\nnode_with_asymmetric_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 0, 1, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_asymmetric_padding = np.array(\n    [\n        [\n            [\n                [21.0, 33.0],  # (1, 1, 4, 2) output tensor\n                [99.0, 117.0],\n                [189.0, 207.0],\n                [171.0, 183.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_asymmetric_padding,\n    inputs=[x, W],\n    outputs=[y_with_asymmetric_padding],\n    name=\"test_conv_with_strides_and_asymmetric_padding\",\n)"
              }
            ],
            "category": "Layer"
          }
        },
        {
          "name": "add_4",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "A",
              "value": [
                {
                  "name": "Conv__197:0",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        128,
                        9,
                        16
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "B",
              "value": [
                {
                  "name": "const_fold_opt__408",
                  "initializer": {
                    "name": "const_fold_opt__408",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float32",
                      "shape": {
                        "dimensions": [
                          1,
                          1,
                          1,
                          1
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        1,
                        1,
                        1
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "C",
              "value": [
                {
                  "name": "add_4:0",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        128,
                        9,
                        16
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "Add",
            "module": "ai.onnx",
            "version": 14,
            "description": "Performs element-wise binary addition (with Numpy-style broadcasting support).\n\nThis operator supports **multidirectional (i.e., Numpy-style) broadcasting**; for more details please check [the doc](https://github.com/onnx/onnx/blob/master/docs/Broadcasting.md).\n\n(Opset 14 change): Extend supported types to include uint8, int8, uint16, and int16.\n",
            "inputs": [
              {
                "name": "A",
                "type": "T",
                "description": "First operand."
              },
              {
                "name": "B",
                "type": "T",
                "description": "Second operand."
              }
            ],
            "min_input": 2,
            "max_input": 2,
            "outputs": [
              {
                "name": "C",
                "type": "T",
                "description": "Result, has same element type as two inputs"
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "type_constraints": [
              {
                "description": "Constrain input and output types to all numeric tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(uint8)",
                  "tensor(uint16)",
                  "tensor(uint32)",
                  "tensor(uint64)",
                  "tensor(int8)",
                  "tensor(int16)",
                  "tensor(int32)",
                  "tensor(int64)",
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)",
                  "tensor(bfloat16)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "add",
                "code": "node = onnx.helper.make_node(\n    \"Add\",\n    inputs=[\"x\", \"y\"],\n    outputs=[\"sum\"],\n)\n\nx = np.random.randn(3, 4, 5).astype(np.float32)\ny = np.random.randn(3, 4, 5).astype(np.float32)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add\")\n\nx = np.random.randint(24, size=(3, 4, 5), dtype=np.int8)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.int8)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add_int8\")\n\nx = np.random.randint(24, size=(3, 4, 5), dtype=np.int16)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.int16)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add_int16\")\n\nx = np.random.randint(24, size=(3, 4, 5), dtype=np.uint8)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.uint8)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add_uint8\")\n\nx = np.random.randint(24, size=(3, 4, 5), dtype=np.uint16)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.uint16)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add_uint16\")\n\nx = np.random.randint(24, size=(3, 4, 5), dtype=np.uint32)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.uint32)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add_uint32\")\n\nx = np.random.randint(24, size=(3, 4, 5), dtype=np.uint64)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.uint64)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add_uint64\")"
              },
              {
                "summary": "add_broadcast",
                "code": "node = onnx.helper.make_node(\n    \"Add\",\n    inputs=[\"x\", \"y\"],\n    outputs=[\"sum\"],\n)\n\nx = np.random.randn(3, 4, 5).astype(np.float32)\ny = np.random.randn(5).astype(np.float32)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add_bcast\")"
              }
            ]
          }
        },
        {
          "name": "Relu6_4",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "input",
              "value": [
                {
                  "name": "add_4:0",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        128,
                        9,
                        16
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "min",
              "value": [
                {
                  "name": "300",
                  "initializer": {
                    "category": "Constant",
                    "encoding": "|",
                    "values": {
                      "0": 0
                    },
                    "type": {
                      "dataType": "float32",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            },
            {
              "name": "max",
              "value": [
                {
                  "name": "301",
                  "initializer": {
                    "category": "Constant",
                    "encoding": "|",
                    "values": {
                      "0": 6
                    },
                    "type": {
                      "dataType": "float32",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "output",
              "value": [
                {
                  "name": "Relu6_4:0",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        128,
                        9,
                        16
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "Clip",
            "module": "ai.onnx",
            "version": 13,
            "description": "Clip operator limits the given input within an interval. The interval is\nspecified by the inputs 'min' and 'max'. They default to\nnumeric_limits::lowest() and numeric_limits::max(), respectively.\nWhen 'min' is greater than 'max', the clip operator sets all the 'input' values to\nthe value of 'max'. Thus, this is equivalent to 'Min(max, Max(input, min))'.\n",
            "inputs": [
              {
                "name": "input",
                "type": "T",
                "description": "Input tensor whose elements to be clipped"
              },
              {
                "name": "min",
                "type": "T",
                "option": "optional",
                "description": "Minimum value, under which element is replaced by min. It must be a scalar(tensor of empty shape)."
              },
              {
                "name": "max",
                "type": "T",
                "option": "optional",
                "description": "Maximum value, above which element is replaced by max. It must be a scalar(tensor of empty shape)."
              }
            ],
            "min_input": 1,
            "max_input": 3,
            "outputs": [
              {
                "name": "output",
                "type": "T",
                "description": "Output tensor with clipped input elements"
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "1 - 3",
            "type_constraints": [
              {
                "description": "Constrain input and output types to all numeric tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(uint8)",
                  "tensor(uint16)",
                  "tensor(uint32)",
                  "tensor(uint64)",
                  "tensor(int8)",
                  "tensor(int16)",
                  "tensor(int32)",
                  "tensor(int64)",
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)",
                  "tensor(bfloat16)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "clip",
                "code": "node = onnx.helper.make_node(\n    \"Clip\",\n    inputs=[\"x\", \"min\", \"max\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([-2, 0, 2]).astype(np.float32)\nmin_val = np.float32(-1)\nmax_val = np.float32(1)\ny = np.clip(x, min_val, max_val)  # expected output [-1., 0., 1.]\nexpect(\n    node, inputs=[x, min_val, max_val], outputs=[y], name=\"test_clip_example\"\n)\n\nx = np.random.randn(3, 4, 5).astype(np.float32)\ny = np.clip(x, min_val, max_val)\nexpect(node, inputs=[x, min_val, max_val], outputs=[y], name=\"test_clip\")\nnode = onnx.helper.make_node(\n    \"Clip\",\n    inputs=[\"x\", \"min\", \"max\"],\n    outputs=[\"y\"],\n)\n\nmin_val = np.float32(-5)\nmax_val = np.float32(5)\n\nx = np.array([-1, 0, 1]).astype(np.float32)\ny = np.array([-1, 0, 1]).astype(np.float32)\nexpect(\n    node, inputs=[x, min_val, max_val], outputs=[y], name=\"test_clip_inbounds\"\n)\n\nx = np.array([-6, 0, 6]).astype(np.float32)\ny = np.array([-5, 0, 5]).astype(np.float32)\nexpect(\n    node, inputs=[x, min_val, max_val], outputs=[y], name=\"test_clip_outbounds\"\n)\n\nx = np.array([-1, 0, 6]).astype(np.float32)\ny = np.array([-1, 0, 5]).astype(np.float32)\nexpect(\n    node,\n    inputs=[x, min_val, max_val],\n    outputs=[y],\n    name=\"test_clip_splitbounds\",\n)\n\nx = np.array([-2, 0, 6]).astype(np.float32)\ny = np.array([1, 1, 1]).astype(np.float32)\nmin_val = np.float32(2)\nmax_val = np.float32(1)\nexpect(\n    node,\n    inputs=[x, min_val, max_val],\n    outputs=[y],\n    name=\"test_clip_min_greater_than_max\",\n)"
              },
              {
                "summary": "clip_default",
                "code": "node = onnx.helper.make_node(\n    \"Clip\",\n    inputs=[\"x\", \"min\"],\n    outputs=[\"y\"],\n)\nmin_val = np.float32(0)\nx = np.random.randn(3, 4, 5).astype(np.float32)\ny = np.clip(x, min_val, np.inf)\nexpect(node, inputs=[x, min_val], outputs=[y], name=\"test_clip_default_min\")\n\nno_min = \"\"  # optional input, not supplied\nnode = onnx.helper.make_node(\n    \"Clip\",\n    inputs=[\"x\", no_min, \"max\"],\n    outputs=[\"y\"],\n)\nmax_val = np.float32(0)\nx = np.random.randn(3, 4, 5).astype(np.float32)\ny = np.clip(x, -np.inf, max_val)\nexpect(node, inputs=[x, max_val], outputs=[y], name=\"test_clip_default_max\")\n\nno_max = \"\"  # optional input, not supplied\nnode = onnx.helper.make_node(\n    \"Clip\",\n    inputs=[\"x\", no_min, no_max],\n    outputs=[\"y\"],\n)\n\nx = np.array([-1, 0, 1]).astype(np.float32)\ny = np.array([-1, 0, 1]).astype(np.float32)\nexpect(node, inputs=[x], outputs=[y], name=\"test_clip_default_inbounds\")"
              },
              {
                "summary": "clip_default_int8",
                "code": "node = onnx.helper.make_node(\n    \"Clip\",\n    inputs=[\"x\", \"min\"],\n    outputs=[\"y\"],\n)\nmin_val = np.int8(0)\nx = np.random.randn(3, 4, 5).astype(np.int8)\ny = np.clip(x, min_val, np.iinfo(np.int8).max)\nexpect(\n    node, inputs=[x, min_val], outputs=[y], name=\"test_clip_default_int8_min\"\n)\n\nno_min = \"\"  # optional input, not supplied\nnode = onnx.helper.make_node(\n    \"Clip\",\n    inputs=[\"x\", no_min, \"max\"],\n    outputs=[\"y\"],\n)\nmax_val = np.int8(0)\nx = np.random.randn(3, 4, 5).astype(np.int8)\ny = np.clip(x, np.iinfo(np.int8).min, max_val)\nexpect(\n    node, inputs=[x, max_val], outputs=[y], name=\"test_clip_default_int8_max\"\n)\n\nno_max = \"\"  # optional input, not supplied\nnode = onnx.helper.make_node(\n    \"Clip\",\n    inputs=[\"x\", no_min, no_max],\n    outputs=[\"y\"],\n)\n\nx = np.array([-1, 0, 1]).astype(np.int8)\ny = np.array([-1, 0, 1]).astype(np.int8)\nexpect(node, inputs=[x], outputs=[y], name=\"test_clip_default_int8_inbounds\")"
              }
            ],
            "category": "Activation"
          }
        },
        {
          "name": "mul_8",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "A",
              "value": [
                {
                  "name": "mul_3/y:0",
                  "initializer": {
                    "name": "mul_3/y:0",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float32",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            },
            {
              "name": "B",
              "value": [
                {
                  "name": "Relu6_4:0",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        128,
                        9,
                        16
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "C",
              "value": [
                {
                  "name": "mul_8:0",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        128,
                        9,
                        16
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "Mul",
            "module": "ai.onnx",
            "version": 14,
            "description": "Performs element-wise binary multiplication (with Numpy-style broadcasting support).\n\nThis operator supports **multidirectional (i.e., Numpy-style) broadcasting**; for more details please check [the doc](https://github.com/onnx/onnx/blob/master/docs/Broadcasting.md).\n\n(Opset 14 change): Extend supported types to include uint8, int8, uint16, and int16.\n",
            "inputs": [
              {
                "name": "A",
                "type": "T",
                "description": "First operand."
              },
              {
                "name": "B",
                "type": "T",
                "description": "Second operand."
              }
            ],
            "min_input": 2,
            "max_input": 2,
            "outputs": [
              {
                "name": "C",
                "type": "T",
                "description": "Result, has same element type as two inputs"
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "type_constraints": [
              {
                "description": "Constrain input and output types to all numeric tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(uint8)",
                  "tensor(uint16)",
                  "tensor(uint32)",
                  "tensor(uint64)",
                  "tensor(int8)",
                  "tensor(int16)",
                  "tensor(int32)",
                  "tensor(int64)",
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)",
                  "tensor(bfloat16)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "mul",
                "code": "node = onnx.helper.make_node(\n    \"Mul\",\n    inputs=[\"x\", \"y\"],\n    outputs=[\"z\"],\n)\n\nx = np.array([1, 2, 3]).astype(np.float32)\ny = np.array([4, 5, 6]).astype(np.float32)\nz = x * y  # expected output [4., 10., 18.]\nexpect(node, inputs=[x, y], outputs=[z], name=\"test_mul_example\")\n\nx = np.random.randn(3, 4, 5).astype(np.float32)\ny = np.random.randn(3, 4, 5).astype(np.float32)\nz = x * y\nexpect(node, inputs=[x, y], outputs=[z], name=\"test_mul\")\n\nx = np.random.randint(4, size=(3, 4, 5), dtype=np.int8)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.int8)\nz = x * y\nexpect(node, inputs=[x, y], outputs=[z], name=\"test_mul_int8\")\n\nx = np.random.randint(4, size=(3, 4, 5), dtype=np.int16)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.int16)\nz = x * y\nexpect(node, inputs=[x, y], outputs=[z], name=\"test_mul_int16\")\n\nx = np.random.randint(4, size=(3, 4, 5), dtype=np.uint8)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.uint8)\nz = x * y\nexpect(node, inputs=[x, y], outputs=[z], name=\"test_mul_uint8\")\n\nx = np.random.randint(4, size=(3, 4, 5), dtype=np.uint16)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.uint16)\nz = x * y\nexpect(node, inputs=[x, y], outputs=[z], name=\"test_mul_uint16\")\n\nx = np.random.randint(4, size=(3, 4, 5), dtype=np.uint32)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.uint32)\nz = x * y\nexpect(node, inputs=[x, y], outputs=[z], name=\"test_mul_uint32\")\n\nx = np.random.randint(4, size=(3, 4, 5), dtype=np.uint64)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.uint64)\nz = x * y\nexpect(node, inputs=[x, y], outputs=[z], name=\"test_mul_uint64\")"
              },
              {
                "summary": "mul_broadcast",
                "code": "node = onnx.helper.make_node(\n    \"Mul\",\n    inputs=[\"x\", \"y\"],\n    outputs=[\"z\"],\n)\n\nx = np.random.randn(3, 4, 5).astype(np.float32)\ny = np.random.randn(5).astype(np.float32)\nz = x * y\nexpect(node, inputs=[x, y], outputs=[z], name=\"test_mul_bcast\")"
              }
            ]
          }
        },
        {
          "name": "mul_9",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "A",
              "value": [
                {
                  "name": "Conv__197:0",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        128,
                        9,
                        16
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "B",
              "value": [
                {
                  "name": "mul_8:0",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        128,
                        9,
                        16
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "C",
              "value": [
                {
                  "name": "mul_9:0",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        128,
                        9,
                        16
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "Mul",
            "module": "ai.onnx",
            "version": 14,
            "description": "Performs element-wise binary multiplication (with Numpy-style broadcasting support).\n\nThis operator supports **multidirectional (i.e., Numpy-style) broadcasting**; for more details please check [the doc](https://github.com/onnx/onnx/blob/master/docs/Broadcasting.md).\n\n(Opset 14 change): Extend supported types to include uint8, int8, uint16, and int16.\n",
            "inputs": [
              {
                "name": "A",
                "type": "T",
                "description": "First operand."
              },
              {
                "name": "B",
                "type": "T",
                "description": "Second operand."
              }
            ],
            "min_input": 2,
            "max_input": 2,
            "outputs": [
              {
                "name": "C",
                "type": "T",
                "description": "Result, has same element type as two inputs"
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "type_constraints": [
              {
                "description": "Constrain input and output types to all numeric tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(uint8)",
                  "tensor(uint16)",
                  "tensor(uint32)",
                  "tensor(uint64)",
                  "tensor(int8)",
                  "tensor(int16)",
                  "tensor(int32)",
                  "tensor(int64)",
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)",
                  "tensor(bfloat16)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "mul",
                "code": "node = onnx.helper.make_node(\n    \"Mul\",\n    inputs=[\"x\", \"y\"],\n    outputs=[\"z\"],\n)\n\nx = np.array([1, 2, 3]).astype(np.float32)\ny = np.array([4, 5, 6]).astype(np.float32)\nz = x * y  # expected output [4., 10., 18.]\nexpect(node, inputs=[x, y], outputs=[z], name=\"test_mul_example\")\n\nx = np.random.randn(3, 4, 5).astype(np.float32)\ny = np.random.randn(3, 4, 5).astype(np.float32)\nz = x * y\nexpect(node, inputs=[x, y], outputs=[z], name=\"test_mul\")\n\nx = np.random.randint(4, size=(3, 4, 5), dtype=np.int8)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.int8)\nz = x * y\nexpect(node, inputs=[x, y], outputs=[z], name=\"test_mul_int8\")\n\nx = np.random.randint(4, size=(3, 4, 5), dtype=np.int16)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.int16)\nz = x * y\nexpect(node, inputs=[x, y], outputs=[z], name=\"test_mul_int16\")\n\nx = np.random.randint(4, size=(3, 4, 5), dtype=np.uint8)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.uint8)\nz = x * y\nexpect(node, inputs=[x, y], outputs=[z], name=\"test_mul_uint8\")\n\nx = np.random.randint(4, size=(3, 4, 5), dtype=np.uint16)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.uint16)\nz = x * y\nexpect(node, inputs=[x, y], outputs=[z], name=\"test_mul_uint16\")\n\nx = np.random.randint(4, size=(3, 4, 5), dtype=np.uint32)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.uint32)\nz = x * y\nexpect(node, inputs=[x, y], outputs=[z], name=\"test_mul_uint32\")\n\nx = np.random.randint(4, size=(3, 4, 5), dtype=np.uint64)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.uint64)\nz = x * y\nexpect(node, inputs=[x, y], outputs=[z], name=\"test_mul_uint64\")"
              },
              {
                "summary": "mul_broadcast",
                "code": "node = onnx.helper.make_node(\n    \"Mul\",\n    inputs=[\"x\", \"y\"],\n    outputs=[\"z\"],\n)\n\nx = np.random.randn(3, 4, 5).astype(np.float32)\ny = np.random.randn(5).astype(np.float32)\nz = x * y\nexpect(node, inputs=[x, y], outputs=[z], name=\"test_mul_bcast\")"
              }
            ]
          }
        },
        {
          "name": "global_average_pooling2d_2",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "X",
              "value": [
                {
                  "name": "mul_9:0",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        128,
                        9,
                        16
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "Y",
              "value": [
                {
                  "name": "global_average_pooling2d_2:0",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        128,
                        1,
                        1
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "GlobalAveragePool",
            "module": "ai.onnx",
            "version": 1,
            "description": "GlobalAveragePool consumes an input tensor X and applies average pooling across\n the values in the same channel. This is equivalent to AveragePool with kernel size\n equal to the spatial dimension of input tensor.",
            "inputs": [
              {
                "name": "X",
                "type": "T",
                "description": "Input data tensor from the previous operator; dimensions for image case are (N x C x H x W), where N is the batch size, C is the number of channels, and H and W are the height and the width of the data. For non image case, the dimensions are in the form of (N x C x D1 x D2 ... Dn), where N is the batch size."
              }
            ],
            "min_input": 1,
            "max_input": 1,
            "outputs": [
              {
                "name": "Y",
                "type": "T",
                "description": "Output data tensor from pooling across the input tensor. The output tensor has the same rank as the input. The first two dimensions of output shape are the same as the input (N x C), while the other dimensions are all 1."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "type_constraints": [
              {
                "description": "Constrain input and output types to float tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "globalaveragepool",
                "code": "node = onnx.helper.make_node(\n    \"GlobalAveragePool\",\n    inputs=[\"x\"],\n    outputs=[\"y\"],\n)\nx = np.random.randn(1, 3, 5, 5).astype(np.float32)\ny = np.mean(x, axis=tuple(range(2, np.ndim(x))), keepdims=True)\nexpect(node, inputs=[x], outputs=[y], name=\"test_globalaveragepool\")"
              },
              {
                "summary": "globalaveragepool_precomputed",
                "code": "node = onnx.helper.make_node(\n    \"GlobalAveragePool\",\n    inputs=[\"x\"],\n    outputs=[\"y\"],\n)\nx = np.array(\n    [\n        [\n            [\n                [1, 2, 3],\n                [4, 5, 6],\n                [7, 8, 9],\n            ]\n        ]\n    ]\n).astype(np.float32)\ny = np.array([[[[5]]]]).astype(np.float32)\nexpect(node, inputs=[x], outputs=[y], name=\"test_globalaveragepool_precomputed\")"
              }
            ],
            "category": "Pool"
          }
        },
        {
          "name": "Conv__200",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "X",
              "value": [
                {
                  "name": "global_average_pooling2d_2:0",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        128,
                        1,
                        1
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "W",
              "value": [
                {
                  "name": "Conv2D_15/filter:0",
                  "initializer": {
                    "name": "Conv2D_15/filter:0",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float32",
                      "shape": {
                        "dimensions": [
                          32,
                          128,
                          1,
                          1
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        32,
                        128,
                        1,
                        1
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "B",
              "value": [
                {
                  "name": "conv2d_14_1/y:0",
                  "initializer": {
                    "name": "conv2d_14_1/y:0",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float32",
                      "shape": {
                        "dimensions": [
                          32
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        32
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "Y",
              "value": [
                {
                  "name": "Conv__200:0",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        32,
                        1,
                        1
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [
            {
              "name": "dilations",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "strides",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "kernel_shape",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "group",
              "type": "int64",
              "value": {
                "type": "bigint",
                "value": "1"
              }
            }
          ],
          "type": {
            "name": "Conv",
            "module": "ai.onnx",
            "version": 11,
            "description": "The convolution operator consumes an input tensor and a filter, and\ncomputes the output.",
            "attributes": [
              {
                "name": "auto_pad",
                "type": "string",
                "required": false,
                "default": "NOTSET",
                "description": "auto_pad must be either NOTSET, SAME_UPPER, SAME_LOWER or VALID. Where default value is NOTSET, which means explicit padding is used. SAME_UPPER or SAME_LOWER mean pad the input so that `output_shape[i] = ceil(input_shape[i] / strides[i])` for each axis `i`. The padding is split between the two sides equally or almost equally (depending on whether it is even or odd). In case the padding is an odd number, the extra padding is added at the end for SAME_UPPER and at the beginning for SAME_LOWER."
              },
              {
                "name": "dilations",
                "type": "int64[]",
                "required": false,
                "description": "dilation value along each spatial axis of the filter. If not present, the dilation defaults is 1 along each spatial axis."
              },
              {
                "name": "group",
                "type": "int64",
                "required": false,
                "default": 1,
                "description": "number of groups input channels and output channels are divided into."
              },
              {
                "name": "kernel_shape",
                "type": "int64[]",
                "required": false,
                "description": "The shape of the convolution kernel. If not present, should be inferred from input W."
              },
              {
                "name": "pads",
                "type": "int64[]",
                "required": false,
                "description": "Padding for the beginning and ending along each spatial axis, it can take any value greater than or equal to 0. The value represent the number of pixels added to the beginning and end part of the corresponding axis. `pads` format should be as follow [x1_begin, x2_begin...x1_end, x2_end,...], where xi_begin the number of pixels added at the beginning of axis `i` and xi_end, the number of pixels added at the end of axis `i`. This attribute cannot be used simultaneously with auto_pad attribute. If not present, the padding defaults to 0 along start and end of each spatial axis."
              },
              {
                "name": "strides",
                "type": "int64[]",
                "required": false,
                "description": "Stride along each spatial axis. If not present, the stride defaults is 1 along each spatial axis."
              }
            ],
            "inputs": [
              {
                "name": "X",
                "type": "T",
                "description": "Input data tensor from previous layer; has size (N x C x H x W), where N is the batch size, C is the number of channels, and H and W are the height and width. Note that this is for the 2D image. Otherwise the size is (N x C x D1 x D2 ... x Dn). Optionally, if dimension denotation is in effect, the operation expects input data tensor to arrive with the dimension denotation of [DATA_BATCH, DATA_CHANNEL, DATA_FEATURE, DATA_FEATURE ...]."
              },
              {
                "name": "W",
                "type": "T",
                "description": "The weight tensor that will be used in the convolutions; has size (M x C/group x kH x kW), where C is the number of channels, and kH and kW are the height and width of the kernel, and M is the number of feature maps. For more than 2 dimensions, the kernel shape will be (M x C/group x k1 x k2 x ... x kn), where (k1 x k2 x ... kn) is the dimension of the kernel. Optionally, if dimension denotation is in effect, the operation expects the weight tensor to arrive with the dimension denotation of [FILTER_OUT_CHANNEL, FILTER_IN_CHANNEL, FILTER_SPATIAL, FILTER_SPATIAL ...]. Assuming zero based indices for the shape array, X.shape[1] == (W.shape[1] * group) == C and W.shape[0] mod G == 0. Or in other words FILTER_IN_CHANNEL multiplied by the number of groups should be equal to DATA_CHANNEL and the number of feature maps M should be a multiple of the number of groups G."
              },
              {
                "name": "B",
                "type": "T",
                "option": "optional",
                "description": "Optional 1D bias to be added to the convolution, has size of M."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "Y",
                "type": "T",
                "description": "Output data tensor that contains the result of the convolution. The output dimensions are functions of the kernel size, stride size, and pad lengths."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain input and output types to float tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "conv",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[1, 1, 1, 1],\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 21.0, 27.0, 33.0, 24.0],  # (1, 1, 5, 5) output tensor\n                [33.0, 54.0, 63.0, 72.0, 51.0],\n                [63.0, 99.0, 108.0, 117.0, 81.0],\n                [93.0, 144.0, 153.0, 162.0, 111.0],\n                [72.0, 111.0, 117.0, 123.0, 84.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_basic_conv_with_padding\",\n)\n\n# Convolution without padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[0, 0, 0, 0],\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 63.0, 72.0],  # (1, 1, 3, 3) output tensor\n                [99.0, 108.0, 117.0],\n                [144.0, 153.0, 162.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_basic_conv_without_padding\",\n)"
              },
              {
                "summary": "conv_with_autopad_same",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with auto_pad='SAME_LOWER' and strides=2\nnode = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    auto_pad=\"SAME_LOWER\",\n    kernel_shape=[3, 3],\n    strides=[2, 2],\n)\ny = np.array(\n    [[[[12.0, 27.0, 24.0], [63.0, 108.0, 81.0], [72.0, 117.0, 84.0]]]]\n).astype(np.float32)\nexpect(node, inputs=[x, W], outputs=[y], name=\"test_conv_with_autopad_same\")"
              },
              {
                "summary": "conv_with_strides",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 7, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n                [25.0, 26.0, 27.0, 28.0, 29.0],\n                [30.0, 31.0, 32.0, 33.0, 34.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with strides=2 and padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 1, 1, 1],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 27.0, 24.0],  # (1, 1, 4, 3) output tensor\n                [63.0, 108.0, 81.0],\n                [123.0, 198.0, 141.0],\n                [112.0, 177.0, 124.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_conv_with_strides_padding\",\n)\n\n# Convolution with strides=2 and no padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[0, 0, 0, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 72.0],  # (1, 1, 3, 2) output tensor\n                [144.0, 162.0],\n                [234.0, 252.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_conv_with_strides_no_padding\",\n)\n\n# Convolution with strides=2 and padding only along one dimension (the H dimension in NxCxHxW tensor)\nnode_with_asymmetric_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 0, 1, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_asymmetric_padding = np.array(\n    [\n        [\n            [\n                [21.0, 33.0],  # (1, 1, 4, 2) output tensor\n                [99.0, 117.0],\n                [189.0, 207.0],\n                [171.0, 183.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_asymmetric_padding,\n    inputs=[x, W],\n    outputs=[y_with_asymmetric_padding],\n    name=\"test_conv_with_strides_and_asymmetric_padding\",\n)"
              }
            ],
            "category": "Layer"
          }
        },
        {
          "name": "re_lu_8",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "X",
              "value": [
                {
                  "name": "Conv__200:0",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        32,
                        1,
                        1
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "Y",
              "value": [
                {
                  "name": "re_lu_8:0",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        32,
                        1,
                        1
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "Relu",
            "module": "ai.onnx",
            "version": 14,
            "description": "Relu takes one input data (Tensor<T>) and produces one output data\n(Tensor<T>) where the rectified linear function, y = max(0, x), is applied to\nthe tensor elementwise.\n",
            "inputs": [
              {
                "name": "X",
                "type": "T",
                "description": "Input tensor"
              }
            ],
            "min_input": 1,
            "max_input": 1,
            "outputs": [
              {
                "name": "Y",
                "type": "T",
                "description": "Output tensor"
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "type_constraints": [
              {
                "description": "Constrain input and output types to signed numeric tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(float)",
                  "tensor(int32)",
                  "tensor(int8)",
                  "tensor(int16)",
                  "tensor(int64)",
                  "tensor(float16)",
                  "tensor(double)",
                  "tensor(bfloat16)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "relu",
                "code": "node = onnx.helper.make_node(\n    \"Relu\",\n    inputs=[\"x\"],\n    outputs=[\"y\"],\n)\nx = np.random.randn(3, 4, 5).astype(np.float32)\ny = np.clip(x, 0, np.inf)\n\nexpect(node, inputs=[x], outputs=[y], name=\"test_relu\")"
              }
            ],
            "category": "Activation"
          }
        },
        {
          "name": "Conv__201",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "X",
              "value": [
                {
                  "name": "re_lu_8:0",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        32,
                        1,
                        1
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "W",
              "value": [
                {
                  "name": "Conv2D_16/filter:0",
                  "initializer": {
                    "name": "Conv2D_16/filter:0",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float32",
                      "shape": {
                        "dimensions": [
                          128,
                          32,
                          1,
                          1
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        128,
                        32,
                        1,
                        1
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "B",
              "value": [
                {
                  "name": "conv2d_15_1/y:0",
                  "initializer": {
                    "name": "conv2d_15_1/y:0",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float32",
                      "shape": {
                        "dimensions": [
                          128
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        128
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "Y",
              "value": [
                {
                  "name": "Conv__201:0",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        128,
                        1,
                        1
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [
            {
              "name": "dilations",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "strides",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "kernel_shape",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "group",
              "type": "int64",
              "value": {
                "type": "bigint",
                "value": "1"
              }
            }
          ],
          "type": {
            "name": "Conv",
            "module": "ai.onnx",
            "version": 11,
            "description": "The convolution operator consumes an input tensor and a filter, and\ncomputes the output.",
            "attributes": [
              {
                "name": "auto_pad",
                "type": "string",
                "required": false,
                "default": "NOTSET",
                "description": "auto_pad must be either NOTSET, SAME_UPPER, SAME_LOWER or VALID. Where default value is NOTSET, which means explicit padding is used. SAME_UPPER or SAME_LOWER mean pad the input so that `output_shape[i] = ceil(input_shape[i] / strides[i])` for each axis `i`. The padding is split between the two sides equally or almost equally (depending on whether it is even or odd). In case the padding is an odd number, the extra padding is added at the end for SAME_UPPER and at the beginning for SAME_LOWER."
              },
              {
                "name": "dilations",
                "type": "int64[]",
                "required": false,
                "description": "dilation value along each spatial axis of the filter. If not present, the dilation defaults is 1 along each spatial axis."
              },
              {
                "name": "group",
                "type": "int64",
                "required": false,
                "default": 1,
                "description": "number of groups input channels and output channels are divided into."
              },
              {
                "name": "kernel_shape",
                "type": "int64[]",
                "required": false,
                "description": "The shape of the convolution kernel. If not present, should be inferred from input W."
              },
              {
                "name": "pads",
                "type": "int64[]",
                "required": false,
                "description": "Padding for the beginning and ending along each spatial axis, it can take any value greater than or equal to 0. The value represent the number of pixels added to the beginning and end part of the corresponding axis. `pads` format should be as follow [x1_begin, x2_begin...x1_end, x2_end,...], where xi_begin the number of pixels added at the beginning of axis `i` and xi_end, the number of pixels added at the end of axis `i`. This attribute cannot be used simultaneously with auto_pad attribute. If not present, the padding defaults to 0 along start and end of each spatial axis."
              },
              {
                "name": "strides",
                "type": "int64[]",
                "required": false,
                "description": "Stride along each spatial axis. If not present, the stride defaults is 1 along each spatial axis."
              }
            ],
            "inputs": [
              {
                "name": "X",
                "type": "T",
                "description": "Input data tensor from previous layer; has size (N x C x H x W), where N is the batch size, C is the number of channels, and H and W are the height and width. Note that this is for the 2D image. Otherwise the size is (N x C x D1 x D2 ... x Dn). Optionally, if dimension denotation is in effect, the operation expects input data tensor to arrive with the dimension denotation of [DATA_BATCH, DATA_CHANNEL, DATA_FEATURE, DATA_FEATURE ...]."
              },
              {
                "name": "W",
                "type": "T",
                "description": "The weight tensor that will be used in the convolutions; has size (M x C/group x kH x kW), where C is the number of channels, and kH and kW are the height and width of the kernel, and M is the number of feature maps. For more than 2 dimensions, the kernel shape will be (M x C/group x k1 x k2 x ... x kn), where (k1 x k2 x ... kn) is the dimension of the kernel. Optionally, if dimension denotation is in effect, the operation expects the weight tensor to arrive with the dimension denotation of [FILTER_OUT_CHANNEL, FILTER_IN_CHANNEL, FILTER_SPATIAL, FILTER_SPATIAL ...]. Assuming zero based indices for the shape array, X.shape[1] == (W.shape[1] * group) == C and W.shape[0] mod G == 0. Or in other words FILTER_IN_CHANNEL multiplied by the number of groups should be equal to DATA_CHANNEL and the number of feature maps M should be a multiple of the number of groups G."
              },
              {
                "name": "B",
                "type": "T",
                "option": "optional",
                "description": "Optional 1D bias to be added to the convolution, has size of M."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "Y",
                "type": "T",
                "description": "Output data tensor that contains the result of the convolution. The output dimensions are functions of the kernel size, stride size, and pad lengths."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain input and output types to float tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "conv",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[1, 1, 1, 1],\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 21.0, 27.0, 33.0, 24.0],  # (1, 1, 5, 5) output tensor\n                [33.0, 54.0, 63.0, 72.0, 51.0],\n                [63.0, 99.0, 108.0, 117.0, 81.0],\n                [93.0, 144.0, 153.0, 162.0, 111.0],\n                [72.0, 111.0, 117.0, 123.0, 84.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_basic_conv_with_padding\",\n)\n\n# Convolution without padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[0, 0, 0, 0],\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 63.0, 72.0],  # (1, 1, 3, 3) output tensor\n                [99.0, 108.0, 117.0],\n                [144.0, 153.0, 162.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_basic_conv_without_padding\",\n)"
              },
              {
                "summary": "conv_with_autopad_same",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with auto_pad='SAME_LOWER' and strides=2\nnode = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    auto_pad=\"SAME_LOWER\",\n    kernel_shape=[3, 3],\n    strides=[2, 2],\n)\ny = np.array(\n    [[[[12.0, 27.0, 24.0], [63.0, 108.0, 81.0], [72.0, 117.0, 84.0]]]]\n).astype(np.float32)\nexpect(node, inputs=[x, W], outputs=[y], name=\"test_conv_with_autopad_same\")"
              },
              {
                "summary": "conv_with_strides",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 7, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n                [25.0, 26.0, 27.0, 28.0, 29.0],\n                [30.0, 31.0, 32.0, 33.0, 34.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with strides=2 and padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 1, 1, 1],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 27.0, 24.0],  # (1, 1, 4, 3) output tensor\n                [63.0, 108.0, 81.0],\n                [123.0, 198.0, 141.0],\n                [112.0, 177.0, 124.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_conv_with_strides_padding\",\n)\n\n# Convolution with strides=2 and no padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[0, 0, 0, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 72.0],  # (1, 1, 3, 2) output tensor\n                [144.0, 162.0],\n                [234.0, 252.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_conv_with_strides_no_padding\",\n)\n\n# Convolution with strides=2 and padding only along one dimension (the H dimension in NxCxHxW tensor)\nnode_with_asymmetric_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 0, 1, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_asymmetric_padding = np.array(\n    [\n        [\n            [\n                [21.0, 33.0],  # (1, 1, 4, 2) output tensor\n                [99.0, 117.0],\n                [189.0, 207.0],\n                [171.0, 183.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_asymmetric_padding,\n    inputs=[x, W],\n    outputs=[y_with_asymmetric_padding],\n    name=\"test_conv_with_strides_and_asymmetric_padding\",\n)"
              }
            ],
            "category": "Layer"
          }
        },
        {
          "name": "activation_2",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "X",
              "value": [
                {
                  "name": "Conv__201:0",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        128,
                        1,
                        1
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "Y",
              "value": [
                {
                  "name": "activation_2:0",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        128,
                        1,
                        1
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "Sigmoid",
            "module": "ai.onnx",
            "version": 13,
            "description": "Sigmoid takes one input data (Tensor<T>) and produces one output data\n(Tensor<T>) where the sigmoid function, y = 1 / (1 + exp(-x)), is applied to the\ntensor elementwise.\n",
            "inputs": [
              {
                "name": "X",
                "type": "T",
                "description": "Input tensor"
              }
            ],
            "min_input": 1,
            "max_input": 1,
            "outputs": [
              {
                "name": "Y",
                "type": "T",
                "description": "Output tensor"
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "type_constraints": [
              {
                "description": "Constrain input and output types to float tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)",
                  "tensor(bfloat16)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "sigmoid",
                "code": "node = onnx.helper.make_node(\n    \"Sigmoid\",\n    inputs=[\"x\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([-1, 0, 1]).astype(np.float32)\ny = 1.0 / (\n    1.0 + np.exp(np.negative(x))\n)  # expected output [0.26894143, 0.5, 0.7310586]\nexpect(node, inputs=[x], outputs=[y], name=\"test_sigmoid_example\")\n\nx = np.random.randn(3, 4, 5).astype(np.float32)\ny = 1.0 / (1.0 + np.exp(np.negative(x)))\nexpect(node, inputs=[x], outputs=[y], name=\"test_sigmoid\")"
              }
            ],
            "category": "Activation"
          }
        },
        {
          "name": "multiply_2",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "A",
              "value": [
                {
                  "name": "mul_9:0",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        128,
                        9,
                        16
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "B",
              "value": [
                {
                  "name": "activation_2:0",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        128,
                        1,
                        1
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "C",
              "value": [
                {
                  "name": "multiply_2:0",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        128,
                        9,
                        16
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "Mul",
            "module": "ai.onnx",
            "version": 14,
            "description": "Performs element-wise binary multiplication (with Numpy-style broadcasting support).\n\nThis operator supports **multidirectional (i.e., Numpy-style) broadcasting**; for more details please check [the doc](https://github.com/onnx/onnx/blob/master/docs/Broadcasting.md).\n\n(Opset 14 change): Extend supported types to include uint8, int8, uint16, and int16.\n",
            "inputs": [
              {
                "name": "A",
                "type": "T",
                "description": "First operand."
              },
              {
                "name": "B",
                "type": "T",
                "description": "Second operand."
              }
            ],
            "min_input": 2,
            "max_input": 2,
            "outputs": [
              {
                "name": "C",
                "type": "T",
                "description": "Result, has same element type as two inputs"
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "type_constraints": [
              {
                "description": "Constrain input and output types to all numeric tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(uint8)",
                  "tensor(uint16)",
                  "tensor(uint32)",
                  "tensor(uint64)",
                  "tensor(int8)",
                  "tensor(int16)",
                  "tensor(int32)",
                  "tensor(int64)",
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)",
                  "tensor(bfloat16)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "mul",
                "code": "node = onnx.helper.make_node(\n    \"Mul\",\n    inputs=[\"x\", \"y\"],\n    outputs=[\"z\"],\n)\n\nx = np.array([1, 2, 3]).astype(np.float32)\ny = np.array([4, 5, 6]).astype(np.float32)\nz = x * y  # expected output [4., 10., 18.]\nexpect(node, inputs=[x, y], outputs=[z], name=\"test_mul_example\")\n\nx = np.random.randn(3, 4, 5).astype(np.float32)\ny = np.random.randn(3, 4, 5).astype(np.float32)\nz = x * y\nexpect(node, inputs=[x, y], outputs=[z], name=\"test_mul\")\n\nx = np.random.randint(4, size=(3, 4, 5), dtype=np.int8)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.int8)\nz = x * y\nexpect(node, inputs=[x, y], outputs=[z], name=\"test_mul_int8\")\n\nx = np.random.randint(4, size=(3, 4, 5), dtype=np.int16)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.int16)\nz = x * y\nexpect(node, inputs=[x, y], outputs=[z], name=\"test_mul_int16\")\n\nx = np.random.randint(4, size=(3, 4, 5), dtype=np.uint8)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.uint8)\nz = x * y\nexpect(node, inputs=[x, y], outputs=[z], name=\"test_mul_uint8\")\n\nx = np.random.randint(4, size=(3, 4, 5), dtype=np.uint16)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.uint16)\nz = x * y\nexpect(node, inputs=[x, y], outputs=[z], name=\"test_mul_uint16\")\n\nx = np.random.randint(4, size=(3, 4, 5), dtype=np.uint32)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.uint32)\nz = x * y\nexpect(node, inputs=[x, y], outputs=[z], name=\"test_mul_uint32\")\n\nx = np.random.randint(4, size=(3, 4, 5), dtype=np.uint64)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.uint64)\nz = x * y\nexpect(node, inputs=[x, y], outputs=[z], name=\"test_mul_uint64\")"
              },
              {
                "summary": "mul_broadcast",
                "code": "node = onnx.helper.make_node(\n    \"Mul\",\n    inputs=[\"x\", \"y\"],\n    outputs=[\"z\"],\n)\n\nx = np.random.randn(3, 4, 5).astype(np.float32)\ny = np.random.randn(5).astype(np.float32)\nz = x * y\nexpect(node, inputs=[x, y], outputs=[z], name=\"test_mul_bcast\")"
              }
            ]
          }
        },
        {
          "name": "Conv__202",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "X",
              "value": [
                {
                  "name": "multiply_2:0",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        128,
                        9,
                        16
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "W",
              "value": [
                {
                  "name": "Conv2D_17/filter:0",
                  "initializer": {
                    "name": "Conv2D_17/filter:0",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float32",
                      "shape": {
                        "dimensions": [
                          32,
                          128,
                          1,
                          1
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        32,
                        128,
                        1,
                        1
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "B",
              "value": [
                {
                  "name": "conv2d_16_1/y:0",
                  "initializer": {
                    "name": "conv2d_16_1/y:0",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float32",
                      "shape": {
                        "dimensions": [
                          32
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        32
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "Y",
              "value": [
                {
                  "name": "Conv__202:0",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        32,
                        9,
                        16
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [
            {
              "name": "dilations",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "strides",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "kernel_shape",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "pads",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "0",
                  "0",
                  "0",
                  "0"
                ]
              }
            },
            {
              "name": "group",
              "type": "int64",
              "value": {
                "type": "bigint",
                "value": "1"
              }
            }
          ],
          "type": {
            "name": "Conv",
            "module": "ai.onnx",
            "version": 11,
            "description": "The convolution operator consumes an input tensor and a filter, and\ncomputes the output.",
            "attributes": [
              {
                "name": "auto_pad",
                "type": "string",
                "required": false,
                "default": "NOTSET",
                "description": "auto_pad must be either NOTSET, SAME_UPPER, SAME_LOWER or VALID. Where default value is NOTSET, which means explicit padding is used. SAME_UPPER or SAME_LOWER mean pad the input so that `output_shape[i] = ceil(input_shape[i] / strides[i])` for each axis `i`. The padding is split between the two sides equally or almost equally (depending on whether it is even or odd). In case the padding is an odd number, the extra padding is added at the end for SAME_UPPER and at the beginning for SAME_LOWER."
              },
              {
                "name": "dilations",
                "type": "int64[]",
                "required": false,
                "description": "dilation value along each spatial axis of the filter. If not present, the dilation defaults is 1 along each spatial axis."
              },
              {
                "name": "group",
                "type": "int64",
                "required": false,
                "default": 1,
                "description": "number of groups input channels and output channels are divided into."
              },
              {
                "name": "kernel_shape",
                "type": "int64[]",
                "required": false,
                "description": "The shape of the convolution kernel. If not present, should be inferred from input W."
              },
              {
                "name": "pads",
                "type": "int64[]",
                "required": false,
                "description": "Padding for the beginning and ending along each spatial axis, it can take any value greater than or equal to 0. The value represent the number of pixels added to the beginning and end part of the corresponding axis. `pads` format should be as follow [x1_begin, x2_begin...x1_end, x2_end,...], where xi_begin the number of pixels added at the beginning of axis `i` and xi_end, the number of pixels added at the end of axis `i`. This attribute cannot be used simultaneously with auto_pad attribute. If not present, the padding defaults to 0 along start and end of each spatial axis."
              },
              {
                "name": "strides",
                "type": "int64[]",
                "required": false,
                "description": "Stride along each spatial axis. If not present, the stride defaults is 1 along each spatial axis."
              }
            ],
            "inputs": [
              {
                "name": "X",
                "type": "T",
                "description": "Input data tensor from previous layer; has size (N x C x H x W), where N is the batch size, C is the number of channels, and H and W are the height and width. Note that this is for the 2D image. Otherwise the size is (N x C x D1 x D2 ... x Dn). Optionally, if dimension denotation is in effect, the operation expects input data tensor to arrive with the dimension denotation of [DATA_BATCH, DATA_CHANNEL, DATA_FEATURE, DATA_FEATURE ...]."
              },
              {
                "name": "W",
                "type": "T",
                "description": "The weight tensor that will be used in the convolutions; has size (M x C/group x kH x kW), where C is the number of channels, and kH and kW are the height and width of the kernel, and M is the number of feature maps. For more than 2 dimensions, the kernel shape will be (M x C/group x k1 x k2 x ... x kn), where (k1 x k2 x ... kn) is the dimension of the kernel. Optionally, if dimension denotation is in effect, the operation expects the weight tensor to arrive with the dimension denotation of [FILTER_OUT_CHANNEL, FILTER_IN_CHANNEL, FILTER_SPATIAL, FILTER_SPATIAL ...]. Assuming zero based indices for the shape array, X.shape[1] == (W.shape[1] * group) == C and W.shape[0] mod G == 0. Or in other words FILTER_IN_CHANNEL multiplied by the number of groups should be equal to DATA_CHANNEL and the number of feature maps M should be a multiple of the number of groups G."
              },
              {
                "name": "B",
                "type": "T",
                "option": "optional",
                "description": "Optional 1D bias to be added to the convolution, has size of M."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "Y",
                "type": "T",
                "description": "Output data tensor that contains the result of the convolution. The output dimensions are functions of the kernel size, stride size, and pad lengths."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain input and output types to float tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "conv",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[1, 1, 1, 1],\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 21.0, 27.0, 33.0, 24.0],  # (1, 1, 5, 5) output tensor\n                [33.0, 54.0, 63.0, 72.0, 51.0],\n                [63.0, 99.0, 108.0, 117.0, 81.0],\n                [93.0, 144.0, 153.0, 162.0, 111.0],\n                [72.0, 111.0, 117.0, 123.0, 84.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_basic_conv_with_padding\",\n)\n\n# Convolution without padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[0, 0, 0, 0],\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 63.0, 72.0],  # (1, 1, 3, 3) output tensor\n                [99.0, 108.0, 117.0],\n                [144.0, 153.0, 162.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_basic_conv_without_padding\",\n)"
              },
              {
                "summary": "conv_with_autopad_same",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with auto_pad='SAME_LOWER' and strides=2\nnode = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    auto_pad=\"SAME_LOWER\",\n    kernel_shape=[3, 3],\n    strides=[2, 2],\n)\ny = np.array(\n    [[[[12.0, 27.0, 24.0], [63.0, 108.0, 81.0], [72.0, 117.0, 84.0]]]]\n).astype(np.float32)\nexpect(node, inputs=[x, W], outputs=[y], name=\"test_conv_with_autopad_same\")"
              },
              {
                "summary": "conv_with_strides",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 7, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n                [25.0, 26.0, 27.0, 28.0, 29.0],\n                [30.0, 31.0, 32.0, 33.0, 34.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with strides=2 and padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 1, 1, 1],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 27.0, 24.0],  # (1, 1, 4, 3) output tensor\n                [63.0, 108.0, 81.0],\n                [123.0, 198.0, 141.0],\n                [112.0, 177.0, 124.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_conv_with_strides_padding\",\n)\n\n# Convolution with strides=2 and no padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[0, 0, 0, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 72.0],  # (1, 1, 3, 2) output tensor\n                [144.0, 162.0],\n                [234.0, 252.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_conv_with_strides_no_padding\",\n)\n\n# Convolution with strides=2 and padding only along one dimension (the H dimension in NxCxHxW tensor)\nnode_with_asymmetric_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 0, 1, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_asymmetric_padding = np.array(\n    [\n        [\n            [\n                [21.0, 33.0],  # (1, 1, 4, 2) output tensor\n                [99.0, 117.0],\n                [189.0, 207.0],\n                [171.0, 183.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_asymmetric_padding,\n    inputs=[x, W],\n    outputs=[y_with_asymmetric_padding],\n    name=\"test_conv_with_strides_and_asymmetric_padding\",\n)"
              }
            ],
            "category": "Layer"
          }
        },
        {
          "name": "add_1__xeno_compat__1",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "A",
              "value": [
                {
                  "name": "Conv__202:0",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        32,
                        9,
                        16
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "B",
              "value": [
                {
                  "name": "Conv__191:0",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        32,
                        9,
                        16
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "C",
              "value": [
                {
                  "name": "add_1__xeno_compat__1:0",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        32,
                        9,
                        16
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "Add",
            "module": "ai.onnx",
            "version": 14,
            "description": "Performs element-wise binary addition (with Numpy-style broadcasting support).\n\nThis operator supports **multidirectional (i.e., Numpy-style) broadcasting**; for more details please check [the doc](https://github.com/onnx/onnx/blob/master/docs/Broadcasting.md).\n\n(Opset 14 change): Extend supported types to include uint8, int8, uint16, and int16.\n",
            "inputs": [
              {
                "name": "A",
                "type": "T",
                "description": "First operand."
              },
              {
                "name": "B",
                "type": "T",
                "description": "Second operand."
              }
            ],
            "min_input": 2,
            "max_input": 2,
            "outputs": [
              {
                "name": "C",
                "type": "T",
                "description": "Result, has same element type as two inputs"
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "type_constraints": [
              {
                "description": "Constrain input and output types to all numeric tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(uint8)",
                  "tensor(uint16)",
                  "tensor(uint32)",
                  "tensor(uint64)",
                  "tensor(int8)",
                  "tensor(int16)",
                  "tensor(int32)",
                  "tensor(int64)",
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)",
                  "tensor(bfloat16)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "add",
                "code": "node = onnx.helper.make_node(\n    \"Add\",\n    inputs=[\"x\", \"y\"],\n    outputs=[\"sum\"],\n)\n\nx = np.random.randn(3, 4, 5).astype(np.float32)\ny = np.random.randn(3, 4, 5).astype(np.float32)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add\")\n\nx = np.random.randint(24, size=(3, 4, 5), dtype=np.int8)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.int8)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add_int8\")\n\nx = np.random.randint(24, size=(3, 4, 5), dtype=np.int16)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.int16)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add_int16\")\n\nx = np.random.randint(24, size=(3, 4, 5), dtype=np.uint8)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.uint8)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add_uint8\")\n\nx = np.random.randint(24, size=(3, 4, 5), dtype=np.uint16)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.uint16)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add_uint16\")\n\nx = np.random.randint(24, size=(3, 4, 5), dtype=np.uint32)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.uint32)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add_uint32\")\n\nx = np.random.randint(24, size=(3, 4, 5), dtype=np.uint64)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.uint64)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add_uint64\")"
              },
              {
                "summary": "add_broadcast",
                "code": "node = onnx.helper.make_node(\n    \"Add\",\n    inputs=[\"x\", \"y\"],\n    outputs=[\"sum\"],\n)\n\nx = np.random.randn(3, 4, 5).astype(np.float32)\ny = np.random.randn(5).astype(np.float32)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add_bcast\")"
              }
            ]
          }
        },
        {
          "name": "Conv__205",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "X",
              "value": [
                {
                  "name": "add_1__xeno_compat__1:0",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        32,
                        9,
                        16
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "W",
              "value": [
                {
                  "name": "Conv2D_18/filter:0",
                  "initializer": {
                    "name": "Conv2D_18/filter:0",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float32",
                      "shape": {
                        "dimensions": [
                          128,
                          32,
                          1,
                          1
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        128,
                        32,
                        1,
                        1
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "B",
              "value": [
                {
                  "name": "conv2d_17_1/y:0",
                  "initializer": {
                    "name": "conv2d_17_1/y:0",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float32",
                      "shape": {
                        "dimensions": [
                          128
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        128
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "Y",
              "value": [
                {
                  "name": "Conv__205:0",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        128,
                        9,
                        16
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [
            {
              "name": "dilations",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "strides",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "kernel_shape",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "pads",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "0",
                  "0",
                  "0",
                  "0"
                ]
              }
            },
            {
              "name": "group",
              "type": "int64",
              "value": {
                "type": "bigint",
                "value": "1"
              }
            }
          ],
          "type": {
            "name": "Conv",
            "module": "ai.onnx",
            "version": 11,
            "description": "The convolution operator consumes an input tensor and a filter, and\ncomputes the output.",
            "attributes": [
              {
                "name": "auto_pad",
                "type": "string",
                "required": false,
                "default": "NOTSET",
                "description": "auto_pad must be either NOTSET, SAME_UPPER, SAME_LOWER or VALID. Where default value is NOTSET, which means explicit padding is used. SAME_UPPER or SAME_LOWER mean pad the input so that `output_shape[i] = ceil(input_shape[i] / strides[i])` for each axis `i`. The padding is split between the two sides equally or almost equally (depending on whether it is even or odd). In case the padding is an odd number, the extra padding is added at the end for SAME_UPPER and at the beginning for SAME_LOWER."
              },
              {
                "name": "dilations",
                "type": "int64[]",
                "required": false,
                "description": "dilation value along each spatial axis of the filter. If not present, the dilation defaults is 1 along each spatial axis."
              },
              {
                "name": "group",
                "type": "int64",
                "required": false,
                "default": 1,
                "description": "number of groups input channels and output channels are divided into."
              },
              {
                "name": "kernel_shape",
                "type": "int64[]",
                "required": false,
                "description": "The shape of the convolution kernel. If not present, should be inferred from input W."
              },
              {
                "name": "pads",
                "type": "int64[]",
                "required": false,
                "description": "Padding for the beginning and ending along each spatial axis, it can take any value greater than or equal to 0. The value represent the number of pixels added to the beginning and end part of the corresponding axis. `pads` format should be as follow [x1_begin, x2_begin...x1_end, x2_end,...], where xi_begin the number of pixels added at the beginning of axis `i` and xi_end, the number of pixels added at the end of axis `i`. This attribute cannot be used simultaneously with auto_pad attribute. If not present, the padding defaults to 0 along start and end of each spatial axis."
              },
              {
                "name": "strides",
                "type": "int64[]",
                "required": false,
                "description": "Stride along each spatial axis. If not present, the stride defaults is 1 along each spatial axis."
              }
            ],
            "inputs": [
              {
                "name": "X",
                "type": "T",
                "description": "Input data tensor from previous layer; has size (N x C x H x W), where N is the batch size, C is the number of channels, and H and W are the height and width. Note that this is for the 2D image. Otherwise the size is (N x C x D1 x D2 ... x Dn). Optionally, if dimension denotation is in effect, the operation expects input data tensor to arrive with the dimension denotation of [DATA_BATCH, DATA_CHANNEL, DATA_FEATURE, DATA_FEATURE ...]."
              },
              {
                "name": "W",
                "type": "T",
                "description": "The weight tensor that will be used in the convolutions; has size (M x C/group x kH x kW), where C is the number of channels, and kH and kW are the height and width of the kernel, and M is the number of feature maps. For more than 2 dimensions, the kernel shape will be (M x C/group x k1 x k2 x ... x kn), where (k1 x k2 x ... kn) is the dimension of the kernel. Optionally, if dimension denotation is in effect, the operation expects the weight tensor to arrive with the dimension denotation of [FILTER_OUT_CHANNEL, FILTER_IN_CHANNEL, FILTER_SPATIAL, FILTER_SPATIAL ...]. Assuming zero based indices for the shape array, X.shape[1] == (W.shape[1] * group) == C and W.shape[0] mod G == 0. Or in other words FILTER_IN_CHANNEL multiplied by the number of groups should be equal to DATA_CHANNEL and the number of feature maps M should be a multiple of the number of groups G."
              },
              {
                "name": "B",
                "type": "T",
                "option": "optional",
                "description": "Optional 1D bias to be added to the convolution, has size of M."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "Y",
                "type": "T",
                "description": "Output data tensor that contains the result of the convolution. The output dimensions are functions of the kernel size, stride size, and pad lengths."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain input and output types to float tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "conv",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[1, 1, 1, 1],\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 21.0, 27.0, 33.0, 24.0],  # (1, 1, 5, 5) output tensor\n                [33.0, 54.0, 63.0, 72.0, 51.0],\n                [63.0, 99.0, 108.0, 117.0, 81.0],\n                [93.0, 144.0, 153.0, 162.0, 111.0],\n                [72.0, 111.0, 117.0, 123.0, 84.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_basic_conv_with_padding\",\n)\n\n# Convolution without padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[0, 0, 0, 0],\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 63.0, 72.0],  # (1, 1, 3, 3) output tensor\n                [99.0, 108.0, 117.0],\n                [144.0, 153.0, 162.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_basic_conv_without_padding\",\n)"
              },
              {
                "summary": "conv_with_autopad_same",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with auto_pad='SAME_LOWER' and strides=2\nnode = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    auto_pad=\"SAME_LOWER\",\n    kernel_shape=[3, 3],\n    strides=[2, 2],\n)\ny = np.array(\n    [[[[12.0, 27.0, 24.0], [63.0, 108.0, 81.0], [72.0, 117.0, 84.0]]]]\n).astype(np.float32)\nexpect(node, inputs=[x, W], outputs=[y], name=\"test_conv_with_autopad_same\")"
              },
              {
                "summary": "conv_with_strides",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 7, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n                [25.0, 26.0, 27.0, 28.0, 29.0],\n                [30.0, 31.0, 32.0, 33.0, 34.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with strides=2 and padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 1, 1, 1],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 27.0, 24.0],  # (1, 1, 4, 3) output tensor\n                [63.0, 108.0, 81.0],\n                [123.0, 198.0, 141.0],\n                [112.0, 177.0, 124.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_conv_with_strides_padding\",\n)\n\n# Convolution with strides=2 and no padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[0, 0, 0, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 72.0],  # (1, 1, 3, 2) output tensor\n                [144.0, 162.0],\n                [234.0, 252.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_conv_with_strides_no_padding\",\n)\n\n# Convolution with strides=2 and padding only along one dimension (the H dimension in NxCxHxW tensor)\nnode_with_asymmetric_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 0, 1, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_asymmetric_padding = np.array(\n    [\n        [\n            [\n                [21.0, 33.0],  # (1, 1, 4, 2) output tensor\n                [99.0, 117.0],\n                [189.0, 207.0],\n                [171.0, 183.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_asymmetric_padding,\n    inputs=[x, W],\n    outputs=[y_with_asymmetric_padding],\n    name=\"test_conv_with_strides_and_asymmetric_padding\",\n)"
              }
            ],
            "category": "Layer"
          }
        },
        {
          "name": "add_5",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "A",
              "value": [
                {
                  "name": "Conv__205:0",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        128,
                        9,
                        16
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "B",
              "value": [
                {
                  "name": "const_fold_opt__408",
                  "initializer": {
                    "name": "const_fold_opt__408",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float32",
                      "shape": {
                        "dimensions": [
                          1,
                          1,
                          1,
                          1
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        1,
                        1,
                        1
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "C",
              "value": [
                {
                  "name": "add_5:0",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        128,
                        9,
                        16
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "Add",
            "module": "ai.onnx",
            "version": 14,
            "description": "Performs element-wise binary addition (with Numpy-style broadcasting support).\n\nThis operator supports **multidirectional (i.e., Numpy-style) broadcasting**; for more details please check [the doc](https://github.com/onnx/onnx/blob/master/docs/Broadcasting.md).\n\n(Opset 14 change): Extend supported types to include uint8, int8, uint16, and int16.\n",
            "inputs": [
              {
                "name": "A",
                "type": "T",
                "description": "First operand."
              },
              {
                "name": "B",
                "type": "T",
                "description": "Second operand."
              }
            ],
            "min_input": 2,
            "max_input": 2,
            "outputs": [
              {
                "name": "C",
                "type": "T",
                "description": "Result, has same element type as two inputs"
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "type_constraints": [
              {
                "description": "Constrain input and output types to all numeric tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(uint8)",
                  "tensor(uint16)",
                  "tensor(uint32)",
                  "tensor(uint64)",
                  "tensor(int8)",
                  "tensor(int16)",
                  "tensor(int32)",
                  "tensor(int64)",
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)",
                  "tensor(bfloat16)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "add",
                "code": "node = onnx.helper.make_node(\n    \"Add\",\n    inputs=[\"x\", \"y\"],\n    outputs=[\"sum\"],\n)\n\nx = np.random.randn(3, 4, 5).astype(np.float32)\ny = np.random.randn(3, 4, 5).astype(np.float32)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add\")\n\nx = np.random.randint(24, size=(3, 4, 5), dtype=np.int8)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.int8)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add_int8\")\n\nx = np.random.randint(24, size=(3, 4, 5), dtype=np.int16)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.int16)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add_int16\")\n\nx = np.random.randint(24, size=(3, 4, 5), dtype=np.uint8)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.uint8)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add_uint8\")\n\nx = np.random.randint(24, size=(3, 4, 5), dtype=np.uint16)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.uint16)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add_uint16\")\n\nx = np.random.randint(24, size=(3, 4, 5), dtype=np.uint32)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.uint32)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add_uint32\")\n\nx = np.random.randint(24, size=(3, 4, 5), dtype=np.uint64)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.uint64)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add_uint64\")"
              },
              {
                "summary": "add_broadcast",
                "code": "node = onnx.helper.make_node(\n    \"Add\",\n    inputs=[\"x\", \"y\"],\n    outputs=[\"sum\"],\n)\n\nx = np.random.randn(3, 4, 5).astype(np.float32)\ny = np.random.randn(5).astype(np.float32)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add_bcast\")"
              }
            ]
          }
        },
        {
          "name": "Relu6_5",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "input",
              "value": [
                {
                  "name": "add_5:0",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        128,
                        9,
                        16
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "min",
              "value": [
                {
                  "name": "302",
                  "initializer": {
                    "category": "Constant",
                    "encoding": "|",
                    "values": {
                      "0": 0
                    },
                    "type": {
                      "dataType": "float32",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            },
            {
              "name": "max",
              "value": [
                {
                  "name": "303",
                  "initializer": {
                    "category": "Constant",
                    "encoding": "|",
                    "values": {
                      "0": 6
                    },
                    "type": {
                      "dataType": "float32",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "output",
              "value": [
                {
                  "name": "Relu6_5:0",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        128,
                        9,
                        16
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "Clip",
            "module": "ai.onnx",
            "version": 13,
            "description": "Clip operator limits the given input within an interval. The interval is\nspecified by the inputs 'min' and 'max'. They default to\nnumeric_limits::lowest() and numeric_limits::max(), respectively.\nWhen 'min' is greater than 'max', the clip operator sets all the 'input' values to\nthe value of 'max'. Thus, this is equivalent to 'Min(max, Max(input, min))'.\n",
            "inputs": [
              {
                "name": "input",
                "type": "T",
                "description": "Input tensor whose elements to be clipped"
              },
              {
                "name": "min",
                "type": "T",
                "option": "optional",
                "description": "Minimum value, under which element is replaced by min. It must be a scalar(tensor of empty shape)."
              },
              {
                "name": "max",
                "type": "T",
                "option": "optional",
                "description": "Maximum value, above which element is replaced by max. It must be a scalar(tensor of empty shape)."
              }
            ],
            "min_input": 1,
            "max_input": 3,
            "outputs": [
              {
                "name": "output",
                "type": "T",
                "description": "Output tensor with clipped input elements"
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "1 - 3",
            "type_constraints": [
              {
                "description": "Constrain input and output types to all numeric tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(uint8)",
                  "tensor(uint16)",
                  "tensor(uint32)",
                  "tensor(uint64)",
                  "tensor(int8)",
                  "tensor(int16)",
                  "tensor(int32)",
                  "tensor(int64)",
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)",
                  "tensor(bfloat16)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "clip",
                "code": "node = onnx.helper.make_node(\n    \"Clip\",\n    inputs=[\"x\", \"min\", \"max\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([-2, 0, 2]).astype(np.float32)\nmin_val = np.float32(-1)\nmax_val = np.float32(1)\ny = np.clip(x, min_val, max_val)  # expected output [-1., 0., 1.]\nexpect(\n    node, inputs=[x, min_val, max_val], outputs=[y], name=\"test_clip_example\"\n)\n\nx = np.random.randn(3, 4, 5).astype(np.float32)\ny = np.clip(x, min_val, max_val)\nexpect(node, inputs=[x, min_val, max_val], outputs=[y], name=\"test_clip\")\nnode = onnx.helper.make_node(\n    \"Clip\",\n    inputs=[\"x\", \"min\", \"max\"],\n    outputs=[\"y\"],\n)\n\nmin_val = np.float32(-5)\nmax_val = np.float32(5)\n\nx = np.array([-1, 0, 1]).astype(np.float32)\ny = np.array([-1, 0, 1]).astype(np.float32)\nexpect(\n    node, inputs=[x, min_val, max_val], outputs=[y], name=\"test_clip_inbounds\"\n)\n\nx = np.array([-6, 0, 6]).astype(np.float32)\ny = np.array([-5, 0, 5]).astype(np.float32)\nexpect(\n    node, inputs=[x, min_val, max_val], outputs=[y], name=\"test_clip_outbounds\"\n)\n\nx = np.array([-1, 0, 6]).astype(np.float32)\ny = np.array([-1, 0, 5]).astype(np.float32)\nexpect(\n    node,\n    inputs=[x, min_val, max_val],\n    outputs=[y],\n    name=\"test_clip_splitbounds\",\n)\n\nx = np.array([-2, 0, 6]).astype(np.float32)\ny = np.array([1, 1, 1]).astype(np.float32)\nmin_val = np.float32(2)\nmax_val = np.float32(1)\nexpect(\n    node,\n    inputs=[x, min_val, max_val],\n    outputs=[y],\n    name=\"test_clip_min_greater_than_max\",\n)"
              },
              {
                "summary": "clip_default",
                "code": "node = onnx.helper.make_node(\n    \"Clip\",\n    inputs=[\"x\", \"min\"],\n    outputs=[\"y\"],\n)\nmin_val = np.float32(0)\nx = np.random.randn(3, 4, 5).astype(np.float32)\ny = np.clip(x, min_val, np.inf)\nexpect(node, inputs=[x, min_val], outputs=[y], name=\"test_clip_default_min\")\n\nno_min = \"\"  # optional input, not supplied\nnode = onnx.helper.make_node(\n    \"Clip\",\n    inputs=[\"x\", no_min, \"max\"],\n    outputs=[\"y\"],\n)\nmax_val = np.float32(0)\nx = np.random.randn(3, 4, 5).astype(np.float32)\ny = np.clip(x, -np.inf, max_val)\nexpect(node, inputs=[x, max_val], outputs=[y], name=\"test_clip_default_max\")\n\nno_max = \"\"  # optional input, not supplied\nnode = onnx.helper.make_node(\n    \"Clip\",\n    inputs=[\"x\", no_min, no_max],\n    outputs=[\"y\"],\n)\n\nx = np.array([-1, 0, 1]).astype(np.float32)\ny = np.array([-1, 0, 1]).astype(np.float32)\nexpect(node, inputs=[x], outputs=[y], name=\"test_clip_default_inbounds\")"
              },
              {
                "summary": "clip_default_int8",
                "code": "node = onnx.helper.make_node(\n    \"Clip\",\n    inputs=[\"x\", \"min\"],\n    outputs=[\"y\"],\n)\nmin_val = np.int8(0)\nx = np.random.randn(3, 4, 5).astype(np.int8)\ny = np.clip(x, min_val, np.iinfo(np.int8).max)\nexpect(\n    node, inputs=[x, min_val], outputs=[y], name=\"test_clip_default_int8_min\"\n)\n\nno_min = \"\"  # optional input, not supplied\nnode = onnx.helper.make_node(\n    \"Clip\",\n    inputs=[\"x\", no_min, \"max\"],\n    outputs=[\"y\"],\n)\nmax_val = np.int8(0)\nx = np.random.randn(3, 4, 5).astype(np.int8)\ny = np.clip(x, np.iinfo(np.int8).min, max_val)\nexpect(\n    node, inputs=[x, max_val], outputs=[y], name=\"test_clip_default_int8_max\"\n)\n\nno_max = \"\"  # optional input, not supplied\nnode = onnx.helper.make_node(\n    \"Clip\",\n    inputs=[\"x\", no_min, no_max],\n    outputs=[\"y\"],\n)\n\nx = np.array([-1, 0, 1]).astype(np.int8)\ny = np.array([-1, 0, 1]).astype(np.int8)\nexpect(node, inputs=[x], outputs=[y], name=\"test_clip_default_int8_inbounds\")"
              }
            ],
            "category": "Activation"
          }
        },
        {
          "name": "mul_10",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "A",
              "value": [
                {
                  "name": "mul_3/y:0",
                  "initializer": {
                    "name": "mul_3/y:0",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float32",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            },
            {
              "name": "B",
              "value": [
                {
                  "name": "Relu6_5:0",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        128,
                        9,
                        16
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "C",
              "value": [
                {
                  "name": "mul_10:0",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        128,
                        9,
                        16
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "Mul",
            "module": "ai.onnx",
            "version": 14,
            "description": "Performs element-wise binary multiplication (with Numpy-style broadcasting support).\n\nThis operator supports **multidirectional (i.e., Numpy-style) broadcasting**; for more details please check [the doc](https://github.com/onnx/onnx/blob/master/docs/Broadcasting.md).\n\n(Opset 14 change): Extend supported types to include uint8, int8, uint16, and int16.\n",
            "inputs": [
              {
                "name": "A",
                "type": "T",
                "description": "First operand."
              },
              {
                "name": "B",
                "type": "T",
                "description": "Second operand."
              }
            ],
            "min_input": 2,
            "max_input": 2,
            "outputs": [
              {
                "name": "C",
                "type": "T",
                "description": "Result, has same element type as two inputs"
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "type_constraints": [
              {
                "description": "Constrain input and output types to all numeric tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(uint8)",
                  "tensor(uint16)",
                  "tensor(uint32)",
                  "tensor(uint64)",
                  "tensor(int8)",
                  "tensor(int16)",
                  "tensor(int32)",
                  "tensor(int64)",
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)",
                  "tensor(bfloat16)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "mul",
                "code": "node = onnx.helper.make_node(\n    \"Mul\",\n    inputs=[\"x\", \"y\"],\n    outputs=[\"z\"],\n)\n\nx = np.array([1, 2, 3]).astype(np.float32)\ny = np.array([4, 5, 6]).astype(np.float32)\nz = x * y  # expected output [4., 10., 18.]\nexpect(node, inputs=[x, y], outputs=[z], name=\"test_mul_example\")\n\nx = np.random.randn(3, 4, 5).astype(np.float32)\ny = np.random.randn(3, 4, 5).astype(np.float32)\nz = x * y\nexpect(node, inputs=[x, y], outputs=[z], name=\"test_mul\")\n\nx = np.random.randint(4, size=(3, 4, 5), dtype=np.int8)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.int8)\nz = x * y\nexpect(node, inputs=[x, y], outputs=[z], name=\"test_mul_int8\")\n\nx = np.random.randint(4, size=(3, 4, 5), dtype=np.int16)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.int16)\nz = x * y\nexpect(node, inputs=[x, y], outputs=[z], name=\"test_mul_int16\")\n\nx = np.random.randint(4, size=(3, 4, 5), dtype=np.uint8)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.uint8)\nz = x * y\nexpect(node, inputs=[x, y], outputs=[z], name=\"test_mul_uint8\")\n\nx = np.random.randint(4, size=(3, 4, 5), dtype=np.uint16)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.uint16)\nz = x * y\nexpect(node, inputs=[x, y], outputs=[z], name=\"test_mul_uint16\")\n\nx = np.random.randint(4, size=(3, 4, 5), dtype=np.uint32)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.uint32)\nz = x * y\nexpect(node, inputs=[x, y], outputs=[z], name=\"test_mul_uint32\")\n\nx = np.random.randint(4, size=(3, 4, 5), dtype=np.uint64)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.uint64)\nz = x * y\nexpect(node, inputs=[x, y], outputs=[z], name=\"test_mul_uint64\")"
              },
              {
                "summary": "mul_broadcast",
                "code": "node = onnx.helper.make_node(\n    \"Mul\",\n    inputs=[\"x\", \"y\"],\n    outputs=[\"z\"],\n)\n\nx = np.random.randn(3, 4, 5).astype(np.float32)\ny = np.random.randn(5).astype(np.float32)\nz = x * y\nexpect(node, inputs=[x, y], outputs=[z], name=\"test_mul_bcast\")"
              }
            ]
          }
        },
        {
          "name": "mul_11",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "A",
              "value": [
                {
                  "name": "Conv__205:0",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        128,
                        9,
                        16
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "B",
              "value": [
                {
                  "name": "mul_10:0",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        128,
                        9,
                        16
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "C",
              "value": [
                {
                  "name": "mul_11:0",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        128,
                        9,
                        16
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "Mul",
            "module": "ai.onnx",
            "version": 14,
            "description": "Performs element-wise binary multiplication (with Numpy-style broadcasting support).\n\nThis operator supports **multidirectional (i.e., Numpy-style) broadcasting**; for more details please check [the doc](https://github.com/onnx/onnx/blob/master/docs/Broadcasting.md).\n\n(Opset 14 change): Extend supported types to include uint8, int8, uint16, and int16.\n",
            "inputs": [
              {
                "name": "A",
                "type": "T",
                "description": "First operand."
              },
              {
                "name": "B",
                "type": "T",
                "description": "Second operand."
              }
            ],
            "min_input": 2,
            "max_input": 2,
            "outputs": [
              {
                "name": "C",
                "type": "T",
                "description": "Result, has same element type as two inputs"
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "type_constraints": [
              {
                "description": "Constrain input and output types to all numeric tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(uint8)",
                  "tensor(uint16)",
                  "tensor(uint32)",
                  "tensor(uint64)",
                  "tensor(int8)",
                  "tensor(int16)",
                  "tensor(int32)",
                  "tensor(int64)",
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)",
                  "tensor(bfloat16)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "mul",
                "code": "node = onnx.helper.make_node(\n    \"Mul\",\n    inputs=[\"x\", \"y\"],\n    outputs=[\"z\"],\n)\n\nx = np.array([1, 2, 3]).astype(np.float32)\ny = np.array([4, 5, 6]).astype(np.float32)\nz = x * y  # expected output [4., 10., 18.]\nexpect(node, inputs=[x, y], outputs=[z], name=\"test_mul_example\")\n\nx = np.random.randn(3, 4, 5).astype(np.float32)\ny = np.random.randn(3, 4, 5).astype(np.float32)\nz = x * y\nexpect(node, inputs=[x, y], outputs=[z], name=\"test_mul\")\n\nx = np.random.randint(4, size=(3, 4, 5), dtype=np.int8)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.int8)\nz = x * y\nexpect(node, inputs=[x, y], outputs=[z], name=\"test_mul_int8\")\n\nx = np.random.randint(4, size=(3, 4, 5), dtype=np.int16)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.int16)\nz = x * y\nexpect(node, inputs=[x, y], outputs=[z], name=\"test_mul_int16\")\n\nx = np.random.randint(4, size=(3, 4, 5), dtype=np.uint8)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.uint8)\nz = x * y\nexpect(node, inputs=[x, y], outputs=[z], name=\"test_mul_uint8\")\n\nx = np.random.randint(4, size=(3, 4, 5), dtype=np.uint16)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.uint16)\nz = x * y\nexpect(node, inputs=[x, y], outputs=[z], name=\"test_mul_uint16\")\n\nx = np.random.randint(4, size=(3, 4, 5), dtype=np.uint32)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.uint32)\nz = x * y\nexpect(node, inputs=[x, y], outputs=[z], name=\"test_mul_uint32\")\n\nx = np.random.randint(4, size=(3, 4, 5), dtype=np.uint64)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.uint64)\nz = x * y\nexpect(node, inputs=[x, y], outputs=[z], name=\"test_mul_uint64\")"
              },
              {
                "summary": "mul_broadcast",
                "code": "node = onnx.helper.make_node(\n    \"Mul\",\n    inputs=[\"x\", \"y\"],\n    outputs=[\"z\"],\n)\n\nx = np.random.randn(3, 4, 5).astype(np.float32)\ny = np.random.randn(5).astype(np.float32)\nz = x * y\nexpect(node, inputs=[x, y], outputs=[z], name=\"test_mul_bcast\")"
              }
            ]
          }
        },
        {
          "name": "Conv__208",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "X",
              "value": [
                {
                  "name": "mul_11:0",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        128,
                        9,
                        16
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "W",
              "value": [
                {
                  "name": "const_fold_opt__379",
                  "initializer": {
                    "name": "const_fold_opt__379",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float32",
                      "shape": {
                        "dimensions": [
                          128,
                          1,
                          5,
                          5
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        128,
                        1,
                        5,
                        5
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "B",
              "value": [
                {
                  "name": "depthwise_conv2d_5/y:0",
                  "initializer": {
                    "name": "depthwise_conv2d_5/y:0",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float32",
                      "shape": {
                        "dimensions": [
                          128
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        128
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "Y",
              "value": [
                {
                  "name": "Conv__208:0",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        128,
                        9,
                        16
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [
            {
              "name": "dilations",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "strides",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "kernel_shape",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "5",
                  "5"
                ]
              }
            },
            {
              "name": "group",
              "type": "int64",
              "value": {
                "type": "bigint",
                "value": "128"
              }
            },
            {
              "name": "pads",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "2",
                  "2",
                  "2",
                  "2"
                ]
              }
            }
          ],
          "type": {
            "name": "Conv",
            "module": "ai.onnx",
            "version": 11,
            "description": "The convolution operator consumes an input tensor and a filter, and\ncomputes the output.",
            "attributes": [
              {
                "name": "auto_pad",
                "type": "string",
                "required": false,
                "default": "NOTSET",
                "description": "auto_pad must be either NOTSET, SAME_UPPER, SAME_LOWER or VALID. Where default value is NOTSET, which means explicit padding is used. SAME_UPPER or SAME_LOWER mean pad the input so that `output_shape[i] = ceil(input_shape[i] / strides[i])` for each axis `i`. The padding is split between the two sides equally or almost equally (depending on whether it is even or odd). In case the padding is an odd number, the extra padding is added at the end for SAME_UPPER and at the beginning for SAME_LOWER."
              },
              {
                "name": "dilations",
                "type": "int64[]",
                "required": false,
                "description": "dilation value along each spatial axis of the filter. If not present, the dilation defaults is 1 along each spatial axis."
              },
              {
                "name": "group",
                "type": "int64",
                "required": false,
                "default": 1,
                "description": "number of groups input channels and output channels are divided into."
              },
              {
                "name": "kernel_shape",
                "type": "int64[]",
                "required": false,
                "description": "The shape of the convolution kernel. If not present, should be inferred from input W."
              },
              {
                "name": "pads",
                "type": "int64[]",
                "required": false,
                "description": "Padding for the beginning and ending along each spatial axis, it can take any value greater than or equal to 0. The value represent the number of pixels added to the beginning and end part of the corresponding axis. `pads` format should be as follow [x1_begin, x2_begin...x1_end, x2_end,...], where xi_begin the number of pixels added at the beginning of axis `i` and xi_end, the number of pixels added at the end of axis `i`. This attribute cannot be used simultaneously with auto_pad attribute. If not present, the padding defaults to 0 along start and end of each spatial axis."
              },
              {
                "name": "strides",
                "type": "int64[]",
                "required": false,
                "description": "Stride along each spatial axis. If not present, the stride defaults is 1 along each spatial axis."
              }
            ],
            "inputs": [
              {
                "name": "X",
                "type": "T",
                "description": "Input data tensor from previous layer; has size (N x C x H x W), where N is the batch size, C is the number of channels, and H and W are the height and width. Note that this is for the 2D image. Otherwise the size is (N x C x D1 x D2 ... x Dn). Optionally, if dimension denotation is in effect, the operation expects input data tensor to arrive with the dimension denotation of [DATA_BATCH, DATA_CHANNEL, DATA_FEATURE, DATA_FEATURE ...]."
              },
              {
                "name": "W",
                "type": "T",
                "description": "The weight tensor that will be used in the convolutions; has size (M x C/group x kH x kW), where C is the number of channels, and kH and kW are the height and width of the kernel, and M is the number of feature maps. For more than 2 dimensions, the kernel shape will be (M x C/group x k1 x k2 x ... x kn), where (k1 x k2 x ... kn) is the dimension of the kernel. Optionally, if dimension denotation is in effect, the operation expects the weight tensor to arrive with the dimension denotation of [FILTER_OUT_CHANNEL, FILTER_IN_CHANNEL, FILTER_SPATIAL, FILTER_SPATIAL ...]. Assuming zero based indices for the shape array, X.shape[1] == (W.shape[1] * group) == C and W.shape[0] mod G == 0. Or in other words FILTER_IN_CHANNEL multiplied by the number of groups should be equal to DATA_CHANNEL and the number of feature maps M should be a multiple of the number of groups G."
              },
              {
                "name": "B",
                "type": "T",
                "option": "optional",
                "description": "Optional 1D bias to be added to the convolution, has size of M."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "Y",
                "type": "T",
                "description": "Output data tensor that contains the result of the convolution. The output dimensions are functions of the kernel size, stride size, and pad lengths."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain input and output types to float tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "conv",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[1, 1, 1, 1],\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 21.0, 27.0, 33.0, 24.0],  # (1, 1, 5, 5) output tensor\n                [33.0, 54.0, 63.0, 72.0, 51.0],\n                [63.0, 99.0, 108.0, 117.0, 81.0],\n                [93.0, 144.0, 153.0, 162.0, 111.0],\n                [72.0, 111.0, 117.0, 123.0, 84.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_basic_conv_with_padding\",\n)\n\n# Convolution without padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[0, 0, 0, 0],\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 63.0, 72.0],  # (1, 1, 3, 3) output tensor\n                [99.0, 108.0, 117.0],\n                [144.0, 153.0, 162.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_basic_conv_without_padding\",\n)"
              },
              {
                "summary": "conv_with_autopad_same",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with auto_pad='SAME_LOWER' and strides=2\nnode = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    auto_pad=\"SAME_LOWER\",\n    kernel_shape=[3, 3],\n    strides=[2, 2],\n)\ny = np.array(\n    [[[[12.0, 27.0, 24.0], [63.0, 108.0, 81.0], [72.0, 117.0, 84.0]]]]\n).astype(np.float32)\nexpect(node, inputs=[x, W], outputs=[y], name=\"test_conv_with_autopad_same\")"
              },
              {
                "summary": "conv_with_strides",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 7, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n                [25.0, 26.0, 27.0, 28.0, 29.0],\n                [30.0, 31.0, 32.0, 33.0, 34.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with strides=2 and padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 1, 1, 1],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 27.0, 24.0],  # (1, 1, 4, 3) output tensor\n                [63.0, 108.0, 81.0],\n                [123.0, 198.0, 141.0],\n                [112.0, 177.0, 124.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_conv_with_strides_padding\",\n)\n\n# Convolution with strides=2 and no padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[0, 0, 0, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 72.0],  # (1, 1, 3, 2) output tensor\n                [144.0, 162.0],\n                [234.0, 252.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_conv_with_strides_no_padding\",\n)\n\n# Convolution with strides=2 and padding only along one dimension (the H dimension in NxCxHxW tensor)\nnode_with_asymmetric_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 0, 1, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_asymmetric_padding = np.array(\n    [\n        [\n            [\n                [21.0, 33.0],  # (1, 1, 4, 2) output tensor\n                [99.0, 117.0],\n                [189.0, 207.0],\n                [171.0, 183.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_asymmetric_padding,\n    inputs=[x, W],\n    outputs=[y_with_asymmetric_padding],\n    name=\"test_conv_with_strides_and_asymmetric_padding\",\n)"
              }
            ],
            "category": "Layer"
          }
        },
        {
          "name": "add_6",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "A",
              "value": [
                {
                  "name": "Conv__208:0",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        128,
                        9,
                        16
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "B",
              "value": [
                {
                  "name": "const_fold_opt__408",
                  "initializer": {
                    "name": "const_fold_opt__408",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float32",
                      "shape": {
                        "dimensions": [
                          1,
                          1,
                          1,
                          1
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        1,
                        1,
                        1
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "C",
              "value": [
                {
                  "name": "add_6:0",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        128,
                        9,
                        16
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "Add",
            "module": "ai.onnx",
            "version": 14,
            "description": "Performs element-wise binary addition (with Numpy-style broadcasting support).\n\nThis operator supports **multidirectional (i.e., Numpy-style) broadcasting**; for more details please check [the doc](https://github.com/onnx/onnx/blob/master/docs/Broadcasting.md).\n\n(Opset 14 change): Extend supported types to include uint8, int8, uint16, and int16.\n",
            "inputs": [
              {
                "name": "A",
                "type": "T",
                "description": "First operand."
              },
              {
                "name": "B",
                "type": "T",
                "description": "Second operand."
              }
            ],
            "min_input": 2,
            "max_input": 2,
            "outputs": [
              {
                "name": "C",
                "type": "T",
                "description": "Result, has same element type as two inputs"
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "type_constraints": [
              {
                "description": "Constrain input and output types to all numeric tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(uint8)",
                  "tensor(uint16)",
                  "tensor(uint32)",
                  "tensor(uint64)",
                  "tensor(int8)",
                  "tensor(int16)",
                  "tensor(int32)",
                  "tensor(int64)",
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)",
                  "tensor(bfloat16)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "add",
                "code": "node = onnx.helper.make_node(\n    \"Add\",\n    inputs=[\"x\", \"y\"],\n    outputs=[\"sum\"],\n)\n\nx = np.random.randn(3, 4, 5).astype(np.float32)\ny = np.random.randn(3, 4, 5).astype(np.float32)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add\")\n\nx = np.random.randint(24, size=(3, 4, 5), dtype=np.int8)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.int8)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add_int8\")\n\nx = np.random.randint(24, size=(3, 4, 5), dtype=np.int16)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.int16)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add_int16\")\n\nx = np.random.randint(24, size=(3, 4, 5), dtype=np.uint8)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.uint8)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add_uint8\")\n\nx = np.random.randint(24, size=(3, 4, 5), dtype=np.uint16)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.uint16)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add_uint16\")\n\nx = np.random.randint(24, size=(3, 4, 5), dtype=np.uint32)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.uint32)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add_uint32\")\n\nx = np.random.randint(24, size=(3, 4, 5), dtype=np.uint64)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.uint64)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add_uint64\")"
              },
              {
                "summary": "add_broadcast",
                "code": "node = onnx.helper.make_node(\n    \"Add\",\n    inputs=[\"x\", \"y\"],\n    outputs=[\"sum\"],\n)\n\nx = np.random.randn(3, 4, 5).astype(np.float32)\ny = np.random.randn(5).astype(np.float32)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add_bcast\")"
              }
            ]
          }
        },
        {
          "name": "Relu6_6",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "input",
              "value": [
                {
                  "name": "add_6:0",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        128,
                        9,
                        16
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "min",
              "value": [
                {
                  "name": "304",
                  "initializer": {
                    "category": "Constant",
                    "encoding": "|",
                    "values": {
                      "0": 0
                    },
                    "type": {
                      "dataType": "float32",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            },
            {
              "name": "max",
              "value": [
                {
                  "name": "305",
                  "initializer": {
                    "category": "Constant",
                    "encoding": "|",
                    "values": {
                      "0": 6
                    },
                    "type": {
                      "dataType": "float32",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "output",
              "value": [
                {
                  "name": "Relu6_6:0",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        128,
                        9,
                        16
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "Clip",
            "module": "ai.onnx",
            "version": 13,
            "description": "Clip operator limits the given input within an interval. The interval is\nspecified by the inputs 'min' and 'max'. They default to\nnumeric_limits::lowest() and numeric_limits::max(), respectively.\nWhen 'min' is greater than 'max', the clip operator sets all the 'input' values to\nthe value of 'max'. Thus, this is equivalent to 'Min(max, Max(input, min))'.\n",
            "inputs": [
              {
                "name": "input",
                "type": "T",
                "description": "Input tensor whose elements to be clipped"
              },
              {
                "name": "min",
                "type": "T",
                "option": "optional",
                "description": "Minimum value, under which element is replaced by min. It must be a scalar(tensor of empty shape)."
              },
              {
                "name": "max",
                "type": "T",
                "option": "optional",
                "description": "Maximum value, above which element is replaced by max. It must be a scalar(tensor of empty shape)."
              }
            ],
            "min_input": 1,
            "max_input": 3,
            "outputs": [
              {
                "name": "output",
                "type": "T",
                "description": "Output tensor with clipped input elements"
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "1 - 3",
            "type_constraints": [
              {
                "description": "Constrain input and output types to all numeric tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(uint8)",
                  "tensor(uint16)",
                  "tensor(uint32)",
                  "tensor(uint64)",
                  "tensor(int8)",
                  "tensor(int16)",
                  "tensor(int32)",
                  "tensor(int64)",
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)",
                  "tensor(bfloat16)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "clip",
                "code": "node = onnx.helper.make_node(\n    \"Clip\",\n    inputs=[\"x\", \"min\", \"max\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([-2, 0, 2]).astype(np.float32)\nmin_val = np.float32(-1)\nmax_val = np.float32(1)\ny = np.clip(x, min_val, max_val)  # expected output [-1., 0., 1.]\nexpect(\n    node, inputs=[x, min_val, max_val], outputs=[y], name=\"test_clip_example\"\n)\n\nx = np.random.randn(3, 4, 5).astype(np.float32)\ny = np.clip(x, min_val, max_val)\nexpect(node, inputs=[x, min_val, max_val], outputs=[y], name=\"test_clip\")\nnode = onnx.helper.make_node(\n    \"Clip\",\n    inputs=[\"x\", \"min\", \"max\"],\n    outputs=[\"y\"],\n)\n\nmin_val = np.float32(-5)\nmax_val = np.float32(5)\n\nx = np.array([-1, 0, 1]).astype(np.float32)\ny = np.array([-1, 0, 1]).astype(np.float32)\nexpect(\n    node, inputs=[x, min_val, max_val], outputs=[y], name=\"test_clip_inbounds\"\n)\n\nx = np.array([-6, 0, 6]).astype(np.float32)\ny = np.array([-5, 0, 5]).astype(np.float32)\nexpect(\n    node, inputs=[x, min_val, max_val], outputs=[y], name=\"test_clip_outbounds\"\n)\n\nx = np.array([-1, 0, 6]).astype(np.float32)\ny = np.array([-1, 0, 5]).astype(np.float32)\nexpect(\n    node,\n    inputs=[x, min_val, max_val],\n    outputs=[y],\n    name=\"test_clip_splitbounds\",\n)\n\nx = np.array([-2, 0, 6]).astype(np.float32)\ny = np.array([1, 1, 1]).astype(np.float32)\nmin_val = np.float32(2)\nmax_val = np.float32(1)\nexpect(\n    node,\n    inputs=[x, min_val, max_val],\n    outputs=[y],\n    name=\"test_clip_min_greater_than_max\",\n)"
              },
              {
                "summary": "clip_default",
                "code": "node = onnx.helper.make_node(\n    \"Clip\",\n    inputs=[\"x\", \"min\"],\n    outputs=[\"y\"],\n)\nmin_val = np.float32(0)\nx = np.random.randn(3, 4, 5).astype(np.float32)\ny = np.clip(x, min_val, np.inf)\nexpect(node, inputs=[x, min_val], outputs=[y], name=\"test_clip_default_min\")\n\nno_min = \"\"  # optional input, not supplied\nnode = onnx.helper.make_node(\n    \"Clip\",\n    inputs=[\"x\", no_min, \"max\"],\n    outputs=[\"y\"],\n)\nmax_val = np.float32(0)\nx = np.random.randn(3, 4, 5).astype(np.float32)\ny = np.clip(x, -np.inf, max_val)\nexpect(node, inputs=[x, max_val], outputs=[y], name=\"test_clip_default_max\")\n\nno_max = \"\"  # optional input, not supplied\nnode = onnx.helper.make_node(\n    \"Clip\",\n    inputs=[\"x\", no_min, no_max],\n    outputs=[\"y\"],\n)\n\nx = np.array([-1, 0, 1]).astype(np.float32)\ny = np.array([-1, 0, 1]).astype(np.float32)\nexpect(node, inputs=[x], outputs=[y], name=\"test_clip_default_inbounds\")"
              },
              {
                "summary": "clip_default_int8",
                "code": "node = onnx.helper.make_node(\n    \"Clip\",\n    inputs=[\"x\", \"min\"],\n    outputs=[\"y\"],\n)\nmin_val = np.int8(0)\nx = np.random.randn(3, 4, 5).astype(np.int8)\ny = np.clip(x, min_val, np.iinfo(np.int8).max)\nexpect(\n    node, inputs=[x, min_val], outputs=[y], name=\"test_clip_default_int8_min\"\n)\n\nno_min = \"\"  # optional input, not supplied\nnode = onnx.helper.make_node(\n    \"Clip\",\n    inputs=[\"x\", no_min, \"max\"],\n    outputs=[\"y\"],\n)\nmax_val = np.int8(0)\nx = np.random.randn(3, 4, 5).astype(np.int8)\ny = np.clip(x, np.iinfo(np.int8).min, max_val)\nexpect(\n    node, inputs=[x, max_val], outputs=[y], name=\"test_clip_default_int8_max\"\n)\n\nno_max = \"\"  # optional input, not supplied\nnode = onnx.helper.make_node(\n    \"Clip\",\n    inputs=[\"x\", no_min, no_max],\n    outputs=[\"y\"],\n)\n\nx = np.array([-1, 0, 1]).astype(np.int8)\ny = np.array([-1, 0, 1]).astype(np.int8)\nexpect(node, inputs=[x], outputs=[y], name=\"test_clip_default_int8_inbounds\")"
              }
            ],
            "category": "Activation"
          }
        },
        {
          "name": "mul_12",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "A",
              "value": [
                {
                  "name": "mul_3/y:0",
                  "initializer": {
                    "name": "mul_3/y:0",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float32",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            },
            {
              "name": "B",
              "value": [
                {
                  "name": "Relu6_6:0",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        128,
                        9,
                        16
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "C",
              "value": [
                {
                  "name": "mul_12:0",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        128,
                        9,
                        16
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "Mul",
            "module": "ai.onnx",
            "version": 14,
            "description": "Performs element-wise binary multiplication (with Numpy-style broadcasting support).\n\nThis operator supports **multidirectional (i.e., Numpy-style) broadcasting**; for more details please check [the doc](https://github.com/onnx/onnx/blob/master/docs/Broadcasting.md).\n\n(Opset 14 change): Extend supported types to include uint8, int8, uint16, and int16.\n",
            "inputs": [
              {
                "name": "A",
                "type": "T",
                "description": "First operand."
              },
              {
                "name": "B",
                "type": "T",
                "description": "Second operand."
              }
            ],
            "min_input": 2,
            "max_input": 2,
            "outputs": [
              {
                "name": "C",
                "type": "T",
                "description": "Result, has same element type as two inputs"
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "type_constraints": [
              {
                "description": "Constrain input and output types to all numeric tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(uint8)",
                  "tensor(uint16)",
                  "tensor(uint32)",
                  "tensor(uint64)",
                  "tensor(int8)",
                  "tensor(int16)",
                  "tensor(int32)",
                  "tensor(int64)",
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)",
                  "tensor(bfloat16)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "mul",
                "code": "node = onnx.helper.make_node(\n    \"Mul\",\n    inputs=[\"x\", \"y\"],\n    outputs=[\"z\"],\n)\n\nx = np.array([1, 2, 3]).astype(np.float32)\ny = np.array([4, 5, 6]).astype(np.float32)\nz = x * y  # expected output [4., 10., 18.]\nexpect(node, inputs=[x, y], outputs=[z], name=\"test_mul_example\")\n\nx = np.random.randn(3, 4, 5).astype(np.float32)\ny = np.random.randn(3, 4, 5).astype(np.float32)\nz = x * y\nexpect(node, inputs=[x, y], outputs=[z], name=\"test_mul\")\n\nx = np.random.randint(4, size=(3, 4, 5), dtype=np.int8)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.int8)\nz = x * y\nexpect(node, inputs=[x, y], outputs=[z], name=\"test_mul_int8\")\n\nx = np.random.randint(4, size=(3, 4, 5), dtype=np.int16)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.int16)\nz = x * y\nexpect(node, inputs=[x, y], outputs=[z], name=\"test_mul_int16\")\n\nx = np.random.randint(4, size=(3, 4, 5), dtype=np.uint8)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.uint8)\nz = x * y\nexpect(node, inputs=[x, y], outputs=[z], name=\"test_mul_uint8\")\n\nx = np.random.randint(4, size=(3, 4, 5), dtype=np.uint16)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.uint16)\nz = x * y\nexpect(node, inputs=[x, y], outputs=[z], name=\"test_mul_uint16\")\n\nx = np.random.randint(4, size=(3, 4, 5), dtype=np.uint32)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.uint32)\nz = x * y\nexpect(node, inputs=[x, y], outputs=[z], name=\"test_mul_uint32\")\n\nx = np.random.randint(4, size=(3, 4, 5), dtype=np.uint64)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.uint64)\nz = x * y\nexpect(node, inputs=[x, y], outputs=[z], name=\"test_mul_uint64\")"
              },
              {
                "summary": "mul_broadcast",
                "code": "node = onnx.helper.make_node(\n    \"Mul\",\n    inputs=[\"x\", \"y\"],\n    outputs=[\"z\"],\n)\n\nx = np.random.randn(3, 4, 5).astype(np.float32)\ny = np.random.randn(5).astype(np.float32)\nz = x * y\nexpect(node, inputs=[x, y], outputs=[z], name=\"test_mul_bcast\")"
              }
            ]
          }
        },
        {
          "name": "mul_13",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "A",
              "value": [
                {
                  "name": "Conv__208:0",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        128,
                        9,
                        16
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "B",
              "value": [
                {
                  "name": "mul_12:0",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        128,
                        9,
                        16
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "C",
              "value": [
                {
                  "name": "mul_13:0",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        128,
                        9,
                        16
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "Mul",
            "module": "ai.onnx",
            "version": 14,
            "description": "Performs element-wise binary multiplication (with Numpy-style broadcasting support).\n\nThis operator supports **multidirectional (i.e., Numpy-style) broadcasting**; for more details please check [the doc](https://github.com/onnx/onnx/blob/master/docs/Broadcasting.md).\n\n(Opset 14 change): Extend supported types to include uint8, int8, uint16, and int16.\n",
            "inputs": [
              {
                "name": "A",
                "type": "T",
                "description": "First operand."
              },
              {
                "name": "B",
                "type": "T",
                "description": "Second operand."
              }
            ],
            "min_input": 2,
            "max_input": 2,
            "outputs": [
              {
                "name": "C",
                "type": "T",
                "description": "Result, has same element type as two inputs"
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "type_constraints": [
              {
                "description": "Constrain input and output types to all numeric tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(uint8)",
                  "tensor(uint16)",
                  "tensor(uint32)",
                  "tensor(uint64)",
                  "tensor(int8)",
                  "tensor(int16)",
                  "tensor(int32)",
                  "tensor(int64)",
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)",
                  "tensor(bfloat16)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "mul",
                "code": "node = onnx.helper.make_node(\n    \"Mul\",\n    inputs=[\"x\", \"y\"],\n    outputs=[\"z\"],\n)\n\nx = np.array([1, 2, 3]).astype(np.float32)\ny = np.array([4, 5, 6]).astype(np.float32)\nz = x * y  # expected output [4., 10., 18.]\nexpect(node, inputs=[x, y], outputs=[z], name=\"test_mul_example\")\n\nx = np.random.randn(3, 4, 5).astype(np.float32)\ny = np.random.randn(3, 4, 5).astype(np.float32)\nz = x * y\nexpect(node, inputs=[x, y], outputs=[z], name=\"test_mul\")\n\nx = np.random.randint(4, size=(3, 4, 5), dtype=np.int8)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.int8)\nz = x * y\nexpect(node, inputs=[x, y], outputs=[z], name=\"test_mul_int8\")\n\nx = np.random.randint(4, size=(3, 4, 5), dtype=np.int16)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.int16)\nz = x * y\nexpect(node, inputs=[x, y], outputs=[z], name=\"test_mul_int16\")\n\nx = np.random.randint(4, size=(3, 4, 5), dtype=np.uint8)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.uint8)\nz = x * y\nexpect(node, inputs=[x, y], outputs=[z], name=\"test_mul_uint8\")\n\nx = np.random.randint(4, size=(3, 4, 5), dtype=np.uint16)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.uint16)\nz = x * y\nexpect(node, inputs=[x, y], outputs=[z], name=\"test_mul_uint16\")\n\nx = np.random.randint(4, size=(3, 4, 5), dtype=np.uint32)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.uint32)\nz = x * y\nexpect(node, inputs=[x, y], outputs=[z], name=\"test_mul_uint32\")\n\nx = np.random.randint(4, size=(3, 4, 5), dtype=np.uint64)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.uint64)\nz = x * y\nexpect(node, inputs=[x, y], outputs=[z], name=\"test_mul_uint64\")"
              },
              {
                "summary": "mul_broadcast",
                "code": "node = onnx.helper.make_node(\n    \"Mul\",\n    inputs=[\"x\", \"y\"],\n    outputs=[\"z\"],\n)\n\nx = np.random.randn(3, 4, 5).astype(np.float32)\ny = np.random.randn(5).astype(np.float32)\nz = x * y\nexpect(node, inputs=[x, y], outputs=[z], name=\"test_mul_bcast\")"
              }
            ]
          }
        },
        {
          "name": "global_average_pooling2d_3",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "X",
              "value": [
                {
                  "name": "mul_13:0",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        128,
                        9,
                        16
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "Y",
              "value": [
                {
                  "name": "global_average_pooling2d_3:0",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        128,
                        1,
                        1
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "GlobalAveragePool",
            "module": "ai.onnx",
            "version": 1,
            "description": "GlobalAveragePool consumes an input tensor X and applies average pooling across\n the values in the same channel. This is equivalent to AveragePool with kernel size\n equal to the spatial dimension of input tensor.",
            "inputs": [
              {
                "name": "X",
                "type": "T",
                "description": "Input data tensor from the previous operator; dimensions for image case are (N x C x H x W), where N is the batch size, C is the number of channels, and H and W are the height and the width of the data. For non image case, the dimensions are in the form of (N x C x D1 x D2 ... Dn), where N is the batch size."
              }
            ],
            "min_input": 1,
            "max_input": 1,
            "outputs": [
              {
                "name": "Y",
                "type": "T",
                "description": "Output data tensor from pooling across the input tensor. The output tensor has the same rank as the input. The first two dimensions of output shape are the same as the input (N x C), while the other dimensions are all 1."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "type_constraints": [
              {
                "description": "Constrain input and output types to float tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "globalaveragepool",
                "code": "node = onnx.helper.make_node(\n    \"GlobalAveragePool\",\n    inputs=[\"x\"],\n    outputs=[\"y\"],\n)\nx = np.random.randn(1, 3, 5, 5).astype(np.float32)\ny = np.mean(x, axis=tuple(range(2, np.ndim(x))), keepdims=True)\nexpect(node, inputs=[x], outputs=[y], name=\"test_globalaveragepool\")"
              },
              {
                "summary": "globalaveragepool_precomputed",
                "code": "node = onnx.helper.make_node(\n    \"GlobalAveragePool\",\n    inputs=[\"x\"],\n    outputs=[\"y\"],\n)\nx = np.array(\n    [\n        [\n            [\n                [1, 2, 3],\n                [4, 5, 6],\n                [7, 8, 9],\n            ]\n        ]\n    ]\n).astype(np.float32)\ny = np.array([[[[5]]]]).astype(np.float32)\nexpect(node, inputs=[x], outputs=[y], name=\"test_globalaveragepool_precomputed\")"
              }
            ],
            "category": "Pool"
          }
        },
        {
          "name": "Conv__211",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "X",
              "value": [
                {
                  "name": "global_average_pooling2d_3:0",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        128,
                        1,
                        1
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "W",
              "value": [
                {
                  "name": "Conv2D_19/filter:0",
                  "initializer": {
                    "name": "Conv2D_19/filter:0",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float32",
                      "shape": {
                        "dimensions": [
                          32,
                          128,
                          1,
                          1
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        32,
                        128,
                        1,
                        1
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "B",
              "value": [
                {
                  "name": "conv2d_18_1/y:0",
                  "initializer": {
                    "name": "conv2d_18_1/y:0",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float32",
                      "shape": {
                        "dimensions": [
                          32
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        32
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "Y",
              "value": [
                {
                  "name": "Conv__211:0",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        32,
                        1,
                        1
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [
            {
              "name": "dilations",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "strides",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "kernel_shape",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "group",
              "type": "int64",
              "value": {
                "type": "bigint",
                "value": "1"
              }
            }
          ],
          "type": {
            "name": "Conv",
            "module": "ai.onnx",
            "version": 11,
            "description": "The convolution operator consumes an input tensor and a filter, and\ncomputes the output.",
            "attributes": [
              {
                "name": "auto_pad",
                "type": "string",
                "required": false,
                "default": "NOTSET",
                "description": "auto_pad must be either NOTSET, SAME_UPPER, SAME_LOWER or VALID. Where default value is NOTSET, which means explicit padding is used. SAME_UPPER or SAME_LOWER mean pad the input so that `output_shape[i] = ceil(input_shape[i] / strides[i])` for each axis `i`. The padding is split between the two sides equally or almost equally (depending on whether it is even or odd). In case the padding is an odd number, the extra padding is added at the end for SAME_UPPER and at the beginning for SAME_LOWER."
              },
              {
                "name": "dilations",
                "type": "int64[]",
                "required": false,
                "description": "dilation value along each spatial axis of the filter. If not present, the dilation defaults is 1 along each spatial axis."
              },
              {
                "name": "group",
                "type": "int64",
                "required": false,
                "default": 1,
                "description": "number of groups input channels and output channels are divided into."
              },
              {
                "name": "kernel_shape",
                "type": "int64[]",
                "required": false,
                "description": "The shape of the convolution kernel. If not present, should be inferred from input W."
              },
              {
                "name": "pads",
                "type": "int64[]",
                "required": false,
                "description": "Padding for the beginning and ending along each spatial axis, it can take any value greater than or equal to 0. The value represent the number of pixels added to the beginning and end part of the corresponding axis. `pads` format should be as follow [x1_begin, x2_begin...x1_end, x2_end,...], where xi_begin the number of pixels added at the beginning of axis `i` and xi_end, the number of pixels added at the end of axis `i`. This attribute cannot be used simultaneously with auto_pad attribute. If not present, the padding defaults to 0 along start and end of each spatial axis."
              },
              {
                "name": "strides",
                "type": "int64[]",
                "required": false,
                "description": "Stride along each spatial axis. If not present, the stride defaults is 1 along each spatial axis."
              }
            ],
            "inputs": [
              {
                "name": "X",
                "type": "T",
                "description": "Input data tensor from previous layer; has size (N x C x H x W), where N is the batch size, C is the number of channels, and H and W are the height and width. Note that this is for the 2D image. Otherwise the size is (N x C x D1 x D2 ... x Dn). Optionally, if dimension denotation is in effect, the operation expects input data tensor to arrive with the dimension denotation of [DATA_BATCH, DATA_CHANNEL, DATA_FEATURE, DATA_FEATURE ...]."
              },
              {
                "name": "W",
                "type": "T",
                "description": "The weight tensor that will be used in the convolutions; has size (M x C/group x kH x kW), where C is the number of channels, and kH and kW are the height and width of the kernel, and M is the number of feature maps. For more than 2 dimensions, the kernel shape will be (M x C/group x k1 x k2 x ... x kn), where (k1 x k2 x ... kn) is the dimension of the kernel. Optionally, if dimension denotation is in effect, the operation expects the weight tensor to arrive with the dimension denotation of [FILTER_OUT_CHANNEL, FILTER_IN_CHANNEL, FILTER_SPATIAL, FILTER_SPATIAL ...]. Assuming zero based indices for the shape array, X.shape[1] == (W.shape[1] * group) == C and W.shape[0] mod G == 0. Or in other words FILTER_IN_CHANNEL multiplied by the number of groups should be equal to DATA_CHANNEL and the number of feature maps M should be a multiple of the number of groups G."
              },
              {
                "name": "B",
                "type": "T",
                "option": "optional",
                "description": "Optional 1D bias to be added to the convolution, has size of M."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "Y",
                "type": "T",
                "description": "Output data tensor that contains the result of the convolution. The output dimensions are functions of the kernel size, stride size, and pad lengths."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain input and output types to float tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "conv",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[1, 1, 1, 1],\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 21.0, 27.0, 33.0, 24.0],  # (1, 1, 5, 5) output tensor\n                [33.0, 54.0, 63.0, 72.0, 51.0],\n                [63.0, 99.0, 108.0, 117.0, 81.0],\n                [93.0, 144.0, 153.0, 162.0, 111.0],\n                [72.0, 111.0, 117.0, 123.0, 84.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_basic_conv_with_padding\",\n)\n\n# Convolution without padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[0, 0, 0, 0],\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 63.0, 72.0],  # (1, 1, 3, 3) output tensor\n                [99.0, 108.0, 117.0],\n                [144.0, 153.0, 162.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_basic_conv_without_padding\",\n)"
              },
              {
                "summary": "conv_with_autopad_same",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with auto_pad='SAME_LOWER' and strides=2\nnode = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    auto_pad=\"SAME_LOWER\",\n    kernel_shape=[3, 3],\n    strides=[2, 2],\n)\ny = np.array(\n    [[[[12.0, 27.0, 24.0], [63.0, 108.0, 81.0], [72.0, 117.0, 84.0]]]]\n).astype(np.float32)\nexpect(node, inputs=[x, W], outputs=[y], name=\"test_conv_with_autopad_same\")"
              },
              {
                "summary": "conv_with_strides",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 7, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n                [25.0, 26.0, 27.0, 28.0, 29.0],\n                [30.0, 31.0, 32.0, 33.0, 34.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with strides=2 and padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 1, 1, 1],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 27.0, 24.0],  # (1, 1, 4, 3) output tensor\n                [63.0, 108.0, 81.0],\n                [123.0, 198.0, 141.0],\n                [112.0, 177.0, 124.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_conv_with_strides_padding\",\n)\n\n# Convolution with strides=2 and no padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[0, 0, 0, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 72.0],  # (1, 1, 3, 2) output tensor\n                [144.0, 162.0],\n                [234.0, 252.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_conv_with_strides_no_padding\",\n)\n\n# Convolution with strides=2 and padding only along one dimension (the H dimension in NxCxHxW tensor)\nnode_with_asymmetric_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 0, 1, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_asymmetric_padding = np.array(\n    [\n        [\n            [\n                [21.0, 33.0],  # (1, 1, 4, 2) output tensor\n                [99.0, 117.0],\n                [189.0, 207.0],\n                [171.0, 183.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_asymmetric_padding,\n    inputs=[x, W],\n    outputs=[y_with_asymmetric_padding],\n    name=\"test_conv_with_strides_and_asymmetric_padding\",\n)"
              }
            ],
            "category": "Layer"
          }
        },
        {
          "name": "re_lu_9",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "X",
              "value": [
                {
                  "name": "Conv__211:0",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        32,
                        1,
                        1
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "Y",
              "value": [
                {
                  "name": "re_lu_9:0",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        32,
                        1,
                        1
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "Relu",
            "module": "ai.onnx",
            "version": 14,
            "description": "Relu takes one input data (Tensor<T>) and produces one output data\n(Tensor<T>) where the rectified linear function, y = max(0, x), is applied to\nthe tensor elementwise.\n",
            "inputs": [
              {
                "name": "X",
                "type": "T",
                "description": "Input tensor"
              }
            ],
            "min_input": 1,
            "max_input": 1,
            "outputs": [
              {
                "name": "Y",
                "type": "T",
                "description": "Output tensor"
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "type_constraints": [
              {
                "description": "Constrain input and output types to signed numeric tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(float)",
                  "tensor(int32)",
                  "tensor(int8)",
                  "tensor(int16)",
                  "tensor(int64)",
                  "tensor(float16)",
                  "tensor(double)",
                  "tensor(bfloat16)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "relu",
                "code": "node = onnx.helper.make_node(\n    \"Relu\",\n    inputs=[\"x\"],\n    outputs=[\"y\"],\n)\nx = np.random.randn(3, 4, 5).astype(np.float32)\ny = np.clip(x, 0, np.inf)\n\nexpect(node, inputs=[x], outputs=[y], name=\"test_relu\")"
              }
            ],
            "category": "Activation"
          }
        },
        {
          "name": "Conv__212",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "X",
              "value": [
                {
                  "name": "re_lu_9:0",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        32,
                        1,
                        1
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "W",
              "value": [
                {
                  "name": "Conv2D_20/filter:0",
                  "initializer": {
                    "name": "Conv2D_20/filter:0",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float32",
                      "shape": {
                        "dimensions": [
                          128,
                          32,
                          1,
                          1
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        128,
                        32,
                        1,
                        1
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "B",
              "value": [
                {
                  "name": "conv2d_19_1/y:0",
                  "initializer": {
                    "name": "conv2d_19_1/y:0",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float32",
                      "shape": {
                        "dimensions": [
                          128
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        128
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "Y",
              "value": [
                {
                  "name": "Conv__212:0",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        128,
                        1,
                        1
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [
            {
              "name": "dilations",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "strides",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "kernel_shape",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "group",
              "type": "int64",
              "value": {
                "type": "bigint",
                "value": "1"
              }
            }
          ],
          "type": {
            "name": "Conv",
            "module": "ai.onnx",
            "version": 11,
            "description": "The convolution operator consumes an input tensor and a filter, and\ncomputes the output.",
            "attributes": [
              {
                "name": "auto_pad",
                "type": "string",
                "required": false,
                "default": "NOTSET",
                "description": "auto_pad must be either NOTSET, SAME_UPPER, SAME_LOWER or VALID. Where default value is NOTSET, which means explicit padding is used. SAME_UPPER or SAME_LOWER mean pad the input so that `output_shape[i] = ceil(input_shape[i] / strides[i])` for each axis `i`. The padding is split between the two sides equally or almost equally (depending on whether it is even or odd). In case the padding is an odd number, the extra padding is added at the end for SAME_UPPER and at the beginning for SAME_LOWER."
              },
              {
                "name": "dilations",
                "type": "int64[]",
                "required": false,
                "description": "dilation value along each spatial axis of the filter. If not present, the dilation defaults is 1 along each spatial axis."
              },
              {
                "name": "group",
                "type": "int64",
                "required": false,
                "default": 1,
                "description": "number of groups input channels and output channels are divided into."
              },
              {
                "name": "kernel_shape",
                "type": "int64[]",
                "required": false,
                "description": "The shape of the convolution kernel. If not present, should be inferred from input W."
              },
              {
                "name": "pads",
                "type": "int64[]",
                "required": false,
                "description": "Padding for the beginning and ending along each spatial axis, it can take any value greater than or equal to 0. The value represent the number of pixels added to the beginning and end part of the corresponding axis. `pads` format should be as follow [x1_begin, x2_begin...x1_end, x2_end,...], where xi_begin the number of pixels added at the beginning of axis `i` and xi_end, the number of pixels added at the end of axis `i`. This attribute cannot be used simultaneously with auto_pad attribute. If not present, the padding defaults to 0 along start and end of each spatial axis."
              },
              {
                "name": "strides",
                "type": "int64[]",
                "required": false,
                "description": "Stride along each spatial axis. If not present, the stride defaults is 1 along each spatial axis."
              }
            ],
            "inputs": [
              {
                "name": "X",
                "type": "T",
                "description": "Input data tensor from previous layer; has size (N x C x H x W), where N is the batch size, C is the number of channels, and H and W are the height and width. Note that this is for the 2D image. Otherwise the size is (N x C x D1 x D2 ... x Dn). Optionally, if dimension denotation is in effect, the operation expects input data tensor to arrive with the dimension denotation of [DATA_BATCH, DATA_CHANNEL, DATA_FEATURE, DATA_FEATURE ...]."
              },
              {
                "name": "W",
                "type": "T",
                "description": "The weight tensor that will be used in the convolutions; has size (M x C/group x kH x kW), where C is the number of channels, and kH and kW are the height and width of the kernel, and M is the number of feature maps. For more than 2 dimensions, the kernel shape will be (M x C/group x k1 x k2 x ... x kn), where (k1 x k2 x ... kn) is the dimension of the kernel. Optionally, if dimension denotation is in effect, the operation expects the weight tensor to arrive with the dimension denotation of [FILTER_OUT_CHANNEL, FILTER_IN_CHANNEL, FILTER_SPATIAL, FILTER_SPATIAL ...]. Assuming zero based indices for the shape array, X.shape[1] == (W.shape[1] * group) == C and W.shape[0] mod G == 0. Or in other words FILTER_IN_CHANNEL multiplied by the number of groups should be equal to DATA_CHANNEL and the number of feature maps M should be a multiple of the number of groups G."
              },
              {
                "name": "B",
                "type": "T",
                "option": "optional",
                "description": "Optional 1D bias to be added to the convolution, has size of M."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "Y",
                "type": "T",
                "description": "Output data tensor that contains the result of the convolution. The output dimensions are functions of the kernel size, stride size, and pad lengths."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain input and output types to float tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "conv",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[1, 1, 1, 1],\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 21.0, 27.0, 33.0, 24.0],  # (1, 1, 5, 5) output tensor\n                [33.0, 54.0, 63.0, 72.0, 51.0],\n                [63.0, 99.0, 108.0, 117.0, 81.0],\n                [93.0, 144.0, 153.0, 162.0, 111.0],\n                [72.0, 111.0, 117.0, 123.0, 84.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_basic_conv_with_padding\",\n)\n\n# Convolution without padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[0, 0, 0, 0],\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 63.0, 72.0],  # (1, 1, 3, 3) output tensor\n                [99.0, 108.0, 117.0],\n                [144.0, 153.0, 162.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_basic_conv_without_padding\",\n)"
              },
              {
                "summary": "conv_with_autopad_same",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with auto_pad='SAME_LOWER' and strides=2\nnode = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    auto_pad=\"SAME_LOWER\",\n    kernel_shape=[3, 3],\n    strides=[2, 2],\n)\ny = np.array(\n    [[[[12.0, 27.0, 24.0], [63.0, 108.0, 81.0], [72.0, 117.0, 84.0]]]]\n).astype(np.float32)\nexpect(node, inputs=[x, W], outputs=[y], name=\"test_conv_with_autopad_same\")"
              },
              {
                "summary": "conv_with_strides",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 7, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n                [25.0, 26.0, 27.0, 28.0, 29.0],\n                [30.0, 31.0, 32.0, 33.0, 34.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with strides=2 and padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 1, 1, 1],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 27.0, 24.0],  # (1, 1, 4, 3) output tensor\n                [63.0, 108.0, 81.0],\n                [123.0, 198.0, 141.0],\n                [112.0, 177.0, 124.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_conv_with_strides_padding\",\n)\n\n# Convolution with strides=2 and no padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[0, 0, 0, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 72.0],  # (1, 1, 3, 2) output tensor\n                [144.0, 162.0],\n                [234.0, 252.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_conv_with_strides_no_padding\",\n)\n\n# Convolution with strides=2 and padding only along one dimension (the H dimension in NxCxHxW tensor)\nnode_with_asymmetric_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 0, 1, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_asymmetric_padding = np.array(\n    [\n        [\n            [\n                [21.0, 33.0],  # (1, 1, 4, 2) output tensor\n                [99.0, 117.0],\n                [189.0, 207.0],\n                [171.0, 183.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_asymmetric_padding,\n    inputs=[x, W],\n    outputs=[y_with_asymmetric_padding],\n    name=\"test_conv_with_strides_and_asymmetric_padding\",\n)"
              }
            ],
            "category": "Layer"
          }
        },
        {
          "name": "activation_3",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "X",
              "value": [
                {
                  "name": "Conv__212:0",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        128,
                        1,
                        1
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "Y",
              "value": [
                {
                  "name": "activation_3:0",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        128,
                        1,
                        1
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "Sigmoid",
            "module": "ai.onnx",
            "version": 13,
            "description": "Sigmoid takes one input data (Tensor<T>) and produces one output data\n(Tensor<T>) where the sigmoid function, y = 1 / (1 + exp(-x)), is applied to the\ntensor elementwise.\n",
            "inputs": [
              {
                "name": "X",
                "type": "T",
                "description": "Input tensor"
              }
            ],
            "min_input": 1,
            "max_input": 1,
            "outputs": [
              {
                "name": "Y",
                "type": "T",
                "description": "Output tensor"
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "type_constraints": [
              {
                "description": "Constrain input and output types to float tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)",
                  "tensor(bfloat16)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "sigmoid",
                "code": "node = onnx.helper.make_node(\n    \"Sigmoid\",\n    inputs=[\"x\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([-1, 0, 1]).astype(np.float32)\ny = 1.0 / (\n    1.0 + np.exp(np.negative(x))\n)  # expected output [0.26894143, 0.5, 0.7310586]\nexpect(node, inputs=[x], outputs=[y], name=\"test_sigmoid_example\")\n\nx = np.random.randn(3, 4, 5).astype(np.float32)\ny = 1.0 / (1.0 + np.exp(np.negative(x)))\nexpect(node, inputs=[x], outputs=[y], name=\"test_sigmoid\")"
              }
            ],
            "category": "Activation"
          }
        },
        {
          "name": "multiply_3",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "A",
              "value": [
                {
                  "name": "mul_13:0",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        128,
                        9,
                        16
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "B",
              "value": [
                {
                  "name": "activation_3:0",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        128,
                        1,
                        1
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "C",
              "value": [
                {
                  "name": "multiply_3:0",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        128,
                        9,
                        16
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "Mul",
            "module": "ai.onnx",
            "version": 14,
            "description": "Performs element-wise binary multiplication (with Numpy-style broadcasting support).\n\nThis operator supports **multidirectional (i.e., Numpy-style) broadcasting**; for more details please check [the doc](https://github.com/onnx/onnx/blob/master/docs/Broadcasting.md).\n\n(Opset 14 change): Extend supported types to include uint8, int8, uint16, and int16.\n",
            "inputs": [
              {
                "name": "A",
                "type": "T",
                "description": "First operand."
              },
              {
                "name": "B",
                "type": "T",
                "description": "Second operand."
              }
            ],
            "min_input": 2,
            "max_input": 2,
            "outputs": [
              {
                "name": "C",
                "type": "T",
                "description": "Result, has same element type as two inputs"
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "type_constraints": [
              {
                "description": "Constrain input and output types to all numeric tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(uint8)",
                  "tensor(uint16)",
                  "tensor(uint32)",
                  "tensor(uint64)",
                  "tensor(int8)",
                  "tensor(int16)",
                  "tensor(int32)",
                  "tensor(int64)",
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)",
                  "tensor(bfloat16)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "mul",
                "code": "node = onnx.helper.make_node(\n    \"Mul\",\n    inputs=[\"x\", \"y\"],\n    outputs=[\"z\"],\n)\n\nx = np.array([1, 2, 3]).astype(np.float32)\ny = np.array([4, 5, 6]).astype(np.float32)\nz = x * y  # expected output [4., 10., 18.]\nexpect(node, inputs=[x, y], outputs=[z], name=\"test_mul_example\")\n\nx = np.random.randn(3, 4, 5).astype(np.float32)\ny = np.random.randn(3, 4, 5).astype(np.float32)\nz = x * y\nexpect(node, inputs=[x, y], outputs=[z], name=\"test_mul\")\n\nx = np.random.randint(4, size=(3, 4, 5), dtype=np.int8)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.int8)\nz = x * y\nexpect(node, inputs=[x, y], outputs=[z], name=\"test_mul_int8\")\n\nx = np.random.randint(4, size=(3, 4, 5), dtype=np.int16)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.int16)\nz = x * y\nexpect(node, inputs=[x, y], outputs=[z], name=\"test_mul_int16\")\n\nx = np.random.randint(4, size=(3, 4, 5), dtype=np.uint8)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.uint8)\nz = x * y\nexpect(node, inputs=[x, y], outputs=[z], name=\"test_mul_uint8\")\n\nx = np.random.randint(4, size=(3, 4, 5), dtype=np.uint16)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.uint16)\nz = x * y\nexpect(node, inputs=[x, y], outputs=[z], name=\"test_mul_uint16\")\n\nx = np.random.randint(4, size=(3, 4, 5), dtype=np.uint32)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.uint32)\nz = x * y\nexpect(node, inputs=[x, y], outputs=[z], name=\"test_mul_uint32\")\n\nx = np.random.randint(4, size=(3, 4, 5), dtype=np.uint64)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.uint64)\nz = x * y\nexpect(node, inputs=[x, y], outputs=[z], name=\"test_mul_uint64\")"
              },
              {
                "summary": "mul_broadcast",
                "code": "node = onnx.helper.make_node(\n    \"Mul\",\n    inputs=[\"x\", \"y\"],\n    outputs=[\"z\"],\n)\n\nx = np.random.randn(3, 4, 5).astype(np.float32)\ny = np.random.randn(5).astype(np.float32)\nz = x * y\nexpect(node, inputs=[x, y], outputs=[z], name=\"test_mul_bcast\")"
              }
            ]
          }
        },
        {
          "name": "Conv__213",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "X",
              "value": [
                {
                  "name": "multiply_3:0",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        128,
                        9,
                        16
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "W",
              "value": [
                {
                  "name": "Conv2D_21/filter:0",
                  "initializer": {
                    "name": "Conv2D_21/filter:0",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float32",
                      "shape": {
                        "dimensions": [
                          32,
                          128,
                          1,
                          1
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        32,
                        128,
                        1,
                        1
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "B",
              "value": [
                {
                  "name": "conv2d_20_1/y:0",
                  "initializer": {
                    "name": "conv2d_20_1/y:0",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float32",
                      "shape": {
                        "dimensions": [
                          32
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        32
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "Y",
              "value": [
                {
                  "name": "Conv__213:0",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        32,
                        9,
                        16
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [
            {
              "name": "dilations",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "strides",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "kernel_shape",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "pads",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "0",
                  "0",
                  "0",
                  "0"
                ]
              }
            },
            {
              "name": "group",
              "type": "int64",
              "value": {
                "type": "bigint",
                "value": "1"
              }
            }
          ],
          "type": {
            "name": "Conv",
            "module": "ai.onnx",
            "version": 11,
            "description": "The convolution operator consumes an input tensor and a filter, and\ncomputes the output.",
            "attributes": [
              {
                "name": "auto_pad",
                "type": "string",
                "required": false,
                "default": "NOTSET",
                "description": "auto_pad must be either NOTSET, SAME_UPPER, SAME_LOWER or VALID. Where default value is NOTSET, which means explicit padding is used. SAME_UPPER or SAME_LOWER mean pad the input so that `output_shape[i] = ceil(input_shape[i] / strides[i])` for each axis `i`. The padding is split between the two sides equally or almost equally (depending on whether it is even or odd). In case the padding is an odd number, the extra padding is added at the end for SAME_UPPER and at the beginning for SAME_LOWER."
              },
              {
                "name": "dilations",
                "type": "int64[]",
                "required": false,
                "description": "dilation value along each spatial axis of the filter. If not present, the dilation defaults is 1 along each spatial axis."
              },
              {
                "name": "group",
                "type": "int64",
                "required": false,
                "default": 1,
                "description": "number of groups input channels and output channels are divided into."
              },
              {
                "name": "kernel_shape",
                "type": "int64[]",
                "required": false,
                "description": "The shape of the convolution kernel. If not present, should be inferred from input W."
              },
              {
                "name": "pads",
                "type": "int64[]",
                "required": false,
                "description": "Padding for the beginning and ending along each spatial axis, it can take any value greater than or equal to 0. The value represent the number of pixels added to the beginning and end part of the corresponding axis. `pads` format should be as follow [x1_begin, x2_begin...x1_end, x2_end,...], where xi_begin the number of pixels added at the beginning of axis `i` and xi_end, the number of pixels added at the end of axis `i`. This attribute cannot be used simultaneously with auto_pad attribute. If not present, the padding defaults to 0 along start and end of each spatial axis."
              },
              {
                "name": "strides",
                "type": "int64[]",
                "required": false,
                "description": "Stride along each spatial axis. If not present, the stride defaults is 1 along each spatial axis."
              }
            ],
            "inputs": [
              {
                "name": "X",
                "type": "T",
                "description": "Input data tensor from previous layer; has size (N x C x H x W), where N is the batch size, C is the number of channels, and H and W are the height and width. Note that this is for the 2D image. Otherwise the size is (N x C x D1 x D2 ... x Dn). Optionally, if dimension denotation is in effect, the operation expects input data tensor to arrive with the dimension denotation of [DATA_BATCH, DATA_CHANNEL, DATA_FEATURE, DATA_FEATURE ...]."
              },
              {
                "name": "W",
                "type": "T",
                "description": "The weight tensor that will be used in the convolutions; has size (M x C/group x kH x kW), where C is the number of channels, and kH and kW are the height and width of the kernel, and M is the number of feature maps. For more than 2 dimensions, the kernel shape will be (M x C/group x k1 x k2 x ... x kn), where (k1 x k2 x ... kn) is the dimension of the kernel. Optionally, if dimension denotation is in effect, the operation expects the weight tensor to arrive with the dimension denotation of [FILTER_OUT_CHANNEL, FILTER_IN_CHANNEL, FILTER_SPATIAL, FILTER_SPATIAL ...]. Assuming zero based indices for the shape array, X.shape[1] == (W.shape[1] * group) == C and W.shape[0] mod G == 0. Or in other words FILTER_IN_CHANNEL multiplied by the number of groups should be equal to DATA_CHANNEL and the number of feature maps M should be a multiple of the number of groups G."
              },
              {
                "name": "B",
                "type": "T",
                "option": "optional",
                "description": "Optional 1D bias to be added to the convolution, has size of M."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "Y",
                "type": "T",
                "description": "Output data tensor that contains the result of the convolution. The output dimensions are functions of the kernel size, stride size, and pad lengths."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain input and output types to float tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "conv",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[1, 1, 1, 1],\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 21.0, 27.0, 33.0, 24.0],  # (1, 1, 5, 5) output tensor\n                [33.0, 54.0, 63.0, 72.0, 51.0],\n                [63.0, 99.0, 108.0, 117.0, 81.0],\n                [93.0, 144.0, 153.0, 162.0, 111.0],\n                [72.0, 111.0, 117.0, 123.0, 84.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_basic_conv_with_padding\",\n)\n\n# Convolution without padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[0, 0, 0, 0],\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 63.0, 72.0],  # (1, 1, 3, 3) output tensor\n                [99.0, 108.0, 117.0],\n                [144.0, 153.0, 162.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_basic_conv_without_padding\",\n)"
              },
              {
                "summary": "conv_with_autopad_same",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with auto_pad='SAME_LOWER' and strides=2\nnode = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    auto_pad=\"SAME_LOWER\",\n    kernel_shape=[3, 3],\n    strides=[2, 2],\n)\ny = np.array(\n    [[[[12.0, 27.0, 24.0], [63.0, 108.0, 81.0], [72.0, 117.0, 84.0]]]]\n).astype(np.float32)\nexpect(node, inputs=[x, W], outputs=[y], name=\"test_conv_with_autopad_same\")"
              },
              {
                "summary": "conv_with_strides",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 7, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n                [25.0, 26.0, 27.0, 28.0, 29.0],\n                [30.0, 31.0, 32.0, 33.0, 34.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with strides=2 and padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 1, 1, 1],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 27.0, 24.0],  # (1, 1, 4, 3) output tensor\n                [63.0, 108.0, 81.0],\n                [123.0, 198.0, 141.0],\n                [112.0, 177.0, 124.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_conv_with_strides_padding\",\n)\n\n# Convolution with strides=2 and no padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[0, 0, 0, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 72.0],  # (1, 1, 3, 2) output tensor\n                [144.0, 162.0],\n                [234.0, 252.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_conv_with_strides_no_padding\",\n)\n\n# Convolution with strides=2 and padding only along one dimension (the H dimension in NxCxHxW tensor)\nnode_with_asymmetric_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 0, 1, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_asymmetric_padding = np.array(\n    [\n        [\n            [\n                [21.0, 33.0],  # (1, 1, 4, 2) output tensor\n                [99.0, 117.0],\n                [189.0, 207.0],\n                [171.0, 183.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_asymmetric_padding,\n    inputs=[x, W],\n    outputs=[y_with_asymmetric_padding],\n    name=\"test_conv_with_strides_and_asymmetric_padding\",\n)"
              }
            ],
            "category": "Layer"
          }
        },
        {
          "name": "add_2__xeno_compat__1",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "A",
              "value": [
                {
                  "name": "Conv__213:0",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        32,
                        9,
                        16
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "B",
              "value": [
                {
                  "name": "add_1__xeno_compat__1:0",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        32,
                        9,
                        16
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "C",
              "value": [
                {
                  "name": "add_2__xeno_compat__1:0",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        32,
                        9,
                        16
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "Add",
            "module": "ai.onnx",
            "version": 14,
            "description": "Performs element-wise binary addition (with Numpy-style broadcasting support).\n\nThis operator supports **multidirectional (i.e., Numpy-style) broadcasting**; for more details please check [the doc](https://github.com/onnx/onnx/blob/master/docs/Broadcasting.md).\n\n(Opset 14 change): Extend supported types to include uint8, int8, uint16, and int16.\n",
            "inputs": [
              {
                "name": "A",
                "type": "T",
                "description": "First operand."
              },
              {
                "name": "B",
                "type": "T",
                "description": "Second operand."
              }
            ],
            "min_input": 2,
            "max_input": 2,
            "outputs": [
              {
                "name": "C",
                "type": "T",
                "description": "Result, has same element type as two inputs"
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "type_constraints": [
              {
                "description": "Constrain input and output types to all numeric tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(uint8)",
                  "tensor(uint16)",
                  "tensor(uint32)",
                  "tensor(uint64)",
                  "tensor(int8)",
                  "tensor(int16)",
                  "tensor(int32)",
                  "tensor(int64)",
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)",
                  "tensor(bfloat16)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "add",
                "code": "node = onnx.helper.make_node(\n    \"Add\",\n    inputs=[\"x\", \"y\"],\n    outputs=[\"sum\"],\n)\n\nx = np.random.randn(3, 4, 5).astype(np.float32)\ny = np.random.randn(3, 4, 5).astype(np.float32)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add\")\n\nx = np.random.randint(24, size=(3, 4, 5), dtype=np.int8)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.int8)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add_int8\")\n\nx = np.random.randint(24, size=(3, 4, 5), dtype=np.int16)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.int16)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add_int16\")\n\nx = np.random.randint(24, size=(3, 4, 5), dtype=np.uint8)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.uint8)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add_uint8\")\n\nx = np.random.randint(24, size=(3, 4, 5), dtype=np.uint16)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.uint16)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add_uint16\")\n\nx = np.random.randint(24, size=(3, 4, 5), dtype=np.uint32)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.uint32)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add_uint32\")\n\nx = np.random.randint(24, size=(3, 4, 5), dtype=np.uint64)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.uint64)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add_uint64\")"
              },
              {
                "summary": "add_broadcast",
                "code": "node = onnx.helper.make_node(\n    \"Add\",\n    inputs=[\"x\", \"y\"],\n    outputs=[\"sum\"],\n)\n\nx = np.random.randn(3, 4, 5).astype(np.float32)\ny = np.random.randn(5).astype(np.float32)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add_bcast\")"
              }
            ]
          }
        },
        {
          "name": "Conv__216",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "X",
              "value": [
                {
                  "name": "add_2__xeno_compat__1:0",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        32,
                        9,
                        16
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "W",
              "value": [
                {
                  "name": "Conv2D_22/filter:0",
                  "initializer": {
                    "name": "Conv2D_22/filter:0",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float32",
                      "shape": {
                        "dimensions": [
                          96,
                          32,
                          1,
                          1
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        96,
                        32,
                        1,
                        1
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "B",
              "value": [
                {
                  "name": "conv2d_21_1/y:0",
                  "initializer": {
                    "name": "conv2d_21_1/y:0",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float32",
                      "shape": {
                        "dimensions": [
                          96
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        96
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "Y",
              "value": [
                {
                  "name": "Conv__216:0",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        96,
                        9,
                        16
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [
            {
              "name": "dilations",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "strides",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "kernel_shape",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "pads",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "0",
                  "0",
                  "0",
                  "0"
                ]
              }
            },
            {
              "name": "group",
              "type": "int64",
              "value": {
                "type": "bigint",
                "value": "1"
              }
            }
          ],
          "type": {
            "name": "Conv",
            "module": "ai.onnx",
            "version": 11,
            "description": "The convolution operator consumes an input tensor and a filter, and\ncomputes the output.",
            "attributes": [
              {
                "name": "auto_pad",
                "type": "string",
                "required": false,
                "default": "NOTSET",
                "description": "auto_pad must be either NOTSET, SAME_UPPER, SAME_LOWER or VALID. Where default value is NOTSET, which means explicit padding is used. SAME_UPPER or SAME_LOWER mean pad the input so that `output_shape[i] = ceil(input_shape[i] / strides[i])` for each axis `i`. The padding is split between the two sides equally or almost equally (depending on whether it is even or odd). In case the padding is an odd number, the extra padding is added at the end for SAME_UPPER and at the beginning for SAME_LOWER."
              },
              {
                "name": "dilations",
                "type": "int64[]",
                "required": false,
                "description": "dilation value along each spatial axis of the filter. If not present, the dilation defaults is 1 along each spatial axis."
              },
              {
                "name": "group",
                "type": "int64",
                "required": false,
                "default": 1,
                "description": "number of groups input channels and output channels are divided into."
              },
              {
                "name": "kernel_shape",
                "type": "int64[]",
                "required": false,
                "description": "The shape of the convolution kernel. If not present, should be inferred from input W."
              },
              {
                "name": "pads",
                "type": "int64[]",
                "required": false,
                "description": "Padding for the beginning and ending along each spatial axis, it can take any value greater than or equal to 0. The value represent the number of pixels added to the beginning and end part of the corresponding axis. `pads` format should be as follow [x1_begin, x2_begin...x1_end, x2_end,...], where xi_begin the number of pixels added at the beginning of axis `i` and xi_end, the number of pixels added at the end of axis `i`. This attribute cannot be used simultaneously with auto_pad attribute. If not present, the padding defaults to 0 along start and end of each spatial axis."
              },
              {
                "name": "strides",
                "type": "int64[]",
                "required": false,
                "description": "Stride along each spatial axis. If not present, the stride defaults is 1 along each spatial axis."
              }
            ],
            "inputs": [
              {
                "name": "X",
                "type": "T",
                "description": "Input data tensor from previous layer; has size (N x C x H x W), where N is the batch size, C is the number of channels, and H and W are the height and width. Note that this is for the 2D image. Otherwise the size is (N x C x D1 x D2 ... x Dn). Optionally, if dimension denotation is in effect, the operation expects input data tensor to arrive with the dimension denotation of [DATA_BATCH, DATA_CHANNEL, DATA_FEATURE, DATA_FEATURE ...]."
              },
              {
                "name": "W",
                "type": "T",
                "description": "The weight tensor that will be used in the convolutions; has size (M x C/group x kH x kW), where C is the number of channels, and kH and kW are the height and width of the kernel, and M is the number of feature maps. For more than 2 dimensions, the kernel shape will be (M x C/group x k1 x k2 x ... x kn), where (k1 x k2 x ... kn) is the dimension of the kernel. Optionally, if dimension denotation is in effect, the operation expects the weight tensor to arrive with the dimension denotation of [FILTER_OUT_CHANNEL, FILTER_IN_CHANNEL, FILTER_SPATIAL, FILTER_SPATIAL ...]. Assuming zero based indices for the shape array, X.shape[1] == (W.shape[1] * group) == C and W.shape[0] mod G == 0. Or in other words FILTER_IN_CHANNEL multiplied by the number of groups should be equal to DATA_CHANNEL and the number of feature maps M should be a multiple of the number of groups G."
              },
              {
                "name": "B",
                "type": "T",
                "option": "optional",
                "description": "Optional 1D bias to be added to the convolution, has size of M."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "Y",
                "type": "T",
                "description": "Output data tensor that contains the result of the convolution. The output dimensions are functions of the kernel size, stride size, and pad lengths."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain input and output types to float tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "conv",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[1, 1, 1, 1],\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 21.0, 27.0, 33.0, 24.0],  # (1, 1, 5, 5) output tensor\n                [33.0, 54.0, 63.0, 72.0, 51.0],\n                [63.0, 99.0, 108.0, 117.0, 81.0],\n                [93.0, 144.0, 153.0, 162.0, 111.0],\n                [72.0, 111.0, 117.0, 123.0, 84.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_basic_conv_with_padding\",\n)\n\n# Convolution without padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[0, 0, 0, 0],\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 63.0, 72.0],  # (1, 1, 3, 3) output tensor\n                [99.0, 108.0, 117.0],\n                [144.0, 153.0, 162.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_basic_conv_without_padding\",\n)"
              },
              {
                "summary": "conv_with_autopad_same",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with auto_pad='SAME_LOWER' and strides=2\nnode = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    auto_pad=\"SAME_LOWER\",\n    kernel_shape=[3, 3],\n    strides=[2, 2],\n)\ny = np.array(\n    [[[[12.0, 27.0, 24.0], [63.0, 108.0, 81.0], [72.0, 117.0, 84.0]]]]\n).astype(np.float32)\nexpect(node, inputs=[x, W], outputs=[y], name=\"test_conv_with_autopad_same\")"
              },
              {
                "summary": "conv_with_strides",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 7, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n                [25.0, 26.0, 27.0, 28.0, 29.0],\n                [30.0, 31.0, 32.0, 33.0, 34.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with strides=2 and padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 1, 1, 1],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 27.0, 24.0],  # (1, 1, 4, 3) output tensor\n                [63.0, 108.0, 81.0],\n                [123.0, 198.0, 141.0],\n                [112.0, 177.0, 124.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_conv_with_strides_padding\",\n)\n\n# Convolution with strides=2 and no padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[0, 0, 0, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 72.0],  # (1, 1, 3, 2) output tensor\n                [144.0, 162.0],\n                [234.0, 252.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_conv_with_strides_no_padding\",\n)\n\n# Convolution with strides=2 and padding only along one dimension (the H dimension in NxCxHxW tensor)\nnode_with_asymmetric_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 0, 1, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_asymmetric_padding = np.array(\n    [\n        [\n            [\n                [21.0, 33.0],  # (1, 1, 4, 2) output tensor\n                [99.0, 117.0],\n                [189.0, 207.0],\n                [171.0, 183.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_asymmetric_padding,\n    inputs=[x, W],\n    outputs=[y_with_asymmetric_padding],\n    name=\"test_conv_with_strides_and_asymmetric_padding\",\n)"
              }
            ],
            "category": "Layer"
          }
        },
        {
          "name": "add_7",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "A",
              "value": [
                {
                  "name": "Conv__216:0",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        96,
                        9,
                        16
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "B",
              "value": [
                {
                  "name": "const_fold_opt__408",
                  "initializer": {
                    "name": "const_fold_opt__408",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float32",
                      "shape": {
                        "dimensions": [
                          1,
                          1,
                          1,
                          1
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        1,
                        1,
                        1
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "C",
              "value": [
                {
                  "name": "add_7:0",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        96,
                        9,
                        16
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "Add",
            "module": "ai.onnx",
            "version": 14,
            "description": "Performs element-wise binary addition (with Numpy-style broadcasting support).\n\nThis operator supports **multidirectional (i.e., Numpy-style) broadcasting**; for more details please check [the doc](https://github.com/onnx/onnx/blob/master/docs/Broadcasting.md).\n\n(Opset 14 change): Extend supported types to include uint8, int8, uint16, and int16.\n",
            "inputs": [
              {
                "name": "A",
                "type": "T",
                "description": "First operand."
              },
              {
                "name": "B",
                "type": "T",
                "description": "Second operand."
              }
            ],
            "min_input": 2,
            "max_input": 2,
            "outputs": [
              {
                "name": "C",
                "type": "T",
                "description": "Result, has same element type as two inputs"
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "type_constraints": [
              {
                "description": "Constrain input and output types to all numeric tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(uint8)",
                  "tensor(uint16)",
                  "tensor(uint32)",
                  "tensor(uint64)",
                  "tensor(int8)",
                  "tensor(int16)",
                  "tensor(int32)",
                  "tensor(int64)",
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)",
                  "tensor(bfloat16)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "add",
                "code": "node = onnx.helper.make_node(\n    \"Add\",\n    inputs=[\"x\", \"y\"],\n    outputs=[\"sum\"],\n)\n\nx = np.random.randn(3, 4, 5).astype(np.float32)\ny = np.random.randn(3, 4, 5).astype(np.float32)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add\")\n\nx = np.random.randint(24, size=(3, 4, 5), dtype=np.int8)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.int8)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add_int8\")\n\nx = np.random.randint(24, size=(3, 4, 5), dtype=np.int16)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.int16)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add_int16\")\n\nx = np.random.randint(24, size=(3, 4, 5), dtype=np.uint8)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.uint8)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add_uint8\")\n\nx = np.random.randint(24, size=(3, 4, 5), dtype=np.uint16)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.uint16)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add_uint16\")\n\nx = np.random.randint(24, size=(3, 4, 5), dtype=np.uint32)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.uint32)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add_uint32\")\n\nx = np.random.randint(24, size=(3, 4, 5), dtype=np.uint64)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.uint64)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add_uint64\")"
              },
              {
                "summary": "add_broadcast",
                "code": "node = onnx.helper.make_node(\n    \"Add\",\n    inputs=[\"x\", \"y\"],\n    outputs=[\"sum\"],\n)\n\nx = np.random.randn(3, 4, 5).astype(np.float32)\ny = np.random.randn(5).astype(np.float32)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add_bcast\")"
              }
            ]
          }
        },
        {
          "name": "Relu6_7",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "input",
              "value": [
                {
                  "name": "add_7:0",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        96,
                        9,
                        16
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "min",
              "value": [
                {
                  "name": "306",
                  "initializer": {
                    "category": "Constant",
                    "encoding": "|",
                    "values": {
                      "0": 0
                    },
                    "type": {
                      "dataType": "float32",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            },
            {
              "name": "max",
              "value": [
                {
                  "name": "307",
                  "initializer": {
                    "category": "Constant",
                    "encoding": "|",
                    "values": {
                      "0": 6
                    },
                    "type": {
                      "dataType": "float32",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "output",
              "value": [
                {
                  "name": "Relu6_7:0",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        96,
                        9,
                        16
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "Clip",
            "module": "ai.onnx",
            "version": 13,
            "description": "Clip operator limits the given input within an interval. The interval is\nspecified by the inputs 'min' and 'max'. They default to\nnumeric_limits::lowest() and numeric_limits::max(), respectively.\nWhen 'min' is greater than 'max', the clip operator sets all the 'input' values to\nthe value of 'max'. Thus, this is equivalent to 'Min(max, Max(input, min))'.\n",
            "inputs": [
              {
                "name": "input",
                "type": "T",
                "description": "Input tensor whose elements to be clipped"
              },
              {
                "name": "min",
                "type": "T",
                "option": "optional",
                "description": "Minimum value, under which element is replaced by min. It must be a scalar(tensor of empty shape)."
              },
              {
                "name": "max",
                "type": "T",
                "option": "optional",
                "description": "Maximum value, above which element is replaced by max. It must be a scalar(tensor of empty shape)."
              }
            ],
            "min_input": 1,
            "max_input": 3,
            "outputs": [
              {
                "name": "output",
                "type": "T",
                "description": "Output tensor with clipped input elements"
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "1 - 3",
            "type_constraints": [
              {
                "description": "Constrain input and output types to all numeric tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(uint8)",
                  "tensor(uint16)",
                  "tensor(uint32)",
                  "tensor(uint64)",
                  "tensor(int8)",
                  "tensor(int16)",
                  "tensor(int32)",
                  "tensor(int64)",
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)",
                  "tensor(bfloat16)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "clip",
                "code": "node = onnx.helper.make_node(\n    \"Clip\",\n    inputs=[\"x\", \"min\", \"max\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([-2, 0, 2]).astype(np.float32)\nmin_val = np.float32(-1)\nmax_val = np.float32(1)\ny = np.clip(x, min_val, max_val)  # expected output [-1., 0., 1.]\nexpect(\n    node, inputs=[x, min_val, max_val], outputs=[y], name=\"test_clip_example\"\n)\n\nx = np.random.randn(3, 4, 5).astype(np.float32)\ny = np.clip(x, min_val, max_val)\nexpect(node, inputs=[x, min_val, max_val], outputs=[y], name=\"test_clip\")\nnode = onnx.helper.make_node(\n    \"Clip\",\n    inputs=[\"x\", \"min\", \"max\"],\n    outputs=[\"y\"],\n)\n\nmin_val = np.float32(-5)\nmax_val = np.float32(5)\n\nx = np.array([-1, 0, 1]).astype(np.float32)\ny = np.array([-1, 0, 1]).astype(np.float32)\nexpect(\n    node, inputs=[x, min_val, max_val], outputs=[y], name=\"test_clip_inbounds\"\n)\n\nx = np.array([-6, 0, 6]).astype(np.float32)\ny = np.array([-5, 0, 5]).astype(np.float32)\nexpect(\n    node, inputs=[x, min_val, max_val], outputs=[y], name=\"test_clip_outbounds\"\n)\n\nx = np.array([-1, 0, 6]).astype(np.float32)\ny = np.array([-1, 0, 5]).astype(np.float32)\nexpect(\n    node,\n    inputs=[x, min_val, max_val],\n    outputs=[y],\n    name=\"test_clip_splitbounds\",\n)\n\nx = np.array([-2, 0, 6]).astype(np.float32)\ny = np.array([1, 1, 1]).astype(np.float32)\nmin_val = np.float32(2)\nmax_val = np.float32(1)\nexpect(\n    node,\n    inputs=[x, min_val, max_val],\n    outputs=[y],\n    name=\"test_clip_min_greater_than_max\",\n)"
              },
              {
                "summary": "clip_default",
                "code": "node = onnx.helper.make_node(\n    \"Clip\",\n    inputs=[\"x\", \"min\"],\n    outputs=[\"y\"],\n)\nmin_val = np.float32(0)\nx = np.random.randn(3, 4, 5).astype(np.float32)\ny = np.clip(x, min_val, np.inf)\nexpect(node, inputs=[x, min_val], outputs=[y], name=\"test_clip_default_min\")\n\nno_min = \"\"  # optional input, not supplied\nnode = onnx.helper.make_node(\n    \"Clip\",\n    inputs=[\"x\", no_min, \"max\"],\n    outputs=[\"y\"],\n)\nmax_val = np.float32(0)\nx = np.random.randn(3, 4, 5).astype(np.float32)\ny = np.clip(x, -np.inf, max_val)\nexpect(node, inputs=[x, max_val], outputs=[y], name=\"test_clip_default_max\")\n\nno_max = \"\"  # optional input, not supplied\nnode = onnx.helper.make_node(\n    \"Clip\",\n    inputs=[\"x\", no_min, no_max],\n    outputs=[\"y\"],\n)\n\nx = np.array([-1, 0, 1]).astype(np.float32)\ny = np.array([-1, 0, 1]).astype(np.float32)\nexpect(node, inputs=[x], outputs=[y], name=\"test_clip_default_inbounds\")"
              },
              {
                "summary": "clip_default_int8",
                "code": "node = onnx.helper.make_node(\n    \"Clip\",\n    inputs=[\"x\", \"min\"],\n    outputs=[\"y\"],\n)\nmin_val = np.int8(0)\nx = np.random.randn(3, 4, 5).astype(np.int8)\ny = np.clip(x, min_val, np.iinfo(np.int8).max)\nexpect(\n    node, inputs=[x, min_val], outputs=[y], name=\"test_clip_default_int8_min\"\n)\n\nno_min = \"\"  # optional input, not supplied\nnode = onnx.helper.make_node(\n    \"Clip\",\n    inputs=[\"x\", no_min, \"max\"],\n    outputs=[\"y\"],\n)\nmax_val = np.int8(0)\nx = np.random.randn(3, 4, 5).astype(np.int8)\ny = np.clip(x, np.iinfo(np.int8).min, max_val)\nexpect(\n    node, inputs=[x, max_val], outputs=[y], name=\"test_clip_default_int8_max\"\n)\n\nno_max = \"\"  # optional input, not supplied\nnode = onnx.helper.make_node(\n    \"Clip\",\n    inputs=[\"x\", no_min, no_max],\n    outputs=[\"y\"],\n)\n\nx = np.array([-1, 0, 1]).astype(np.int8)\ny = np.array([-1, 0, 1]).astype(np.int8)\nexpect(node, inputs=[x], outputs=[y], name=\"test_clip_default_int8_inbounds\")"
              }
            ],
            "category": "Activation"
          }
        },
        {
          "name": "mul_14",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "A",
              "value": [
                {
                  "name": "mul_3/y:0",
                  "initializer": {
                    "name": "mul_3/y:0",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float32",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            },
            {
              "name": "B",
              "value": [
                {
                  "name": "Relu6_7:0",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        96,
                        9,
                        16
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "C",
              "value": [
                {
                  "name": "mul_14:0",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        96,
                        9,
                        16
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "Mul",
            "module": "ai.onnx",
            "version": 14,
            "description": "Performs element-wise binary multiplication (with Numpy-style broadcasting support).\n\nThis operator supports **multidirectional (i.e., Numpy-style) broadcasting**; for more details please check [the doc](https://github.com/onnx/onnx/blob/master/docs/Broadcasting.md).\n\n(Opset 14 change): Extend supported types to include uint8, int8, uint16, and int16.\n",
            "inputs": [
              {
                "name": "A",
                "type": "T",
                "description": "First operand."
              },
              {
                "name": "B",
                "type": "T",
                "description": "Second operand."
              }
            ],
            "min_input": 2,
            "max_input": 2,
            "outputs": [
              {
                "name": "C",
                "type": "T",
                "description": "Result, has same element type as two inputs"
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "type_constraints": [
              {
                "description": "Constrain input and output types to all numeric tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(uint8)",
                  "tensor(uint16)",
                  "tensor(uint32)",
                  "tensor(uint64)",
                  "tensor(int8)",
                  "tensor(int16)",
                  "tensor(int32)",
                  "tensor(int64)",
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)",
                  "tensor(bfloat16)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "mul",
                "code": "node = onnx.helper.make_node(\n    \"Mul\",\n    inputs=[\"x\", \"y\"],\n    outputs=[\"z\"],\n)\n\nx = np.array([1, 2, 3]).astype(np.float32)\ny = np.array([4, 5, 6]).astype(np.float32)\nz = x * y  # expected output [4., 10., 18.]\nexpect(node, inputs=[x, y], outputs=[z], name=\"test_mul_example\")\n\nx = np.random.randn(3, 4, 5).astype(np.float32)\ny = np.random.randn(3, 4, 5).astype(np.float32)\nz = x * y\nexpect(node, inputs=[x, y], outputs=[z], name=\"test_mul\")\n\nx = np.random.randint(4, size=(3, 4, 5), dtype=np.int8)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.int8)\nz = x * y\nexpect(node, inputs=[x, y], outputs=[z], name=\"test_mul_int8\")\n\nx = np.random.randint(4, size=(3, 4, 5), dtype=np.int16)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.int16)\nz = x * y\nexpect(node, inputs=[x, y], outputs=[z], name=\"test_mul_int16\")\n\nx = np.random.randint(4, size=(3, 4, 5), dtype=np.uint8)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.uint8)\nz = x * y\nexpect(node, inputs=[x, y], outputs=[z], name=\"test_mul_uint8\")\n\nx = np.random.randint(4, size=(3, 4, 5), dtype=np.uint16)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.uint16)\nz = x * y\nexpect(node, inputs=[x, y], outputs=[z], name=\"test_mul_uint16\")\n\nx = np.random.randint(4, size=(3, 4, 5), dtype=np.uint32)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.uint32)\nz = x * y\nexpect(node, inputs=[x, y], outputs=[z], name=\"test_mul_uint32\")\n\nx = np.random.randint(4, size=(3, 4, 5), dtype=np.uint64)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.uint64)\nz = x * y\nexpect(node, inputs=[x, y], outputs=[z], name=\"test_mul_uint64\")"
              },
              {
                "summary": "mul_broadcast",
                "code": "node = onnx.helper.make_node(\n    \"Mul\",\n    inputs=[\"x\", \"y\"],\n    outputs=[\"z\"],\n)\n\nx = np.random.randn(3, 4, 5).astype(np.float32)\ny = np.random.randn(5).astype(np.float32)\nz = x * y\nexpect(node, inputs=[x, y], outputs=[z], name=\"test_mul_bcast\")"
              }
            ]
          }
        },
        {
          "name": "mul_15",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "A",
              "value": [
                {
                  "name": "Conv__216:0",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        96,
                        9,
                        16
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "B",
              "value": [
                {
                  "name": "mul_14:0",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        96,
                        9,
                        16
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "C",
              "value": [
                {
                  "name": "mul_15:0",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        96,
                        9,
                        16
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "Mul",
            "module": "ai.onnx",
            "version": 14,
            "description": "Performs element-wise binary multiplication (with Numpy-style broadcasting support).\n\nThis operator supports **multidirectional (i.e., Numpy-style) broadcasting**; for more details please check [the doc](https://github.com/onnx/onnx/blob/master/docs/Broadcasting.md).\n\n(Opset 14 change): Extend supported types to include uint8, int8, uint16, and int16.\n",
            "inputs": [
              {
                "name": "A",
                "type": "T",
                "description": "First operand."
              },
              {
                "name": "B",
                "type": "T",
                "description": "Second operand."
              }
            ],
            "min_input": 2,
            "max_input": 2,
            "outputs": [
              {
                "name": "C",
                "type": "T",
                "description": "Result, has same element type as two inputs"
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "type_constraints": [
              {
                "description": "Constrain input and output types to all numeric tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(uint8)",
                  "tensor(uint16)",
                  "tensor(uint32)",
                  "tensor(uint64)",
                  "tensor(int8)",
                  "tensor(int16)",
                  "tensor(int32)",
                  "tensor(int64)",
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)",
                  "tensor(bfloat16)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "mul",
                "code": "node = onnx.helper.make_node(\n    \"Mul\",\n    inputs=[\"x\", \"y\"],\n    outputs=[\"z\"],\n)\n\nx = np.array([1, 2, 3]).astype(np.float32)\ny = np.array([4, 5, 6]).astype(np.float32)\nz = x * y  # expected output [4., 10., 18.]\nexpect(node, inputs=[x, y], outputs=[z], name=\"test_mul_example\")\n\nx = np.random.randn(3, 4, 5).astype(np.float32)\ny = np.random.randn(3, 4, 5).astype(np.float32)\nz = x * y\nexpect(node, inputs=[x, y], outputs=[z], name=\"test_mul\")\n\nx = np.random.randint(4, size=(3, 4, 5), dtype=np.int8)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.int8)\nz = x * y\nexpect(node, inputs=[x, y], outputs=[z], name=\"test_mul_int8\")\n\nx = np.random.randint(4, size=(3, 4, 5), dtype=np.int16)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.int16)\nz = x * y\nexpect(node, inputs=[x, y], outputs=[z], name=\"test_mul_int16\")\n\nx = np.random.randint(4, size=(3, 4, 5), dtype=np.uint8)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.uint8)\nz = x * y\nexpect(node, inputs=[x, y], outputs=[z], name=\"test_mul_uint8\")\n\nx = np.random.randint(4, size=(3, 4, 5), dtype=np.uint16)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.uint16)\nz = x * y\nexpect(node, inputs=[x, y], outputs=[z], name=\"test_mul_uint16\")\n\nx = np.random.randint(4, size=(3, 4, 5), dtype=np.uint32)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.uint32)\nz = x * y\nexpect(node, inputs=[x, y], outputs=[z], name=\"test_mul_uint32\")\n\nx = np.random.randint(4, size=(3, 4, 5), dtype=np.uint64)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.uint64)\nz = x * y\nexpect(node, inputs=[x, y], outputs=[z], name=\"test_mul_uint64\")"
              },
              {
                "summary": "mul_broadcast",
                "code": "node = onnx.helper.make_node(\n    \"Mul\",\n    inputs=[\"x\", \"y\"],\n    outputs=[\"z\"],\n)\n\nx = np.random.randn(3, 4, 5).astype(np.float32)\ny = np.random.randn(5).astype(np.float32)\nz = x * y\nexpect(node, inputs=[x, y], outputs=[z], name=\"test_mul_bcast\")"
              }
            ]
          }
        },
        {
          "name": "Conv__219",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "X",
              "value": [
                {
                  "name": "mul_15:0",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        96,
                        9,
                        16
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "W",
              "value": [
                {
                  "name": "const_fold_opt__395",
                  "initializer": {
                    "name": "const_fold_opt__395",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float32",
                      "shape": {
                        "dimensions": [
                          96,
                          1,
                          5,
                          5
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        96,
                        1,
                        5,
                        5
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "B",
              "value": [
                {
                  "name": "depthwise_conv2d_6/y:0",
                  "initializer": {
                    "name": "depthwise_conv2d_6/y:0",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float32",
                      "shape": {
                        "dimensions": [
                          96
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        96
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "Y",
              "value": [
                {
                  "name": "Conv__219:0",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        96,
                        9,
                        16
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [
            {
              "name": "dilations",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "strides",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "kernel_shape",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "5",
                  "5"
                ]
              }
            },
            {
              "name": "group",
              "type": "int64",
              "value": {
                "type": "bigint",
                "value": "96"
              }
            },
            {
              "name": "pads",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "2",
                  "2",
                  "2",
                  "2"
                ]
              }
            }
          ],
          "type": {
            "name": "Conv",
            "module": "ai.onnx",
            "version": 11,
            "description": "The convolution operator consumes an input tensor and a filter, and\ncomputes the output.",
            "attributes": [
              {
                "name": "auto_pad",
                "type": "string",
                "required": false,
                "default": "NOTSET",
                "description": "auto_pad must be either NOTSET, SAME_UPPER, SAME_LOWER or VALID. Where default value is NOTSET, which means explicit padding is used. SAME_UPPER or SAME_LOWER mean pad the input so that `output_shape[i] = ceil(input_shape[i] / strides[i])` for each axis `i`. The padding is split between the two sides equally or almost equally (depending on whether it is even or odd). In case the padding is an odd number, the extra padding is added at the end for SAME_UPPER and at the beginning for SAME_LOWER."
              },
              {
                "name": "dilations",
                "type": "int64[]",
                "required": false,
                "description": "dilation value along each spatial axis of the filter. If not present, the dilation defaults is 1 along each spatial axis."
              },
              {
                "name": "group",
                "type": "int64",
                "required": false,
                "default": 1,
                "description": "number of groups input channels and output channels are divided into."
              },
              {
                "name": "kernel_shape",
                "type": "int64[]",
                "required": false,
                "description": "The shape of the convolution kernel. If not present, should be inferred from input W."
              },
              {
                "name": "pads",
                "type": "int64[]",
                "required": false,
                "description": "Padding for the beginning and ending along each spatial axis, it can take any value greater than or equal to 0. The value represent the number of pixels added to the beginning and end part of the corresponding axis. `pads` format should be as follow [x1_begin, x2_begin...x1_end, x2_end,...], where xi_begin the number of pixels added at the beginning of axis `i` and xi_end, the number of pixels added at the end of axis `i`. This attribute cannot be used simultaneously with auto_pad attribute. If not present, the padding defaults to 0 along start and end of each spatial axis."
              },
              {
                "name": "strides",
                "type": "int64[]",
                "required": false,
                "description": "Stride along each spatial axis. If not present, the stride defaults is 1 along each spatial axis."
              }
            ],
            "inputs": [
              {
                "name": "X",
                "type": "T",
                "description": "Input data tensor from previous layer; has size (N x C x H x W), where N is the batch size, C is the number of channels, and H and W are the height and width. Note that this is for the 2D image. Otherwise the size is (N x C x D1 x D2 ... x Dn). Optionally, if dimension denotation is in effect, the operation expects input data tensor to arrive with the dimension denotation of [DATA_BATCH, DATA_CHANNEL, DATA_FEATURE, DATA_FEATURE ...]."
              },
              {
                "name": "W",
                "type": "T",
                "description": "The weight tensor that will be used in the convolutions; has size (M x C/group x kH x kW), where C is the number of channels, and kH and kW are the height and width of the kernel, and M is the number of feature maps. For more than 2 dimensions, the kernel shape will be (M x C/group x k1 x k2 x ... x kn), where (k1 x k2 x ... kn) is the dimension of the kernel. Optionally, if dimension denotation is in effect, the operation expects the weight tensor to arrive with the dimension denotation of [FILTER_OUT_CHANNEL, FILTER_IN_CHANNEL, FILTER_SPATIAL, FILTER_SPATIAL ...]. Assuming zero based indices for the shape array, X.shape[1] == (W.shape[1] * group) == C and W.shape[0] mod G == 0. Or in other words FILTER_IN_CHANNEL multiplied by the number of groups should be equal to DATA_CHANNEL and the number of feature maps M should be a multiple of the number of groups G."
              },
              {
                "name": "B",
                "type": "T",
                "option": "optional",
                "description": "Optional 1D bias to be added to the convolution, has size of M."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "Y",
                "type": "T",
                "description": "Output data tensor that contains the result of the convolution. The output dimensions are functions of the kernel size, stride size, and pad lengths."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain input and output types to float tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "conv",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[1, 1, 1, 1],\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 21.0, 27.0, 33.0, 24.0],  # (1, 1, 5, 5) output tensor\n                [33.0, 54.0, 63.0, 72.0, 51.0],\n                [63.0, 99.0, 108.0, 117.0, 81.0],\n                [93.0, 144.0, 153.0, 162.0, 111.0],\n                [72.0, 111.0, 117.0, 123.0, 84.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_basic_conv_with_padding\",\n)\n\n# Convolution without padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[0, 0, 0, 0],\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 63.0, 72.0],  # (1, 1, 3, 3) output tensor\n                [99.0, 108.0, 117.0],\n                [144.0, 153.0, 162.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_basic_conv_without_padding\",\n)"
              },
              {
                "summary": "conv_with_autopad_same",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with auto_pad='SAME_LOWER' and strides=2\nnode = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    auto_pad=\"SAME_LOWER\",\n    kernel_shape=[3, 3],\n    strides=[2, 2],\n)\ny = np.array(\n    [[[[12.0, 27.0, 24.0], [63.0, 108.0, 81.0], [72.0, 117.0, 84.0]]]]\n).astype(np.float32)\nexpect(node, inputs=[x, W], outputs=[y], name=\"test_conv_with_autopad_same\")"
              },
              {
                "summary": "conv_with_strides",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 7, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n                [25.0, 26.0, 27.0, 28.0, 29.0],\n                [30.0, 31.0, 32.0, 33.0, 34.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with strides=2 and padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 1, 1, 1],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 27.0, 24.0],  # (1, 1, 4, 3) output tensor\n                [63.0, 108.0, 81.0],\n                [123.0, 198.0, 141.0],\n                [112.0, 177.0, 124.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_conv_with_strides_padding\",\n)\n\n# Convolution with strides=2 and no padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[0, 0, 0, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 72.0],  # (1, 1, 3, 2) output tensor\n                [144.0, 162.0],\n                [234.0, 252.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_conv_with_strides_no_padding\",\n)\n\n# Convolution with strides=2 and padding only along one dimension (the H dimension in NxCxHxW tensor)\nnode_with_asymmetric_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 0, 1, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_asymmetric_padding = np.array(\n    [\n        [\n            [\n                [21.0, 33.0],  # (1, 1, 4, 2) output tensor\n                [99.0, 117.0],\n                [189.0, 207.0],\n                [171.0, 183.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_asymmetric_padding,\n    inputs=[x, W],\n    outputs=[y_with_asymmetric_padding],\n    name=\"test_conv_with_strides_and_asymmetric_padding\",\n)"
              }
            ],
            "category": "Layer"
          }
        },
        {
          "name": "add_8",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "A",
              "value": [
                {
                  "name": "Conv__219:0",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        96,
                        9,
                        16
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "B",
              "value": [
                {
                  "name": "const_fold_opt__408",
                  "initializer": {
                    "name": "const_fold_opt__408",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float32",
                      "shape": {
                        "dimensions": [
                          1,
                          1,
                          1,
                          1
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        1,
                        1,
                        1
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "C",
              "value": [
                {
                  "name": "add_8:0",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        96,
                        9,
                        16
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "Add",
            "module": "ai.onnx",
            "version": 14,
            "description": "Performs element-wise binary addition (with Numpy-style broadcasting support).\n\nThis operator supports **multidirectional (i.e., Numpy-style) broadcasting**; for more details please check [the doc](https://github.com/onnx/onnx/blob/master/docs/Broadcasting.md).\n\n(Opset 14 change): Extend supported types to include uint8, int8, uint16, and int16.\n",
            "inputs": [
              {
                "name": "A",
                "type": "T",
                "description": "First operand."
              },
              {
                "name": "B",
                "type": "T",
                "description": "Second operand."
              }
            ],
            "min_input": 2,
            "max_input": 2,
            "outputs": [
              {
                "name": "C",
                "type": "T",
                "description": "Result, has same element type as two inputs"
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "type_constraints": [
              {
                "description": "Constrain input and output types to all numeric tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(uint8)",
                  "tensor(uint16)",
                  "tensor(uint32)",
                  "tensor(uint64)",
                  "tensor(int8)",
                  "tensor(int16)",
                  "tensor(int32)",
                  "tensor(int64)",
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)",
                  "tensor(bfloat16)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "add",
                "code": "node = onnx.helper.make_node(\n    \"Add\",\n    inputs=[\"x\", \"y\"],\n    outputs=[\"sum\"],\n)\n\nx = np.random.randn(3, 4, 5).astype(np.float32)\ny = np.random.randn(3, 4, 5).astype(np.float32)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add\")\n\nx = np.random.randint(24, size=(3, 4, 5), dtype=np.int8)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.int8)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add_int8\")\n\nx = np.random.randint(24, size=(3, 4, 5), dtype=np.int16)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.int16)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add_int16\")\n\nx = np.random.randint(24, size=(3, 4, 5), dtype=np.uint8)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.uint8)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add_uint8\")\n\nx = np.random.randint(24, size=(3, 4, 5), dtype=np.uint16)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.uint16)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add_uint16\")\n\nx = np.random.randint(24, size=(3, 4, 5), dtype=np.uint32)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.uint32)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add_uint32\")\n\nx = np.random.randint(24, size=(3, 4, 5), dtype=np.uint64)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.uint64)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add_uint64\")"
              },
              {
                "summary": "add_broadcast",
                "code": "node = onnx.helper.make_node(\n    \"Add\",\n    inputs=[\"x\", \"y\"],\n    outputs=[\"sum\"],\n)\n\nx = np.random.randn(3, 4, 5).astype(np.float32)\ny = np.random.randn(5).astype(np.float32)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add_bcast\")"
              }
            ]
          }
        },
        {
          "name": "Relu6_8",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "input",
              "value": [
                {
                  "name": "add_8:0",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        96,
                        9,
                        16
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "min",
              "value": [
                {
                  "name": "308",
                  "initializer": {
                    "category": "Constant",
                    "encoding": "|",
                    "values": {
                      "0": 0
                    },
                    "type": {
                      "dataType": "float32",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            },
            {
              "name": "max",
              "value": [
                {
                  "name": "309",
                  "initializer": {
                    "category": "Constant",
                    "encoding": "|",
                    "values": {
                      "0": 6
                    },
                    "type": {
                      "dataType": "float32",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "output",
              "value": [
                {
                  "name": "Relu6_8:0",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        96,
                        9,
                        16
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "Clip",
            "module": "ai.onnx",
            "version": 13,
            "description": "Clip operator limits the given input within an interval. The interval is\nspecified by the inputs 'min' and 'max'. They default to\nnumeric_limits::lowest() and numeric_limits::max(), respectively.\nWhen 'min' is greater than 'max', the clip operator sets all the 'input' values to\nthe value of 'max'. Thus, this is equivalent to 'Min(max, Max(input, min))'.\n",
            "inputs": [
              {
                "name": "input",
                "type": "T",
                "description": "Input tensor whose elements to be clipped"
              },
              {
                "name": "min",
                "type": "T",
                "option": "optional",
                "description": "Minimum value, under which element is replaced by min. It must be a scalar(tensor of empty shape)."
              },
              {
                "name": "max",
                "type": "T",
                "option": "optional",
                "description": "Maximum value, above which element is replaced by max. It must be a scalar(tensor of empty shape)."
              }
            ],
            "min_input": 1,
            "max_input": 3,
            "outputs": [
              {
                "name": "output",
                "type": "T",
                "description": "Output tensor with clipped input elements"
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "1 - 3",
            "type_constraints": [
              {
                "description": "Constrain input and output types to all numeric tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(uint8)",
                  "tensor(uint16)",
                  "tensor(uint32)",
                  "tensor(uint64)",
                  "tensor(int8)",
                  "tensor(int16)",
                  "tensor(int32)",
                  "tensor(int64)",
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)",
                  "tensor(bfloat16)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "clip",
                "code": "node = onnx.helper.make_node(\n    \"Clip\",\n    inputs=[\"x\", \"min\", \"max\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([-2, 0, 2]).astype(np.float32)\nmin_val = np.float32(-1)\nmax_val = np.float32(1)\ny = np.clip(x, min_val, max_val)  # expected output [-1., 0., 1.]\nexpect(\n    node, inputs=[x, min_val, max_val], outputs=[y], name=\"test_clip_example\"\n)\n\nx = np.random.randn(3, 4, 5).astype(np.float32)\ny = np.clip(x, min_val, max_val)\nexpect(node, inputs=[x, min_val, max_val], outputs=[y], name=\"test_clip\")\nnode = onnx.helper.make_node(\n    \"Clip\",\n    inputs=[\"x\", \"min\", \"max\"],\n    outputs=[\"y\"],\n)\n\nmin_val = np.float32(-5)\nmax_val = np.float32(5)\n\nx = np.array([-1, 0, 1]).astype(np.float32)\ny = np.array([-1, 0, 1]).astype(np.float32)\nexpect(\n    node, inputs=[x, min_val, max_val], outputs=[y], name=\"test_clip_inbounds\"\n)\n\nx = np.array([-6, 0, 6]).astype(np.float32)\ny = np.array([-5, 0, 5]).astype(np.float32)\nexpect(\n    node, inputs=[x, min_val, max_val], outputs=[y], name=\"test_clip_outbounds\"\n)\n\nx = np.array([-1, 0, 6]).astype(np.float32)\ny = np.array([-1, 0, 5]).astype(np.float32)\nexpect(\n    node,\n    inputs=[x, min_val, max_val],\n    outputs=[y],\n    name=\"test_clip_splitbounds\",\n)\n\nx = np.array([-2, 0, 6]).astype(np.float32)\ny = np.array([1, 1, 1]).astype(np.float32)\nmin_val = np.float32(2)\nmax_val = np.float32(1)\nexpect(\n    node,\n    inputs=[x, min_val, max_val],\n    outputs=[y],\n    name=\"test_clip_min_greater_than_max\",\n)"
              },
              {
                "summary": "clip_default",
                "code": "node = onnx.helper.make_node(\n    \"Clip\",\n    inputs=[\"x\", \"min\"],\n    outputs=[\"y\"],\n)\nmin_val = np.float32(0)\nx = np.random.randn(3, 4, 5).astype(np.float32)\ny = np.clip(x, min_val, np.inf)\nexpect(node, inputs=[x, min_val], outputs=[y], name=\"test_clip_default_min\")\n\nno_min = \"\"  # optional input, not supplied\nnode = onnx.helper.make_node(\n    \"Clip\",\n    inputs=[\"x\", no_min, \"max\"],\n    outputs=[\"y\"],\n)\nmax_val = np.float32(0)\nx = np.random.randn(3, 4, 5).astype(np.float32)\ny = np.clip(x, -np.inf, max_val)\nexpect(node, inputs=[x, max_val], outputs=[y], name=\"test_clip_default_max\")\n\nno_max = \"\"  # optional input, not supplied\nnode = onnx.helper.make_node(\n    \"Clip\",\n    inputs=[\"x\", no_min, no_max],\n    outputs=[\"y\"],\n)\n\nx = np.array([-1, 0, 1]).astype(np.float32)\ny = np.array([-1, 0, 1]).astype(np.float32)\nexpect(node, inputs=[x], outputs=[y], name=\"test_clip_default_inbounds\")"
              },
              {
                "summary": "clip_default_int8",
                "code": "node = onnx.helper.make_node(\n    \"Clip\",\n    inputs=[\"x\", \"min\"],\n    outputs=[\"y\"],\n)\nmin_val = np.int8(0)\nx = np.random.randn(3, 4, 5).astype(np.int8)\ny = np.clip(x, min_val, np.iinfo(np.int8).max)\nexpect(\n    node, inputs=[x, min_val], outputs=[y], name=\"test_clip_default_int8_min\"\n)\n\nno_min = \"\"  # optional input, not supplied\nnode = onnx.helper.make_node(\n    \"Clip\",\n    inputs=[\"x\", no_min, \"max\"],\n    outputs=[\"y\"],\n)\nmax_val = np.int8(0)\nx = np.random.randn(3, 4, 5).astype(np.int8)\ny = np.clip(x, np.iinfo(np.int8).min, max_val)\nexpect(\n    node, inputs=[x, max_val], outputs=[y], name=\"test_clip_default_int8_max\"\n)\n\nno_max = \"\"  # optional input, not supplied\nnode = onnx.helper.make_node(\n    \"Clip\",\n    inputs=[\"x\", no_min, no_max],\n    outputs=[\"y\"],\n)\n\nx = np.array([-1, 0, 1]).astype(np.int8)\ny = np.array([-1, 0, 1]).astype(np.int8)\nexpect(node, inputs=[x], outputs=[y], name=\"test_clip_default_int8_inbounds\")"
              }
            ],
            "category": "Activation"
          }
        },
        {
          "name": "mul_16",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "A",
              "value": [
                {
                  "name": "mul_3/y:0",
                  "initializer": {
                    "name": "mul_3/y:0",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float32",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            },
            {
              "name": "B",
              "value": [
                {
                  "name": "Relu6_8:0",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        96,
                        9,
                        16
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "C",
              "value": [
                {
                  "name": "mul_16:0",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        96,
                        9,
                        16
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "Mul",
            "module": "ai.onnx",
            "version": 14,
            "description": "Performs element-wise binary multiplication (with Numpy-style broadcasting support).\n\nThis operator supports **multidirectional (i.e., Numpy-style) broadcasting**; for more details please check [the doc](https://github.com/onnx/onnx/blob/master/docs/Broadcasting.md).\n\n(Opset 14 change): Extend supported types to include uint8, int8, uint16, and int16.\n",
            "inputs": [
              {
                "name": "A",
                "type": "T",
                "description": "First operand."
              },
              {
                "name": "B",
                "type": "T",
                "description": "Second operand."
              }
            ],
            "min_input": 2,
            "max_input": 2,
            "outputs": [
              {
                "name": "C",
                "type": "T",
                "description": "Result, has same element type as two inputs"
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "type_constraints": [
              {
                "description": "Constrain input and output types to all numeric tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(uint8)",
                  "tensor(uint16)",
                  "tensor(uint32)",
                  "tensor(uint64)",
                  "tensor(int8)",
                  "tensor(int16)",
                  "tensor(int32)",
                  "tensor(int64)",
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)",
                  "tensor(bfloat16)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "mul",
                "code": "node = onnx.helper.make_node(\n    \"Mul\",\n    inputs=[\"x\", \"y\"],\n    outputs=[\"z\"],\n)\n\nx = np.array([1, 2, 3]).astype(np.float32)\ny = np.array([4, 5, 6]).astype(np.float32)\nz = x * y  # expected output [4., 10., 18.]\nexpect(node, inputs=[x, y], outputs=[z], name=\"test_mul_example\")\n\nx = np.random.randn(3, 4, 5).astype(np.float32)\ny = np.random.randn(3, 4, 5).astype(np.float32)\nz = x * y\nexpect(node, inputs=[x, y], outputs=[z], name=\"test_mul\")\n\nx = np.random.randint(4, size=(3, 4, 5), dtype=np.int8)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.int8)\nz = x * y\nexpect(node, inputs=[x, y], outputs=[z], name=\"test_mul_int8\")\n\nx = np.random.randint(4, size=(3, 4, 5), dtype=np.int16)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.int16)\nz = x * y\nexpect(node, inputs=[x, y], outputs=[z], name=\"test_mul_int16\")\n\nx = np.random.randint(4, size=(3, 4, 5), dtype=np.uint8)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.uint8)\nz = x * y\nexpect(node, inputs=[x, y], outputs=[z], name=\"test_mul_uint8\")\n\nx = np.random.randint(4, size=(3, 4, 5), dtype=np.uint16)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.uint16)\nz = x * y\nexpect(node, inputs=[x, y], outputs=[z], name=\"test_mul_uint16\")\n\nx = np.random.randint(4, size=(3, 4, 5), dtype=np.uint32)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.uint32)\nz = x * y\nexpect(node, inputs=[x, y], outputs=[z], name=\"test_mul_uint32\")\n\nx = np.random.randint(4, size=(3, 4, 5), dtype=np.uint64)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.uint64)\nz = x * y\nexpect(node, inputs=[x, y], outputs=[z], name=\"test_mul_uint64\")"
              },
              {
                "summary": "mul_broadcast",
                "code": "node = onnx.helper.make_node(\n    \"Mul\",\n    inputs=[\"x\", \"y\"],\n    outputs=[\"z\"],\n)\n\nx = np.random.randn(3, 4, 5).astype(np.float32)\ny = np.random.randn(5).astype(np.float32)\nz = x * y\nexpect(node, inputs=[x, y], outputs=[z], name=\"test_mul_bcast\")"
              }
            ]
          }
        },
        {
          "name": "mul_17",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "A",
              "value": [
                {
                  "name": "Conv__219:0",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        96,
                        9,
                        16
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "B",
              "value": [
                {
                  "name": "mul_16:0",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        96,
                        9,
                        16
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "C",
              "value": [
                {
                  "name": "mul_17:0",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        96,
                        9,
                        16
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "Mul",
            "module": "ai.onnx",
            "version": 14,
            "description": "Performs element-wise binary multiplication (with Numpy-style broadcasting support).\n\nThis operator supports **multidirectional (i.e., Numpy-style) broadcasting**; for more details please check [the doc](https://github.com/onnx/onnx/blob/master/docs/Broadcasting.md).\n\n(Opset 14 change): Extend supported types to include uint8, int8, uint16, and int16.\n",
            "inputs": [
              {
                "name": "A",
                "type": "T",
                "description": "First operand."
              },
              {
                "name": "B",
                "type": "T",
                "description": "Second operand."
              }
            ],
            "min_input": 2,
            "max_input": 2,
            "outputs": [
              {
                "name": "C",
                "type": "T",
                "description": "Result, has same element type as two inputs"
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "type_constraints": [
              {
                "description": "Constrain input and output types to all numeric tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(uint8)",
                  "tensor(uint16)",
                  "tensor(uint32)",
                  "tensor(uint64)",
                  "tensor(int8)",
                  "tensor(int16)",
                  "tensor(int32)",
                  "tensor(int64)",
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)",
                  "tensor(bfloat16)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "mul",
                "code": "node = onnx.helper.make_node(\n    \"Mul\",\n    inputs=[\"x\", \"y\"],\n    outputs=[\"z\"],\n)\n\nx = np.array([1, 2, 3]).astype(np.float32)\ny = np.array([4, 5, 6]).astype(np.float32)\nz = x * y  # expected output [4., 10., 18.]\nexpect(node, inputs=[x, y], outputs=[z], name=\"test_mul_example\")\n\nx = np.random.randn(3, 4, 5).astype(np.float32)\ny = np.random.randn(3, 4, 5).astype(np.float32)\nz = x * y\nexpect(node, inputs=[x, y], outputs=[z], name=\"test_mul\")\n\nx = np.random.randint(4, size=(3, 4, 5), dtype=np.int8)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.int8)\nz = x * y\nexpect(node, inputs=[x, y], outputs=[z], name=\"test_mul_int8\")\n\nx = np.random.randint(4, size=(3, 4, 5), dtype=np.int16)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.int16)\nz = x * y\nexpect(node, inputs=[x, y], outputs=[z], name=\"test_mul_int16\")\n\nx = np.random.randint(4, size=(3, 4, 5), dtype=np.uint8)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.uint8)\nz = x * y\nexpect(node, inputs=[x, y], outputs=[z], name=\"test_mul_uint8\")\n\nx = np.random.randint(4, size=(3, 4, 5), dtype=np.uint16)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.uint16)\nz = x * y\nexpect(node, inputs=[x, y], outputs=[z], name=\"test_mul_uint16\")\n\nx = np.random.randint(4, size=(3, 4, 5), dtype=np.uint32)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.uint32)\nz = x * y\nexpect(node, inputs=[x, y], outputs=[z], name=\"test_mul_uint32\")\n\nx = np.random.randint(4, size=(3, 4, 5), dtype=np.uint64)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.uint64)\nz = x * y\nexpect(node, inputs=[x, y], outputs=[z], name=\"test_mul_uint64\")"
              },
              {
                "summary": "mul_broadcast",
                "code": "node = onnx.helper.make_node(\n    \"Mul\",\n    inputs=[\"x\", \"y\"],\n    outputs=[\"z\"],\n)\n\nx = np.random.randn(3, 4, 5).astype(np.float32)\ny = np.random.randn(5).astype(np.float32)\nz = x * y\nexpect(node, inputs=[x, y], outputs=[z], name=\"test_mul_bcast\")"
              }
            ]
          }
        },
        {
          "name": "global_average_pooling2d_4",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "X",
              "value": [
                {
                  "name": "mul_17:0",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        96,
                        9,
                        16
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "Y",
              "value": [
                {
                  "name": "global_average_pooling2d_4:0",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        96,
                        1,
                        1
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "GlobalAveragePool",
            "module": "ai.onnx",
            "version": 1,
            "description": "GlobalAveragePool consumes an input tensor X and applies average pooling across\n the values in the same channel. This is equivalent to AveragePool with kernel size\n equal to the spatial dimension of input tensor.",
            "inputs": [
              {
                "name": "X",
                "type": "T",
                "description": "Input data tensor from the previous operator; dimensions for image case are (N x C x H x W), where N is the batch size, C is the number of channels, and H and W are the height and the width of the data. For non image case, the dimensions are in the form of (N x C x D1 x D2 ... Dn), where N is the batch size."
              }
            ],
            "min_input": 1,
            "max_input": 1,
            "outputs": [
              {
                "name": "Y",
                "type": "T",
                "description": "Output data tensor from pooling across the input tensor. The output tensor has the same rank as the input. The first two dimensions of output shape are the same as the input (N x C), while the other dimensions are all 1."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "type_constraints": [
              {
                "description": "Constrain input and output types to float tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "globalaveragepool",
                "code": "node = onnx.helper.make_node(\n    \"GlobalAveragePool\",\n    inputs=[\"x\"],\n    outputs=[\"y\"],\n)\nx = np.random.randn(1, 3, 5, 5).astype(np.float32)\ny = np.mean(x, axis=tuple(range(2, np.ndim(x))), keepdims=True)\nexpect(node, inputs=[x], outputs=[y], name=\"test_globalaveragepool\")"
              },
              {
                "summary": "globalaveragepool_precomputed",
                "code": "node = onnx.helper.make_node(\n    \"GlobalAveragePool\",\n    inputs=[\"x\"],\n    outputs=[\"y\"],\n)\nx = np.array(\n    [\n        [\n            [\n                [1, 2, 3],\n                [4, 5, 6],\n                [7, 8, 9],\n            ]\n        ]\n    ]\n).astype(np.float32)\ny = np.array([[[[5]]]]).astype(np.float32)\nexpect(node, inputs=[x], outputs=[y], name=\"test_globalaveragepool_precomputed\")"
              }
            ],
            "category": "Pool"
          }
        },
        {
          "name": "Conv__222",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "X",
              "value": [
                {
                  "name": "global_average_pooling2d_4:0",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        96,
                        1,
                        1
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "W",
              "value": [
                {
                  "name": "Conv2D_23/filter:0",
                  "initializer": {
                    "name": "Conv2D_23/filter:0",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float32",
                      "shape": {
                        "dimensions": [
                          24,
                          96,
                          1,
                          1
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        24,
                        96,
                        1,
                        1
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "B",
              "value": [
                {
                  "name": "conv2d_22_1/y:0",
                  "initializer": {
                    "name": "conv2d_22_1/y:0",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float32",
                      "shape": {
                        "dimensions": [
                          24
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        24
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "Y",
              "value": [
                {
                  "name": "Conv__222:0",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        24,
                        1,
                        1
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [
            {
              "name": "dilations",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "strides",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "kernel_shape",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "group",
              "type": "int64",
              "value": {
                "type": "bigint",
                "value": "1"
              }
            }
          ],
          "type": {
            "name": "Conv",
            "module": "ai.onnx",
            "version": 11,
            "description": "The convolution operator consumes an input tensor and a filter, and\ncomputes the output.",
            "attributes": [
              {
                "name": "auto_pad",
                "type": "string",
                "required": false,
                "default": "NOTSET",
                "description": "auto_pad must be either NOTSET, SAME_UPPER, SAME_LOWER or VALID. Where default value is NOTSET, which means explicit padding is used. SAME_UPPER or SAME_LOWER mean pad the input so that `output_shape[i] = ceil(input_shape[i] / strides[i])` for each axis `i`. The padding is split between the two sides equally or almost equally (depending on whether it is even or odd). In case the padding is an odd number, the extra padding is added at the end for SAME_UPPER and at the beginning for SAME_LOWER."
              },
              {
                "name": "dilations",
                "type": "int64[]",
                "required": false,
                "description": "dilation value along each spatial axis of the filter. If not present, the dilation defaults is 1 along each spatial axis."
              },
              {
                "name": "group",
                "type": "int64",
                "required": false,
                "default": 1,
                "description": "number of groups input channels and output channels are divided into."
              },
              {
                "name": "kernel_shape",
                "type": "int64[]",
                "required": false,
                "description": "The shape of the convolution kernel. If not present, should be inferred from input W."
              },
              {
                "name": "pads",
                "type": "int64[]",
                "required": false,
                "description": "Padding for the beginning and ending along each spatial axis, it can take any value greater than or equal to 0. The value represent the number of pixels added to the beginning and end part of the corresponding axis. `pads` format should be as follow [x1_begin, x2_begin...x1_end, x2_end,...], where xi_begin the number of pixels added at the beginning of axis `i` and xi_end, the number of pixels added at the end of axis `i`. This attribute cannot be used simultaneously with auto_pad attribute. If not present, the padding defaults to 0 along start and end of each spatial axis."
              },
              {
                "name": "strides",
                "type": "int64[]",
                "required": false,
                "description": "Stride along each spatial axis. If not present, the stride defaults is 1 along each spatial axis."
              }
            ],
            "inputs": [
              {
                "name": "X",
                "type": "T",
                "description": "Input data tensor from previous layer; has size (N x C x H x W), where N is the batch size, C is the number of channels, and H and W are the height and width. Note that this is for the 2D image. Otherwise the size is (N x C x D1 x D2 ... x Dn). Optionally, if dimension denotation is in effect, the operation expects input data tensor to arrive with the dimension denotation of [DATA_BATCH, DATA_CHANNEL, DATA_FEATURE, DATA_FEATURE ...]."
              },
              {
                "name": "W",
                "type": "T",
                "description": "The weight tensor that will be used in the convolutions; has size (M x C/group x kH x kW), where C is the number of channels, and kH and kW are the height and width of the kernel, and M is the number of feature maps. For more than 2 dimensions, the kernel shape will be (M x C/group x k1 x k2 x ... x kn), where (k1 x k2 x ... kn) is the dimension of the kernel. Optionally, if dimension denotation is in effect, the operation expects the weight tensor to arrive with the dimension denotation of [FILTER_OUT_CHANNEL, FILTER_IN_CHANNEL, FILTER_SPATIAL, FILTER_SPATIAL ...]. Assuming zero based indices for the shape array, X.shape[1] == (W.shape[1] * group) == C and W.shape[0] mod G == 0. Or in other words FILTER_IN_CHANNEL multiplied by the number of groups should be equal to DATA_CHANNEL and the number of feature maps M should be a multiple of the number of groups G."
              },
              {
                "name": "B",
                "type": "T",
                "option": "optional",
                "description": "Optional 1D bias to be added to the convolution, has size of M."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "Y",
                "type": "T",
                "description": "Output data tensor that contains the result of the convolution. The output dimensions are functions of the kernel size, stride size, and pad lengths."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain input and output types to float tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "conv",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[1, 1, 1, 1],\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 21.0, 27.0, 33.0, 24.0],  # (1, 1, 5, 5) output tensor\n                [33.0, 54.0, 63.0, 72.0, 51.0],\n                [63.0, 99.0, 108.0, 117.0, 81.0],\n                [93.0, 144.0, 153.0, 162.0, 111.0],\n                [72.0, 111.0, 117.0, 123.0, 84.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_basic_conv_with_padding\",\n)\n\n# Convolution without padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[0, 0, 0, 0],\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 63.0, 72.0],  # (1, 1, 3, 3) output tensor\n                [99.0, 108.0, 117.0],\n                [144.0, 153.0, 162.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_basic_conv_without_padding\",\n)"
              },
              {
                "summary": "conv_with_autopad_same",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with auto_pad='SAME_LOWER' and strides=2\nnode = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    auto_pad=\"SAME_LOWER\",\n    kernel_shape=[3, 3],\n    strides=[2, 2],\n)\ny = np.array(\n    [[[[12.0, 27.0, 24.0], [63.0, 108.0, 81.0], [72.0, 117.0, 84.0]]]]\n).astype(np.float32)\nexpect(node, inputs=[x, W], outputs=[y], name=\"test_conv_with_autopad_same\")"
              },
              {
                "summary": "conv_with_strides",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 7, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n                [25.0, 26.0, 27.0, 28.0, 29.0],\n                [30.0, 31.0, 32.0, 33.0, 34.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with strides=2 and padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 1, 1, 1],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 27.0, 24.0],  # (1, 1, 4, 3) output tensor\n                [63.0, 108.0, 81.0],\n                [123.0, 198.0, 141.0],\n                [112.0, 177.0, 124.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_conv_with_strides_padding\",\n)\n\n# Convolution with strides=2 and no padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[0, 0, 0, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 72.0],  # (1, 1, 3, 2) output tensor\n                [144.0, 162.0],\n                [234.0, 252.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_conv_with_strides_no_padding\",\n)\n\n# Convolution with strides=2 and padding only along one dimension (the H dimension in NxCxHxW tensor)\nnode_with_asymmetric_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 0, 1, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_asymmetric_padding = np.array(\n    [\n        [\n            [\n                [21.0, 33.0],  # (1, 1, 4, 2) output tensor\n                [99.0, 117.0],\n                [189.0, 207.0],\n                [171.0, 183.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_asymmetric_padding,\n    inputs=[x, W],\n    outputs=[y_with_asymmetric_padding],\n    name=\"test_conv_with_strides_and_asymmetric_padding\",\n)"
              }
            ],
            "category": "Layer"
          }
        },
        {
          "name": "re_lu_10",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "X",
              "value": [
                {
                  "name": "Conv__222:0",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        24,
                        1,
                        1
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "Y",
              "value": [
                {
                  "name": "re_lu_10:0",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        24,
                        1,
                        1
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "Relu",
            "module": "ai.onnx",
            "version": 14,
            "description": "Relu takes one input data (Tensor<T>) and produces one output data\n(Tensor<T>) where the rectified linear function, y = max(0, x), is applied to\nthe tensor elementwise.\n",
            "inputs": [
              {
                "name": "X",
                "type": "T",
                "description": "Input tensor"
              }
            ],
            "min_input": 1,
            "max_input": 1,
            "outputs": [
              {
                "name": "Y",
                "type": "T",
                "description": "Output tensor"
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "type_constraints": [
              {
                "description": "Constrain input and output types to signed numeric tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(float)",
                  "tensor(int32)",
                  "tensor(int8)",
                  "tensor(int16)",
                  "tensor(int64)",
                  "tensor(float16)",
                  "tensor(double)",
                  "tensor(bfloat16)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "relu",
                "code": "node = onnx.helper.make_node(\n    \"Relu\",\n    inputs=[\"x\"],\n    outputs=[\"y\"],\n)\nx = np.random.randn(3, 4, 5).astype(np.float32)\ny = np.clip(x, 0, np.inf)\n\nexpect(node, inputs=[x], outputs=[y], name=\"test_relu\")"
              }
            ],
            "category": "Activation"
          }
        },
        {
          "name": "Conv__223",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "X",
              "value": [
                {
                  "name": "re_lu_10:0",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        24,
                        1,
                        1
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "W",
              "value": [
                {
                  "name": "Conv2D_24/filter:0",
                  "initializer": {
                    "name": "Conv2D_24/filter:0",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float32",
                      "shape": {
                        "dimensions": [
                          96,
                          24,
                          1,
                          1
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        96,
                        24,
                        1,
                        1
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "B",
              "value": [
                {
                  "name": "conv2d_23_1/y:0",
                  "initializer": {
                    "name": "conv2d_23_1/y:0",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float32",
                      "shape": {
                        "dimensions": [
                          96
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        96
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "Y",
              "value": [
                {
                  "name": "Conv__223:0",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        96,
                        1,
                        1
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [
            {
              "name": "dilations",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "strides",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "kernel_shape",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "group",
              "type": "int64",
              "value": {
                "type": "bigint",
                "value": "1"
              }
            }
          ],
          "type": {
            "name": "Conv",
            "module": "ai.onnx",
            "version": 11,
            "description": "The convolution operator consumes an input tensor and a filter, and\ncomputes the output.",
            "attributes": [
              {
                "name": "auto_pad",
                "type": "string",
                "required": false,
                "default": "NOTSET",
                "description": "auto_pad must be either NOTSET, SAME_UPPER, SAME_LOWER or VALID. Where default value is NOTSET, which means explicit padding is used. SAME_UPPER or SAME_LOWER mean pad the input so that `output_shape[i] = ceil(input_shape[i] / strides[i])` for each axis `i`. The padding is split between the two sides equally or almost equally (depending on whether it is even or odd). In case the padding is an odd number, the extra padding is added at the end for SAME_UPPER and at the beginning for SAME_LOWER."
              },
              {
                "name": "dilations",
                "type": "int64[]",
                "required": false,
                "description": "dilation value along each spatial axis of the filter. If not present, the dilation defaults is 1 along each spatial axis."
              },
              {
                "name": "group",
                "type": "int64",
                "required": false,
                "default": 1,
                "description": "number of groups input channels and output channels are divided into."
              },
              {
                "name": "kernel_shape",
                "type": "int64[]",
                "required": false,
                "description": "The shape of the convolution kernel. If not present, should be inferred from input W."
              },
              {
                "name": "pads",
                "type": "int64[]",
                "required": false,
                "description": "Padding for the beginning and ending along each spatial axis, it can take any value greater than or equal to 0. The value represent the number of pixels added to the beginning and end part of the corresponding axis. `pads` format should be as follow [x1_begin, x2_begin...x1_end, x2_end,...], where xi_begin the number of pixels added at the beginning of axis `i` and xi_end, the number of pixels added at the end of axis `i`. This attribute cannot be used simultaneously with auto_pad attribute. If not present, the padding defaults to 0 along start and end of each spatial axis."
              },
              {
                "name": "strides",
                "type": "int64[]",
                "required": false,
                "description": "Stride along each spatial axis. If not present, the stride defaults is 1 along each spatial axis."
              }
            ],
            "inputs": [
              {
                "name": "X",
                "type": "T",
                "description": "Input data tensor from previous layer; has size (N x C x H x W), where N is the batch size, C is the number of channels, and H and W are the height and width. Note that this is for the 2D image. Otherwise the size is (N x C x D1 x D2 ... x Dn). Optionally, if dimension denotation is in effect, the operation expects input data tensor to arrive with the dimension denotation of [DATA_BATCH, DATA_CHANNEL, DATA_FEATURE, DATA_FEATURE ...]."
              },
              {
                "name": "W",
                "type": "T",
                "description": "The weight tensor that will be used in the convolutions; has size (M x C/group x kH x kW), where C is the number of channels, and kH and kW are the height and width of the kernel, and M is the number of feature maps. For more than 2 dimensions, the kernel shape will be (M x C/group x k1 x k2 x ... x kn), where (k1 x k2 x ... kn) is the dimension of the kernel. Optionally, if dimension denotation is in effect, the operation expects the weight tensor to arrive with the dimension denotation of [FILTER_OUT_CHANNEL, FILTER_IN_CHANNEL, FILTER_SPATIAL, FILTER_SPATIAL ...]. Assuming zero based indices for the shape array, X.shape[1] == (W.shape[1] * group) == C and W.shape[0] mod G == 0. Or in other words FILTER_IN_CHANNEL multiplied by the number of groups should be equal to DATA_CHANNEL and the number of feature maps M should be a multiple of the number of groups G."
              },
              {
                "name": "B",
                "type": "T",
                "option": "optional",
                "description": "Optional 1D bias to be added to the convolution, has size of M."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "Y",
                "type": "T",
                "description": "Output data tensor that contains the result of the convolution. The output dimensions are functions of the kernel size, stride size, and pad lengths."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain input and output types to float tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "conv",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[1, 1, 1, 1],\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 21.0, 27.0, 33.0, 24.0],  # (1, 1, 5, 5) output tensor\n                [33.0, 54.0, 63.0, 72.0, 51.0],\n                [63.0, 99.0, 108.0, 117.0, 81.0],\n                [93.0, 144.0, 153.0, 162.0, 111.0],\n                [72.0, 111.0, 117.0, 123.0, 84.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_basic_conv_with_padding\",\n)\n\n# Convolution without padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[0, 0, 0, 0],\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 63.0, 72.0],  # (1, 1, 3, 3) output tensor\n                [99.0, 108.0, 117.0],\n                [144.0, 153.0, 162.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_basic_conv_without_padding\",\n)"
              },
              {
                "summary": "conv_with_autopad_same",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with auto_pad='SAME_LOWER' and strides=2\nnode = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    auto_pad=\"SAME_LOWER\",\n    kernel_shape=[3, 3],\n    strides=[2, 2],\n)\ny = np.array(\n    [[[[12.0, 27.0, 24.0], [63.0, 108.0, 81.0], [72.0, 117.0, 84.0]]]]\n).astype(np.float32)\nexpect(node, inputs=[x, W], outputs=[y], name=\"test_conv_with_autopad_same\")"
              },
              {
                "summary": "conv_with_strides",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 7, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n                [25.0, 26.0, 27.0, 28.0, 29.0],\n                [30.0, 31.0, 32.0, 33.0, 34.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with strides=2 and padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 1, 1, 1],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 27.0, 24.0],  # (1, 1, 4, 3) output tensor\n                [63.0, 108.0, 81.0],\n                [123.0, 198.0, 141.0],\n                [112.0, 177.0, 124.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_conv_with_strides_padding\",\n)\n\n# Convolution with strides=2 and no padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[0, 0, 0, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 72.0],  # (1, 1, 3, 2) output tensor\n                [144.0, 162.0],\n                [234.0, 252.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_conv_with_strides_no_padding\",\n)\n\n# Convolution with strides=2 and padding only along one dimension (the H dimension in NxCxHxW tensor)\nnode_with_asymmetric_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 0, 1, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_asymmetric_padding = np.array(\n    [\n        [\n            [\n                [21.0, 33.0],  # (1, 1, 4, 2) output tensor\n                [99.0, 117.0],\n                [189.0, 207.0],\n                [171.0, 183.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_asymmetric_padding,\n    inputs=[x, W],\n    outputs=[y_with_asymmetric_padding],\n    name=\"test_conv_with_strides_and_asymmetric_padding\",\n)"
              }
            ],
            "category": "Layer"
          }
        },
        {
          "name": "activation_4",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "X",
              "value": [
                {
                  "name": "Conv__223:0",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        96,
                        1,
                        1
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "Y",
              "value": [
                {
                  "name": "activation_4:0",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        96,
                        1,
                        1
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "Sigmoid",
            "module": "ai.onnx",
            "version": 13,
            "description": "Sigmoid takes one input data (Tensor<T>) and produces one output data\n(Tensor<T>) where the sigmoid function, y = 1 / (1 + exp(-x)), is applied to the\ntensor elementwise.\n",
            "inputs": [
              {
                "name": "X",
                "type": "T",
                "description": "Input tensor"
              }
            ],
            "min_input": 1,
            "max_input": 1,
            "outputs": [
              {
                "name": "Y",
                "type": "T",
                "description": "Output tensor"
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "type_constraints": [
              {
                "description": "Constrain input and output types to float tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)",
                  "tensor(bfloat16)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "sigmoid",
                "code": "node = onnx.helper.make_node(\n    \"Sigmoid\",\n    inputs=[\"x\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([-1, 0, 1]).astype(np.float32)\ny = 1.0 / (\n    1.0 + np.exp(np.negative(x))\n)  # expected output [0.26894143, 0.5, 0.7310586]\nexpect(node, inputs=[x], outputs=[y], name=\"test_sigmoid_example\")\n\nx = np.random.randn(3, 4, 5).astype(np.float32)\ny = 1.0 / (1.0 + np.exp(np.negative(x)))\nexpect(node, inputs=[x], outputs=[y], name=\"test_sigmoid\")"
              }
            ],
            "category": "Activation"
          }
        },
        {
          "name": "multiply_4",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "A",
              "value": [
                {
                  "name": "mul_17:0",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        96,
                        9,
                        16
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "B",
              "value": [
                {
                  "name": "activation_4:0",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        96,
                        1,
                        1
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "C",
              "value": [
                {
                  "name": "multiply_4:0",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        96,
                        9,
                        16
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "Mul",
            "module": "ai.onnx",
            "version": 14,
            "description": "Performs element-wise binary multiplication (with Numpy-style broadcasting support).\n\nThis operator supports **multidirectional (i.e., Numpy-style) broadcasting**; for more details please check [the doc](https://github.com/onnx/onnx/blob/master/docs/Broadcasting.md).\n\n(Opset 14 change): Extend supported types to include uint8, int8, uint16, and int16.\n",
            "inputs": [
              {
                "name": "A",
                "type": "T",
                "description": "First operand."
              },
              {
                "name": "B",
                "type": "T",
                "description": "Second operand."
              }
            ],
            "min_input": 2,
            "max_input": 2,
            "outputs": [
              {
                "name": "C",
                "type": "T",
                "description": "Result, has same element type as two inputs"
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "type_constraints": [
              {
                "description": "Constrain input and output types to all numeric tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(uint8)",
                  "tensor(uint16)",
                  "tensor(uint32)",
                  "tensor(uint64)",
                  "tensor(int8)",
                  "tensor(int16)",
                  "tensor(int32)",
                  "tensor(int64)",
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)",
                  "tensor(bfloat16)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "mul",
                "code": "node = onnx.helper.make_node(\n    \"Mul\",\n    inputs=[\"x\", \"y\"],\n    outputs=[\"z\"],\n)\n\nx = np.array([1, 2, 3]).astype(np.float32)\ny = np.array([4, 5, 6]).astype(np.float32)\nz = x * y  # expected output [4., 10., 18.]\nexpect(node, inputs=[x, y], outputs=[z], name=\"test_mul_example\")\n\nx = np.random.randn(3, 4, 5).astype(np.float32)\ny = np.random.randn(3, 4, 5).astype(np.float32)\nz = x * y\nexpect(node, inputs=[x, y], outputs=[z], name=\"test_mul\")\n\nx = np.random.randint(4, size=(3, 4, 5), dtype=np.int8)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.int8)\nz = x * y\nexpect(node, inputs=[x, y], outputs=[z], name=\"test_mul_int8\")\n\nx = np.random.randint(4, size=(3, 4, 5), dtype=np.int16)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.int16)\nz = x * y\nexpect(node, inputs=[x, y], outputs=[z], name=\"test_mul_int16\")\n\nx = np.random.randint(4, size=(3, 4, 5), dtype=np.uint8)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.uint8)\nz = x * y\nexpect(node, inputs=[x, y], outputs=[z], name=\"test_mul_uint8\")\n\nx = np.random.randint(4, size=(3, 4, 5), dtype=np.uint16)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.uint16)\nz = x * y\nexpect(node, inputs=[x, y], outputs=[z], name=\"test_mul_uint16\")\n\nx = np.random.randint(4, size=(3, 4, 5), dtype=np.uint32)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.uint32)\nz = x * y\nexpect(node, inputs=[x, y], outputs=[z], name=\"test_mul_uint32\")\n\nx = np.random.randint(4, size=(3, 4, 5), dtype=np.uint64)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.uint64)\nz = x * y\nexpect(node, inputs=[x, y], outputs=[z], name=\"test_mul_uint64\")"
              },
              {
                "summary": "mul_broadcast",
                "code": "node = onnx.helper.make_node(\n    \"Mul\",\n    inputs=[\"x\", \"y\"],\n    outputs=[\"z\"],\n)\n\nx = np.random.randn(3, 4, 5).astype(np.float32)\ny = np.random.randn(5).astype(np.float32)\nz = x * y\nexpect(node, inputs=[x, y], outputs=[z], name=\"test_mul_bcast\")"
              }
            ]
          }
        },
        {
          "name": "Conv__224",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "X",
              "value": [
                {
                  "name": "multiply_4:0",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        96,
                        9,
                        16
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "W",
              "value": [
                {
                  "name": "Conv2D_25/filter:0",
                  "initializer": {
                    "name": "Conv2D_25/filter:0",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float32",
                      "shape": {
                        "dimensions": [
                          32,
                          96,
                          1,
                          1
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        32,
                        96,
                        1,
                        1
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "B",
              "value": [
                {
                  "name": "conv2d_24_1/y:0",
                  "initializer": {
                    "name": "conv2d_24_1/y:0",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float32",
                      "shape": {
                        "dimensions": [
                          32
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        32
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "Y",
              "value": [
                {
                  "name": "Conv__224:0",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        32,
                        9,
                        16
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [
            {
              "name": "dilations",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "strides",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "kernel_shape",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "pads",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "0",
                  "0",
                  "0",
                  "0"
                ]
              }
            },
            {
              "name": "group",
              "type": "int64",
              "value": {
                "type": "bigint",
                "value": "1"
              }
            }
          ],
          "type": {
            "name": "Conv",
            "module": "ai.onnx",
            "version": 11,
            "description": "The convolution operator consumes an input tensor and a filter, and\ncomputes the output.",
            "attributes": [
              {
                "name": "auto_pad",
                "type": "string",
                "required": false,
                "default": "NOTSET",
                "description": "auto_pad must be either NOTSET, SAME_UPPER, SAME_LOWER or VALID. Where default value is NOTSET, which means explicit padding is used. SAME_UPPER or SAME_LOWER mean pad the input so that `output_shape[i] = ceil(input_shape[i] / strides[i])` for each axis `i`. The padding is split between the two sides equally or almost equally (depending on whether it is even or odd). In case the padding is an odd number, the extra padding is added at the end for SAME_UPPER and at the beginning for SAME_LOWER."
              },
              {
                "name": "dilations",
                "type": "int64[]",
                "required": false,
                "description": "dilation value along each spatial axis of the filter. If not present, the dilation defaults is 1 along each spatial axis."
              },
              {
                "name": "group",
                "type": "int64",
                "required": false,
                "default": 1,
                "description": "number of groups input channels and output channels are divided into."
              },
              {
                "name": "kernel_shape",
                "type": "int64[]",
                "required": false,
                "description": "The shape of the convolution kernel. If not present, should be inferred from input W."
              },
              {
                "name": "pads",
                "type": "int64[]",
                "required": false,
                "description": "Padding for the beginning and ending along each spatial axis, it can take any value greater than or equal to 0. The value represent the number of pixels added to the beginning and end part of the corresponding axis. `pads` format should be as follow [x1_begin, x2_begin...x1_end, x2_end,...], where xi_begin the number of pixels added at the beginning of axis `i` and xi_end, the number of pixels added at the end of axis `i`. This attribute cannot be used simultaneously with auto_pad attribute. If not present, the padding defaults to 0 along start and end of each spatial axis."
              },
              {
                "name": "strides",
                "type": "int64[]",
                "required": false,
                "description": "Stride along each spatial axis. If not present, the stride defaults is 1 along each spatial axis."
              }
            ],
            "inputs": [
              {
                "name": "X",
                "type": "T",
                "description": "Input data tensor from previous layer; has size (N x C x H x W), where N is the batch size, C is the number of channels, and H and W are the height and width. Note that this is for the 2D image. Otherwise the size is (N x C x D1 x D2 ... x Dn). Optionally, if dimension denotation is in effect, the operation expects input data tensor to arrive with the dimension denotation of [DATA_BATCH, DATA_CHANNEL, DATA_FEATURE, DATA_FEATURE ...]."
              },
              {
                "name": "W",
                "type": "T",
                "description": "The weight tensor that will be used in the convolutions; has size (M x C/group x kH x kW), where C is the number of channels, and kH and kW are the height and width of the kernel, and M is the number of feature maps. For more than 2 dimensions, the kernel shape will be (M x C/group x k1 x k2 x ... x kn), where (k1 x k2 x ... kn) is the dimension of the kernel. Optionally, if dimension denotation is in effect, the operation expects the weight tensor to arrive with the dimension denotation of [FILTER_OUT_CHANNEL, FILTER_IN_CHANNEL, FILTER_SPATIAL, FILTER_SPATIAL ...]. Assuming zero based indices for the shape array, X.shape[1] == (W.shape[1] * group) == C and W.shape[0] mod G == 0. Or in other words FILTER_IN_CHANNEL multiplied by the number of groups should be equal to DATA_CHANNEL and the number of feature maps M should be a multiple of the number of groups G."
              },
              {
                "name": "B",
                "type": "T",
                "option": "optional",
                "description": "Optional 1D bias to be added to the convolution, has size of M."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "Y",
                "type": "T",
                "description": "Output data tensor that contains the result of the convolution. The output dimensions are functions of the kernel size, stride size, and pad lengths."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain input and output types to float tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "conv",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[1, 1, 1, 1],\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 21.0, 27.0, 33.0, 24.0],  # (1, 1, 5, 5) output tensor\n                [33.0, 54.0, 63.0, 72.0, 51.0],\n                [63.0, 99.0, 108.0, 117.0, 81.0],\n                [93.0, 144.0, 153.0, 162.0, 111.0],\n                [72.0, 111.0, 117.0, 123.0, 84.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_basic_conv_with_padding\",\n)\n\n# Convolution without padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[0, 0, 0, 0],\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 63.0, 72.0],  # (1, 1, 3, 3) output tensor\n                [99.0, 108.0, 117.0],\n                [144.0, 153.0, 162.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_basic_conv_without_padding\",\n)"
              },
              {
                "summary": "conv_with_autopad_same",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with auto_pad='SAME_LOWER' and strides=2\nnode = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    auto_pad=\"SAME_LOWER\",\n    kernel_shape=[3, 3],\n    strides=[2, 2],\n)\ny = np.array(\n    [[[[12.0, 27.0, 24.0], [63.0, 108.0, 81.0], [72.0, 117.0, 84.0]]]]\n).astype(np.float32)\nexpect(node, inputs=[x, W], outputs=[y], name=\"test_conv_with_autopad_same\")"
              },
              {
                "summary": "conv_with_strides",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 7, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n                [25.0, 26.0, 27.0, 28.0, 29.0],\n                [30.0, 31.0, 32.0, 33.0, 34.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with strides=2 and padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 1, 1, 1],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 27.0, 24.0],  # (1, 1, 4, 3) output tensor\n                [63.0, 108.0, 81.0],\n                [123.0, 198.0, 141.0],\n                [112.0, 177.0, 124.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_conv_with_strides_padding\",\n)\n\n# Convolution with strides=2 and no padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[0, 0, 0, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 72.0],  # (1, 1, 3, 2) output tensor\n                [144.0, 162.0],\n                [234.0, 252.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_conv_with_strides_no_padding\",\n)\n\n# Convolution with strides=2 and padding only along one dimension (the H dimension in NxCxHxW tensor)\nnode_with_asymmetric_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 0, 1, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_asymmetric_padding = np.array(\n    [\n        [\n            [\n                [21.0, 33.0],  # (1, 1, 4, 2) output tensor\n                [99.0, 117.0],\n                [189.0, 207.0],\n                [171.0, 183.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_asymmetric_padding,\n    inputs=[x, W],\n    outputs=[y_with_asymmetric_padding],\n    name=\"test_conv_with_strides_and_asymmetric_padding\",\n)"
              }
            ],
            "category": "Layer"
          }
        },
        {
          "name": "add_3__xeno_compat__1",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "A",
              "value": [
                {
                  "name": "Conv__224:0",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        32,
                        9,
                        16
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "B",
              "value": [
                {
                  "name": "add_2__xeno_compat__1:0",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        32,
                        9,
                        16
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "C",
              "value": [
                {
                  "name": "add_3__xeno_compat__1:0",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        32,
                        9,
                        16
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "Add",
            "module": "ai.onnx",
            "version": 14,
            "description": "Performs element-wise binary addition (with Numpy-style broadcasting support).\n\nThis operator supports **multidirectional (i.e., Numpy-style) broadcasting**; for more details please check [the doc](https://github.com/onnx/onnx/blob/master/docs/Broadcasting.md).\n\n(Opset 14 change): Extend supported types to include uint8, int8, uint16, and int16.\n",
            "inputs": [
              {
                "name": "A",
                "type": "T",
                "description": "First operand."
              },
              {
                "name": "B",
                "type": "T",
                "description": "Second operand."
              }
            ],
            "min_input": 2,
            "max_input": 2,
            "outputs": [
              {
                "name": "C",
                "type": "T",
                "description": "Result, has same element type as two inputs"
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "type_constraints": [
              {
                "description": "Constrain input and output types to all numeric tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(uint8)",
                  "tensor(uint16)",
                  "tensor(uint32)",
                  "tensor(uint64)",
                  "tensor(int8)",
                  "tensor(int16)",
                  "tensor(int32)",
                  "tensor(int64)",
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)",
                  "tensor(bfloat16)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "add",
                "code": "node = onnx.helper.make_node(\n    \"Add\",\n    inputs=[\"x\", \"y\"],\n    outputs=[\"sum\"],\n)\n\nx = np.random.randn(3, 4, 5).astype(np.float32)\ny = np.random.randn(3, 4, 5).astype(np.float32)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add\")\n\nx = np.random.randint(24, size=(3, 4, 5), dtype=np.int8)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.int8)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add_int8\")\n\nx = np.random.randint(24, size=(3, 4, 5), dtype=np.int16)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.int16)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add_int16\")\n\nx = np.random.randint(24, size=(3, 4, 5), dtype=np.uint8)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.uint8)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add_uint8\")\n\nx = np.random.randint(24, size=(3, 4, 5), dtype=np.uint16)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.uint16)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add_uint16\")\n\nx = np.random.randint(24, size=(3, 4, 5), dtype=np.uint32)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.uint32)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add_uint32\")\n\nx = np.random.randint(24, size=(3, 4, 5), dtype=np.uint64)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.uint64)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add_uint64\")"
              },
              {
                "summary": "add_broadcast",
                "code": "node = onnx.helper.make_node(\n    \"Add\",\n    inputs=[\"x\", \"y\"],\n    outputs=[\"sum\"],\n)\n\nx = np.random.randn(3, 4, 5).astype(np.float32)\ny = np.random.randn(5).astype(np.float32)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add_bcast\")"
              }
            ]
          }
        },
        {
          "name": "Conv__227",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "X",
              "value": [
                {
                  "name": "add_3__xeno_compat__1:0",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        32,
                        9,
                        16
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "W",
              "value": [
                {
                  "name": "Conv2D_26/filter:0",
                  "initializer": {
                    "name": "Conv2D_26/filter:0",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float32",
                      "shape": {
                        "dimensions": [
                          96,
                          32,
                          1,
                          1
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        96,
                        32,
                        1,
                        1
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "B",
              "value": [
                {
                  "name": "conv2d_25_1/y:0",
                  "initializer": {
                    "name": "conv2d_25_1/y:0",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float32",
                      "shape": {
                        "dimensions": [
                          96
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        96
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "Y",
              "value": [
                {
                  "name": "Conv__227:0",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        96,
                        9,
                        16
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [
            {
              "name": "dilations",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "strides",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "kernel_shape",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "pads",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "0",
                  "0",
                  "0",
                  "0"
                ]
              }
            },
            {
              "name": "group",
              "type": "int64",
              "value": {
                "type": "bigint",
                "value": "1"
              }
            }
          ],
          "type": {
            "name": "Conv",
            "module": "ai.onnx",
            "version": 11,
            "description": "The convolution operator consumes an input tensor and a filter, and\ncomputes the output.",
            "attributes": [
              {
                "name": "auto_pad",
                "type": "string",
                "required": false,
                "default": "NOTSET",
                "description": "auto_pad must be either NOTSET, SAME_UPPER, SAME_LOWER or VALID. Where default value is NOTSET, which means explicit padding is used. SAME_UPPER or SAME_LOWER mean pad the input so that `output_shape[i] = ceil(input_shape[i] / strides[i])` for each axis `i`. The padding is split between the two sides equally or almost equally (depending on whether it is even or odd). In case the padding is an odd number, the extra padding is added at the end for SAME_UPPER and at the beginning for SAME_LOWER."
              },
              {
                "name": "dilations",
                "type": "int64[]",
                "required": false,
                "description": "dilation value along each spatial axis of the filter. If not present, the dilation defaults is 1 along each spatial axis."
              },
              {
                "name": "group",
                "type": "int64",
                "required": false,
                "default": 1,
                "description": "number of groups input channels and output channels are divided into."
              },
              {
                "name": "kernel_shape",
                "type": "int64[]",
                "required": false,
                "description": "The shape of the convolution kernel. If not present, should be inferred from input W."
              },
              {
                "name": "pads",
                "type": "int64[]",
                "required": false,
                "description": "Padding for the beginning and ending along each spatial axis, it can take any value greater than or equal to 0. The value represent the number of pixels added to the beginning and end part of the corresponding axis. `pads` format should be as follow [x1_begin, x2_begin...x1_end, x2_end,...], where xi_begin the number of pixels added at the beginning of axis `i` and xi_end, the number of pixels added at the end of axis `i`. This attribute cannot be used simultaneously with auto_pad attribute. If not present, the padding defaults to 0 along start and end of each spatial axis."
              },
              {
                "name": "strides",
                "type": "int64[]",
                "required": false,
                "description": "Stride along each spatial axis. If not present, the stride defaults is 1 along each spatial axis."
              }
            ],
            "inputs": [
              {
                "name": "X",
                "type": "T",
                "description": "Input data tensor from previous layer; has size (N x C x H x W), where N is the batch size, C is the number of channels, and H and W are the height and width. Note that this is for the 2D image. Otherwise the size is (N x C x D1 x D2 ... x Dn). Optionally, if dimension denotation is in effect, the operation expects input data tensor to arrive with the dimension denotation of [DATA_BATCH, DATA_CHANNEL, DATA_FEATURE, DATA_FEATURE ...]."
              },
              {
                "name": "W",
                "type": "T",
                "description": "The weight tensor that will be used in the convolutions; has size (M x C/group x kH x kW), where C is the number of channels, and kH and kW are the height and width of the kernel, and M is the number of feature maps. For more than 2 dimensions, the kernel shape will be (M x C/group x k1 x k2 x ... x kn), where (k1 x k2 x ... kn) is the dimension of the kernel. Optionally, if dimension denotation is in effect, the operation expects the weight tensor to arrive with the dimension denotation of [FILTER_OUT_CHANNEL, FILTER_IN_CHANNEL, FILTER_SPATIAL, FILTER_SPATIAL ...]. Assuming zero based indices for the shape array, X.shape[1] == (W.shape[1] * group) == C and W.shape[0] mod G == 0. Or in other words FILTER_IN_CHANNEL multiplied by the number of groups should be equal to DATA_CHANNEL and the number of feature maps M should be a multiple of the number of groups G."
              },
              {
                "name": "B",
                "type": "T",
                "option": "optional",
                "description": "Optional 1D bias to be added to the convolution, has size of M."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "Y",
                "type": "T",
                "description": "Output data tensor that contains the result of the convolution. The output dimensions are functions of the kernel size, stride size, and pad lengths."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain input and output types to float tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "conv",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[1, 1, 1, 1],\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 21.0, 27.0, 33.0, 24.0],  # (1, 1, 5, 5) output tensor\n                [33.0, 54.0, 63.0, 72.0, 51.0],\n                [63.0, 99.0, 108.0, 117.0, 81.0],\n                [93.0, 144.0, 153.0, 162.0, 111.0],\n                [72.0, 111.0, 117.0, 123.0, 84.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_basic_conv_with_padding\",\n)\n\n# Convolution without padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[0, 0, 0, 0],\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 63.0, 72.0],  # (1, 1, 3, 3) output tensor\n                [99.0, 108.0, 117.0],\n                [144.0, 153.0, 162.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_basic_conv_without_padding\",\n)"
              },
              {
                "summary": "conv_with_autopad_same",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with auto_pad='SAME_LOWER' and strides=2\nnode = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    auto_pad=\"SAME_LOWER\",\n    kernel_shape=[3, 3],\n    strides=[2, 2],\n)\ny = np.array(\n    [[[[12.0, 27.0, 24.0], [63.0, 108.0, 81.0], [72.0, 117.0, 84.0]]]]\n).astype(np.float32)\nexpect(node, inputs=[x, W], outputs=[y], name=\"test_conv_with_autopad_same\")"
              },
              {
                "summary": "conv_with_strides",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 7, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n                [25.0, 26.0, 27.0, 28.0, 29.0],\n                [30.0, 31.0, 32.0, 33.0, 34.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with strides=2 and padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 1, 1, 1],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 27.0, 24.0],  # (1, 1, 4, 3) output tensor\n                [63.0, 108.0, 81.0],\n                [123.0, 198.0, 141.0],\n                [112.0, 177.0, 124.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_conv_with_strides_padding\",\n)\n\n# Convolution with strides=2 and no padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[0, 0, 0, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 72.0],  # (1, 1, 3, 2) output tensor\n                [144.0, 162.0],\n                [234.0, 252.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_conv_with_strides_no_padding\",\n)\n\n# Convolution with strides=2 and padding only along one dimension (the H dimension in NxCxHxW tensor)\nnode_with_asymmetric_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 0, 1, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_asymmetric_padding = np.array(\n    [\n        [\n            [\n                [21.0, 33.0],  # (1, 1, 4, 2) output tensor\n                [99.0, 117.0],\n                [189.0, 207.0],\n                [171.0, 183.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_asymmetric_padding,\n    inputs=[x, W],\n    outputs=[y_with_asymmetric_padding],\n    name=\"test_conv_with_strides_and_asymmetric_padding\",\n)"
              }
            ],
            "category": "Layer"
          }
        },
        {
          "name": "add_9",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "A",
              "value": [
                {
                  "name": "Conv__227:0",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        96,
                        9,
                        16
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "B",
              "value": [
                {
                  "name": "const_fold_opt__408",
                  "initializer": {
                    "name": "const_fold_opt__408",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float32",
                      "shape": {
                        "dimensions": [
                          1,
                          1,
                          1,
                          1
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        1,
                        1,
                        1
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "C",
              "value": [
                {
                  "name": "add_9:0",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        96,
                        9,
                        16
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "Add",
            "module": "ai.onnx",
            "version": 14,
            "description": "Performs element-wise binary addition (with Numpy-style broadcasting support).\n\nThis operator supports **multidirectional (i.e., Numpy-style) broadcasting**; for more details please check [the doc](https://github.com/onnx/onnx/blob/master/docs/Broadcasting.md).\n\n(Opset 14 change): Extend supported types to include uint8, int8, uint16, and int16.\n",
            "inputs": [
              {
                "name": "A",
                "type": "T",
                "description": "First operand."
              },
              {
                "name": "B",
                "type": "T",
                "description": "Second operand."
              }
            ],
            "min_input": 2,
            "max_input": 2,
            "outputs": [
              {
                "name": "C",
                "type": "T",
                "description": "Result, has same element type as two inputs"
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "type_constraints": [
              {
                "description": "Constrain input and output types to all numeric tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(uint8)",
                  "tensor(uint16)",
                  "tensor(uint32)",
                  "tensor(uint64)",
                  "tensor(int8)",
                  "tensor(int16)",
                  "tensor(int32)",
                  "tensor(int64)",
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)",
                  "tensor(bfloat16)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "add",
                "code": "node = onnx.helper.make_node(\n    \"Add\",\n    inputs=[\"x\", \"y\"],\n    outputs=[\"sum\"],\n)\n\nx = np.random.randn(3, 4, 5).astype(np.float32)\ny = np.random.randn(3, 4, 5).astype(np.float32)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add\")\n\nx = np.random.randint(24, size=(3, 4, 5), dtype=np.int8)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.int8)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add_int8\")\n\nx = np.random.randint(24, size=(3, 4, 5), dtype=np.int16)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.int16)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add_int16\")\n\nx = np.random.randint(24, size=(3, 4, 5), dtype=np.uint8)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.uint8)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add_uint8\")\n\nx = np.random.randint(24, size=(3, 4, 5), dtype=np.uint16)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.uint16)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add_uint16\")\n\nx = np.random.randint(24, size=(3, 4, 5), dtype=np.uint32)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.uint32)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add_uint32\")\n\nx = np.random.randint(24, size=(3, 4, 5), dtype=np.uint64)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.uint64)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add_uint64\")"
              },
              {
                "summary": "add_broadcast",
                "code": "node = onnx.helper.make_node(\n    \"Add\",\n    inputs=[\"x\", \"y\"],\n    outputs=[\"sum\"],\n)\n\nx = np.random.randn(3, 4, 5).astype(np.float32)\ny = np.random.randn(5).astype(np.float32)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add_bcast\")"
              }
            ]
          }
        },
        {
          "name": "Relu6_9",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "input",
              "value": [
                {
                  "name": "add_9:0",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        96,
                        9,
                        16
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "min",
              "value": [
                {
                  "name": "310",
                  "initializer": {
                    "category": "Constant",
                    "encoding": "|",
                    "values": {
                      "0": 0
                    },
                    "type": {
                      "dataType": "float32",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            },
            {
              "name": "max",
              "value": [
                {
                  "name": "311",
                  "initializer": {
                    "category": "Constant",
                    "encoding": "|",
                    "values": {
                      "0": 6
                    },
                    "type": {
                      "dataType": "float32",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "output",
              "value": [
                {
                  "name": "Relu6_9:0",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        96,
                        9,
                        16
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "Clip",
            "module": "ai.onnx",
            "version": 13,
            "description": "Clip operator limits the given input within an interval. The interval is\nspecified by the inputs 'min' and 'max'. They default to\nnumeric_limits::lowest() and numeric_limits::max(), respectively.\nWhen 'min' is greater than 'max', the clip operator sets all the 'input' values to\nthe value of 'max'. Thus, this is equivalent to 'Min(max, Max(input, min))'.\n",
            "inputs": [
              {
                "name": "input",
                "type": "T",
                "description": "Input tensor whose elements to be clipped"
              },
              {
                "name": "min",
                "type": "T",
                "option": "optional",
                "description": "Minimum value, under which element is replaced by min. It must be a scalar(tensor of empty shape)."
              },
              {
                "name": "max",
                "type": "T",
                "option": "optional",
                "description": "Maximum value, above which element is replaced by max. It must be a scalar(tensor of empty shape)."
              }
            ],
            "min_input": 1,
            "max_input": 3,
            "outputs": [
              {
                "name": "output",
                "type": "T",
                "description": "Output tensor with clipped input elements"
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "1 - 3",
            "type_constraints": [
              {
                "description": "Constrain input and output types to all numeric tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(uint8)",
                  "tensor(uint16)",
                  "tensor(uint32)",
                  "tensor(uint64)",
                  "tensor(int8)",
                  "tensor(int16)",
                  "tensor(int32)",
                  "tensor(int64)",
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)",
                  "tensor(bfloat16)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "clip",
                "code": "node = onnx.helper.make_node(\n    \"Clip\",\n    inputs=[\"x\", \"min\", \"max\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([-2, 0, 2]).astype(np.float32)\nmin_val = np.float32(-1)\nmax_val = np.float32(1)\ny = np.clip(x, min_val, max_val)  # expected output [-1., 0., 1.]\nexpect(\n    node, inputs=[x, min_val, max_val], outputs=[y], name=\"test_clip_example\"\n)\n\nx = np.random.randn(3, 4, 5).astype(np.float32)\ny = np.clip(x, min_val, max_val)\nexpect(node, inputs=[x, min_val, max_val], outputs=[y], name=\"test_clip\")\nnode = onnx.helper.make_node(\n    \"Clip\",\n    inputs=[\"x\", \"min\", \"max\"],\n    outputs=[\"y\"],\n)\n\nmin_val = np.float32(-5)\nmax_val = np.float32(5)\n\nx = np.array([-1, 0, 1]).astype(np.float32)\ny = np.array([-1, 0, 1]).astype(np.float32)\nexpect(\n    node, inputs=[x, min_val, max_val], outputs=[y], name=\"test_clip_inbounds\"\n)\n\nx = np.array([-6, 0, 6]).astype(np.float32)\ny = np.array([-5, 0, 5]).astype(np.float32)\nexpect(\n    node, inputs=[x, min_val, max_val], outputs=[y], name=\"test_clip_outbounds\"\n)\n\nx = np.array([-1, 0, 6]).astype(np.float32)\ny = np.array([-1, 0, 5]).astype(np.float32)\nexpect(\n    node,\n    inputs=[x, min_val, max_val],\n    outputs=[y],\n    name=\"test_clip_splitbounds\",\n)\n\nx = np.array([-2, 0, 6]).astype(np.float32)\ny = np.array([1, 1, 1]).astype(np.float32)\nmin_val = np.float32(2)\nmax_val = np.float32(1)\nexpect(\n    node,\n    inputs=[x, min_val, max_val],\n    outputs=[y],\n    name=\"test_clip_min_greater_than_max\",\n)"
              },
              {
                "summary": "clip_default",
                "code": "node = onnx.helper.make_node(\n    \"Clip\",\n    inputs=[\"x\", \"min\"],\n    outputs=[\"y\"],\n)\nmin_val = np.float32(0)\nx = np.random.randn(3, 4, 5).astype(np.float32)\ny = np.clip(x, min_val, np.inf)\nexpect(node, inputs=[x, min_val], outputs=[y], name=\"test_clip_default_min\")\n\nno_min = \"\"  # optional input, not supplied\nnode = onnx.helper.make_node(\n    \"Clip\",\n    inputs=[\"x\", no_min, \"max\"],\n    outputs=[\"y\"],\n)\nmax_val = np.float32(0)\nx = np.random.randn(3, 4, 5).astype(np.float32)\ny = np.clip(x, -np.inf, max_val)\nexpect(node, inputs=[x, max_val], outputs=[y], name=\"test_clip_default_max\")\n\nno_max = \"\"  # optional input, not supplied\nnode = onnx.helper.make_node(\n    \"Clip\",\n    inputs=[\"x\", no_min, no_max],\n    outputs=[\"y\"],\n)\n\nx = np.array([-1, 0, 1]).astype(np.float32)\ny = np.array([-1, 0, 1]).astype(np.float32)\nexpect(node, inputs=[x], outputs=[y], name=\"test_clip_default_inbounds\")"
              },
              {
                "summary": "clip_default_int8",
                "code": "node = onnx.helper.make_node(\n    \"Clip\",\n    inputs=[\"x\", \"min\"],\n    outputs=[\"y\"],\n)\nmin_val = np.int8(0)\nx = np.random.randn(3, 4, 5).astype(np.int8)\ny = np.clip(x, min_val, np.iinfo(np.int8).max)\nexpect(\n    node, inputs=[x, min_val], outputs=[y], name=\"test_clip_default_int8_min\"\n)\n\nno_min = \"\"  # optional input, not supplied\nnode = onnx.helper.make_node(\n    \"Clip\",\n    inputs=[\"x\", no_min, \"max\"],\n    outputs=[\"y\"],\n)\nmax_val = np.int8(0)\nx = np.random.randn(3, 4, 5).astype(np.int8)\ny = np.clip(x, np.iinfo(np.int8).min, max_val)\nexpect(\n    node, inputs=[x, max_val], outputs=[y], name=\"test_clip_default_int8_max\"\n)\n\nno_max = \"\"  # optional input, not supplied\nnode = onnx.helper.make_node(\n    \"Clip\",\n    inputs=[\"x\", no_min, no_max],\n    outputs=[\"y\"],\n)\n\nx = np.array([-1, 0, 1]).astype(np.int8)\ny = np.array([-1, 0, 1]).astype(np.int8)\nexpect(node, inputs=[x], outputs=[y], name=\"test_clip_default_int8_inbounds\")"
              }
            ],
            "category": "Activation"
          }
        },
        {
          "name": "mul_18",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "A",
              "value": [
                {
                  "name": "mul_3/y:0",
                  "initializer": {
                    "name": "mul_3/y:0",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float32",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            },
            {
              "name": "B",
              "value": [
                {
                  "name": "Relu6_9:0",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        96,
                        9,
                        16
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "C",
              "value": [
                {
                  "name": "mul_18:0",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        96,
                        9,
                        16
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "Mul",
            "module": "ai.onnx",
            "version": 14,
            "description": "Performs element-wise binary multiplication (with Numpy-style broadcasting support).\n\nThis operator supports **multidirectional (i.e., Numpy-style) broadcasting**; for more details please check [the doc](https://github.com/onnx/onnx/blob/master/docs/Broadcasting.md).\n\n(Opset 14 change): Extend supported types to include uint8, int8, uint16, and int16.\n",
            "inputs": [
              {
                "name": "A",
                "type": "T",
                "description": "First operand."
              },
              {
                "name": "B",
                "type": "T",
                "description": "Second operand."
              }
            ],
            "min_input": 2,
            "max_input": 2,
            "outputs": [
              {
                "name": "C",
                "type": "T",
                "description": "Result, has same element type as two inputs"
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "type_constraints": [
              {
                "description": "Constrain input and output types to all numeric tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(uint8)",
                  "tensor(uint16)",
                  "tensor(uint32)",
                  "tensor(uint64)",
                  "tensor(int8)",
                  "tensor(int16)",
                  "tensor(int32)",
                  "tensor(int64)",
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)",
                  "tensor(bfloat16)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "mul",
                "code": "node = onnx.helper.make_node(\n    \"Mul\",\n    inputs=[\"x\", \"y\"],\n    outputs=[\"z\"],\n)\n\nx = np.array([1, 2, 3]).astype(np.float32)\ny = np.array([4, 5, 6]).astype(np.float32)\nz = x * y  # expected output [4., 10., 18.]\nexpect(node, inputs=[x, y], outputs=[z], name=\"test_mul_example\")\n\nx = np.random.randn(3, 4, 5).astype(np.float32)\ny = np.random.randn(3, 4, 5).astype(np.float32)\nz = x * y\nexpect(node, inputs=[x, y], outputs=[z], name=\"test_mul\")\n\nx = np.random.randint(4, size=(3, 4, 5), dtype=np.int8)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.int8)\nz = x * y\nexpect(node, inputs=[x, y], outputs=[z], name=\"test_mul_int8\")\n\nx = np.random.randint(4, size=(3, 4, 5), dtype=np.int16)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.int16)\nz = x * y\nexpect(node, inputs=[x, y], outputs=[z], name=\"test_mul_int16\")\n\nx = np.random.randint(4, size=(3, 4, 5), dtype=np.uint8)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.uint8)\nz = x * y\nexpect(node, inputs=[x, y], outputs=[z], name=\"test_mul_uint8\")\n\nx = np.random.randint(4, size=(3, 4, 5), dtype=np.uint16)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.uint16)\nz = x * y\nexpect(node, inputs=[x, y], outputs=[z], name=\"test_mul_uint16\")\n\nx = np.random.randint(4, size=(3, 4, 5), dtype=np.uint32)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.uint32)\nz = x * y\nexpect(node, inputs=[x, y], outputs=[z], name=\"test_mul_uint32\")\n\nx = np.random.randint(4, size=(3, 4, 5), dtype=np.uint64)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.uint64)\nz = x * y\nexpect(node, inputs=[x, y], outputs=[z], name=\"test_mul_uint64\")"
              },
              {
                "summary": "mul_broadcast",
                "code": "node = onnx.helper.make_node(\n    \"Mul\",\n    inputs=[\"x\", \"y\"],\n    outputs=[\"z\"],\n)\n\nx = np.random.randn(3, 4, 5).astype(np.float32)\ny = np.random.randn(5).astype(np.float32)\nz = x * y\nexpect(node, inputs=[x, y], outputs=[z], name=\"test_mul_bcast\")"
              }
            ]
          }
        },
        {
          "name": "mul_19",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "A",
              "value": [
                {
                  "name": "Conv__227:0",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        96,
                        9,
                        16
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "B",
              "value": [
                {
                  "name": "mul_18:0",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        96,
                        9,
                        16
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "C",
              "value": [
                {
                  "name": "mul_19:0",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        96,
                        9,
                        16
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "Mul",
            "module": "ai.onnx",
            "version": 14,
            "description": "Performs element-wise binary multiplication (with Numpy-style broadcasting support).\n\nThis operator supports **multidirectional (i.e., Numpy-style) broadcasting**; for more details please check [the doc](https://github.com/onnx/onnx/blob/master/docs/Broadcasting.md).\n\n(Opset 14 change): Extend supported types to include uint8, int8, uint16, and int16.\n",
            "inputs": [
              {
                "name": "A",
                "type": "T",
                "description": "First operand."
              },
              {
                "name": "B",
                "type": "T",
                "description": "Second operand."
              }
            ],
            "min_input": 2,
            "max_input": 2,
            "outputs": [
              {
                "name": "C",
                "type": "T",
                "description": "Result, has same element type as two inputs"
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "type_constraints": [
              {
                "description": "Constrain input and output types to all numeric tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(uint8)",
                  "tensor(uint16)",
                  "tensor(uint32)",
                  "tensor(uint64)",
                  "tensor(int8)",
                  "tensor(int16)",
                  "tensor(int32)",
                  "tensor(int64)",
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)",
                  "tensor(bfloat16)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "mul",
                "code": "node = onnx.helper.make_node(\n    \"Mul\",\n    inputs=[\"x\", \"y\"],\n    outputs=[\"z\"],\n)\n\nx = np.array([1, 2, 3]).astype(np.float32)\ny = np.array([4, 5, 6]).astype(np.float32)\nz = x * y  # expected output [4., 10., 18.]\nexpect(node, inputs=[x, y], outputs=[z], name=\"test_mul_example\")\n\nx = np.random.randn(3, 4, 5).astype(np.float32)\ny = np.random.randn(3, 4, 5).astype(np.float32)\nz = x * y\nexpect(node, inputs=[x, y], outputs=[z], name=\"test_mul\")\n\nx = np.random.randint(4, size=(3, 4, 5), dtype=np.int8)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.int8)\nz = x * y\nexpect(node, inputs=[x, y], outputs=[z], name=\"test_mul_int8\")\n\nx = np.random.randint(4, size=(3, 4, 5), dtype=np.int16)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.int16)\nz = x * y\nexpect(node, inputs=[x, y], outputs=[z], name=\"test_mul_int16\")\n\nx = np.random.randint(4, size=(3, 4, 5), dtype=np.uint8)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.uint8)\nz = x * y\nexpect(node, inputs=[x, y], outputs=[z], name=\"test_mul_uint8\")\n\nx = np.random.randint(4, size=(3, 4, 5), dtype=np.uint16)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.uint16)\nz = x * y\nexpect(node, inputs=[x, y], outputs=[z], name=\"test_mul_uint16\")\n\nx = np.random.randint(4, size=(3, 4, 5), dtype=np.uint32)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.uint32)\nz = x * y\nexpect(node, inputs=[x, y], outputs=[z], name=\"test_mul_uint32\")\n\nx = np.random.randint(4, size=(3, 4, 5), dtype=np.uint64)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.uint64)\nz = x * y\nexpect(node, inputs=[x, y], outputs=[z], name=\"test_mul_uint64\")"
              },
              {
                "summary": "mul_broadcast",
                "code": "node = onnx.helper.make_node(\n    \"Mul\",\n    inputs=[\"x\", \"y\"],\n    outputs=[\"z\"],\n)\n\nx = np.random.randn(3, 4, 5).astype(np.float32)\ny = np.random.randn(5).astype(np.float32)\nz = x * y\nexpect(node, inputs=[x, y], outputs=[z], name=\"test_mul_bcast\")"
              }
            ]
          }
        },
        {
          "name": "Conv__230",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "X",
              "value": [
                {
                  "name": "mul_19:0",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        96,
                        9,
                        16
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "W",
              "value": [
                {
                  "name": "const_fold_opt__407",
                  "initializer": {
                    "name": "const_fold_opt__407",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float32",
                      "shape": {
                        "dimensions": [
                          96,
                          1,
                          5,
                          5
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        96,
                        1,
                        5,
                        5
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "B",
              "value": [
                {
                  "name": "depthwise_conv2d_7/y:0",
                  "initializer": {
                    "name": "depthwise_conv2d_7/y:0",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float32",
                      "shape": {
                        "dimensions": [
                          96
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        96
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "Y",
              "value": [
                {
                  "name": "Conv__230:0",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        96,
                        9,
                        16
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [
            {
              "name": "dilations",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "strides",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "kernel_shape",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "5",
                  "5"
                ]
              }
            },
            {
              "name": "group",
              "type": "int64",
              "value": {
                "type": "bigint",
                "value": "96"
              }
            },
            {
              "name": "pads",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "2",
                  "2",
                  "2",
                  "2"
                ]
              }
            }
          ],
          "type": {
            "name": "Conv",
            "module": "ai.onnx",
            "version": 11,
            "description": "The convolution operator consumes an input tensor and a filter, and\ncomputes the output.",
            "attributes": [
              {
                "name": "auto_pad",
                "type": "string",
                "required": false,
                "default": "NOTSET",
                "description": "auto_pad must be either NOTSET, SAME_UPPER, SAME_LOWER or VALID. Where default value is NOTSET, which means explicit padding is used. SAME_UPPER or SAME_LOWER mean pad the input so that `output_shape[i] = ceil(input_shape[i] / strides[i])` for each axis `i`. The padding is split between the two sides equally or almost equally (depending on whether it is even or odd). In case the padding is an odd number, the extra padding is added at the end for SAME_UPPER and at the beginning for SAME_LOWER."
              },
              {
                "name": "dilations",
                "type": "int64[]",
                "required": false,
                "description": "dilation value along each spatial axis of the filter. If not present, the dilation defaults is 1 along each spatial axis."
              },
              {
                "name": "group",
                "type": "int64",
                "required": false,
                "default": 1,
                "description": "number of groups input channels and output channels are divided into."
              },
              {
                "name": "kernel_shape",
                "type": "int64[]",
                "required": false,
                "description": "The shape of the convolution kernel. If not present, should be inferred from input W."
              },
              {
                "name": "pads",
                "type": "int64[]",
                "required": false,
                "description": "Padding for the beginning and ending along each spatial axis, it can take any value greater than or equal to 0. The value represent the number of pixels added to the beginning and end part of the corresponding axis. `pads` format should be as follow [x1_begin, x2_begin...x1_end, x2_end,...], where xi_begin the number of pixels added at the beginning of axis `i` and xi_end, the number of pixels added at the end of axis `i`. This attribute cannot be used simultaneously with auto_pad attribute. If not present, the padding defaults to 0 along start and end of each spatial axis."
              },
              {
                "name": "strides",
                "type": "int64[]",
                "required": false,
                "description": "Stride along each spatial axis. If not present, the stride defaults is 1 along each spatial axis."
              }
            ],
            "inputs": [
              {
                "name": "X",
                "type": "T",
                "description": "Input data tensor from previous layer; has size (N x C x H x W), where N is the batch size, C is the number of channels, and H and W are the height and width. Note that this is for the 2D image. Otherwise the size is (N x C x D1 x D2 ... x Dn). Optionally, if dimension denotation is in effect, the operation expects input data tensor to arrive with the dimension denotation of [DATA_BATCH, DATA_CHANNEL, DATA_FEATURE, DATA_FEATURE ...]."
              },
              {
                "name": "W",
                "type": "T",
                "description": "The weight tensor that will be used in the convolutions; has size (M x C/group x kH x kW), where C is the number of channels, and kH and kW are the height and width of the kernel, and M is the number of feature maps. For more than 2 dimensions, the kernel shape will be (M x C/group x k1 x k2 x ... x kn), where (k1 x k2 x ... kn) is the dimension of the kernel. Optionally, if dimension denotation is in effect, the operation expects the weight tensor to arrive with the dimension denotation of [FILTER_OUT_CHANNEL, FILTER_IN_CHANNEL, FILTER_SPATIAL, FILTER_SPATIAL ...]. Assuming zero based indices for the shape array, X.shape[1] == (W.shape[1] * group) == C and W.shape[0] mod G == 0. Or in other words FILTER_IN_CHANNEL multiplied by the number of groups should be equal to DATA_CHANNEL and the number of feature maps M should be a multiple of the number of groups G."
              },
              {
                "name": "B",
                "type": "T",
                "option": "optional",
                "description": "Optional 1D bias to be added to the convolution, has size of M."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "Y",
                "type": "T",
                "description": "Output data tensor that contains the result of the convolution. The output dimensions are functions of the kernel size, stride size, and pad lengths."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain input and output types to float tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "conv",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[1, 1, 1, 1],\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 21.0, 27.0, 33.0, 24.0],  # (1, 1, 5, 5) output tensor\n                [33.0, 54.0, 63.0, 72.0, 51.0],\n                [63.0, 99.0, 108.0, 117.0, 81.0],\n                [93.0, 144.0, 153.0, 162.0, 111.0],\n                [72.0, 111.0, 117.0, 123.0, 84.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_basic_conv_with_padding\",\n)\n\n# Convolution without padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[0, 0, 0, 0],\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 63.0, 72.0],  # (1, 1, 3, 3) output tensor\n                [99.0, 108.0, 117.0],\n                [144.0, 153.0, 162.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_basic_conv_without_padding\",\n)"
              },
              {
                "summary": "conv_with_autopad_same",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with auto_pad='SAME_LOWER' and strides=2\nnode = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    auto_pad=\"SAME_LOWER\",\n    kernel_shape=[3, 3],\n    strides=[2, 2],\n)\ny = np.array(\n    [[[[12.0, 27.0, 24.0], [63.0, 108.0, 81.0], [72.0, 117.0, 84.0]]]]\n).astype(np.float32)\nexpect(node, inputs=[x, W], outputs=[y], name=\"test_conv_with_autopad_same\")"
              },
              {
                "summary": "conv_with_strides",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 7, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n                [25.0, 26.0, 27.0, 28.0, 29.0],\n                [30.0, 31.0, 32.0, 33.0, 34.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with strides=2 and padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 1, 1, 1],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 27.0, 24.0],  # (1, 1, 4, 3) output tensor\n                [63.0, 108.0, 81.0],\n                [123.0, 198.0, 141.0],\n                [112.0, 177.0, 124.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_conv_with_strides_padding\",\n)\n\n# Convolution with strides=2 and no padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[0, 0, 0, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 72.0],  # (1, 1, 3, 2) output tensor\n                [144.0, 162.0],\n                [234.0, 252.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_conv_with_strides_no_padding\",\n)\n\n# Convolution with strides=2 and padding only along one dimension (the H dimension in NxCxHxW tensor)\nnode_with_asymmetric_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 0, 1, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_asymmetric_padding = np.array(\n    [\n        [\n            [\n                [21.0, 33.0],  # (1, 1, 4, 2) output tensor\n                [99.0, 117.0],\n                [189.0, 207.0],\n                [171.0, 183.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_asymmetric_padding,\n    inputs=[x, W],\n    outputs=[y_with_asymmetric_padding],\n    name=\"test_conv_with_strides_and_asymmetric_padding\",\n)"
              }
            ],
            "category": "Layer"
          }
        },
        {
          "name": "add_10",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "A",
              "value": [
                {
                  "name": "Conv__230:0",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        96,
                        9,
                        16
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "B",
              "value": [
                {
                  "name": "const_fold_opt__408",
                  "initializer": {
                    "name": "const_fold_opt__408",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float32",
                      "shape": {
                        "dimensions": [
                          1,
                          1,
                          1,
                          1
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        1,
                        1,
                        1
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "C",
              "value": [
                {
                  "name": "add_10:0",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        96,
                        9,
                        16
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "Add",
            "module": "ai.onnx",
            "version": 14,
            "description": "Performs element-wise binary addition (with Numpy-style broadcasting support).\n\nThis operator supports **multidirectional (i.e., Numpy-style) broadcasting**; for more details please check [the doc](https://github.com/onnx/onnx/blob/master/docs/Broadcasting.md).\n\n(Opset 14 change): Extend supported types to include uint8, int8, uint16, and int16.\n",
            "inputs": [
              {
                "name": "A",
                "type": "T",
                "description": "First operand."
              },
              {
                "name": "B",
                "type": "T",
                "description": "Second operand."
              }
            ],
            "min_input": 2,
            "max_input": 2,
            "outputs": [
              {
                "name": "C",
                "type": "T",
                "description": "Result, has same element type as two inputs"
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "type_constraints": [
              {
                "description": "Constrain input and output types to all numeric tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(uint8)",
                  "tensor(uint16)",
                  "tensor(uint32)",
                  "tensor(uint64)",
                  "tensor(int8)",
                  "tensor(int16)",
                  "tensor(int32)",
                  "tensor(int64)",
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)",
                  "tensor(bfloat16)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "add",
                "code": "node = onnx.helper.make_node(\n    \"Add\",\n    inputs=[\"x\", \"y\"],\n    outputs=[\"sum\"],\n)\n\nx = np.random.randn(3, 4, 5).astype(np.float32)\ny = np.random.randn(3, 4, 5).astype(np.float32)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add\")\n\nx = np.random.randint(24, size=(3, 4, 5), dtype=np.int8)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.int8)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add_int8\")\n\nx = np.random.randint(24, size=(3, 4, 5), dtype=np.int16)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.int16)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add_int16\")\n\nx = np.random.randint(24, size=(3, 4, 5), dtype=np.uint8)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.uint8)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add_uint8\")\n\nx = np.random.randint(24, size=(3, 4, 5), dtype=np.uint16)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.uint16)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add_uint16\")\n\nx = np.random.randint(24, size=(3, 4, 5), dtype=np.uint32)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.uint32)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add_uint32\")\n\nx = np.random.randint(24, size=(3, 4, 5), dtype=np.uint64)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.uint64)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add_uint64\")"
              },
              {
                "summary": "add_broadcast",
                "code": "node = onnx.helper.make_node(\n    \"Add\",\n    inputs=[\"x\", \"y\"],\n    outputs=[\"sum\"],\n)\n\nx = np.random.randn(3, 4, 5).astype(np.float32)\ny = np.random.randn(5).astype(np.float32)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add_bcast\")"
              }
            ]
          }
        },
        {
          "name": "Relu6_10",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "input",
              "value": [
                {
                  "name": "add_10:0",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        96,
                        9,
                        16
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "min",
              "value": [
                {
                  "name": "312",
                  "initializer": {
                    "category": "Constant",
                    "encoding": "|",
                    "values": {
                      "0": 0
                    },
                    "type": {
                      "dataType": "float32",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            },
            {
              "name": "max",
              "value": [
                {
                  "name": "313",
                  "initializer": {
                    "category": "Constant",
                    "encoding": "|",
                    "values": {
                      "0": 6
                    },
                    "type": {
                      "dataType": "float32",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "output",
              "value": [
                {
                  "name": "Relu6_10:0",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        96,
                        9,
                        16
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "Clip",
            "module": "ai.onnx",
            "version": 13,
            "description": "Clip operator limits the given input within an interval. The interval is\nspecified by the inputs 'min' and 'max'. They default to\nnumeric_limits::lowest() and numeric_limits::max(), respectively.\nWhen 'min' is greater than 'max', the clip operator sets all the 'input' values to\nthe value of 'max'. Thus, this is equivalent to 'Min(max, Max(input, min))'.\n",
            "inputs": [
              {
                "name": "input",
                "type": "T",
                "description": "Input tensor whose elements to be clipped"
              },
              {
                "name": "min",
                "type": "T",
                "option": "optional",
                "description": "Minimum value, under which element is replaced by min. It must be a scalar(tensor of empty shape)."
              },
              {
                "name": "max",
                "type": "T",
                "option": "optional",
                "description": "Maximum value, above which element is replaced by max. It must be a scalar(tensor of empty shape)."
              }
            ],
            "min_input": 1,
            "max_input": 3,
            "outputs": [
              {
                "name": "output",
                "type": "T",
                "description": "Output tensor with clipped input elements"
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "1 - 3",
            "type_constraints": [
              {
                "description": "Constrain input and output types to all numeric tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(uint8)",
                  "tensor(uint16)",
                  "tensor(uint32)",
                  "tensor(uint64)",
                  "tensor(int8)",
                  "tensor(int16)",
                  "tensor(int32)",
                  "tensor(int64)",
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)",
                  "tensor(bfloat16)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "clip",
                "code": "node = onnx.helper.make_node(\n    \"Clip\",\n    inputs=[\"x\", \"min\", \"max\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([-2, 0, 2]).astype(np.float32)\nmin_val = np.float32(-1)\nmax_val = np.float32(1)\ny = np.clip(x, min_val, max_val)  # expected output [-1., 0., 1.]\nexpect(\n    node, inputs=[x, min_val, max_val], outputs=[y], name=\"test_clip_example\"\n)\n\nx = np.random.randn(3, 4, 5).astype(np.float32)\ny = np.clip(x, min_val, max_val)\nexpect(node, inputs=[x, min_val, max_val], outputs=[y], name=\"test_clip\")\nnode = onnx.helper.make_node(\n    \"Clip\",\n    inputs=[\"x\", \"min\", \"max\"],\n    outputs=[\"y\"],\n)\n\nmin_val = np.float32(-5)\nmax_val = np.float32(5)\n\nx = np.array([-1, 0, 1]).astype(np.float32)\ny = np.array([-1, 0, 1]).astype(np.float32)\nexpect(\n    node, inputs=[x, min_val, max_val], outputs=[y], name=\"test_clip_inbounds\"\n)\n\nx = np.array([-6, 0, 6]).astype(np.float32)\ny = np.array([-5, 0, 5]).astype(np.float32)\nexpect(\n    node, inputs=[x, min_val, max_val], outputs=[y], name=\"test_clip_outbounds\"\n)\n\nx = np.array([-1, 0, 6]).astype(np.float32)\ny = np.array([-1, 0, 5]).astype(np.float32)\nexpect(\n    node,\n    inputs=[x, min_val, max_val],\n    outputs=[y],\n    name=\"test_clip_splitbounds\",\n)\n\nx = np.array([-2, 0, 6]).astype(np.float32)\ny = np.array([1, 1, 1]).astype(np.float32)\nmin_val = np.float32(2)\nmax_val = np.float32(1)\nexpect(\n    node,\n    inputs=[x, min_val, max_val],\n    outputs=[y],\n    name=\"test_clip_min_greater_than_max\",\n)"
              },
              {
                "summary": "clip_default",
                "code": "node = onnx.helper.make_node(\n    \"Clip\",\n    inputs=[\"x\", \"min\"],\n    outputs=[\"y\"],\n)\nmin_val = np.float32(0)\nx = np.random.randn(3, 4, 5).astype(np.float32)\ny = np.clip(x, min_val, np.inf)\nexpect(node, inputs=[x, min_val], outputs=[y], name=\"test_clip_default_min\")\n\nno_min = \"\"  # optional input, not supplied\nnode = onnx.helper.make_node(\n    \"Clip\",\n    inputs=[\"x\", no_min, \"max\"],\n    outputs=[\"y\"],\n)\nmax_val = np.float32(0)\nx = np.random.randn(3, 4, 5).astype(np.float32)\ny = np.clip(x, -np.inf, max_val)\nexpect(node, inputs=[x, max_val], outputs=[y], name=\"test_clip_default_max\")\n\nno_max = \"\"  # optional input, not supplied\nnode = onnx.helper.make_node(\n    \"Clip\",\n    inputs=[\"x\", no_min, no_max],\n    outputs=[\"y\"],\n)\n\nx = np.array([-1, 0, 1]).astype(np.float32)\ny = np.array([-1, 0, 1]).astype(np.float32)\nexpect(node, inputs=[x], outputs=[y], name=\"test_clip_default_inbounds\")"
              },
              {
                "summary": "clip_default_int8",
                "code": "node = onnx.helper.make_node(\n    \"Clip\",\n    inputs=[\"x\", \"min\"],\n    outputs=[\"y\"],\n)\nmin_val = np.int8(0)\nx = np.random.randn(3, 4, 5).astype(np.int8)\ny = np.clip(x, min_val, np.iinfo(np.int8).max)\nexpect(\n    node, inputs=[x, min_val], outputs=[y], name=\"test_clip_default_int8_min\"\n)\n\nno_min = \"\"  # optional input, not supplied\nnode = onnx.helper.make_node(\n    \"Clip\",\n    inputs=[\"x\", no_min, \"max\"],\n    outputs=[\"y\"],\n)\nmax_val = np.int8(0)\nx = np.random.randn(3, 4, 5).astype(np.int8)\ny = np.clip(x, np.iinfo(np.int8).min, max_val)\nexpect(\n    node, inputs=[x, max_val], outputs=[y], name=\"test_clip_default_int8_max\"\n)\n\nno_max = \"\"  # optional input, not supplied\nnode = onnx.helper.make_node(\n    \"Clip\",\n    inputs=[\"x\", no_min, no_max],\n    outputs=[\"y\"],\n)\n\nx = np.array([-1, 0, 1]).astype(np.int8)\ny = np.array([-1, 0, 1]).astype(np.int8)\nexpect(node, inputs=[x], outputs=[y], name=\"test_clip_default_int8_inbounds\")"
              }
            ],
            "category": "Activation"
          }
        },
        {
          "name": "mul_20",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "A",
              "value": [
                {
                  "name": "mul_3/y:0",
                  "initializer": {
                    "name": "mul_3/y:0",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float32",
                      "shape": {
                        "dimensions": []
                      }
                    }
                  },
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": []
                    }
                  }
                }
              ]
            },
            {
              "name": "B",
              "value": [
                {
                  "name": "Relu6_10:0",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        96,
                        9,
                        16
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "C",
              "value": [
                {
                  "name": "mul_20:0",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        96,
                        9,
                        16
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "Mul",
            "module": "ai.onnx",
            "version": 14,
            "description": "Performs element-wise binary multiplication (with Numpy-style broadcasting support).\n\nThis operator supports **multidirectional (i.e., Numpy-style) broadcasting**; for more details please check [the doc](https://github.com/onnx/onnx/blob/master/docs/Broadcasting.md).\n\n(Opset 14 change): Extend supported types to include uint8, int8, uint16, and int16.\n",
            "inputs": [
              {
                "name": "A",
                "type": "T",
                "description": "First operand."
              },
              {
                "name": "B",
                "type": "T",
                "description": "Second operand."
              }
            ],
            "min_input": 2,
            "max_input": 2,
            "outputs": [
              {
                "name": "C",
                "type": "T",
                "description": "Result, has same element type as two inputs"
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "type_constraints": [
              {
                "description": "Constrain input and output types to all numeric tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(uint8)",
                  "tensor(uint16)",
                  "tensor(uint32)",
                  "tensor(uint64)",
                  "tensor(int8)",
                  "tensor(int16)",
                  "tensor(int32)",
                  "tensor(int64)",
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)",
                  "tensor(bfloat16)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "mul",
                "code": "node = onnx.helper.make_node(\n    \"Mul\",\n    inputs=[\"x\", \"y\"],\n    outputs=[\"z\"],\n)\n\nx = np.array([1, 2, 3]).astype(np.float32)\ny = np.array([4, 5, 6]).astype(np.float32)\nz = x * y  # expected output [4., 10., 18.]\nexpect(node, inputs=[x, y], outputs=[z], name=\"test_mul_example\")\n\nx = np.random.randn(3, 4, 5).astype(np.float32)\ny = np.random.randn(3, 4, 5).astype(np.float32)\nz = x * y\nexpect(node, inputs=[x, y], outputs=[z], name=\"test_mul\")\n\nx = np.random.randint(4, size=(3, 4, 5), dtype=np.int8)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.int8)\nz = x * y\nexpect(node, inputs=[x, y], outputs=[z], name=\"test_mul_int8\")\n\nx = np.random.randint(4, size=(3, 4, 5), dtype=np.int16)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.int16)\nz = x * y\nexpect(node, inputs=[x, y], outputs=[z], name=\"test_mul_int16\")\n\nx = np.random.randint(4, size=(3, 4, 5), dtype=np.uint8)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.uint8)\nz = x * y\nexpect(node, inputs=[x, y], outputs=[z], name=\"test_mul_uint8\")\n\nx = np.random.randint(4, size=(3, 4, 5), dtype=np.uint16)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.uint16)\nz = x * y\nexpect(node, inputs=[x, y], outputs=[z], name=\"test_mul_uint16\")\n\nx = np.random.randint(4, size=(3, 4, 5), dtype=np.uint32)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.uint32)\nz = x * y\nexpect(node, inputs=[x, y], outputs=[z], name=\"test_mul_uint32\")\n\nx = np.random.randint(4, size=(3, 4, 5), dtype=np.uint64)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.uint64)\nz = x * y\nexpect(node, inputs=[x, y], outputs=[z], name=\"test_mul_uint64\")"
              },
              {
                "summary": "mul_broadcast",
                "code": "node = onnx.helper.make_node(\n    \"Mul\",\n    inputs=[\"x\", \"y\"],\n    outputs=[\"z\"],\n)\n\nx = np.random.randn(3, 4, 5).astype(np.float32)\ny = np.random.randn(5).astype(np.float32)\nz = x * y\nexpect(node, inputs=[x, y], outputs=[z], name=\"test_mul_bcast\")"
              }
            ]
          }
        },
        {
          "name": "mul_21",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "A",
              "value": [
                {
                  "name": "Conv__230:0",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        96,
                        9,
                        16
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "B",
              "value": [
                {
                  "name": "mul_20:0",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        96,
                        9,
                        16
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "C",
              "value": [
                {
                  "name": "mul_21:0",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        96,
                        9,
                        16
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "Mul",
            "module": "ai.onnx",
            "version": 14,
            "description": "Performs element-wise binary multiplication (with Numpy-style broadcasting support).\n\nThis operator supports **multidirectional (i.e., Numpy-style) broadcasting**; for more details please check [the doc](https://github.com/onnx/onnx/blob/master/docs/Broadcasting.md).\n\n(Opset 14 change): Extend supported types to include uint8, int8, uint16, and int16.\n",
            "inputs": [
              {
                "name": "A",
                "type": "T",
                "description": "First operand."
              },
              {
                "name": "B",
                "type": "T",
                "description": "Second operand."
              }
            ],
            "min_input": 2,
            "max_input": 2,
            "outputs": [
              {
                "name": "C",
                "type": "T",
                "description": "Result, has same element type as two inputs"
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "type_constraints": [
              {
                "description": "Constrain input and output types to all numeric tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(uint8)",
                  "tensor(uint16)",
                  "tensor(uint32)",
                  "tensor(uint64)",
                  "tensor(int8)",
                  "tensor(int16)",
                  "tensor(int32)",
                  "tensor(int64)",
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)",
                  "tensor(bfloat16)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "mul",
                "code": "node = onnx.helper.make_node(\n    \"Mul\",\n    inputs=[\"x\", \"y\"],\n    outputs=[\"z\"],\n)\n\nx = np.array([1, 2, 3]).astype(np.float32)\ny = np.array([4, 5, 6]).astype(np.float32)\nz = x * y  # expected output [4., 10., 18.]\nexpect(node, inputs=[x, y], outputs=[z], name=\"test_mul_example\")\n\nx = np.random.randn(3, 4, 5).astype(np.float32)\ny = np.random.randn(3, 4, 5).astype(np.float32)\nz = x * y\nexpect(node, inputs=[x, y], outputs=[z], name=\"test_mul\")\n\nx = np.random.randint(4, size=(3, 4, 5), dtype=np.int8)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.int8)\nz = x * y\nexpect(node, inputs=[x, y], outputs=[z], name=\"test_mul_int8\")\n\nx = np.random.randint(4, size=(3, 4, 5), dtype=np.int16)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.int16)\nz = x * y\nexpect(node, inputs=[x, y], outputs=[z], name=\"test_mul_int16\")\n\nx = np.random.randint(4, size=(3, 4, 5), dtype=np.uint8)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.uint8)\nz = x * y\nexpect(node, inputs=[x, y], outputs=[z], name=\"test_mul_uint8\")\n\nx = np.random.randint(4, size=(3, 4, 5), dtype=np.uint16)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.uint16)\nz = x * y\nexpect(node, inputs=[x, y], outputs=[z], name=\"test_mul_uint16\")\n\nx = np.random.randint(4, size=(3, 4, 5), dtype=np.uint32)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.uint32)\nz = x * y\nexpect(node, inputs=[x, y], outputs=[z], name=\"test_mul_uint32\")\n\nx = np.random.randint(4, size=(3, 4, 5), dtype=np.uint64)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.uint64)\nz = x * y\nexpect(node, inputs=[x, y], outputs=[z], name=\"test_mul_uint64\")"
              },
              {
                "summary": "mul_broadcast",
                "code": "node = onnx.helper.make_node(\n    \"Mul\",\n    inputs=[\"x\", \"y\"],\n    outputs=[\"z\"],\n)\n\nx = np.random.randn(3, 4, 5).astype(np.float32)\ny = np.random.randn(5).astype(np.float32)\nz = x * y\nexpect(node, inputs=[x, y], outputs=[z], name=\"test_mul_bcast\")"
              }
            ]
          }
        },
        {
          "name": "global_average_pooling2d_5",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "X",
              "value": [
                {
                  "name": "mul_21:0",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        96,
                        9,
                        16
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "Y",
              "value": [
                {
                  "name": "global_average_pooling2d_5:0",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        96,
                        1,
                        1
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "GlobalAveragePool",
            "module": "ai.onnx",
            "version": 1,
            "description": "GlobalAveragePool consumes an input tensor X and applies average pooling across\n the values in the same channel. This is equivalent to AveragePool with kernel size\n equal to the spatial dimension of input tensor.",
            "inputs": [
              {
                "name": "X",
                "type": "T",
                "description": "Input data tensor from the previous operator; dimensions for image case are (N x C x H x W), where N is the batch size, C is the number of channels, and H and W are the height and the width of the data. For non image case, the dimensions are in the form of (N x C x D1 x D2 ... Dn), where N is the batch size."
              }
            ],
            "min_input": 1,
            "max_input": 1,
            "outputs": [
              {
                "name": "Y",
                "type": "T",
                "description": "Output data tensor from pooling across the input tensor. The output tensor has the same rank as the input. The first two dimensions of output shape are the same as the input (N x C), while the other dimensions are all 1."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "type_constraints": [
              {
                "description": "Constrain input and output types to float tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "globalaveragepool",
                "code": "node = onnx.helper.make_node(\n    \"GlobalAveragePool\",\n    inputs=[\"x\"],\n    outputs=[\"y\"],\n)\nx = np.random.randn(1, 3, 5, 5).astype(np.float32)\ny = np.mean(x, axis=tuple(range(2, np.ndim(x))), keepdims=True)\nexpect(node, inputs=[x], outputs=[y], name=\"test_globalaveragepool\")"
              },
              {
                "summary": "globalaveragepool_precomputed",
                "code": "node = onnx.helper.make_node(\n    \"GlobalAveragePool\",\n    inputs=[\"x\"],\n    outputs=[\"y\"],\n)\nx = np.array(\n    [\n        [\n            [\n                [1, 2, 3],\n                [4, 5, 6],\n                [7, 8, 9],\n            ]\n        ]\n    ]\n).astype(np.float32)\ny = np.array([[[[5]]]]).astype(np.float32)\nexpect(node, inputs=[x], outputs=[y], name=\"test_globalaveragepool_precomputed\")"
              }
            ],
            "category": "Pool"
          }
        },
        {
          "name": "Conv__233",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "X",
              "value": [
                {
                  "name": "global_average_pooling2d_5:0",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        96,
                        1,
                        1
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "W",
              "value": [
                {
                  "name": "Conv2D_27/filter:0",
                  "initializer": {
                    "name": "Conv2D_27/filter:0",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float32",
                      "shape": {
                        "dimensions": [
                          24,
                          96,
                          1,
                          1
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        24,
                        96,
                        1,
                        1
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "B",
              "value": [
                {
                  "name": "conv2d_26_1/y:0",
                  "initializer": {
                    "name": "conv2d_26_1/y:0",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float32",
                      "shape": {
                        "dimensions": [
                          24
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        24
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "Y",
              "value": [
                {
                  "name": "Conv__233:0",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        24,
                        1,
                        1
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [
            {
              "name": "dilations",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "strides",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "kernel_shape",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "group",
              "type": "int64",
              "value": {
                "type": "bigint",
                "value": "1"
              }
            }
          ],
          "type": {
            "name": "Conv",
            "module": "ai.onnx",
            "version": 11,
            "description": "The convolution operator consumes an input tensor and a filter, and\ncomputes the output.",
            "attributes": [
              {
                "name": "auto_pad",
                "type": "string",
                "required": false,
                "default": "NOTSET",
                "description": "auto_pad must be either NOTSET, SAME_UPPER, SAME_LOWER or VALID. Where default value is NOTSET, which means explicit padding is used. SAME_UPPER or SAME_LOWER mean pad the input so that `output_shape[i] = ceil(input_shape[i] / strides[i])` for each axis `i`. The padding is split between the two sides equally or almost equally (depending on whether it is even or odd). In case the padding is an odd number, the extra padding is added at the end for SAME_UPPER and at the beginning for SAME_LOWER."
              },
              {
                "name": "dilations",
                "type": "int64[]",
                "required": false,
                "description": "dilation value along each spatial axis of the filter. If not present, the dilation defaults is 1 along each spatial axis."
              },
              {
                "name": "group",
                "type": "int64",
                "required": false,
                "default": 1,
                "description": "number of groups input channels and output channels are divided into."
              },
              {
                "name": "kernel_shape",
                "type": "int64[]",
                "required": false,
                "description": "The shape of the convolution kernel. If not present, should be inferred from input W."
              },
              {
                "name": "pads",
                "type": "int64[]",
                "required": false,
                "description": "Padding for the beginning and ending along each spatial axis, it can take any value greater than or equal to 0. The value represent the number of pixels added to the beginning and end part of the corresponding axis. `pads` format should be as follow [x1_begin, x2_begin...x1_end, x2_end,...], where xi_begin the number of pixels added at the beginning of axis `i` and xi_end, the number of pixels added at the end of axis `i`. This attribute cannot be used simultaneously with auto_pad attribute. If not present, the padding defaults to 0 along start and end of each spatial axis."
              },
              {
                "name": "strides",
                "type": "int64[]",
                "required": false,
                "description": "Stride along each spatial axis. If not present, the stride defaults is 1 along each spatial axis."
              }
            ],
            "inputs": [
              {
                "name": "X",
                "type": "T",
                "description": "Input data tensor from previous layer; has size (N x C x H x W), where N is the batch size, C is the number of channels, and H and W are the height and width. Note that this is for the 2D image. Otherwise the size is (N x C x D1 x D2 ... x Dn). Optionally, if dimension denotation is in effect, the operation expects input data tensor to arrive with the dimension denotation of [DATA_BATCH, DATA_CHANNEL, DATA_FEATURE, DATA_FEATURE ...]."
              },
              {
                "name": "W",
                "type": "T",
                "description": "The weight tensor that will be used in the convolutions; has size (M x C/group x kH x kW), where C is the number of channels, and kH and kW are the height and width of the kernel, and M is the number of feature maps. For more than 2 dimensions, the kernel shape will be (M x C/group x k1 x k2 x ... x kn), where (k1 x k2 x ... kn) is the dimension of the kernel. Optionally, if dimension denotation is in effect, the operation expects the weight tensor to arrive with the dimension denotation of [FILTER_OUT_CHANNEL, FILTER_IN_CHANNEL, FILTER_SPATIAL, FILTER_SPATIAL ...]. Assuming zero based indices for the shape array, X.shape[1] == (W.shape[1] * group) == C and W.shape[0] mod G == 0. Or in other words FILTER_IN_CHANNEL multiplied by the number of groups should be equal to DATA_CHANNEL and the number of feature maps M should be a multiple of the number of groups G."
              },
              {
                "name": "B",
                "type": "T",
                "option": "optional",
                "description": "Optional 1D bias to be added to the convolution, has size of M."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "Y",
                "type": "T",
                "description": "Output data tensor that contains the result of the convolution. The output dimensions are functions of the kernel size, stride size, and pad lengths."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain input and output types to float tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "conv",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[1, 1, 1, 1],\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 21.0, 27.0, 33.0, 24.0],  # (1, 1, 5, 5) output tensor\n                [33.0, 54.0, 63.0, 72.0, 51.0],\n                [63.0, 99.0, 108.0, 117.0, 81.0],\n                [93.0, 144.0, 153.0, 162.0, 111.0],\n                [72.0, 111.0, 117.0, 123.0, 84.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_basic_conv_with_padding\",\n)\n\n# Convolution without padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[0, 0, 0, 0],\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 63.0, 72.0],  # (1, 1, 3, 3) output tensor\n                [99.0, 108.0, 117.0],\n                [144.0, 153.0, 162.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_basic_conv_without_padding\",\n)"
              },
              {
                "summary": "conv_with_autopad_same",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with auto_pad='SAME_LOWER' and strides=2\nnode = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    auto_pad=\"SAME_LOWER\",\n    kernel_shape=[3, 3],\n    strides=[2, 2],\n)\ny = np.array(\n    [[[[12.0, 27.0, 24.0], [63.0, 108.0, 81.0], [72.0, 117.0, 84.0]]]]\n).astype(np.float32)\nexpect(node, inputs=[x, W], outputs=[y], name=\"test_conv_with_autopad_same\")"
              },
              {
                "summary": "conv_with_strides",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 7, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n                [25.0, 26.0, 27.0, 28.0, 29.0],\n                [30.0, 31.0, 32.0, 33.0, 34.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with strides=2 and padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 1, 1, 1],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 27.0, 24.0],  # (1, 1, 4, 3) output tensor\n                [63.0, 108.0, 81.0],\n                [123.0, 198.0, 141.0],\n                [112.0, 177.0, 124.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_conv_with_strides_padding\",\n)\n\n# Convolution with strides=2 and no padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[0, 0, 0, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 72.0],  # (1, 1, 3, 2) output tensor\n                [144.0, 162.0],\n                [234.0, 252.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_conv_with_strides_no_padding\",\n)\n\n# Convolution with strides=2 and padding only along one dimension (the H dimension in NxCxHxW tensor)\nnode_with_asymmetric_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 0, 1, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_asymmetric_padding = np.array(\n    [\n        [\n            [\n                [21.0, 33.0],  # (1, 1, 4, 2) output tensor\n                [99.0, 117.0],\n                [189.0, 207.0],\n                [171.0, 183.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_asymmetric_padding,\n    inputs=[x, W],\n    outputs=[y_with_asymmetric_padding],\n    name=\"test_conv_with_strides_and_asymmetric_padding\",\n)"
              }
            ],
            "category": "Layer"
          }
        },
        {
          "name": "re_lu_11",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "X",
              "value": [
                {
                  "name": "Conv__233:0",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        24,
                        1,
                        1
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "Y",
              "value": [
                {
                  "name": "re_lu_11:0",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        24,
                        1,
                        1
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "Relu",
            "module": "ai.onnx",
            "version": 14,
            "description": "Relu takes one input data (Tensor<T>) and produces one output data\n(Tensor<T>) where the rectified linear function, y = max(0, x), is applied to\nthe tensor elementwise.\n",
            "inputs": [
              {
                "name": "X",
                "type": "T",
                "description": "Input tensor"
              }
            ],
            "min_input": 1,
            "max_input": 1,
            "outputs": [
              {
                "name": "Y",
                "type": "T",
                "description": "Output tensor"
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "type_constraints": [
              {
                "description": "Constrain input and output types to signed numeric tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(float)",
                  "tensor(int32)",
                  "tensor(int8)",
                  "tensor(int16)",
                  "tensor(int64)",
                  "tensor(float16)",
                  "tensor(double)",
                  "tensor(bfloat16)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "relu",
                "code": "node = onnx.helper.make_node(\n    \"Relu\",\n    inputs=[\"x\"],\n    outputs=[\"y\"],\n)\nx = np.random.randn(3, 4, 5).astype(np.float32)\ny = np.clip(x, 0, np.inf)\n\nexpect(node, inputs=[x], outputs=[y], name=\"test_relu\")"
              }
            ],
            "category": "Activation"
          }
        },
        {
          "name": "Conv__234",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "X",
              "value": [
                {
                  "name": "re_lu_11:0",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        24,
                        1,
                        1
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "W",
              "value": [
                {
                  "name": "Conv2D_28/filter:0",
                  "initializer": {
                    "name": "Conv2D_28/filter:0",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float32",
                      "shape": {
                        "dimensions": [
                          96,
                          24,
                          1,
                          1
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        96,
                        24,
                        1,
                        1
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "B",
              "value": [
                {
                  "name": "conv2d_27_1/y:0",
                  "initializer": {
                    "name": "conv2d_27_1/y:0",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float32",
                      "shape": {
                        "dimensions": [
                          96
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        96
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "Y",
              "value": [
                {
                  "name": "Conv__234:0",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        96,
                        1,
                        1
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [
            {
              "name": "dilations",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "strides",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "kernel_shape",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "group",
              "type": "int64",
              "value": {
                "type": "bigint",
                "value": "1"
              }
            }
          ],
          "type": {
            "name": "Conv",
            "module": "ai.onnx",
            "version": 11,
            "description": "The convolution operator consumes an input tensor and a filter, and\ncomputes the output.",
            "attributes": [
              {
                "name": "auto_pad",
                "type": "string",
                "required": false,
                "default": "NOTSET",
                "description": "auto_pad must be either NOTSET, SAME_UPPER, SAME_LOWER or VALID. Where default value is NOTSET, which means explicit padding is used. SAME_UPPER or SAME_LOWER mean pad the input so that `output_shape[i] = ceil(input_shape[i] / strides[i])` for each axis `i`. The padding is split between the two sides equally or almost equally (depending on whether it is even or odd). In case the padding is an odd number, the extra padding is added at the end for SAME_UPPER and at the beginning for SAME_LOWER."
              },
              {
                "name": "dilations",
                "type": "int64[]",
                "required": false,
                "description": "dilation value along each spatial axis of the filter. If not present, the dilation defaults is 1 along each spatial axis."
              },
              {
                "name": "group",
                "type": "int64",
                "required": false,
                "default": 1,
                "description": "number of groups input channels and output channels are divided into."
              },
              {
                "name": "kernel_shape",
                "type": "int64[]",
                "required": false,
                "description": "The shape of the convolution kernel. If not present, should be inferred from input W."
              },
              {
                "name": "pads",
                "type": "int64[]",
                "required": false,
                "description": "Padding for the beginning and ending along each spatial axis, it can take any value greater than or equal to 0. The value represent the number of pixels added to the beginning and end part of the corresponding axis. `pads` format should be as follow [x1_begin, x2_begin...x1_end, x2_end,...], where xi_begin the number of pixels added at the beginning of axis `i` and xi_end, the number of pixels added at the end of axis `i`. This attribute cannot be used simultaneously with auto_pad attribute. If not present, the padding defaults to 0 along start and end of each spatial axis."
              },
              {
                "name": "strides",
                "type": "int64[]",
                "required": false,
                "description": "Stride along each spatial axis. If not present, the stride defaults is 1 along each spatial axis."
              }
            ],
            "inputs": [
              {
                "name": "X",
                "type": "T",
                "description": "Input data tensor from previous layer; has size (N x C x H x W), where N is the batch size, C is the number of channels, and H and W are the height and width. Note that this is for the 2D image. Otherwise the size is (N x C x D1 x D2 ... x Dn). Optionally, if dimension denotation is in effect, the operation expects input data tensor to arrive with the dimension denotation of [DATA_BATCH, DATA_CHANNEL, DATA_FEATURE, DATA_FEATURE ...]."
              },
              {
                "name": "W",
                "type": "T",
                "description": "The weight tensor that will be used in the convolutions; has size (M x C/group x kH x kW), where C is the number of channels, and kH and kW are the height and width of the kernel, and M is the number of feature maps. For more than 2 dimensions, the kernel shape will be (M x C/group x k1 x k2 x ... x kn), where (k1 x k2 x ... kn) is the dimension of the kernel. Optionally, if dimension denotation is in effect, the operation expects the weight tensor to arrive with the dimension denotation of [FILTER_OUT_CHANNEL, FILTER_IN_CHANNEL, FILTER_SPATIAL, FILTER_SPATIAL ...]. Assuming zero based indices for the shape array, X.shape[1] == (W.shape[1] * group) == C and W.shape[0] mod G == 0. Or in other words FILTER_IN_CHANNEL multiplied by the number of groups should be equal to DATA_CHANNEL and the number of feature maps M should be a multiple of the number of groups G."
              },
              {
                "name": "B",
                "type": "T",
                "option": "optional",
                "description": "Optional 1D bias to be added to the convolution, has size of M."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "Y",
                "type": "T",
                "description": "Output data tensor that contains the result of the convolution. The output dimensions are functions of the kernel size, stride size, and pad lengths."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain input and output types to float tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "conv",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[1, 1, 1, 1],\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 21.0, 27.0, 33.0, 24.0],  # (1, 1, 5, 5) output tensor\n                [33.0, 54.0, 63.0, 72.0, 51.0],\n                [63.0, 99.0, 108.0, 117.0, 81.0],\n                [93.0, 144.0, 153.0, 162.0, 111.0],\n                [72.0, 111.0, 117.0, 123.0, 84.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_basic_conv_with_padding\",\n)\n\n# Convolution without padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[0, 0, 0, 0],\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 63.0, 72.0],  # (1, 1, 3, 3) output tensor\n                [99.0, 108.0, 117.0],\n                [144.0, 153.0, 162.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_basic_conv_without_padding\",\n)"
              },
              {
                "summary": "conv_with_autopad_same",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with auto_pad='SAME_LOWER' and strides=2\nnode = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    auto_pad=\"SAME_LOWER\",\n    kernel_shape=[3, 3],\n    strides=[2, 2],\n)\ny = np.array(\n    [[[[12.0, 27.0, 24.0], [63.0, 108.0, 81.0], [72.0, 117.0, 84.0]]]]\n).astype(np.float32)\nexpect(node, inputs=[x, W], outputs=[y], name=\"test_conv_with_autopad_same\")"
              },
              {
                "summary": "conv_with_strides",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 7, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n                [25.0, 26.0, 27.0, 28.0, 29.0],\n                [30.0, 31.0, 32.0, 33.0, 34.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with strides=2 and padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 1, 1, 1],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 27.0, 24.0],  # (1, 1, 4, 3) output tensor\n                [63.0, 108.0, 81.0],\n                [123.0, 198.0, 141.0],\n                [112.0, 177.0, 124.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_conv_with_strides_padding\",\n)\n\n# Convolution with strides=2 and no padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[0, 0, 0, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 72.0],  # (1, 1, 3, 2) output tensor\n                [144.0, 162.0],\n                [234.0, 252.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_conv_with_strides_no_padding\",\n)\n\n# Convolution with strides=2 and padding only along one dimension (the H dimension in NxCxHxW tensor)\nnode_with_asymmetric_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 0, 1, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_asymmetric_padding = np.array(\n    [\n        [\n            [\n                [21.0, 33.0],  # (1, 1, 4, 2) output tensor\n                [99.0, 117.0],\n                [189.0, 207.0],\n                [171.0, 183.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_asymmetric_padding,\n    inputs=[x, W],\n    outputs=[y_with_asymmetric_padding],\n    name=\"test_conv_with_strides_and_asymmetric_padding\",\n)"
              }
            ],
            "category": "Layer"
          }
        },
        {
          "name": "activation_5",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "X",
              "value": [
                {
                  "name": "Conv__234:0",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        96,
                        1,
                        1
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "Y",
              "value": [
                {
                  "name": "activation_5:0",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        96,
                        1,
                        1
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "Sigmoid",
            "module": "ai.onnx",
            "version": 13,
            "description": "Sigmoid takes one input data (Tensor<T>) and produces one output data\n(Tensor<T>) where the sigmoid function, y = 1 / (1 + exp(-x)), is applied to the\ntensor elementwise.\n",
            "inputs": [
              {
                "name": "X",
                "type": "T",
                "description": "Input tensor"
              }
            ],
            "min_input": 1,
            "max_input": 1,
            "outputs": [
              {
                "name": "Y",
                "type": "T",
                "description": "Output tensor"
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "type_constraints": [
              {
                "description": "Constrain input and output types to float tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)",
                  "tensor(bfloat16)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "sigmoid",
                "code": "node = onnx.helper.make_node(\n    \"Sigmoid\",\n    inputs=[\"x\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([-1, 0, 1]).astype(np.float32)\ny = 1.0 / (\n    1.0 + np.exp(np.negative(x))\n)  # expected output [0.26894143, 0.5, 0.7310586]\nexpect(node, inputs=[x], outputs=[y], name=\"test_sigmoid_example\")\n\nx = np.random.randn(3, 4, 5).astype(np.float32)\ny = 1.0 / (1.0 + np.exp(np.negative(x)))\nexpect(node, inputs=[x], outputs=[y], name=\"test_sigmoid\")"
              }
            ],
            "category": "Activation"
          }
        },
        {
          "name": "multiply_5",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "A",
              "value": [
                {
                  "name": "mul_21:0",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        96,
                        9,
                        16
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "B",
              "value": [
                {
                  "name": "activation_5:0",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        96,
                        1,
                        1
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "C",
              "value": [
                {
                  "name": "multiply_5:0",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        96,
                        9,
                        16
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "Mul",
            "module": "ai.onnx",
            "version": 14,
            "description": "Performs element-wise binary multiplication (with Numpy-style broadcasting support).\n\nThis operator supports **multidirectional (i.e., Numpy-style) broadcasting**; for more details please check [the doc](https://github.com/onnx/onnx/blob/master/docs/Broadcasting.md).\n\n(Opset 14 change): Extend supported types to include uint8, int8, uint16, and int16.\n",
            "inputs": [
              {
                "name": "A",
                "type": "T",
                "description": "First operand."
              },
              {
                "name": "B",
                "type": "T",
                "description": "Second operand."
              }
            ],
            "min_input": 2,
            "max_input": 2,
            "outputs": [
              {
                "name": "C",
                "type": "T",
                "description": "Result, has same element type as two inputs"
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "type_constraints": [
              {
                "description": "Constrain input and output types to all numeric tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(uint8)",
                  "tensor(uint16)",
                  "tensor(uint32)",
                  "tensor(uint64)",
                  "tensor(int8)",
                  "tensor(int16)",
                  "tensor(int32)",
                  "tensor(int64)",
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)",
                  "tensor(bfloat16)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "mul",
                "code": "node = onnx.helper.make_node(\n    \"Mul\",\n    inputs=[\"x\", \"y\"],\n    outputs=[\"z\"],\n)\n\nx = np.array([1, 2, 3]).astype(np.float32)\ny = np.array([4, 5, 6]).astype(np.float32)\nz = x * y  # expected output [4., 10., 18.]\nexpect(node, inputs=[x, y], outputs=[z], name=\"test_mul_example\")\n\nx = np.random.randn(3, 4, 5).astype(np.float32)\ny = np.random.randn(3, 4, 5).astype(np.float32)\nz = x * y\nexpect(node, inputs=[x, y], outputs=[z], name=\"test_mul\")\n\nx = np.random.randint(4, size=(3, 4, 5), dtype=np.int8)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.int8)\nz = x * y\nexpect(node, inputs=[x, y], outputs=[z], name=\"test_mul_int8\")\n\nx = np.random.randint(4, size=(3, 4, 5), dtype=np.int16)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.int16)\nz = x * y\nexpect(node, inputs=[x, y], outputs=[z], name=\"test_mul_int16\")\n\nx = np.random.randint(4, size=(3, 4, 5), dtype=np.uint8)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.uint8)\nz = x * y\nexpect(node, inputs=[x, y], outputs=[z], name=\"test_mul_uint8\")\n\nx = np.random.randint(4, size=(3, 4, 5), dtype=np.uint16)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.uint16)\nz = x * y\nexpect(node, inputs=[x, y], outputs=[z], name=\"test_mul_uint16\")\n\nx = np.random.randint(4, size=(3, 4, 5), dtype=np.uint32)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.uint32)\nz = x * y\nexpect(node, inputs=[x, y], outputs=[z], name=\"test_mul_uint32\")\n\nx = np.random.randint(4, size=(3, 4, 5), dtype=np.uint64)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.uint64)\nz = x * y\nexpect(node, inputs=[x, y], outputs=[z], name=\"test_mul_uint64\")"
              },
              {
                "summary": "mul_broadcast",
                "code": "node = onnx.helper.make_node(\n    \"Mul\",\n    inputs=[\"x\", \"y\"],\n    outputs=[\"z\"],\n)\n\nx = np.random.randn(3, 4, 5).astype(np.float32)\ny = np.random.randn(5).astype(np.float32)\nz = x * y\nexpect(node, inputs=[x, y], outputs=[z], name=\"test_mul_bcast\")"
              }
            ]
          }
        },
        {
          "name": "Conv__235",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "X",
              "value": [
                {
                  "name": "multiply_5:0",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        96,
                        9,
                        16
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "W",
              "value": [
                {
                  "name": "Conv2D_29/filter:0",
                  "initializer": {
                    "name": "Conv2D_29/filter:0",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float32",
                      "shape": {
                        "dimensions": [
                          32,
                          96,
                          1,
                          1
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        32,
                        96,
                        1,
                        1
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "B",
              "value": [
                {
                  "name": "conv2d_28_1/y:0",
                  "initializer": {
                    "name": "conv2d_28_1/y:0",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float32",
                      "shape": {
                        "dimensions": [
                          32
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        32
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "Y",
              "value": [
                {
                  "name": "Conv__235:0",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        32,
                        9,
                        16
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [
            {
              "name": "dilations",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "strides",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "kernel_shape",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "pads",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "0",
                  "0",
                  "0",
                  "0"
                ]
              }
            },
            {
              "name": "group",
              "type": "int64",
              "value": {
                "type": "bigint",
                "value": "1"
              }
            }
          ],
          "type": {
            "name": "Conv",
            "module": "ai.onnx",
            "version": 11,
            "description": "The convolution operator consumes an input tensor and a filter, and\ncomputes the output.",
            "attributes": [
              {
                "name": "auto_pad",
                "type": "string",
                "required": false,
                "default": "NOTSET",
                "description": "auto_pad must be either NOTSET, SAME_UPPER, SAME_LOWER or VALID. Where default value is NOTSET, which means explicit padding is used. SAME_UPPER or SAME_LOWER mean pad the input so that `output_shape[i] = ceil(input_shape[i] / strides[i])` for each axis `i`. The padding is split between the two sides equally or almost equally (depending on whether it is even or odd). In case the padding is an odd number, the extra padding is added at the end for SAME_UPPER and at the beginning for SAME_LOWER."
              },
              {
                "name": "dilations",
                "type": "int64[]",
                "required": false,
                "description": "dilation value along each spatial axis of the filter. If not present, the dilation defaults is 1 along each spatial axis."
              },
              {
                "name": "group",
                "type": "int64",
                "required": false,
                "default": 1,
                "description": "number of groups input channels and output channels are divided into."
              },
              {
                "name": "kernel_shape",
                "type": "int64[]",
                "required": false,
                "description": "The shape of the convolution kernel. If not present, should be inferred from input W."
              },
              {
                "name": "pads",
                "type": "int64[]",
                "required": false,
                "description": "Padding for the beginning and ending along each spatial axis, it can take any value greater than or equal to 0. The value represent the number of pixels added to the beginning and end part of the corresponding axis. `pads` format should be as follow [x1_begin, x2_begin...x1_end, x2_end,...], where xi_begin the number of pixels added at the beginning of axis `i` and xi_end, the number of pixels added at the end of axis `i`. This attribute cannot be used simultaneously with auto_pad attribute. If not present, the padding defaults to 0 along start and end of each spatial axis."
              },
              {
                "name": "strides",
                "type": "int64[]",
                "required": false,
                "description": "Stride along each spatial axis. If not present, the stride defaults is 1 along each spatial axis."
              }
            ],
            "inputs": [
              {
                "name": "X",
                "type": "T",
                "description": "Input data tensor from previous layer; has size (N x C x H x W), where N is the batch size, C is the number of channels, and H and W are the height and width. Note that this is for the 2D image. Otherwise the size is (N x C x D1 x D2 ... x Dn). Optionally, if dimension denotation is in effect, the operation expects input data tensor to arrive with the dimension denotation of [DATA_BATCH, DATA_CHANNEL, DATA_FEATURE, DATA_FEATURE ...]."
              },
              {
                "name": "W",
                "type": "T",
                "description": "The weight tensor that will be used in the convolutions; has size (M x C/group x kH x kW), where C is the number of channels, and kH and kW are the height and width of the kernel, and M is the number of feature maps. For more than 2 dimensions, the kernel shape will be (M x C/group x k1 x k2 x ... x kn), where (k1 x k2 x ... kn) is the dimension of the kernel. Optionally, if dimension denotation is in effect, the operation expects the weight tensor to arrive with the dimension denotation of [FILTER_OUT_CHANNEL, FILTER_IN_CHANNEL, FILTER_SPATIAL, FILTER_SPATIAL ...]. Assuming zero based indices for the shape array, X.shape[1] == (W.shape[1] * group) == C and W.shape[0] mod G == 0. Or in other words FILTER_IN_CHANNEL multiplied by the number of groups should be equal to DATA_CHANNEL and the number of feature maps M should be a multiple of the number of groups G."
              },
              {
                "name": "B",
                "type": "T",
                "option": "optional",
                "description": "Optional 1D bias to be added to the convolution, has size of M."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "Y",
                "type": "T",
                "description": "Output data tensor that contains the result of the convolution. The output dimensions are functions of the kernel size, stride size, and pad lengths."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain input and output types to float tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "conv",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[1, 1, 1, 1],\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 21.0, 27.0, 33.0, 24.0],  # (1, 1, 5, 5) output tensor\n                [33.0, 54.0, 63.0, 72.0, 51.0],\n                [63.0, 99.0, 108.0, 117.0, 81.0],\n                [93.0, 144.0, 153.0, 162.0, 111.0],\n                [72.0, 111.0, 117.0, 123.0, 84.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_basic_conv_with_padding\",\n)\n\n# Convolution without padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[0, 0, 0, 0],\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 63.0, 72.0],  # (1, 1, 3, 3) output tensor\n                [99.0, 108.0, 117.0],\n                [144.0, 153.0, 162.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_basic_conv_without_padding\",\n)"
              },
              {
                "summary": "conv_with_autopad_same",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with auto_pad='SAME_LOWER' and strides=2\nnode = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    auto_pad=\"SAME_LOWER\",\n    kernel_shape=[3, 3],\n    strides=[2, 2],\n)\ny = np.array(\n    [[[[12.0, 27.0, 24.0], [63.0, 108.0, 81.0], [72.0, 117.0, 84.0]]]]\n).astype(np.float32)\nexpect(node, inputs=[x, W], outputs=[y], name=\"test_conv_with_autopad_same\")"
              },
              {
                "summary": "conv_with_strides",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 7, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n                [25.0, 26.0, 27.0, 28.0, 29.0],\n                [30.0, 31.0, 32.0, 33.0, 34.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with strides=2 and padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 1, 1, 1],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 27.0, 24.0],  # (1, 1, 4, 3) output tensor\n                [63.0, 108.0, 81.0],\n                [123.0, 198.0, 141.0],\n                [112.0, 177.0, 124.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_conv_with_strides_padding\",\n)\n\n# Convolution with strides=2 and no padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[0, 0, 0, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 72.0],  # (1, 1, 3, 2) output tensor\n                [144.0, 162.0],\n                [234.0, 252.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_conv_with_strides_no_padding\",\n)\n\n# Convolution with strides=2 and padding only along one dimension (the H dimension in NxCxHxW tensor)\nnode_with_asymmetric_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 0, 1, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_asymmetric_padding = np.array(\n    [\n        [\n            [\n                [21.0, 33.0],  # (1, 1, 4, 2) output tensor\n                [99.0, 117.0],\n                [189.0, 207.0],\n                [171.0, 183.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_asymmetric_padding,\n    inputs=[x, W],\n    outputs=[y_with_asymmetric_padding],\n    name=\"test_conv_with_strides_and_asymmetric_padding\",\n)"
              }
            ],
            "category": "Layer"
          }
        },
        {
          "name": "add_4__xeno_compat__1",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "A",
              "value": [
                {
                  "name": "Conv__235:0",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        32,
                        9,
                        16
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "B",
              "value": [
                {
                  "name": "add_3__xeno_compat__1:0",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        32,
                        9,
                        16
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "C",
              "value": [
                {
                  "name": "add_4__xeno_compat__1:0",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        32,
                        9,
                        16
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "Add",
            "module": "ai.onnx",
            "version": 14,
            "description": "Performs element-wise binary addition (with Numpy-style broadcasting support).\n\nThis operator supports **multidirectional (i.e., Numpy-style) broadcasting**; for more details please check [the doc](https://github.com/onnx/onnx/blob/master/docs/Broadcasting.md).\n\n(Opset 14 change): Extend supported types to include uint8, int8, uint16, and int16.\n",
            "inputs": [
              {
                "name": "A",
                "type": "T",
                "description": "First operand."
              },
              {
                "name": "B",
                "type": "T",
                "description": "Second operand."
              }
            ],
            "min_input": 2,
            "max_input": 2,
            "outputs": [
              {
                "name": "C",
                "type": "T",
                "description": "Result, has same element type as two inputs"
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "type_constraints": [
              {
                "description": "Constrain input and output types to all numeric tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(uint8)",
                  "tensor(uint16)",
                  "tensor(uint32)",
                  "tensor(uint64)",
                  "tensor(int8)",
                  "tensor(int16)",
                  "tensor(int32)",
                  "tensor(int64)",
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)",
                  "tensor(bfloat16)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "add",
                "code": "node = onnx.helper.make_node(\n    \"Add\",\n    inputs=[\"x\", \"y\"],\n    outputs=[\"sum\"],\n)\n\nx = np.random.randn(3, 4, 5).astype(np.float32)\ny = np.random.randn(3, 4, 5).astype(np.float32)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add\")\n\nx = np.random.randint(24, size=(3, 4, 5), dtype=np.int8)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.int8)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add_int8\")\n\nx = np.random.randint(24, size=(3, 4, 5), dtype=np.int16)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.int16)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add_int16\")\n\nx = np.random.randint(24, size=(3, 4, 5), dtype=np.uint8)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.uint8)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add_uint8\")\n\nx = np.random.randint(24, size=(3, 4, 5), dtype=np.uint16)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.uint16)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add_uint16\")\n\nx = np.random.randint(24, size=(3, 4, 5), dtype=np.uint32)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.uint32)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add_uint32\")\n\nx = np.random.randint(24, size=(3, 4, 5), dtype=np.uint64)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.uint64)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add_uint64\")"
              },
              {
                "summary": "add_broadcast",
                "code": "node = onnx.helper.make_node(\n    \"Add\",\n    inputs=[\"x\", \"y\"],\n    outputs=[\"sum\"],\n)\n\nx = np.random.randn(3, 4, 5).astype(np.float32)\ny = np.random.randn(5).astype(np.float32)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add_bcast\")"
              }
            ]
          }
        },
        {
          "name": "global_average_pooling2d_6",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "X",
              "value": [
                {
                  "name": "add_4__xeno_compat__1:0",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        32,
                        9,
                        16
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "Y",
              "value": [
                {
                  "name": "global_average_pooling2d_6:0",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        32,
                        1,
                        1
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "GlobalAveragePool",
            "module": "ai.onnx",
            "version": 1,
            "description": "GlobalAveragePool consumes an input tensor X and applies average pooling across\n the values in the same channel. This is equivalent to AveragePool with kernel size\n equal to the spatial dimension of input tensor.",
            "inputs": [
              {
                "name": "X",
                "type": "T",
                "description": "Input data tensor from the previous operator; dimensions for image case are (N x C x H x W), where N is the batch size, C is the number of channels, and H and W are the height and the width of the data. For non image case, the dimensions are in the form of (N x C x D1 x D2 ... Dn), where N is the batch size."
              }
            ],
            "min_input": 1,
            "max_input": 1,
            "outputs": [
              {
                "name": "Y",
                "type": "T",
                "description": "Output data tensor from pooling across the input tensor. The output tensor has the same rank as the input. The first two dimensions of output shape are the same as the input (N x C), while the other dimensions are all 1."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "type_constraints": [
              {
                "description": "Constrain input and output types to float tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "globalaveragepool",
                "code": "node = onnx.helper.make_node(\n    \"GlobalAveragePool\",\n    inputs=[\"x\"],\n    outputs=[\"y\"],\n)\nx = np.random.randn(1, 3, 5, 5).astype(np.float32)\ny = np.mean(x, axis=tuple(range(2, np.ndim(x))), keepdims=True)\nexpect(node, inputs=[x], outputs=[y], name=\"test_globalaveragepool\")"
              },
              {
                "summary": "globalaveragepool_precomputed",
                "code": "node = onnx.helper.make_node(\n    \"GlobalAveragePool\",\n    inputs=[\"x\"],\n    outputs=[\"y\"],\n)\nx = np.array(\n    [\n        [\n            [\n                [1, 2, 3],\n                [4, 5, 6],\n                [7, 8, 9],\n            ]\n        ]\n    ]\n).astype(np.float32)\ny = np.array([[[[5]]]]).astype(np.float32)\nexpect(node, inputs=[x], outputs=[y], name=\"test_globalaveragepool_precomputed\")"
              }
            ],
            "category": "Pool"
          }
        },
        {
          "name": "Conv__238",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "X",
              "value": [
                {
                  "name": "global_average_pooling2d_6:0",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        32,
                        1,
                        1
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "W",
              "value": [
                {
                  "name": "Conv2D_31/filter:0",
                  "initializer": {
                    "name": "Conv2D_31/filter:0",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float32",
                      "shape": {
                        "dimensions": [
                          128,
                          32,
                          1,
                          1
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        128,
                        32,
                        1,
                        1
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "B",
              "value": [
                {
                  "name": "conv2d_30_1/y:0",
                  "initializer": {
                    "name": "conv2d_30_1/y:0",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float32",
                      "shape": {
                        "dimensions": [
                          128
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        128
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "Y",
              "value": [
                {
                  "name": "Conv__238:0",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        128,
                        1,
                        1
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [
            {
              "name": "dilations",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "strides",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "kernel_shape",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "group",
              "type": "int64",
              "value": {
                "type": "bigint",
                "value": "1"
              }
            }
          ],
          "type": {
            "name": "Conv",
            "module": "ai.onnx",
            "version": 11,
            "description": "The convolution operator consumes an input tensor and a filter, and\ncomputes the output.",
            "attributes": [
              {
                "name": "auto_pad",
                "type": "string",
                "required": false,
                "default": "NOTSET",
                "description": "auto_pad must be either NOTSET, SAME_UPPER, SAME_LOWER or VALID. Where default value is NOTSET, which means explicit padding is used. SAME_UPPER or SAME_LOWER mean pad the input so that `output_shape[i] = ceil(input_shape[i] / strides[i])` for each axis `i`. The padding is split between the two sides equally or almost equally (depending on whether it is even or odd). In case the padding is an odd number, the extra padding is added at the end for SAME_UPPER and at the beginning for SAME_LOWER."
              },
              {
                "name": "dilations",
                "type": "int64[]",
                "required": false,
                "description": "dilation value along each spatial axis of the filter. If not present, the dilation defaults is 1 along each spatial axis."
              },
              {
                "name": "group",
                "type": "int64",
                "required": false,
                "default": 1,
                "description": "number of groups input channels and output channels are divided into."
              },
              {
                "name": "kernel_shape",
                "type": "int64[]",
                "required": false,
                "description": "The shape of the convolution kernel. If not present, should be inferred from input W."
              },
              {
                "name": "pads",
                "type": "int64[]",
                "required": false,
                "description": "Padding for the beginning and ending along each spatial axis, it can take any value greater than or equal to 0. The value represent the number of pixels added to the beginning and end part of the corresponding axis. `pads` format should be as follow [x1_begin, x2_begin...x1_end, x2_end,...], where xi_begin the number of pixels added at the beginning of axis `i` and xi_end, the number of pixels added at the end of axis `i`. This attribute cannot be used simultaneously with auto_pad attribute. If not present, the padding defaults to 0 along start and end of each spatial axis."
              },
              {
                "name": "strides",
                "type": "int64[]",
                "required": false,
                "description": "Stride along each spatial axis. If not present, the stride defaults is 1 along each spatial axis."
              }
            ],
            "inputs": [
              {
                "name": "X",
                "type": "T",
                "description": "Input data tensor from previous layer; has size (N x C x H x W), where N is the batch size, C is the number of channels, and H and W are the height and width. Note that this is for the 2D image. Otherwise the size is (N x C x D1 x D2 ... x Dn). Optionally, if dimension denotation is in effect, the operation expects input data tensor to arrive with the dimension denotation of [DATA_BATCH, DATA_CHANNEL, DATA_FEATURE, DATA_FEATURE ...]."
              },
              {
                "name": "W",
                "type": "T",
                "description": "The weight tensor that will be used in the convolutions; has size (M x C/group x kH x kW), where C is the number of channels, and kH and kW are the height and width of the kernel, and M is the number of feature maps. For more than 2 dimensions, the kernel shape will be (M x C/group x k1 x k2 x ... x kn), where (k1 x k2 x ... kn) is the dimension of the kernel. Optionally, if dimension denotation is in effect, the operation expects the weight tensor to arrive with the dimension denotation of [FILTER_OUT_CHANNEL, FILTER_IN_CHANNEL, FILTER_SPATIAL, FILTER_SPATIAL ...]. Assuming zero based indices for the shape array, X.shape[1] == (W.shape[1] * group) == C and W.shape[0] mod G == 0. Or in other words FILTER_IN_CHANNEL multiplied by the number of groups should be equal to DATA_CHANNEL and the number of feature maps M should be a multiple of the number of groups G."
              },
              {
                "name": "B",
                "type": "T",
                "option": "optional",
                "description": "Optional 1D bias to be added to the convolution, has size of M."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "Y",
                "type": "T",
                "description": "Output data tensor that contains the result of the convolution. The output dimensions are functions of the kernel size, stride size, and pad lengths."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain input and output types to float tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "conv",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[1, 1, 1, 1],\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 21.0, 27.0, 33.0, 24.0],  # (1, 1, 5, 5) output tensor\n                [33.0, 54.0, 63.0, 72.0, 51.0],\n                [63.0, 99.0, 108.0, 117.0, 81.0],\n                [93.0, 144.0, 153.0, 162.0, 111.0],\n                [72.0, 111.0, 117.0, 123.0, 84.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_basic_conv_with_padding\",\n)\n\n# Convolution without padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[0, 0, 0, 0],\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 63.0, 72.0],  # (1, 1, 3, 3) output tensor\n                [99.0, 108.0, 117.0],\n                [144.0, 153.0, 162.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_basic_conv_without_padding\",\n)"
              },
              {
                "summary": "conv_with_autopad_same",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with auto_pad='SAME_LOWER' and strides=2\nnode = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    auto_pad=\"SAME_LOWER\",\n    kernel_shape=[3, 3],\n    strides=[2, 2],\n)\ny = np.array(\n    [[[[12.0, 27.0, 24.0], [63.0, 108.0, 81.0], [72.0, 117.0, 84.0]]]]\n).astype(np.float32)\nexpect(node, inputs=[x, W], outputs=[y], name=\"test_conv_with_autopad_same\")"
              },
              {
                "summary": "conv_with_strides",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 7, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n                [25.0, 26.0, 27.0, 28.0, 29.0],\n                [30.0, 31.0, 32.0, 33.0, 34.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with strides=2 and padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 1, 1, 1],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 27.0, 24.0],  # (1, 1, 4, 3) output tensor\n                [63.0, 108.0, 81.0],\n                [123.0, 198.0, 141.0],\n                [112.0, 177.0, 124.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_conv_with_strides_padding\",\n)\n\n# Convolution with strides=2 and no padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[0, 0, 0, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 72.0],  # (1, 1, 3, 2) output tensor\n                [144.0, 162.0],\n                [234.0, 252.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_conv_with_strides_no_padding\",\n)\n\n# Convolution with strides=2 and padding only along one dimension (the H dimension in NxCxHxW tensor)\nnode_with_asymmetric_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 0, 1, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_asymmetric_padding = np.array(\n    [\n        [\n            [\n                [21.0, 33.0],  # (1, 1, 4, 2) output tensor\n                [99.0, 117.0],\n                [189.0, 207.0],\n                [171.0, 183.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_asymmetric_padding,\n    inputs=[x, W],\n    outputs=[y_with_asymmetric_padding],\n    name=\"test_conv_with_strides_and_asymmetric_padding\",\n)"
              }
            ],
            "category": "Layer"
          }
        },
        {
          "name": "activation_6",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "X",
              "value": [
                {
                  "name": "Conv__238:0",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        128,
                        1,
                        1
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "Y",
              "value": [
                {
                  "name": "activation_6:0",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        128,
                        1,
                        1
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "Sigmoid",
            "module": "ai.onnx",
            "version": 13,
            "description": "Sigmoid takes one input data (Tensor<T>) and produces one output data\n(Tensor<T>) where the sigmoid function, y = 1 / (1 + exp(-x)), is applied to the\ntensor elementwise.\n",
            "inputs": [
              {
                "name": "X",
                "type": "T",
                "description": "Input tensor"
              }
            ],
            "min_input": 1,
            "max_input": 1,
            "outputs": [
              {
                "name": "Y",
                "type": "T",
                "description": "Output tensor"
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "type_constraints": [
              {
                "description": "Constrain input and output types to float tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)",
                  "tensor(bfloat16)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "sigmoid",
                "code": "node = onnx.helper.make_node(\n    \"Sigmoid\",\n    inputs=[\"x\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([-1, 0, 1]).astype(np.float32)\ny = 1.0 / (\n    1.0 + np.exp(np.negative(x))\n)  # expected output [0.26894143, 0.5, 0.7310586]\nexpect(node, inputs=[x], outputs=[y], name=\"test_sigmoid_example\")\n\nx = np.random.randn(3, 4, 5).astype(np.float32)\ny = 1.0 / (1.0 + np.exp(np.negative(x)))\nexpect(node, inputs=[x], outputs=[y], name=\"test_sigmoid\")"
              }
            ],
            "category": "Activation"
          }
        },
        {
          "name": "Conv__239",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "X",
              "value": [
                {
                  "name": "add_4__xeno_compat__1:0",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        32,
                        9,
                        16
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "W",
              "value": [
                {
                  "name": "Conv2D_30/filter:0",
                  "initializer": {
                    "name": "Conv2D_30/filter:0",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float32",
                      "shape": {
                        "dimensions": [
                          128,
                          32,
                          1,
                          1
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        128,
                        32,
                        1,
                        1
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "B",
              "value": [
                {
                  "name": "conv2d_29_1/y:0",
                  "initializer": {
                    "name": "conv2d_29_1/y:0",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float32",
                      "shape": {
                        "dimensions": [
                          128
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        128
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "Y",
              "value": [
                {
                  "name": "Conv__239:0",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        128,
                        9,
                        16
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [
            {
              "name": "dilations",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "strides",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "kernel_shape",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "group",
              "type": "int64",
              "value": {
                "type": "bigint",
                "value": "1"
              }
            }
          ],
          "type": {
            "name": "Conv",
            "module": "ai.onnx",
            "version": 11,
            "description": "The convolution operator consumes an input tensor and a filter, and\ncomputes the output.",
            "attributes": [
              {
                "name": "auto_pad",
                "type": "string",
                "required": false,
                "default": "NOTSET",
                "description": "auto_pad must be either NOTSET, SAME_UPPER, SAME_LOWER or VALID. Where default value is NOTSET, which means explicit padding is used. SAME_UPPER or SAME_LOWER mean pad the input so that `output_shape[i] = ceil(input_shape[i] / strides[i])` for each axis `i`. The padding is split between the two sides equally or almost equally (depending on whether it is even or odd). In case the padding is an odd number, the extra padding is added at the end for SAME_UPPER and at the beginning for SAME_LOWER."
              },
              {
                "name": "dilations",
                "type": "int64[]",
                "required": false,
                "description": "dilation value along each spatial axis of the filter. If not present, the dilation defaults is 1 along each spatial axis."
              },
              {
                "name": "group",
                "type": "int64",
                "required": false,
                "default": 1,
                "description": "number of groups input channels and output channels are divided into."
              },
              {
                "name": "kernel_shape",
                "type": "int64[]",
                "required": false,
                "description": "The shape of the convolution kernel. If not present, should be inferred from input W."
              },
              {
                "name": "pads",
                "type": "int64[]",
                "required": false,
                "description": "Padding for the beginning and ending along each spatial axis, it can take any value greater than or equal to 0. The value represent the number of pixels added to the beginning and end part of the corresponding axis. `pads` format should be as follow [x1_begin, x2_begin...x1_end, x2_end,...], where xi_begin the number of pixels added at the beginning of axis `i` and xi_end, the number of pixels added at the end of axis `i`. This attribute cannot be used simultaneously with auto_pad attribute. If not present, the padding defaults to 0 along start and end of each spatial axis."
              },
              {
                "name": "strides",
                "type": "int64[]",
                "required": false,
                "description": "Stride along each spatial axis. If not present, the stride defaults is 1 along each spatial axis."
              }
            ],
            "inputs": [
              {
                "name": "X",
                "type": "T",
                "description": "Input data tensor from previous layer; has size (N x C x H x W), where N is the batch size, C is the number of channels, and H and W are the height and width. Note that this is for the 2D image. Otherwise the size is (N x C x D1 x D2 ... x Dn). Optionally, if dimension denotation is in effect, the operation expects input data tensor to arrive with the dimension denotation of [DATA_BATCH, DATA_CHANNEL, DATA_FEATURE, DATA_FEATURE ...]."
              },
              {
                "name": "W",
                "type": "T",
                "description": "The weight tensor that will be used in the convolutions; has size (M x C/group x kH x kW), where C is the number of channels, and kH and kW are the height and width of the kernel, and M is the number of feature maps. For more than 2 dimensions, the kernel shape will be (M x C/group x k1 x k2 x ... x kn), where (k1 x k2 x ... kn) is the dimension of the kernel. Optionally, if dimension denotation is in effect, the operation expects the weight tensor to arrive with the dimension denotation of [FILTER_OUT_CHANNEL, FILTER_IN_CHANNEL, FILTER_SPATIAL, FILTER_SPATIAL ...]. Assuming zero based indices for the shape array, X.shape[1] == (W.shape[1] * group) == C and W.shape[0] mod G == 0. Or in other words FILTER_IN_CHANNEL multiplied by the number of groups should be equal to DATA_CHANNEL and the number of feature maps M should be a multiple of the number of groups G."
              },
              {
                "name": "B",
                "type": "T",
                "option": "optional",
                "description": "Optional 1D bias to be added to the convolution, has size of M."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "Y",
                "type": "T",
                "description": "Output data tensor that contains the result of the convolution. The output dimensions are functions of the kernel size, stride size, and pad lengths."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain input and output types to float tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "conv",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[1, 1, 1, 1],\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 21.0, 27.0, 33.0, 24.0],  # (1, 1, 5, 5) output tensor\n                [33.0, 54.0, 63.0, 72.0, 51.0],\n                [63.0, 99.0, 108.0, 117.0, 81.0],\n                [93.0, 144.0, 153.0, 162.0, 111.0],\n                [72.0, 111.0, 117.0, 123.0, 84.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_basic_conv_with_padding\",\n)\n\n# Convolution without padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[0, 0, 0, 0],\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 63.0, 72.0],  # (1, 1, 3, 3) output tensor\n                [99.0, 108.0, 117.0],\n                [144.0, 153.0, 162.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_basic_conv_without_padding\",\n)"
              },
              {
                "summary": "conv_with_autopad_same",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with auto_pad='SAME_LOWER' and strides=2\nnode = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    auto_pad=\"SAME_LOWER\",\n    kernel_shape=[3, 3],\n    strides=[2, 2],\n)\ny = np.array(\n    [[[[12.0, 27.0, 24.0], [63.0, 108.0, 81.0], [72.0, 117.0, 84.0]]]]\n).astype(np.float32)\nexpect(node, inputs=[x, W], outputs=[y], name=\"test_conv_with_autopad_same\")"
              },
              {
                "summary": "conv_with_strides",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 7, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n                [25.0, 26.0, 27.0, 28.0, 29.0],\n                [30.0, 31.0, 32.0, 33.0, 34.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with strides=2 and padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 1, 1, 1],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 27.0, 24.0],  # (1, 1, 4, 3) output tensor\n                [63.0, 108.0, 81.0],\n                [123.0, 198.0, 141.0],\n                [112.0, 177.0, 124.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_conv_with_strides_padding\",\n)\n\n# Convolution with strides=2 and no padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[0, 0, 0, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 72.0],  # (1, 1, 3, 2) output tensor\n                [144.0, 162.0],\n                [234.0, 252.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_conv_with_strides_no_padding\",\n)\n\n# Convolution with strides=2 and padding only along one dimension (the H dimension in NxCxHxW tensor)\nnode_with_asymmetric_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 0, 1, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_asymmetric_padding = np.array(\n    [\n        [\n            [\n                [21.0, 33.0],  # (1, 1, 4, 2) output tensor\n                [99.0, 117.0],\n                [189.0, 207.0],\n                [171.0, 183.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_asymmetric_padding,\n    inputs=[x, W],\n    outputs=[y_with_asymmetric_padding],\n    name=\"test_conv_with_strides_and_asymmetric_padding\",\n)"
              }
            ],
            "category": "Layer"
          }
        },
        {
          "name": "re_lu_12",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "X",
              "value": [
                {
                  "name": "Conv__239:0",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        128,
                        9,
                        16
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "Y",
              "value": [
                {
                  "name": "re_lu_12:0",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        128,
                        9,
                        16
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "Relu",
            "module": "ai.onnx",
            "version": 14,
            "description": "Relu takes one input data (Tensor<T>) and produces one output data\n(Tensor<T>) where the rectified linear function, y = max(0, x), is applied to\nthe tensor elementwise.\n",
            "inputs": [
              {
                "name": "X",
                "type": "T",
                "description": "Input tensor"
              }
            ],
            "min_input": 1,
            "max_input": 1,
            "outputs": [
              {
                "name": "Y",
                "type": "T",
                "description": "Output tensor"
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "type_constraints": [
              {
                "description": "Constrain input and output types to signed numeric tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(float)",
                  "tensor(int32)",
                  "tensor(int8)",
                  "tensor(int16)",
                  "tensor(int64)",
                  "tensor(float16)",
                  "tensor(double)",
                  "tensor(bfloat16)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "relu",
                "code": "node = onnx.helper.make_node(\n    \"Relu\",\n    inputs=[\"x\"],\n    outputs=[\"y\"],\n)\nx = np.random.randn(3, 4, 5).astype(np.float32)\ny = np.clip(x, 0, np.inf)\n\nexpect(node, inputs=[x], outputs=[y], name=\"test_relu\")"
              }
            ],
            "category": "Activation"
          }
        },
        {
          "name": "multiply_6",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "A",
              "value": [
                {
                  "name": "re_lu_12:0",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        128,
                        9,
                        16
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "B",
              "value": [
                {
                  "name": "activation_6:0",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        128,
                        1,
                        1
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "C",
              "value": [
                {
                  "name": "multiply_6:0",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        128,
                        9,
                        16
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "Mul",
            "module": "ai.onnx",
            "version": 14,
            "description": "Performs element-wise binary multiplication (with Numpy-style broadcasting support).\n\nThis operator supports **multidirectional (i.e., Numpy-style) broadcasting**; for more details please check [the doc](https://github.com/onnx/onnx/blob/master/docs/Broadcasting.md).\n\n(Opset 14 change): Extend supported types to include uint8, int8, uint16, and int16.\n",
            "inputs": [
              {
                "name": "A",
                "type": "T",
                "description": "First operand."
              },
              {
                "name": "B",
                "type": "T",
                "description": "Second operand."
              }
            ],
            "min_input": 2,
            "max_input": 2,
            "outputs": [
              {
                "name": "C",
                "type": "T",
                "description": "Result, has same element type as two inputs"
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "type_constraints": [
              {
                "description": "Constrain input and output types to all numeric tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(uint8)",
                  "tensor(uint16)",
                  "tensor(uint32)",
                  "tensor(uint64)",
                  "tensor(int8)",
                  "tensor(int16)",
                  "tensor(int32)",
                  "tensor(int64)",
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)",
                  "tensor(bfloat16)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "mul",
                "code": "node = onnx.helper.make_node(\n    \"Mul\",\n    inputs=[\"x\", \"y\"],\n    outputs=[\"z\"],\n)\n\nx = np.array([1, 2, 3]).astype(np.float32)\ny = np.array([4, 5, 6]).astype(np.float32)\nz = x * y  # expected output [4., 10., 18.]\nexpect(node, inputs=[x, y], outputs=[z], name=\"test_mul_example\")\n\nx = np.random.randn(3, 4, 5).astype(np.float32)\ny = np.random.randn(3, 4, 5).astype(np.float32)\nz = x * y\nexpect(node, inputs=[x, y], outputs=[z], name=\"test_mul\")\n\nx = np.random.randint(4, size=(3, 4, 5), dtype=np.int8)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.int8)\nz = x * y\nexpect(node, inputs=[x, y], outputs=[z], name=\"test_mul_int8\")\n\nx = np.random.randint(4, size=(3, 4, 5), dtype=np.int16)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.int16)\nz = x * y\nexpect(node, inputs=[x, y], outputs=[z], name=\"test_mul_int16\")\n\nx = np.random.randint(4, size=(3, 4, 5), dtype=np.uint8)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.uint8)\nz = x * y\nexpect(node, inputs=[x, y], outputs=[z], name=\"test_mul_uint8\")\n\nx = np.random.randint(4, size=(3, 4, 5), dtype=np.uint16)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.uint16)\nz = x * y\nexpect(node, inputs=[x, y], outputs=[z], name=\"test_mul_uint16\")\n\nx = np.random.randint(4, size=(3, 4, 5), dtype=np.uint32)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.uint32)\nz = x * y\nexpect(node, inputs=[x, y], outputs=[z], name=\"test_mul_uint32\")\n\nx = np.random.randint(4, size=(3, 4, 5), dtype=np.uint64)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.uint64)\nz = x * y\nexpect(node, inputs=[x, y], outputs=[z], name=\"test_mul_uint64\")"
              },
              {
                "summary": "mul_broadcast",
                "code": "node = onnx.helper.make_node(\n    \"Mul\",\n    inputs=[\"x\", \"y\"],\n    outputs=[\"z\"],\n)\n\nx = np.random.randn(3, 4, 5).astype(np.float32)\ny = np.random.randn(5).astype(np.float32)\nz = x * y\nexpect(node, inputs=[x, y], outputs=[z], name=\"test_mul_bcast\")"
              }
            ]
          }
        },
        {
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "X",
              "value": [
                {
                  "name": "multiply_6:0",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        128,
                        9,
                        16
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "roi",
              "value": [
                {
                  "name": "314",
                  "initializer": {
                    "category": "Constant",
                    "encoding": "|",
                    "values": {
                      "0": 0,
                      "1": 0,
                      "2": 0,
                      "3": 0,
                      "4": 1,
                      "5": 1,
                      "6": 1,
                      "7": 1
                    },
                    "type": {
                      "dataType": "float32",
                      "shape": {
                        "dimensions": [
                          8
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        8
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "scales",
              "value": [
                {
                  "name": "scales__125",
                  "initializer": {
                    "name": "scales__125",
                    "category": "Initializer",
                    "encoding": "|",
                    "values": {
                      "0": 1,
                      "1": 1,
                      "2": 2,
                      "3": 2
                    },
                    "type": {
                      "dataType": "float32",
                      "shape": {
                        "dimensions": [
                          4
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        4
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "Y",
              "value": [
                {
                  "name": "289",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        128,
                        18,
                        32
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [
            {
              "name": "mode",
              "type": "string",
              "value": "linear"
            }
          ],
          "type": {
            "name": "Resize",
            "module": "ai.onnx",
            "version": 19,
            "description": "Resize the input tensor. In general, it calculates every value in the output tensor as a weighted average of neighborhood (a.k.a. sampling locations) in the input tensor.\nEach dimension value of the output tensor is:\n```\noutput_dimension = floor(input_dimension * (roi_end - roi_start) * scale)\n```\nif input \\\"sizes\\\" is not specified.\n",
            "attributes": [
              {
                "name": "antialias",
                "type": "int64",
                "required": false,
                "description": "If set to 1, \"linear\" and \"cubic\" interpolation modes will use an antialiasing filter when downscaling. Antialiasing is achieved by stretching the resampling filter by a factor max(1, 1 / scale), which means that when downsampling, more input pixels contribute to an output pixel."
              },
              {
                "name": "axes",
                "type": "int64[]",
                "required": false,
                "description": "If provided, it specifies a subset of axes that 'roi', 'scales' and 'sizes' refer to. If not provided, all axes are assumed [0, 1, ..., r-1], where r = rank(data). Non-specified dimensions are interpreted as non-resizable. Negative value means counting dimensions from the back. Accepted range is [-r, r-1], where r = rank(data). Behavior is undefined if an axis is repeated."
              },
              {
                "name": "coordinate_transformation_mode",
                "type": "string",
                "required": false,
                "default": "half_pixel",
                "description": "\nThis attribute describes how to transform the coordinate in the resized tensor to the coordinate in the original tensor.\n\nThe coordinate of each dimension is transformed individually. Let's describe a case using axis x as an example.\nDenote `x_resized` as the coordinate of axis x in the resized tensor,\n `x_original` as the coordinate of axis x in the original tensor,\n `length_original` as the length of the original tensor in axis x,\n `length_resized` as the length of the resized tensor in axis x,\n `scale = length_resized / length_original`,\n `output_width` the target length on the axis x which can be a fractional number when it is calculated out of a scale factor,\n and `output_width_int` the effective output width as an integer.\n\nif coordinate_transformation_mode is `\"half_pixel\"`,\n```\nx_original = (x_resized + 0.5) / scale - 0.5\n```\n\nif coordinate_transformation_mode is `\"half_pixel_symmetric\"`,\n```\nadjustment = output_width_int / output_width\ncenter = input_width / 2\noffset = center * (1 - adjustment)\nx_ori = offset + (x + 0.5) / scale - 0.5\n```\n\nif coordinate_transformation_mode is `\"pytorch_half_pixel\"`,\n```\nx_original = length_resized > 1 ? (x_resized + 0.5) / scale - 0.5 : 0\n```\n\nif coordinate_transformation_mode is `\"align_corners\"`,\n```\nx_original = x_resized * (length_original - 1) / (length_resized - 1)\n```\n\nif coordinate_transformation_mode is `\"asymmetric\"`,\n```\nx_original = x_resized / scale\n```\n\nif coordinate_transformation_mode is `\"tf_crop_and_resize\"`,\n```\nx_original = length_resized > 1 ? start_x * (length_original - 1) + x_resized * (end_x - start_x) * (length_original - 1) / (length_resized - 1) : 0.5 * (start_x + end_x) * (length_original - 1)\n```\n."
              },
              {
                "name": "cubic_coeff_a",
                "type": "float32",
                "required": false,
                "default": -0.75,
                "description": "The coefficient 'a' used in cubic interpolation. Two common choice are -0.5 (in some cases of TensorFlow) and -0.75 (in PyTorch). Check out Equation (4) in https://ieeexplore.ieee.org/document/1163711 for the details. This attribute is valid only if mode is \"cubic\"."
              },
              {
                "name": "exclude_outside",
                "type": "int64",
                "required": false,
                "description": "If set to 1, the weight of sampling locations outside the tensor will be set to 0 and the weight will be renormalized so that their sum is 1.0. The default value is 0."
              },
              {
                "name": "extrapolation_value",
                "type": "float32",
                "required": false,
                "description": "When coordinate_transformation_mode is \"tf_crop_and_resize\" and x_original is outside the range [0, length_original - 1], this value is used as the corresponding output value. Default is 0.0f."
              },
              {
                "name": "keep_aspect_ratio_policy",
                "type": "string",
                "required": false,
                "default": "stretch",
                "description": "\nThis attribute describes how to interpret the `sizes` input with regard to keeping the original aspect ratio of the input, and it is not applicable when\nthe `scales` input is used.\n\nGiven a set of `sizes`, associated with a subset of `axes` (explicitly provided or default), and assuming `d = axes[i]`, with `i` being the index of the provided `sizes`.\n\nIf `keep_aspect_ratio_policy` is `\"stretch\"`, the original aspect ratio is disregarded, and the input is resized to the specified size:\n`out_size[d] = sizes[i]`\n\nIf `keep_aspect_ratio_policy` is `\"not_larger\"`, the sizes are adjusted so that no extent of the output is larger than the specified size, while keeping the original aspect ratio:\n```\nscale = Min(sizes[i] / in_size[d])\nout_size[d] = round_int(scale * in_size[i])\n```\n\nIf `keep_aspect_ratio_policy` is `\"not_smaller\"`, the sizes are adjusted so that no extent of the output is smaller than the specified size, while keeping the original aspect ratio:\n```\nscale = Max(sizes[i] / in_size[d])\nout_size[d] = round_int(scale * in_size[i])\n```\n\nFor non-resizable axes (those not specified in `axes`), the output size will be equal to the input size.\n\nNote: `round_int` stands for computing the nearest integer value, rounding halfway cases up."
              },
              {
                "name": "mode",
                "type": "string",
                "required": false,
                "default": "nearest",
                "description": "Three interpolation modes: \"nearest\" (default), \"linear\" and \"cubic\". The \"linear\" mode includes linear interpolation for 1D tensor and N-linear interpolation for N-D tensor (for example, bilinear interpolation for 2D tensor). The \"cubic\" mode includes cubic interpolation for 1D tensor and N-cubic interpolation for N-D tensor (for example, bicubic interpolation for 2D tensor)."
              },
              {
                "name": "nearest_mode",
                "type": "string",
                "required": false,
                "default": "round_prefer_floor",
                "description": "Four modes: \"round_prefer_floor\" (default, as known as round half down), \"round_prefer_ceil\" (as known as round half up), \"floor\", \"ceil\". Only used by nearest interpolation. It indicates how to get \"nearest\" pixel in input tensor from x_original, so this attribute is valid only if \"mode\" is \"nearest\"."
              }
            ],
            "inputs": [
              {
                "name": "X",
                "type": "T1",
                "description": "N-D tensor"
              },
              {
                "name": "roi",
                "type": "T2",
                "option": "optional",
                "description": "1-D tensor given as [start1, ..., startN, end1, ..., endN], where N is the rank of X or the length of axes, if provided. The RoIs' coordinates are normalized in the coordinate system of the input image. It only takes effect when coordinate_transformation_mode is \"tf_crop_and_resize\""
              },
              {
                "name": "scales",
                "type": "tensor(float)",
                "option": "optional",
                "description": "The scale array along each dimension. It takes value greater than 0. If it's less than 1, it's sampling down, otherwise, it's upsampling. The number of elements of 'scales' should be the same as the rank of input 'X' or the length of 'axes', if provided. One of 'scales' and 'sizes' MUST be specified and it is an error if both are specified. If 'sizes' is needed, the user can use an empty string as the name of 'scales' in this operator's input list."
              },
              {
                "name": "sizes",
                "type": "tensor(int64)",
                "option": "optional",
                "description": "Target size of the output tensor. Its interpretation depends on the 'keep_aspect_ratio_policy' value.The number of elements of 'sizes' should be the same as the rank of input 'X', or the length of 'axes', if provided. Only one of 'scales' and 'sizes' can be specified. "
              }
            ],
            "min_input": 1,
            "max_input": 4,
            "outputs": [
              {
                "name": "Y",
                "type": "T1",
                "description": "N-D tensor after resizing"
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "1 - 4",
            "type_constraints": [
              {
                "description": "Constrain input 'X' and output 'Y' to all tensor types.",
                "type_param_str": "T1",
                "allowed_type_strs": [
                  "tensor(uint8)",
                  "tensor(uint16)",
                  "tensor(uint32)",
                  "tensor(uint64)",
                  "tensor(int8)",
                  "tensor(int16)",
                  "tensor(int32)",
                  "tensor(int64)",
                  "tensor(bfloat16)",
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)",
                  "tensor(string)",
                  "tensor(bool)",
                  "tensor(complex64)",
                  "tensor(complex128)"
                ]
              },
              {
                "description": "Constrain roi type to float or double.",
                "type_param_str": "T2",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "resize_downsample_scales_cubic",
                "code": "node = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"\", \"scales\"],\n    outputs=[\"Y\"],\n    mode=\"cubic\",\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2, 3, 4],\n                [5, 6, 7, 8],\n                [9, 10, 11, 12],\n                [13, 14, 15, 16],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\nscales = np.array([1.0, 1.0, 0.8, 0.8], dtype=np.float32)\n\n# [[[[ 1.47119141  2.78125     4.08251953]\n#    [ 6.71142578  8.02148438  9.32275391]\n#    [11.91650391 13.2265625  14.52783203]]]]\noutput = interpolate_nd(\n    data, lambda x, _: cubic_coeffs(x), scale_factors=scales\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, scales],\n    outputs=[output],\n    name=\"test_resize_downsample_scales_cubic\",\n)"
              },
              {
                "summary": "resize_downsample_scales_cubic_A_n0p5_exclude_outside",
                "code": "node = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"\", \"scales\"],\n    outputs=[\"Y\"],\n    mode=\"cubic\",\n    cubic_coeff_a=-0.5,\n    exclude_outside=True,\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2, 3, 4],\n                [5, 6, 7, 8],\n                [9, 10, 11, 12],\n                [13, 14, 15, 16],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\nscales = np.array([1.0, 1.0, 0.8, 0.8], dtype=np.float32)\n\n# [[[[ 1.36812675  2.6695014   4.0133367 ]\n#    [ 6.57362535  7.875       9.2188353 ]\n#    [11.94896657 13.25034122 14.59417652]]]]\noutput = interpolate_nd(\n    data,\n    lambda x, _: cubic_coeffs(x, A=-0.5),\n    scale_factors=scales,\n    exclude_outside=True,\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, scales],\n    outputs=[output],\n    name=\"test_resize_downsample_scales_cubic_A_n0p5_exclude_outside\",\n)"
              },
              {
                "summary": "resize_downsample_scales_cubic_align_corners",
                "code": "node = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"\", \"scales\"],\n    outputs=[\"Y\"],\n    mode=\"cubic\",\n    coordinate_transformation_mode=\"align_corners\",\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2, 3, 4],\n                [5, 6, 7, 8],\n                [9, 10, 11, 12],\n                [13, 14, 15, 16],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\nscales = np.array([1.0, 1.0, 0.8, 0.8], dtype=np.float32)\n\n# [[[[ 1.          2.39519159  3.79038317]\n#    [ 6.58076634  7.97595793  9.37114951]\n#    [12.16153268 13.55672427 14.95191585]]]]\noutput = interpolate_nd(\n    data,\n    lambda x, _: cubic_coeffs(x),\n    scale_factors=scales,\n    coordinate_transformation_mode=\"align_corners\",\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, scales],\n    outputs=[output],\n    name=\"test_resize_downsample_scales_cubic_align_corners\",\n)"
              },
              {
                "summary": "resize_downsample_scales_cubic_antialias",
                "code": "node = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"\", \"scales\"],\n    outputs=[\"Y\"],\n    mode=\"cubic\",\n    antialias=1,\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2, 3, 4],\n                [5, 6, 7, 8],\n                [9, 10, 11, 12],\n                [13, 14, 15, 16],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\nscales = np.array([1.0, 1.0, 0.6, 0.6], dtype=np.float32)\n\n# [[[[ 2.5180721  4.2858863]\n#    [ 9.589329  11.357142 ]]]]\noutput = interpolate_nd(\n    data, cubic_coeffs_antialias, scale_factors=scales\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, scales],\n    outputs=[output],\n    name=\"test_resize_downsample_scales_cubic_antialias\",\n)"
              },
              {
                "summary": "resize_downsample_scales_linear",
                "code": "node = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"\", \"scales\"],\n    outputs=[\"Y\"],\n    mode=\"linear\",\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2, 3, 4],\n                [5, 6, 7, 8],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\nscales = np.array([1.0, 1.0, 0.6, 0.6], dtype=np.float32)\n\n# [[[[2.6666665 4.3333331]]]]\noutput = interpolate_nd(\n    data, lambda x, _: linear_coeffs(x), scale_factors=scales\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, scales],\n    outputs=[output],\n    name=\"test_resize_downsample_scales_linear\",\n)"
              },
              {
                "summary": "resize_downsample_scales_linear_align_corners",
                "code": "node = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"\", \"scales\"],\n    outputs=[\"Y\"],\n    mode=\"linear\",\n    coordinate_transformation_mode=\"align_corners\",\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2, 3, 4],\n                [5, 6, 7, 8],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\nscales = np.array([1.0, 1.0, 0.6, 0.6], dtype=np.float32)\n\n# [[[[1.       3.142857]]]]\noutput = interpolate_nd(\n    data,\n    lambda x, _: linear_coeffs(x),\n    scale_factors=scales,\n    coordinate_transformation_mode=\"align_corners\",\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, scales],\n    outputs=[output],\n    name=\"test_resize_downsample_scales_linear_align_corners\",\n)"
              },
              {
                "summary": "resize_downsample_scales_linear_antialias",
                "code": "node = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"\", \"scales\"],\n    outputs=[\"Y\"],\n    mode=\"linear\",\n    antialias=1,\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2, 3, 4],\n                [5, 6, 7, 8],\n                [9, 10, 11, 12],\n                [13, 14, 15, 16],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\nscales = np.array([1.0, 1.0, 0.6, 0.6], dtype=np.float32)\n\n# [[[[ 2.875  4.5  ]\n#    [ 9.375 11.   ]]]]\noutput = interpolate_nd(\n    data, linear_coeffs_antialias, scale_factors=scales\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, scales],\n    outputs=[output],\n    name=\"test_resize_downsample_scales_linear_antialias\",\n)"
              },
              {
                "summary": "resize_downsample_scales_linear_half_pixel_symmetric",
                "code": "node = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"\", \"scales\"],\n    outputs=[\"Y\"],\n    mode=\"linear\",\n    coordinate_transformation_mode=\"half_pixel_symmetric\",\n)\n\ndata = np.array([[[[1, 2, 3, 4]]]], dtype=np.float32)\nscales = np.array([1.0, 1.0, 1.0, 0.6], dtype=np.float32)\n\n# [[[[1.6666667, 3.3333333]]]]\noutput = interpolate_nd(\n    data,\n    lambda x, _: linear_coeffs(x),\n    scale_factors=scales,\n    coordinate_transformation_mode=\"half_pixel_symmetric\",\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, scales],\n    outputs=[output],\n    name=\"test_resize_downsample_scales_linear_half_pixel_symmetric\",\n)"
              },
              {
                "summary": "resize_downsample_scales_nearest",
                "code": "node = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"\", \"scales\"],\n    outputs=[\"Y\"],\n    mode=\"nearest\",\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2, 3, 4],\n                [5, 6, 7, 8],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\nscales = np.array([1.0, 1.0, 0.6, 0.6], dtype=np.float32)\n\n# [[[[1. 3.]]]]\noutput = interpolate_nd(\n    data, lambda x, _: nearest_coeffs(x), scale_factors=scales\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, scales],\n    outputs=[output],\n    name=\"test_resize_downsample_scales_nearest\",\n)"
              },
              {
                "summary": "resize_downsample_sizes_cubic",
                "code": "node = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"\", \"\", \"sizes\"],\n    outputs=[\"Y\"],\n    mode=\"cubic\",\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2, 3, 4],\n                [5, 6, 7, 8],\n                [9, 10, 11, 12],\n                [13, 14, 15, 16],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\nsizes = np.array([1, 1, 3, 3], dtype=np.int64)\n\n# [[[[ 1.63078704  3.00462963  4.37847222]\n#    [ 7.12615741  8.5         9.87384259]\n#    [12.62152778 13.99537037 15.36921296]]]]\noutput = interpolate_nd(\n    data, lambda x, _: cubic_coeffs(x), output_size=sizes\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, sizes],\n    outputs=[output],\n    name=\"test_resize_downsample_sizes_cubic\",\n)"
              },
              {
                "summary": "resize_downsample_sizes_cubic_antialias",
                "code": "node = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"\", \"\", \"sizes\"],\n    outputs=[\"Y\"],\n    mode=\"cubic\",\n    antialias=1,\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2, 3, 4],\n                [5, 6, 7, 8],\n                [9, 10, 11, 12],\n                [13, 14, 15, 16],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\nsizes = np.array([1, 1, 3, 3], dtype=np.int64)\n\n# [[[[ 1.7750092  3.1200073  4.4650054]\n#    [ 7.1550016  8.5        9.844998 ]\n#    [12.534994  13.8799925 15.224991 ]]]]\noutput = interpolate_nd(data, cubic_coeffs_antialias, output_size=sizes).astype(\n    np.float32\n)\n\nexpect(\n    node,\n    inputs=[data, sizes],\n    outputs=[output],\n    name=\"test_resize_downsample_sizes_cubic_antialias\",\n)"
              },
              {
                "summary": "resize_downsample_sizes_linear_antialias",
                "code": "node = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"\", \"\", \"sizes\"],\n    outputs=[\"Y\"],\n    mode=\"linear\",\n    antialias=1,\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2, 3, 4],\n                [5, 6, 7, 8],\n                [9, 10, 11, 12],\n                [13, 14, 15, 16],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\nsizes = np.array([1, 1, 3, 3], dtype=np.int64)\n\n# [[[[ 2.3636363  3.590909   4.818182 ]\n#    [ 7.2727275  8.5        9.727273 ]\n#    [12.181818  13.409091  14.636364 ]]]]\noutput = interpolate_nd(\n    data, linear_coeffs_antialias, output_size=sizes\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, sizes],\n    outputs=[output],\n    name=\"test_resize_downsample_sizes_linear_antialias\",\n)"
              },
              {
                "summary": "resize_downsample_sizes_linear_pytorch_half_pixel",
                "code": "node = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"\", \"\", \"sizes\"],\n    outputs=[\"Y\"],\n    mode=\"linear\",\n    coordinate_transformation_mode=\"pytorch_half_pixel\",\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2, 3, 4],\n                [5, 6, 7, 8],\n                [9, 10, 11, 12],\n                [13, 14, 15, 16],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\nsizes = np.array([1, 1, 3, 1], dtype=np.int64)\n\n# [[[[ 1.6666666]\n#    [ 7.       ]\n#    [12.333333 ]]]]\noutput = interpolate_nd(\n    data,\n    lambda x, _: linear_coeffs(x),\n    output_size=sizes,\n    coordinate_transformation_mode=\"pytorch_half_pixel\",\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, sizes],\n    outputs=[output],\n    name=\"test_resize_downsample_sizes_linear_pytorch_half_pixel\",\n)"
              },
              {
                "summary": "resize_downsample_sizes_nearest",
                "code": "node = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"\", \"\", \"sizes\"],\n    outputs=[\"Y\"],\n    mode=\"nearest\",\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2, 3, 4],\n                [5, 6, 7, 8],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\nsizes = np.array([1, 1, 1, 3], dtype=np.int64)\n\n# [[[[1. 2. 4.]]]]\noutput = interpolate_nd(\n    data, lambda x, _: nearest_coeffs(x), output_size=sizes\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, sizes],\n    outputs=[output],\n    name=\"test_resize_downsample_sizes_nearest\",\n)"
              },
              {
                "summary": "resize_downsample_sizes_nearest_not_larger",
                "code": "keep_aspect_ratio_policy = \"not_larger\"\naxes = [2, 3]\nnode = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"\", \"\", \"sizes\"],\n    outputs=[\"Y\"],\n    mode=\"nearest\",\n    axes=axes,\n    keep_aspect_ratio_policy=keep_aspect_ratio_policy,\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2, 3, 4],\n                [5, 6, 7, 8],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\nsizes = np.array([1, 3], dtype=np.int64)  # Results in 1x2\n\n# [[[[1. 3.]]]]\noutput = interpolate_nd(\n    data,\n    lambda x, _: nearest_coeffs(x),\n    output_size=sizes,\n    axes=axes,\n    keep_aspect_ratio_policy=keep_aspect_ratio_policy,\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, sizes],\n    outputs=[output],\n    name=\"test_resize_downsample_sizes_nearest_not_larger\",\n)"
              },
              {
                "summary": "resize_downsample_sizes_nearest_not_smaller",
                "code": "keep_aspect_ratio_policy = \"not_smaller\"\naxes = [2, 3]\nnode = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"\", \"\", \"sizes\"],\n    outputs=[\"Y\"],\n    mode=\"nearest\",\n    axes=axes,\n    keep_aspect_ratio_policy=keep_aspect_ratio_policy,\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2, 3, 4],\n                [5, 6, 7, 8],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\nsizes = np.array([1, 3], dtype=np.int64)  # Results in 2x3\n\n# [[[[1. 2. 4.]\n#    [5. 6. 8.]]]]\noutput = interpolate_nd(\n    data,\n    lambda x, _: nearest_coeffs(x),\n    output_size=sizes,\n    axes=axes,\n    keep_aspect_ratio_policy=keep_aspect_ratio_policy,\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, sizes],\n    outputs=[output],\n    name=\"test_resize_downsample_sizes_nearest_not_smaller\",\n)"
              },
              {
                "summary": "resize_tf_crop_and_resize",
                "code": "node = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"roi\", \"\", \"sizes\"],\n    outputs=[\"Y\"],\n    mode=\"linear\",\n    coordinate_transformation_mode=\"tf_crop_and_resize\",\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2, 3, 4],\n                [5, 6, 7, 8],\n                [9, 10, 11, 12],\n                [13, 14, 15, 16],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\n# Note: for some rois, the result may be different with that of TF for inaccurate floating point\nroi = np.array([0, 0, 0.4, 0.6, 1, 1, 0.6, 0.8], dtype=np.float32)\nsizes = np.array([1, 1, 3, 3], dtype=np.int64)\n\n# [[[[ 7.6000004  7.9        8.2      ]\n#    [ 8.8        9.1        9.400001 ]\n#    [10.        10.3       10.6      ]]]]\noutput = interpolate_nd(\n    data,\n    lambda x, _: linear_coeffs(x),\n    output_size=sizes,\n    roi=roi,\n    coordinate_transformation_mode=\"tf_crop_and_resize\",\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, roi, sizes],\n    outputs=[output],\n    name=\"test_resize_tf_crop_and_resize\",\n)"
              },
              {
                "summary": "resize_tf_crop_and_resize_axes_2_3",
                "code": "axes = [2, 3]\nnode = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"roi\", \"\", \"sizes\"],\n    outputs=[\"Y\"],\n    mode=\"linear\",\n    coordinate_transformation_mode=\"tf_crop_and_resize\",\n    axes=axes,\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2, 3, 4],\n                [5, 6, 7, 8],\n                [9, 10, 11, 12],\n                [13, 14, 15, 16],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\n# Note: for some rois, the result may be different with that of TF for inaccurate floating point\nroi = np.array([0.4, 0.6, 0.6, 0.8], dtype=np.float32)\nsizes = np.array([3, 3], dtype=np.int64)\n\n# [[[[ 7.6000004  7.9        8.2      ]\n#    [ 8.8        9.1        9.400001 ]\n#    [10.        10.3       10.6      ]]]]\noutput = interpolate_nd(\n    data,\n    lambda x, _: linear_coeffs(x),\n    output_size=sizes,\n    roi=roi,\n    axes=axes,\n    coordinate_transformation_mode=\"tf_crop_and_resize\",\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, roi, sizes],\n    outputs=[output],\n    name=\"test_resize_tf_crop_and_resize_axes_2_3\",\n)"
              },
              {
                "summary": "resize_tf_crop_and_resize_axes_3_2",
                "code": "axes = [3, 2]\nnode = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"roi\", \"\", \"sizes\"],\n    outputs=[\"Y\"],\n    mode=\"linear\",\n    coordinate_transformation_mode=\"tf_crop_and_resize\",\n    axes=axes,\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2, 3, 4],\n                [5, 6, 7, 8],\n                [9, 10, 11, 12],\n                [13, 14, 15, 16],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\n# Note: for some rois, the result may be different with that of TF for inaccurate floating point\nroi = np.array([0.6, 0.4, 0.8, 0.6], dtype=np.float32)\nsizes = np.array([3, 3], dtype=np.int64)\n\n# [[[[ 7.6000004  7.9        8.2      ]\n#    [ 8.8        9.1        9.400001 ]\n#    [10.        10.3       10.6      ]]]]\noutput = interpolate_nd(\n    data,\n    lambda x, _: linear_coeffs(x),\n    output_size=sizes,\n    roi=roi,\n    axes=axes,\n    coordinate_transformation_mode=\"tf_crop_and_resize\",\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, roi, sizes],\n    outputs=[output],\n    name=\"test_resize_tf_crop_and_resize_axes_3_2\",\n)"
              },
              {
                "summary": "resize_tf_crop_and_resize_extrapolation_value",
                "code": "node = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"roi\", \"\", \"sizes\"],\n    outputs=[\"Y\"],\n    mode=\"linear\",\n    coordinate_transformation_mode=\"tf_crop_and_resize\",\n    extrapolation_value=10.0,\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2, 3, 4],\n                [5, 6, 7, 8],\n                [9, 10, 11, 12],\n                [13, 14, 15, 16],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\n# Note: for some rois, the result may be different with that of TF for inaccurate floating point\nroi = np.array([0, 0, 0.4, 0.6, 1, 1, 1.2, 1.7], dtype=np.float32)\nsizes = np.array([1, 1, 3, 3], dtype=np.int64)\n\n# [[[[ 7.6000004 10.        10.       ]\n#    [12.400001  10.        10.       ]\n#    [10.        10.        10.       ]]]]\noutput = interpolate_nd(\n    data,\n    lambda x, _: linear_coeffs(x),\n    output_size=sizes,\n    roi=roi,\n    coordinate_transformation_mode=\"tf_crop_and_resize\",\n    extrapolation_value=10.0,\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, roi, sizes],\n    outputs=[output],\n    name=\"test_resize_tf_crop_and_resize_extrapolation_value\",\n)"
              },
              {
                "summary": "resize_upsample_scales_cubic",
                "code": "node = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"\", \"scales\"],\n    outputs=[\"Y\"],\n    mode=\"cubic\",\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2, 3, 4],\n                [5, 6, 7, 8],\n                [9, 10, 11, 12],\n                [13, 14, 15, 16],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\nscales = np.array([1.0, 1.0, 2.0, 2.0], dtype=np.float32)\n\n# [[[[ 0.47265625  0.76953125  1.24609375  1.875       2.28125\n#      2.91015625  3.38671875  3.68359375]\n#    [ 1.66015625  1.95703125  2.43359375  3.0625      3.46875\n#      4.09765625  4.57421875  4.87109375]\n#    [ 3.56640625  3.86328125  4.33984375  4.96875     5.375\n#      6.00390625  6.48046875  6.77734375]\n#    [ 6.08203125  6.37890625  6.85546875  7.484375    7.890625\n#      8.51953125  8.99609375  9.29296875]\n#    [ 7.70703125  8.00390625  8.48046875  9.109375    9.515625\n#     10.14453125 10.62109375 10.91796875]\n#    [10.22265625 10.51953125 10.99609375 11.625      12.03125\n#     12.66015625 13.13671875 13.43359375]\n#    [12.12890625 12.42578125 12.90234375 13.53125    13.9375\n#     14.56640625 15.04296875 15.33984375]\n#    [13.31640625 13.61328125 14.08984375 14.71875    15.125\n#     15.75390625 16.23046875 16.52734375]]]]\noutput = interpolate_nd(\n    data, lambda x, _: cubic_coeffs(x), scale_factors=scales\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, scales],\n    outputs=[output],\n    name=\"test_resize_upsample_scales_cubic\",\n)"
              },
              {
                "summary": "resize_upsample_scales_cubic_A_n0p5_exclude_outside",
                "code": "node = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"\", \"scales\"],\n    outputs=[\"Y\"],\n    mode=\"cubic\",\n    cubic_coeff_a=-0.5,\n    exclude_outside=True,\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2, 3, 4],\n                [5, 6, 7, 8],\n                [9, 10, 11, 12],\n                [13, 14, 15, 16],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\nscales = np.array([1.0, 1.0, 2.0, 2.0], dtype=np.float32)\n\n# [[[[ 0.55882353  0.81494204  1.35698249  1.89705882  2.39705882\n#      2.93713516  3.47917561  3.73529412]\n#    [ 1.58329755  1.83941606  2.38145651  2.92153285  3.42153285\n#      3.96160918  4.50364964  4.75976814]\n#    [ 3.75145936  4.00757787  4.54961832  5.08969466  5.58969466\n#      6.12977099  6.67181144  6.92792995]\n#    [ 5.91176471  6.16788321  6.70992366  7.25        7.75\n#      8.29007634  8.83211679  9.08823529]\n#    [ 7.91176471  8.16788321  8.70992366  9.25        9.75\n#     10.29007634 10.83211679 11.08823529]\n#    [10.07207005 10.32818856 10.87022901 11.41030534 11.91030534\n#     12.45038168 12.99242213 13.24854064]\n#    [12.24023186 12.49635036 13.03839082 13.57846715 14.07846715\n#     14.61854349 15.16058394 15.41670245]\n#    [13.26470588 13.52082439 14.06286484 14.60294118 15.10294118\n#     15.64301751 16.18505796 16.44117647]]]]\noutput = interpolate_nd(\n    data,\n    lambda x, _: cubic_coeffs(x, A=-0.5),\n    scale_factors=scales,\n    exclude_outside=True,\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, scales],\n    outputs=[output],\n    name=\"test_resize_upsample_scales_cubic_A_n0p5_exclude_outside\",\n)"
              },
              {
                "summary": "resize_upsample_scales_cubic_align_corners",
                "code": "node = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"\", \"scales\"],\n    outputs=[\"Y\"],\n    mode=\"cubic\",\n    coordinate_transformation_mode=\"align_corners\",\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2, 3, 4],\n                [5, 6, 7, 8],\n                [9, 10, 11, 12],\n                [13, 14, 15, 16],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\nscales = np.array([1.0, 1.0, 2.0, 2.0], dtype=np.float32)\n\n# [[[[ 1.          1.34110787  1.80029155  2.32944606  2.67055394\n#      3.19970845  3.65889213  4.        ]\n#    [ 2.36443149  2.70553936  3.16472303  3.69387755  4.03498542\n#      4.56413994  5.02332362  5.36443149]\n#    [ 4.20116618  4.54227405  5.00145773  5.53061224  5.87172012\n#      6.40087464  6.86005831  7.20116618]\n#    [ 6.31778426  6.65889213  7.1180758   7.64723032  7.98833819\n#      8.51749271  8.97667638  9.31778426]\n#    [ 7.68221574  8.02332362  8.48250729  9.01166181  9.35276968\n#      9.8819242  10.34110787 10.68221574]\n#    [ 9.79883382 10.13994169 10.59912536 11.12827988 11.46938776\n#     11.99854227 12.45772595 12.79883382]\n#    [11.63556851 11.97667638 12.43586006 12.96501458 13.30612245\n#     13.83527697 14.29446064 14.63556851]\n#    [13.         13.34110787 13.80029155 14.32944606 14.67055394\n#     15.19970845 15.65889213 16.        ]]]]\noutput = interpolate_nd(\n    data,\n    lambda x, _: cubic_coeffs(x),\n    scale_factors=scales,\n    coordinate_transformation_mode=\"align_corners\",\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, scales],\n    outputs=[output],\n    name=\"test_resize_upsample_scales_cubic_align_corners\",\n)"
              },
              {
                "summary": "resize_upsample_scales_cubic_asymmetric",
                "code": "node = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"\", \"scales\"],\n    outputs=[\"Y\"],\n    mode=\"cubic\",\n    coordinate_transformation_mode=\"asymmetric\",\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2, 3, 4],\n                [5, 6, 7, 8],\n                [9, 10, 11, 12],\n                [13, 14, 15, 16],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\nscales = np.array([1.0, 1.0, 2.0, 2.0], dtype=np.float32)\n\n# [[[[ 1.       1.40625  2.       2.5      3.       3.59375  4.\n#      4.09375]\n#    [ 2.625    3.03125  3.625    4.125    4.625    5.21875  5.625\n#      5.71875]\n#    [ 5.       5.40625  6.       6.5      7.       7.59375  8.\n#      8.09375]\n#    [ 7.       7.40625  8.       8.5      9.       9.59375 10.\n#     10.09375]\n#    [ 9.       9.40625 10.      10.5     11.      11.59375 12.\n#     12.09375]\n#    [11.375   11.78125 12.375   12.875   13.375   13.96875 14.375\n#     14.46875]\n#    [13.      13.40625 14.      14.5     15.      15.59375 16.\n#     16.09375]\n#    [13.375   13.78125 14.375   14.875   15.375   15.96875 16.375\n#     16.46875]]]]\noutput = interpolate_nd(\n    data,\n    lambda x, _: cubic_coeffs(x, A=-0.75),\n    scale_factors=scales,\n    coordinate_transformation_mode=\"asymmetric\",\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, scales],\n    outputs=[output],\n    name=\"test_resize_upsample_scales_cubic_asymmetric\",\n)"
              },
              {
                "summary": "resize_upsample_scales_linear",
                "code": "node = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"\", \"scales\"],\n    outputs=[\"Y\"],\n    mode=\"linear\",\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2],\n                [3, 4],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\nscales = np.array([1.0, 1.0, 2.0, 2.0], dtype=np.float32)\n\n# [[[[1.   1.25 1.75 2.  ]\n#    [1.5  1.75 2.25 2.5 ]\n#    [2.5  2.75 3.25 3.5 ]\n#    [3.   3.25 3.75 4.  ]]]]\noutput = interpolate_nd(\n    data, lambda x, _: linear_coeffs(x), scale_factors=scales\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, scales],\n    outputs=[output],\n    name=\"test_resize_upsample_scales_linear\",\n)"
              },
              {
                "summary": "resize_upsample_scales_linear_align_corners",
                "code": "node = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"\", \"scales\"],\n    outputs=[\"Y\"],\n    mode=\"linear\",\n    coordinate_transformation_mode=\"align_corners\",\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2],\n                [3, 4],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\nscales = np.array([1.0, 1.0, 2.0, 2.0], dtype=np.float32)\n\n# [[[[1.         1.33333333 1.66666667 2.        ]\n#    [1.66666667 2.         2.33333333 2.66666667]\n#    [2.33333333 2.66666667 3.         3.33333333]\n#    [3.         3.33333333 3.66666667 4.        ]]]]\noutput = interpolate_nd(\n    data,\n    lambda x, _: linear_coeffs(x),\n    scale_factors=scales,\n    coordinate_transformation_mode=\"align_corners\",\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, scales],\n    outputs=[output],\n    name=\"test_resize_upsample_scales_linear_align_corners\",\n)"
              },
              {
                "summary": "resize_upsample_scales_linear_half_pixel_symmetric",
                "code": "node = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"\", \"scales\"],\n    outputs=[\"Y\"],\n    mode=\"linear\",\n    coordinate_transformation_mode=\"half_pixel_symmetric\",\n)\n\ndata = np.array([[[[1, 2], [3, 4]]]], dtype=np.float32)\nscales = np.array([1.0, 1.0, 2.3, 2.94], dtype=np.float32)\n\n# [[[[1.        , 1.15986395, 1.5       , 1.84013605, 2.        ],\n#    [1.56521738, 1.72508133, 2.06521738, 2.40535343, 2.56521738],\n#    [2.43478262, 2.59464657, 2.93478262, 3.27491867, 3.43478262],\n#    [3.        , 3.15986395, 3.5       , 3.84013605, 4.        ]]]]\noutput = interpolate_nd(\n    data,\n    lambda x, _: linear_coeffs(x),\n    scale_factors=scales,\n    coordinate_transformation_mode=\"half_pixel_symmetric\",\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, scales],\n    outputs=[output],\n    name=\"test_resize_upsample_scales_linear_half_pixel_symmetric\",\n)"
              },
              {
                "summary": "resize_upsample_scales_nearest",
                "code": "node = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"\", \"scales\"],\n    outputs=[\"Y\"],\n    mode=\"nearest\",\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2],\n                [3, 4],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\nscales = np.array([1.0, 1.0, 2.0, 3.0], dtype=np.float32)\n\n# [[[[1. 1. 1. 2. 2. 2.]\n#    [1. 1. 1. 2. 2. 2.]\n#    [3. 3. 3. 4. 4. 4.]\n#    [3. 3. 3. 4. 4. 4.]]]]\noutput = interpolate_nd(\n    data, lambda x, _: nearest_coeffs(x), scale_factors=scales\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, scales],\n    outputs=[output],\n    name=\"test_resize_upsample_scales_nearest\",\n)"
              },
              {
                "summary": "resize_upsample_scales_nearest_axes_2_3",
                "code": "axes = [2, 3]\nnode = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"\", \"scales\"],\n    outputs=[\"Y\"],\n    mode=\"nearest\",\n    axes=axes,\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2],\n                [3, 4],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\nscales = np.array([2.0, 3.0], dtype=np.float32)\n\n# [[[[1. 1. 1. 2. 2. 2.]\n#    [1. 1. 1. 2. 2. 2.]\n#    [3. 3. 3. 4. 4. 4.]\n#    [3. 3. 3. 4. 4. 4.]]]]\noutput = interpolate_nd(\n    data, lambda x, _: nearest_coeffs(x), scale_factors=scales, axes=axes\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, scales],\n    outputs=[output],\n    name=\"test_resize_upsample_scales_nearest_axes_2_3\",\n)"
              },
              {
                "summary": "resize_upsample_scales_nearest_axes_3_2",
                "code": "axes = [3, 2]\nnode = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"\", \"scales\"],\n    outputs=[\"Y\"],\n    mode=\"nearest\",\n    axes=axes,\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2],\n                [3, 4],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\nscales = np.array([3.0, 2.0], dtype=np.float32)\n\n# [[[[1. 1. 1. 2. 2. 2.]\n#    [1. 1. 1. 2. 2. 2.]\n#    [3. 3. 3. 4. 4. 4.]\n#    [3. 3. 3. 4. 4. 4.]]]]\noutput = interpolate_nd(\n    data, lambda x, _: nearest_coeffs(x), scale_factors=scales, axes=axes\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, scales],\n    outputs=[output],\n    name=\"test_resize_upsample_scales_nearest_axes_3_2\",\n)"
              },
              {
                "summary": "resize_upsample_sizes_cubic",
                "code": "node = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"\", \"\", \"sizes\"],\n    outputs=[\"Y\"],\n    mode=\"cubic\",\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2, 3, 4],\n                [5, 6, 7, 8],\n                [9, 10, 11, 12],\n                [13, 14, 15, 16],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\nsizes = np.array([1, 1, 9, 10], dtype=np.int64)\n\n# [[[[ 0.45507922  0.64057922  0.97157922  1.42257922  1.90732922\n#      2.22332922  2.70807922  3.15907922  3.49007922  3.67557922]\n#    [ 1.39437963  1.57987963  1.91087963  2.36187963  2.84662963\n#      3.16262963  3.64737963  4.09837963  4.42937963  4.61487963]\n#    [ 2.95130693  3.13680693  3.46780693  3.91880693  4.40355693\n#      4.71955693  5.20430693  5.65530693  5.98630693  6.17180693]\n#    [ 5.20525069  5.39075069  5.72175069  6.17275069  6.65750069\n#      6.97350069  7.45825069  7.90925069  8.24025069  8.42575069]\n#    [ 6.88975     7.07525     7.40625     7.85725     8.342\n#      8.658       9.14275     9.59375     9.92475    10.11025   ]\n#    [ 8.57424931  8.75974931  9.09074931  9.54174931 10.02649931\n#     10.34249931 10.82724931 11.27824931 11.60924931 11.79474931]\n#    [10.82819307 11.01369307 11.34469307 11.79569307 12.28044307\n#     12.59644307 13.08119307 13.53219307 13.86319307 14.04869307]\n#    [12.38512037 12.57062037 12.90162037 13.35262037 13.83737037\n#     14.15337037 14.63812037 15.08912037 15.42012037 15.60562037]\n#    [13.32442078 13.50992078 13.84092078 14.29192078 14.77667078\n#     15.09267078 15.57742078 16.02842078 16.35942078 16.54492078]]]]\noutput = interpolate_nd(\n    data, lambda x, _: cubic_coeffs(x), output_size=sizes\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, sizes],\n    outputs=[output],\n    name=\"test_resize_upsample_sizes_cubic\",\n)"
              },
              {
                "summary": "resize_upsample_sizes_nearest",
                "code": "node = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"\", \"\", \"sizes\"],\n    outputs=[\"Y\"],\n    mode=\"nearest\",\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2],\n                [3, 4],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\nsizes = np.array([1, 1, 7, 8], dtype=np.int64)\n\n# [[[[1. 1. 1. 1. 2. 2. 2. 2.]\n#    [1. 1. 1. 1. 2. 2. 2. 2.]\n#    [1. 1. 1. 1. 2. 2. 2. 2.]\n#    [1. 1. 1. 1. 2. 2. 2. 2.]\n#    [3. 3. 3. 3. 4. 4. 4. 4.]\n#    [3. 3. 3. 3. 4. 4. 4. 4.]\n#    [3. 3. 3. 3. 4. 4. 4. 4.]]]]\noutput = interpolate_nd(\n    data, lambda x, _: nearest_coeffs(x), output_size=sizes\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, sizes],\n    outputs=[output],\n    name=\"test_resize_upsample_sizes_nearest\",\n)"
              },
              {
                "summary": "resize_upsample_sizes_nearest_axes_2_3",
                "code": "axes = [2, 3]\nnode = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"\", \"\", \"sizes\"],\n    outputs=[\"Y\"],\n    mode=\"nearest\",\n    axes=axes,\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2],\n                [3, 4],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\nsizes = np.array([7, 8], dtype=np.int64)\n\n# [[[[1. 1. 1. 1. 2. 2. 2. 2.]\n#    [1. 1. 1. 1. 2. 2. 2. 2.]\n#    [1. 1. 1. 1. 2. 2. 2. 2.]\n#    [1. 1. 1. 1. 2. 2. 2. 2.]\n#    [3. 3. 3. 3. 4. 4. 4. 4.]\n#    [3. 3. 3. 3. 4. 4. 4. 4.]\n#    [3. 3. 3. 3. 4. 4. 4. 4.]]]]\noutput = interpolate_nd(\n    data, lambda x, _: nearest_coeffs(x), output_size=sizes, axes=axes\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, sizes],\n    outputs=[output],\n    name=\"test_resize_upsample_sizes_nearest_axes_2_3\",\n)"
              },
              {
                "summary": "resize_upsample_sizes_nearest_axes_3_2",
                "code": "axes = [3, 2]\nnode = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"\", \"\", \"sizes\"],\n    outputs=[\"Y\"],\n    mode=\"nearest\",\n    axes=axes,\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2],\n                [3, 4],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\nsizes = np.array([8, 7], dtype=np.int64)\n\n# [[[[1. 1. 1. 1. 2. 2. 2. 2.]\n#    [1. 1. 1. 1. 2. 2. 2. 2.]\n#    [1. 1. 1. 1. 2. 2. 2. 2.]\n#    [1. 1. 1. 1. 2. 2. 2. 2.]\n#    [3. 3. 3. 3. 4. 4. 4. 4.]\n#    [3. 3. 3. 3. 4. 4. 4. 4.]\n#    [3. 3. 3. 3. 4. 4. 4. 4.]]]]\noutput = interpolate_nd(\n    data, lambda x, _: nearest_coeffs(x), output_size=sizes, axes=axes\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, sizes],\n    outputs=[output],\n    name=\"test_resize_upsample_sizes_nearest_axes_3_2\",\n)"
              },
              {
                "summary": "resize_upsample_sizes_nearest_ceil_half_pixel",
                "code": "node = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"\", \"\", \"sizes\"],\n    outputs=[\"Y\"],\n    mode=\"nearest\",\n    coordinate_transformation_mode=\"half_pixel\",\n    nearest_mode=\"ceil\",\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2, 3, 4],\n                [5, 6, 7, 8],\n                [9, 10, 11, 12],\n                [13, 14, 15, 16],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\nsizes = np.array([1, 1, 8, 8], dtype=np.int64)\n\n# [[[[ 1.  2.  2.  3.  3.  4.  4.  4.]\n#    [ 5.  6.  6.  7.  7.  8.  8.  8.]\n#    [ 5.  6.  6.  7.  7.  8.  8.  8.]\n#    [ 9. 10. 10. 11. 11. 12. 12. 12.]\n#    [ 9. 10. 10. 11. 11. 12. 12. 12.]\n#    [13. 14. 14. 15. 15. 16. 16. 16.]\n#    [13. 14. 14. 15. 15. 16. 16. 16.]\n#    [13. 14. 14. 15. 15. 16. 16. 16.]]]]\noutput = interpolate_nd(\n    data, lambda x, _: nearest_coeffs(x, mode=\"ceil\"), output_size=sizes\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, sizes],\n    outputs=[output],\n    name=\"test_resize_upsample_sizes_nearest_ceil_half_pixel\",\n)"
              },
              {
                "summary": "resize_upsample_sizes_nearest_floor_align_corners",
                "code": "node = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"\", \"\", \"sizes\"],\n    outputs=[\"Y\"],\n    mode=\"nearest\",\n    coordinate_transformation_mode=\"align_corners\",\n    nearest_mode=\"floor\",\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2, 3, 4],\n                [5, 6, 7, 8],\n                [9, 10, 11, 12],\n                [13, 14, 15, 16],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\nsizes = np.array([1, 1, 8, 8], dtype=np.int64)\n\n# [[[[ 1.  1.  1.  2.  2.  3.  3.  4.]\n#    [ 1.  1.  1.  2.  2.  3.  3.  4.]\n#    [ 1.  1.  1.  2.  2.  3.  3.  4.]\n#    [ 5.  5.  5.  6.  6.  7.  7.  8.]\n#    [ 5.  5.  5.  6.  6.  7.  7.  8.]\n#    [ 9.  9.  9. 10. 10. 11. 11. 12.]\n#    [ 9.  9.  9. 10. 10. 11. 11. 12.]\n#    [13. 13. 13. 14. 14. 15. 15. 16.]]]]\noutput = interpolate_nd(\n    data,\n    lambda x, _: nearest_coeffs(x, mode=\"floor\"),\n    output_size=sizes,\n    coordinate_transformation_mode=\"align_corners\",\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, sizes],\n    outputs=[output],\n    name=\"test_resize_upsample_sizes_nearest_floor_align_corners\",\n)"
              },
              {
                "summary": "resize_upsample_sizes_nearest_not_larger",
                "code": "keep_aspect_ratio_policy = \"not_larger\"\naxes = [2, 3]\nnode = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"\", \"\", \"sizes\"],\n    outputs=[\"Y\"],\n    mode=\"nearest\",\n    axes=axes,\n    keep_aspect_ratio_policy=keep_aspect_ratio_policy,\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2],\n                [3, 4],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\nsizes = np.array([7, 8], dtype=np.int64)  # Results in 7x7\n\n# [[[[1. 1. 1. 1. 2. 2. 2.]\n#    [1. 1. 1. 1. 2. 2. 2.]\n#    [1. 1. 1. 1. 2. 2. 2.]\n#    [1. 1. 1. 1. 2. 2. 2.]\n#    [3. 3. 3. 3. 4. 4. 4.]\n#    [3. 3. 3. 3. 4. 4. 4.]\n#    [3. 3. 3. 3. 4. 4. 4.]]]]\noutput = interpolate_nd(\n    data,\n    lambda x, _: nearest_coeffs(x),\n    output_size=sizes,\n    axes=axes,\n    keep_aspect_ratio_policy=keep_aspect_ratio_policy,\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, sizes],\n    outputs=[output],\n    name=\"test_resize_upsample_sizes_nearest_not_larger\",\n)"
              },
              {
                "summary": "resize_upsample_sizes_nearest_not_smaller",
                "code": "keep_aspect_ratio_policy = \"not_smaller\"\naxes = [2, 3]\nnode = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"\", \"\", \"sizes\"],\n    outputs=[\"Y\"],\n    mode=\"nearest\",\n    axes=axes,\n    keep_aspect_ratio_policy=keep_aspect_ratio_policy,\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2],\n                [3, 4],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\nsizes = np.array([7, 8], dtype=np.int64)  # Results in 8x8\n\n# [[[[1. 1. 1. 1. 2. 2. 2. 2.]\n#    [1. 1. 1. 1. 2. 2. 2. 2.]\n#    [1. 1. 1. 1. 2. 2. 2. 2.]\n#    [1. 1. 1. 1. 2. 2. 2. 2.]\n#    [3. 3. 3. 3. 4. 4. 4. 4.]\n#    [3. 3. 3. 3. 4. 4. 4. 4.]\n#    [3. 3. 3. 3. 4. 4. 4. 4.]]]]\noutput = interpolate_nd(\n    data,\n    lambda x, _: nearest_coeffs(x),\n    output_size=sizes,\n    axes=axes,\n    keep_aspect_ratio_policy=keep_aspect_ratio_policy,\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, sizes],\n    outputs=[output],\n    name=\"test_resize_upsample_sizes_nearest_not_smaller\",\n)"
              },
              {
                "summary": "resize_upsample_sizes_nearest_round_prefer_ceil_asymmetric",
                "code": "node = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"\", \"\", \"sizes\"],\n    outputs=[\"Y\"],\n    mode=\"nearest\",\n    coordinate_transformation_mode=\"asymmetric\",\n    nearest_mode=\"round_prefer_ceil\",\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2, 3, 4],\n                [5, 6, 7, 8],\n                [9, 10, 11, 12],\n                [13, 14, 15, 16],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\nsizes = np.array([1, 1, 8, 8], dtype=np.int64)\n\n# [[[[ 1.  2.  2.  3.  3.  4.  4.  4.]\n#    [ 5.  6.  6.  7.  7.  8.  8.  8.]\n#    [ 5.  6.  6.  7.  7.  8.  8.  8.]\n#    [ 9. 10. 10. 11. 11. 12. 12. 12.]\n#    [ 9. 10. 10. 11. 11. 12. 12. 12.]\n#    [13. 14. 14. 15. 15. 16. 16. 16.]\n#    [13. 14. 14. 15. 15. 16. 16. 16.]\n#    [13. 14. 14. 15. 15. 16. 16. 16.]]]]\noutput = interpolate_nd(\n    data,\n    lambda x, _: nearest_coeffs(x, mode=\"round_prefer_ceil\"),\n    output_size=sizes,\n    coordinate_transformation_mode=\"asymmetric\",\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, sizes],\n    outputs=[output],\n    name=\"test_resize_upsample_sizes_nearest_round_prefer_ceil_asymmetric\",\n)"
              }
            ]
          }
        },
        {
          "name": "Conv__240",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "X",
              "value": [
                {
                  "name": "289",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        128,
                        18,
                        32
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "W",
              "value": [
                {
                  "name": "Conv2D_32/filter:0",
                  "initializer": {
                    "name": "Conv2D_32/filter:0",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float32",
                      "shape": {
                        "dimensions": [
                          24,
                          128,
                          1,
                          1
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        24,
                        128,
                        1,
                        1
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "B",
              "value": [
                {
                  "name": "conv2d_31_1/y:0",
                  "initializer": {
                    "name": "conv2d_31_1/y:0",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float32",
                      "shape": {
                        "dimensions": [
                          24
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        24
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "Y",
              "value": [
                {
                  "name": "Conv__240:0",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        24,
                        18,
                        32
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [
            {
              "name": "dilations",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "strides",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "kernel_shape",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "group",
              "type": "int64",
              "value": {
                "type": "bigint",
                "value": "1"
              }
            }
          ],
          "type": {
            "name": "Conv",
            "module": "ai.onnx",
            "version": 11,
            "description": "The convolution operator consumes an input tensor and a filter, and\ncomputes the output.",
            "attributes": [
              {
                "name": "auto_pad",
                "type": "string",
                "required": false,
                "default": "NOTSET",
                "description": "auto_pad must be either NOTSET, SAME_UPPER, SAME_LOWER or VALID. Where default value is NOTSET, which means explicit padding is used. SAME_UPPER or SAME_LOWER mean pad the input so that `output_shape[i] = ceil(input_shape[i] / strides[i])` for each axis `i`. The padding is split between the two sides equally or almost equally (depending on whether it is even or odd). In case the padding is an odd number, the extra padding is added at the end for SAME_UPPER and at the beginning for SAME_LOWER."
              },
              {
                "name": "dilations",
                "type": "int64[]",
                "required": false,
                "description": "dilation value along each spatial axis of the filter. If not present, the dilation defaults is 1 along each spatial axis."
              },
              {
                "name": "group",
                "type": "int64",
                "required": false,
                "default": 1,
                "description": "number of groups input channels and output channels are divided into."
              },
              {
                "name": "kernel_shape",
                "type": "int64[]",
                "required": false,
                "description": "The shape of the convolution kernel. If not present, should be inferred from input W."
              },
              {
                "name": "pads",
                "type": "int64[]",
                "required": false,
                "description": "Padding for the beginning and ending along each spatial axis, it can take any value greater than or equal to 0. The value represent the number of pixels added to the beginning and end part of the corresponding axis. `pads` format should be as follow [x1_begin, x2_begin...x1_end, x2_end,...], where xi_begin the number of pixels added at the beginning of axis `i` and xi_end, the number of pixels added at the end of axis `i`. This attribute cannot be used simultaneously with auto_pad attribute. If not present, the padding defaults to 0 along start and end of each spatial axis."
              },
              {
                "name": "strides",
                "type": "int64[]",
                "required": false,
                "description": "Stride along each spatial axis. If not present, the stride defaults is 1 along each spatial axis."
              }
            ],
            "inputs": [
              {
                "name": "X",
                "type": "T",
                "description": "Input data tensor from previous layer; has size (N x C x H x W), where N is the batch size, C is the number of channels, and H and W are the height and width. Note that this is for the 2D image. Otherwise the size is (N x C x D1 x D2 ... x Dn). Optionally, if dimension denotation is in effect, the operation expects input data tensor to arrive with the dimension denotation of [DATA_BATCH, DATA_CHANNEL, DATA_FEATURE, DATA_FEATURE ...]."
              },
              {
                "name": "W",
                "type": "T",
                "description": "The weight tensor that will be used in the convolutions; has size (M x C/group x kH x kW), where C is the number of channels, and kH and kW are the height and width of the kernel, and M is the number of feature maps. For more than 2 dimensions, the kernel shape will be (M x C/group x k1 x k2 x ... x kn), where (k1 x k2 x ... kn) is the dimension of the kernel. Optionally, if dimension denotation is in effect, the operation expects the weight tensor to arrive with the dimension denotation of [FILTER_OUT_CHANNEL, FILTER_IN_CHANNEL, FILTER_SPATIAL, FILTER_SPATIAL ...]. Assuming zero based indices for the shape array, X.shape[1] == (W.shape[1] * group) == C and W.shape[0] mod G == 0. Or in other words FILTER_IN_CHANNEL multiplied by the number of groups should be equal to DATA_CHANNEL and the number of feature maps M should be a multiple of the number of groups G."
              },
              {
                "name": "B",
                "type": "T",
                "option": "optional",
                "description": "Optional 1D bias to be added to the convolution, has size of M."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "Y",
                "type": "T",
                "description": "Output data tensor that contains the result of the convolution. The output dimensions are functions of the kernel size, stride size, and pad lengths."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain input and output types to float tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "conv",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[1, 1, 1, 1],\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 21.0, 27.0, 33.0, 24.0],  # (1, 1, 5, 5) output tensor\n                [33.0, 54.0, 63.0, 72.0, 51.0],\n                [63.0, 99.0, 108.0, 117.0, 81.0],\n                [93.0, 144.0, 153.0, 162.0, 111.0],\n                [72.0, 111.0, 117.0, 123.0, 84.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_basic_conv_with_padding\",\n)\n\n# Convolution without padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[0, 0, 0, 0],\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 63.0, 72.0],  # (1, 1, 3, 3) output tensor\n                [99.0, 108.0, 117.0],\n                [144.0, 153.0, 162.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_basic_conv_without_padding\",\n)"
              },
              {
                "summary": "conv_with_autopad_same",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with auto_pad='SAME_LOWER' and strides=2\nnode = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    auto_pad=\"SAME_LOWER\",\n    kernel_shape=[3, 3],\n    strides=[2, 2],\n)\ny = np.array(\n    [[[[12.0, 27.0, 24.0], [63.0, 108.0, 81.0], [72.0, 117.0, 84.0]]]]\n).astype(np.float32)\nexpect(node, inputs=[x, W], outputs=[y], name=\"test_conv_with_autopad_same\")"
              },
              {
                "summary": "conv_with_strides",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 7, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n                [25.0, 26.0, 27.0, 28.0, 29.0],\n                [30.0, 31.0, 32.0, 33.0, 34.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with strides=2 and padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 1, 1, 1],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 27.0, 24.0],  # (1, 1, 4, 3) output tensor\n                [63.0, 108.0, 81.0],\n                [123.0, 198.0, 141.0],\n                [112.0, 177.0, 124.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_conv_with_strides_padding\",\n)\n\n# Convolution with strides=2 and no padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[0, 0, 0, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 72.0],  # (1, 1, 3, 2) output tensor\n                [144.0, 162.0],\n                [234.0, 252.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_conv_with_strides_no_padding\",\n)\n\n# Convolution with strides=2 and padding only along one dimension (the H dimension in NxCxHxW tensor)\nnode_with_asymmetric_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 0, 1, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_asymmetric_padding = np.array(\n    [\n        [\n            [\n                [21.0, 33.0],  # (1, 1, 4, 2) output tensor\n                [99.0, 117.0],\n                [189.0, 207.0],\n                [171.0, 183.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_asymmetric_padding,\n    inputs=[x, W],\n    outputs=[y_with_asymmetric_padding],\n    name=\"test_conv_with_strides_and_asymmetric_padding\",\n)"
              }
            ],
            "category": "Layer"
          }
        },
        {
          "name": "add_5__xeno_compat__1",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "A",
              "value": [
                {
                  "name": "add__xeno_compat__1:0",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        24,
                        18,
                        32
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "B",
              "value": [
                {
                  "name": "Conv__240:0",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        24,
                        18,
                        32
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "C",
              "value": [
                {
                  "name": "add_5__xeno_compat__1:0",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        24,
                        18,
                        32
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "Add",
            "module": "ai.onnx",
            "version": 14,
            "description": "Performs element-wise binary addition (with Numpy-style broadcasting support).\n\nThis operator supports **multidirectional (i.e., Numpy-style) broadcasting**; for more details please check [the doc](https://github.com/onnx/onnx/blob/master/docs/Broadcasting.md).\n\n(Opset 14 change): Extend supported types to include uint8, int8, uint16, and int16.\n",
            "inputs": [
              {
                "name": "A",
                "type": "T",
                "description": "First operand."
              },
              {
                "name": "B",
                "type": "T",
                "description": "Second operand."
              }
            ],
            "min_input": 2,
            "max_input": 2,
            "outputs": [
              {
                "name": "C",
                "type": "T",
                "description": "Result, has same element type as two inputs"
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "type_constraints": [
              {
                "description": "Constrain input and output types to all numeric tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(uint8)",
                  "tensor(uint16)",
                  "tensor(uint32)",
                  "tensor(uint64)",
                  "tensor(int8)",
                  "tensor(int16)",
                  "tensor(int32)",
                  "tensor(int64)",
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)",
                  "tensor(bfloat16)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "add",
                "code": "node = onnx.helper.make_node(\n    \"Add\",\n    inputs=[\"x\", \"y\"],\n    outputs=[\"sum\"],\n)\n\nx = np.random.randn(3, 4, 5).astype(np.float32)\ny = np.random.randn(3, 4, 5).astype(np.float32)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add\")\n\nx = np.random.randint(24, size=(3, 4, 5), dtype=np.int8)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.int8)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add_int8\")\n\nx = np.random.randint(24, size=(3, 4, 5), dtype=np.int16)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.int16)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add_int16\")\n\nx = np.random.randint(24, size=(3, 4, 5), dtype=np.uint8)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.uint8)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add_uint8\")\n\nx = np.random.randint(24, size=(3, 4, 5), dtype=np.uint16)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.uint16)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add_uint16\")\n\nx = np.random.randint(24, size=(3, 4, 5), dtype=np.uint32)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.uint32)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add_uint32\")\n\nx = np.random.randint(24, size=(3, 4, 5), dtype=np.uint64)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.uint64)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add_uint64\")"
              },
              {
                "summary": "add_broadcast",
                "code": "node = onnx.helper.make_node(\n    \"Add\",\n    inputs=[\"x\", \"y\"],\n    outputs=[\"sum\"],\n)\n\nx = np.random.randn(3, 4, 5).astype(np.float32)\ny = np.random.randn(5).astype(np.float32)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add_bcast\")"
              }
            ]
          }
        },
        {
          "name": "global_average_pooling2d_7",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "X",
              "value": [
                {
                  "name": "add_5__xeno_compat__1:0",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        24,
                        18,
                        32
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "Y",
              "value": [
                {
                  "name": "global_average_pooling2d_7:0",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        24,
                        1,
                        1
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "GlobalAveragePool",
            "module": "ai.onnx",
            "version": 1,
            "description": "GlobalAveragePool consumes an input tensor X and applies average pooling across\n the values in the same channel. This is equivalent to AveragePool with kernel size\n equal to the spatial dimension of input tensor.",
            "inputs": [
              {
                "name": "X",
                "type": "T",
                "description": "Input data tensor from the previous operator; dimensions for image case are (N x C x H x W), where N is the batch size, C is the number of channels, and H and W are the height and the width of the data. For non image case, the dimensions are in the form of (N x C x D1 x D2 ... Dn), where N is the batch size."
              }
            ],
            "min_input": 1,
            "max_input": 1,
            "outputs": [
              {
                "name": "Y",
                "type": "T",
                "description": "Output data tensor from pooling across the input tensor. The output tensor has the same rank as the input. The first two dimensions of output shape are the same as the input (N x C), while the other dimensions are all 1."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "type_constraints": [
              {
                "description": "Constrain input and output types to float tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "globalaveragepool",
                "code": "node = onnx.helper.make_node(\n    \"GlobalAveragePool\",\n    inputs=[\"x\"],\n    outputs=[\"y\"],\n)\nx = np.random.randn(1, 3, 5, 5).astype(np.float32)\ny = np.mean(x, axis=tuple(range(2, np.ndim(x))), keepdims=True)\nexpect(node, inputs=[x], outputs=[y], name=\"test_globalaveragepool\")"
              },
              {
                "summary": "globalaveragepool_precomputed",
                "code": "node = onnx.helper.make_node(\n    \"GlobalAveragePool\",\n    inputs=[\"x\"],\n    outputs=[\"y\"],\n)\nx = np.array(\n    [\n        [\n            [\n                [1, 2, 3],\n                [4, 5, 6],\n                [7, 8, 9],\n            ]\n        ]\n    ]\n).astype(np.float32)\ny = np.array([[[[5]]]]).astype(np.float32)\nexpect(node, inputs=[x], outputs=[y], name=\"test_globalaveragepool_precomputed\")"
              }
            ],
            "category": "Pool"
          }
        },
        {
          "name": "Conv__243",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "X",
              "value": [
                {
                  "name": "global_average_pooling2d_7:0",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        24,
                        1,
                        1
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "W",
              "value": [
                {
                  "name": "Conv2D_33/filter:0",
                  "initializer": {
                    "name": "Conv2D_33/filter:0",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float32",
                      "shape": {
                        "dimensions": [
                          24,
                          24,
                          1,
                          1
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        24,
                        24,
                        1,
                        1
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "B",
              "value": [
                {
                  "name": "conv2d_32_1/y:0",
                  "initializer": {
                    "name": "conv2d_32_1/y:0",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float32",
                      "shape": {
                        "dimensions": [
                          24
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        24
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "Y",
              "value": [
                {
                  "name": "Conv__243:0",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        24,
                        1,
                        1
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [
            {
              "name": "dilations",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "strides",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "kernel_shape",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "group",
              "type": "int64",
              "value": {
                "type": "bigint",
                "value": "1"
              }
            }
          ],
          "type": {
            "name": "Conv",
            "module": "ai.onnx",
            "version": 11,
            "description": "The convolution operator consumes an input tensor and a filter, and\ncomputes the output.",
            "attributes": [
              {
                "name": "auto_pad",
                "type": "string",
                "required": false,
                "default": "NOTSET",
                "description": "auto_pad must be either NOTSET, SAME_UPPER, SAME_LOWER or VALID. Where default value is NOTSET, which means explicit padding is used. SAME_UPPER or SAME_LOWER mean pad the input so that `output_shape[i] = ceil(input_shape[i] / strides[i])` for each axis `i`. The padding is split between the two sides equally or almost equally (depending on whether it is even or odd). In case the padding is an odd number, the extra padding is added at the end for SAME_UPPER and at the beginning for SAME_LOWER."
              },
              {
                "name": "dilations",
                "type": "int64[]",
                "required": false,
                "description": "dilation value along each spatial axis of the filter. If not present, the dilation defaults is 1 along each spatial axis."
              },
              {
                "name": "group",
                "type": "int64",
                "required": false,
                "default": 1,
                "description": "number of groups input channels and output channels are divided into."
              },
              {
                "name": "kernel_shape",
                "type": "int64[]",
                "required": false,
                "description": "The shape of the convolution kernel. If not present, should be inferred from input W."
              },
              {
                "name": "pads",
                "type": "int64[]",
                "required": false,
                "description": "Padding for the beginning and ending along each spatial axis, it can take any value greater than or equal to 0. The value represent the number of pixels added to the beginning and end part of the corresponding axis. `pads` format should be as follow [x1_begin, x2_begin...x1_end, x2_end,...], where xi_begin the number of pixels added at the beginning of axis `i` and xi_end, the number of pixels added at the end of axis `i`. This attribute cannot be used simultaneously with auto_pad attribute. If not present, the padding defaults to 0 along start and end of each spatial axis."
              },
              {
                "name": "strides",
                "type": "int64[]",
                "required": false,
                "description": "Stride along each spatial axis. If not present, the stride defaults is 1 along each spatial axis."
              }
            ],
            "inputs": [
              {
                "name": "X",
                "type": "T",
                "description": "Input data tensor from previous layer; has size (N x C x H x W), where N is the batch size, C is the number of channels, and H and W are the height and width. Note that this is for the 2D image. Otherwise the size is (N x C x D1 x D2 ... x Dn). Optionally, if dimension denotation is in effect, the operation expects input data tensor to arrive with the dimension denotation of [DATA_BATCH, DATA_CHANNEL, DATA_FEATURE, DATA_FEATURE ...]."
              },
              {
                "name": "W",
                "type": "T",
                "description": "The weight tensor that will be used in the convolutions; has size (M x C/group x kH x kW), where C is the number of channels, and kH and kW are the height and width of the kernel, and M is the number of feature maps. For more than 2 dimensions, the kernel shape will be (M x C/group x k1 x k2 x ... x kn), where (k1 x k2 x ... kn) is the dimension of the kernel. Optionally, if dimension denotation is in effect, the operation expects the weight tensor to arrive with the dimension denotation of [FILTER_OUT_CHANNEL, FILTER_IN_CHANNEL, FILTER_SPATIAL, FILTER_SPATIAL ...]. Assuming zero based indices for the shape array, X.shape[1] == (W.shape[1] * group) == C and W.shape[0] mod G == 0. Or in other words FILTER_IN_CHANNEL multiplied by the number of groups should be equal to DATA_CHANNEL and the number of feature maps M should be a multiple of the number of groups G."
              },
              {
                "name": "B",
                "type": "T",
                "option": "optional",
                "description": "Optional 1D bias to be added to the convolution, has size of M."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "Y",
                "type": "T",
                "description": "Output data tensor that contains the result of the convolution. The output dimensions are functions of the kernel size, stride size, and pad lengths."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain input and output types to float tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "conv",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[1, 1, 1, 1],\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 21.0, 27.0, 33.0, 24.0],  # (1, 1, 5, 5) output tensor\n                [33.0, 54.0, 63.0, 72.0, 51.0],\n                [63.0, 99.0, 108.0, 117.0, 81.0],\n                [93.0, 144.0, 153.0, 162.0, 111.0],\n                [72.0, 111.0, 117.0, 123.0, 84.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_basic_conv_with_padding\",\n)\n\n# Convolution without padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[0, 0, 0, 0],\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 63.0, 72.0],  # (1, 1, 3, 3) output tensor\n                [99.0, 108.0, 117.0],\n                [144.0, 153.0, 162.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_basic_conv_without_padding\",\n)"
              },
              {
                "summary": "conv_with_autopad_same",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with auto_pad='SAME_LOWER' and strides=2\nnode = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    auto_pad=\"SAME_LOWER\",\n    kernel_shape=[3, 3],\n    strides=[2, 2],\n)\ny = np.array(\n    [[[[12.0, 27.0, 24.0], [63.0, 108.0, 81.0], [72.0, 117.0, 84.0]]]]\n).astype(np.float32)\nexpect(node, inputs=[x, W], outputs=[y], name=\"test_conv_with_autopad_same\")"
              },
              {
                "summary": "conv_with_strides",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 7, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n                [25.0, 26.0, 27.0, 28.0, 29.0],\n                [30.0, 31.0, 32.0, 33.0, 34.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with strides=2 and padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 1, 1, 1],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 27.0, 24.0],  # (1, 1, 4, 3) output tensor\n                [63.0, 108.0, 81.0],\n                [123.0, 198.0, 141.0],\n                [112.0, 177.0, 124.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_conv_with_strides_padding\",\n)\n\n# Convolution with strides=2 and no padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[0, 0, 0, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 72.0],  # (1, 1, 3, 2) output tensor\n                [144.0, 162.0],\n                [234.0, 252.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_conv_with_strides_no_padding\",\n)\n\n# Convolution with strides=2 and padding only along one dimension (the H dimension in NxCxHxW tensor)\nnode_with_asymmetric_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 0, 1, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_asymmetric_padding = np.array(\n    [\n        [\n            [\n                [21.0, 33.0],  # (1, 1, 4, 2) output tensor\n                [99.0, 117.0],\n                [189.0, 207.0],\n                [171.0, 183.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_asymmetric_padding,\n    inputs=[x, W],\n    outputs=[y_with_asymmetric_padding],\n    name=\"test_conv_with_strides_and_asymmetric_padding\",\n)"
              }
            ],
            "category": "Layer"
          }
        },
        {
          "name": "re_lu_13",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "X",
              "value": [
                {
                  "name": "Conv__243:0",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        24,
                        1,
                        1
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "Y",
              "value": [
                {
                  "name": "re_lu_13:0",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        24,
                        1,
                        1
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "Relu",
            "module": "ai.onnx",
            "version": 14,
            "description": "Relu takes one input data (Tensor<T>) and produces one output data\n(Tensor<T>) where the rectified linear function, y = max(0, x), is applied to\nthe tensor elementwise.\n",
            "inputs": [
              {
                "name": "X",
                "type": "T",
                "description": "Input tensor"
              }
            ],
            "min_input": 1,
            "max_input": 1,
            "outputs": [
              {
                "name": "Y",
                "type": "T",
                "description": "Output tensor"
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "type_constraints": [
              {
                "description": "Constrain input and output types to signed numeric tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(float)",
                  "tensor(int32)",
                  "tensor(int8)",
                  "tensor(int16)",
                  "tensor(int64)",
                  "tensor(float16)",
                  "tensor(double)",
                  "tensor(bfloat16)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "relu",
                "code": "node = onnx.helper.make_node(\n    \"Relu\",\n    inputs=[\"x\"],\n    outputs=[\"y\"],\n)\nx = np.random.randn(3, 4, 5).astype(np.float32)\ny = np.clip(x, 0, np.inf)\n\nexpect(node, inputs=[x], outputs=[y], name=\"test_relu\")"
              }
            ],
            "category": "Activation"
          }
        },
        {
          "name": "Conv__244",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "X",
              "value": [
                {
                  "name": "re_lu_13:0",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        24,
                        1,
                        1
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "W",
              "value": [
                {
                  "name": "Conv2D_34/filter:0",
                  "initializer": {
                    "name": "Conv2D_34/filter:0",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float32",
                      "shape": {
                        "dimensions": [
                          24,
                          24,
                          1,
                          1
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        24,
                        24,
                        1,
                        1
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "B",
              "value": [
                {
                  "name": "conv2d_33_1/y:0",
                  "initializer": {
                    "name": "conv2d_33_1/y:0",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float32",
                      "shape": {
                        "dimensions": [
                          24
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        24
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "Y",
              "value": [
                {
                  "name": "Conv__244:0",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        24,
                        1,
                        1
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [
            {
              "name": "dilations",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "strides",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "kernel_shape",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "group",
              "type": "int64",
              "value": {
                "type": "bigint",
                "value": "1"
              }
            }
          ],
          "type": {
            "name": "Conv",
            "module": "ai.onnx",
            "version": 11,
            "description": "The convolution operator consumes an input tensor and a filter, and\ncomputes the output.",
            "attributes": [
              {
                "name": "auto_pad",
                "type": "string",
                "required": false,
                "default": "NOTSET",
                "description": "auto_pad must be either NOTSET, SAME_UPPER, SAME_LOWER or VALID. Where default value is NOTSET, which means explicit padding is used. SAME_UPPER or SAME_LOWER mean pad the input so that `output_shape[i] = ceil(input_shape[i] / strides[i])` for each axis `i`. The padding is split between the two sides equally or almost equally (depending on whether it is even or odd). In case the padding is an odd number, the extra padding is added at the end for SAME_UPPER and at the beginning for SAME_LOWER."
              },
              {
                "name": "dilations",
                "type": "int64[]",
                "required": false,
                "description": "dilation value along each spatial axis of the filter. If not present, the dilation defaults is 1 along each spatial axis."
              },
              {
                "name": "group",
                "type": "int64",
                "required": false,
                "default": 1,
                "description": "number of groups input channels and output channels are divided into."
              },
              {
                "name": "kernel_shape",
                "type": "int64[]",
                "required": false,
                "description": "The shape of the convolution kernel. If not present, should be inferred from input W."
              },
              {
                "name": "pads",
                "type": "int64[]",
                "required": false,
                "description": "Padding for the beginning and ending along each spatial axis, it can take any value greater than or equal to 0. The value represent the number of pixels added to the beginning and end part of the corresponding axis. `pads` format should be as follow [x1_begin, x2_begin...x1_end, x2_end,...], where xi_begin the number of pixels added at the beginning of axis `i` and xi_end, the number of pixels added at the end of axis `i`. This attribute cannot be used simultaneously with auto_pad attribute. If not present, the padding defaults to 0 along start and end of each spatial axis."
              },
              {
                "name": "strides",
                "type": "int64[]",
                "required": false,
                "description": "Stride along each spatial axis. If not present, the stride defaults is 1 along each spatial axis."
              }
            ],
            "inputs": [
              {
                "name": "X",
                "type": "T",
                "description": "Input data tensor from previous layer; has size (N x C x H x W), where N is the batch size, C is the number of channels, and H and W are the height and width. Note that this is for the 2D image. Otherwise the size is (N x C x D1 x D2 ... x Dn). Optionally, if dimension denotation is in effect, the operation expects input data tensor to arrive with the dimension denotation of [DATA_BATCH, DATA_CHANNEL, DATA_FEATURE, DATA_FEATURE ...]."
              },
              {
                "name": "W",
                "type": "T",
                "description": "The weight tensor that will be used in the convolutions; has size (M x C/group x kH x kW), where C is the number of channels, and kH and kW are the height and width of the kernel, and M is the number of feature maps. For more than 2 dimensions, the kernel shape will be (M x C/group x k1 x k2 x ... x kn), where (k1 x k2 x ... kn) is the dimension of the kernel. Optionally, if dimension denotation is in effect, the operation expects the weight tensor to arrive with the dimension denotation of [FILTER_OUT_CHANNEL, FILTER_IN_CHANNEL, FILTER_SPATIAL, FILTER_SPATIAL ...]. Assuming zero based indices for the shape array, X.shape[1] == (W.shape[1] * group) == C and W.shape[0] mod G == 0. Or in other words FILTER_IN_CHANNEL multiplied by the number of groups should be equal to DATA_CHANNEL and the number of feature maps M should be a multiple of the number of groups G."
              },
              {
                "name": "B",
                "type": "T",
                "option": "optional",
                "description": "Optional 1D bias to be added to the convolution, has size of M."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "Y",
                "type": "T",
                "description": "Output data tensor that contains the result of the convolution. The output dimensions are functions of the kernel size, stride size, and pad lengths."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain input and output types to float tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "conv",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[1, 1, 1, 1],\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 21.0, 27.0, 33.0, 24.0],  # (1, 1, 5, 5) output tensor\n                [33.0, 54.0, 63.0, 72.0, 51.0],\n                [63.0, 99.0, 108.0, 117.0, 81.0],\n                [93.0, 144.0, 153.0, 162.0, 111.0],\n                [72.0, 111.0, 117.0, 123.0, 84.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_basic_conv_with_padding\",\n)\n\n# Convolution without padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[0, 0, 0, 0],\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 63.0, 72.0],  # (1, 1, 3, 3) output tensor\n                [99.0, 108.0, 117.0],\n                [144.0, 153.0, 162.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_basic_conv_without_padding\",\n)"
              },
              {
                "summary": "conv_with_autopad_same",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with auto_pad='SAME_LOWER' and strides=2\nnode = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    auto_pad=\"SAME_LOWER\",\n    kernel_shape=[3, 3],\n    strides=[2, 2],\n)\ny = np.array(\n    [[[[12.0, 27.0, 24.0], [63.0, 108.0, 81.0], [72.0, 117.0, 84.0]]]]\n).astype(np.float32)\nexpect(node, inputs=[x, W], outputs=[y], name=\"test_conv_with_autopad_same\")"
              },
              {
                "summary": "conv_with_strides",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 7, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n                [25.0, 26.0, 27.0, 28.0, 29.0],\n                [30.0, 31.0, 32.0, 33.0, 34.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with strides=2 and padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 1, 1, 1],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 27.0, 24.0],  # (1, 1, 4, 3) output tensor\n                [63.0, 108.0, 81.0],\n                [123.0, 198.0, 141.0],\n                [112.0, 177.0, 124.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_conv_with_strides_padding\",\n)\n\n# Convolution with strides=2 and no padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[0, 0, 0, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 72.0],  # (1, 1, 3, 2) output tensor\n                [144.0, 162.0],\n                [234.0, 252.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_conv_with_strides_no_padding\",\n)\n\n# Convolution with strides=2 and padding only along one dimension (the H dimension in NxCxHxW tensor)\nnode_with_asymmetric_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 0, 1, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_asymmetric_padding = np.array(\n    [\n        [\n            [\n                [21.0, 33.0],  # (1, 1, 4, 2) output tensor\n                [99.0, 117.0],\n                [189.0, 207.0],\n                [171.0, 183.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_asymmetric_padding,\n    inputs=[x, W],\n    outputs=[y_with_asymmetric_padding],\n    name=\"test_conv_with_strides_and_asymmetric_padding\",\n)"
              }
            ],
            "category": "Layer"
          }
        },
        {
          "name": "activation_7",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "X",
              "value": [
                {
                  "name": "Conv__244:0",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        24,
                        1,
                        1
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "Y",
              "value": [
                {
                  "name": "activation_7:0",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        24,
                        1,
                        1
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "Sigmoid",
            "module": "ai.onnx",
            "version": 13,
            "description": "Sigmoid takes one input data (Tensor<T>) and produces one output data\n(Tensor<T>) where the sigmoid function, y = 1 / (1 + exp(-x)), is applied to the\ntensor elementwise.\n",
            "inputs": [
              {
                "name": "X",
                "type": "T",
                "description": "Input tensor"
              }
            ],
            "min_input": 1,
            "max_input": 1,
            "outputs": [
              {
                "name": "Y",
                "type": "T",
                "description": "Output tensor"
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "type_constraints": [
              {
                "description": "Constrain input and output types to float tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)",
                  "tensor(bfloat16)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "sigmoid",
                "code": "node = onnx.helper.make_node(\n    \"Sigmoid\",\n    inputs=[\"x\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([-1, 0, 1]).astype(np.float32)\ny = 1.0 / (\n    1.0 + np.exp(np.negative(x))\n)  # expected output [0.26894143, 0.5, 0.7310586]\nexpect(node, inputs=[x], outputs=[y], name=\"test_sigmoid_example\")\n\nx = np.random.randn(3, 4, 5).astype(np.float32)\ny = 1.0 / (1.0 + np.exp(np.negative(x)))\nexpect(node, inputs=[x], outputs=[y], name=\"test_sigmoid\")"
              }
            ],
            "category": "Activation"
          }
        },
        {
          "name": "multiply_7",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "A",
              "value": [
                {
                  "name": "add__xeno_compat__1:0",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        24,
                        18,
                        32
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "B",
              "value": [
                {
                  "name": "activation_7:0",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        24,
                        1,
                        1
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "C",
              "value": [
                {
                  "name": "multiply_7:0",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        24,
                        18,
                        32
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "Mul",
            "module": "ai.onnx",
            "version": 14,
            "description": "Performs element-wise binary multiplication (with Numpy-style broadcasting support).\n\nThis operator supports **multidirectional (i.e., Numpy-style) broadcasting**; for more details please check [the doc](https://github.com/onnx/onnx/blob/master/docs/Broadcasting.md).\n\n(Opset 14 change): Extend supported types to include uint8, int8, uint16, and int16.\n",
            "inputs": [
              {
                "name": "A",
                "type": "T",
                "description": "First operand."
              },
              {
                "name": "B",
                "type": "T",
                "description": "Second operand."
              }
            ],
            "min_input": 2,
            "max_input": 2,
            "outputs": [
              {
                "name": "C",
                "type": "T",
                "description": "Result, has same element type as two inputs"
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "type_constraints": [
              {
                "description": "Constrain input and output types to all numeric tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(uint8)",
                  "tensor(uint16)",
                  "tensor(uint32)",
                  "tensor(uint64)",
                  "tensor(int8)",
                  "tensor(int16)",
                  "tensor(int32)",
                  "tensor(int64)",
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)",
                  "tensor(bfloat16)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "mul",
                "code": "node = onnx.helper.make_node(\n    \"Mul\",\n    inputs=[\"x\", \"y\"],\n    outputs=[\"z\"],\n)\n\nx = np.array([1, 2, 3]).astype(np.float32)\ny = np.array([4, 5, 6]).astype(np.float32)\nz = x * y  # expected output [4., 10., 18.]\nexpect(node, inputs=[x, y], outputs=[z], name=\"test_mul_example\")\n\nx = np.random.randn(3, 4, 5).astype(np.float32)\ny = np.random.randn(3, 4, 5).astype(np.float32)\nz = x * y\nexpect(node, inputs=[x, y], outputs=[z], name=\"test_mul\")\n\nx = np.random.randint(4, size=(3, 4, 5), dtype=np.int8)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.int8)\nz = x * y\nexpect(node, inputs=[x, y], outputs=[z], name=\"test_mul_int8\")\n\nx = np.random.randint(4, size=(3, 4, 5), dtype=np.int16)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.int16)\nz = x * y\nexpect(node, inputs=[x, y], outputs=[z], name=\"test_mul_int16\")\n\nx = np.random.randint(4, size=(3, 4, 5), dtype=np.uint8)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.uint8)\nz = x * y\nexpect(node, inputs=[x, y], outputs=[z], name=\"test_mul_uint8\")\n\nx = np.random.randint(4, size=(3, 4, 5), dtype=np.uint16)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.uint16)\nz = x * y\nexpect(node, inputs=[x, y], outputs=[z], name=\"test_mul_uint16\")\n\nx = np.random.randint(4, size=(3, 4, 5), dtype=np.uint32)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.uint32)\nz = x * y\nexpect(node, inputs=[x, y], outputs=[z], name=\"test_mul_uint32\")\n\nx = np.random.randint(4, size=(3, 4, 5), dtype=np.uint64)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.uint64)\nz = x * y\nexpect(node, inputs=[x, y], outputs=[z], name=\"test_mul_uint64\")"
              },
              {
                "summary": "mul_broadcast",
                "code": "node = onnx.helper.make_node(\n    \"Mul\",\n    inputs=[\"x\", \"y\"],\n    outputs=[\"z\"],\n)\n\nx = np.random.randn(3, 4, 5).astype(np.float32)\ny = np.random.randn(5).astype(np.float32)\nz = x * y\nexpect(node, inputs=[x, y], outputs=[z], name=\"test_mul_bcast\")"
              }
            ]
          }
        },
        {
          "name": "add_6__xeno_compat__1",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "A",
              "value": [
                {
                  "name": "multiply_7:0",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        24,
                        18,
                        32
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "B",
              "value": [
                {
                  "name": "Conv__240:0",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        24,
                        18,
                        32
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "C",
              "value": [
                {
                  "name": "add_6__xeno_compat__1:0",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        24,
                        18,
                        32
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "Add",
            "module": "ai.onnx",
            "version": 14,
            "description": "Performs element-wise binary addition (with Numpy-style broadcasting support).\n\nThis operator supports **multidirectional (i.e., Numpy-style) broadcasting**; for more details please check [the doc](https://github.com/onnx/onnx/blob/master/docs/Broadcasting.md).\n\n(Opset 14 change): Extend supported types to include uint8, int8, uint16, and int16.\n",
            "inputs": [
              {
                "name": "A",
                "type": "T",
                "description": "First operand."
              },
              {
                "name": "B",
                "type": "T",
                "description": "Second operand."
              }
            ],
            "min_input": 2,
            "max_input": 2,
            "outputs": [
              {
                "name": "C",
                "type": "T",
                "description": "Result, has same element type as two inputs"
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "type_constraints": [
              {
                "description": "Constrain input and output types to all numeric tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(uint8)",
                  "tensor(uint16)",
                  "tensor(uint32)",
                  "tensor(uint64)",
                  "tensor(int8)",
                  "tensor(int16)",
                  "tensor(int32)",
                  "tensor(int64)",
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)",
                  "tensor(bfloat16)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "add",
                "code": "node = onnx.helper.make_node(\n    \"Add\",\n    inputs=[\"x\", \"y\"],\n    outputs=[\"sum\"],\n)\n\nx = np.random.randn(3, 4, 5).astype(np.float32)\ny = np.random.randn(3, 4, 5).astype(np.float32)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add\")\n\nx = np.random.randint(24, size=(3, 4, 5), dtype=np.int8)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.int8)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add_int8\")\n\nx = np.random.randint(24, size=(3, 4, 5), dtype=np.int16)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.int16)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add_int16\")\n\nx = np.random.randint(24, size=(3, 4, 5), dtype=np.uint8)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.uint8)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add_uint8\")\n\nx = np.random.randint(24, size=(3, 4, 5), dtype=np.uint16)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.uint16)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add_uint16\")\n\nx = np.random.randint(24, size=(3, 4, 5), dtype=np.uint32)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.uint32)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add_uint32\")\n\nx = np.random.randint(24, size=(3, 4, 5), dtype=np.uint64)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.uint64)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add_uint64\")"
              },
              {
                "summary": "add_broadcast",
                "code": "node = onnx.helper.make_node(\n    \"Add\",\n    inputs=[\"x\", \"y\"],\n    outputs=[\"sum\"],\n)\n\nx = np.random.randn(3, 4, 5).astype(np.float32)\ny = np.random.randn(5).astype(np.float32)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add_bcast\")"
              }
            ]
          }
        },
        {
          "name": "Conv__245",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "X",
              "value": [
                {
                  "name": "add_6__xeno_compat__1:0",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        24,
                        18,
                        32
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "W",
              "value": [
                {
                  "name": "Conv2D_35/filter:0",
                  "initializer": {
                    "name": "Conv2D_35/filter:0",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float32",
                      "shape": {
                        "dimensions": [
                          24,
                          24,
                          1,
                          1
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        24,
                        24,
                        1,
                        1
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "B",
              "value": [
                {
                  "name": "conv2d_34_1/y:0",
                  "initializer": {
                    "name": "conv2d_34_1/y:0",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float32",
                      "shape": {
                        "dimensions": [
                          24
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        24
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "Y",
              "value": [
                {
                  "name": "Conv__245:0",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        24,
                        18,
                        32
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [
            {
              "name": "dilations",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "strides",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "kernel_shape",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "group",
              "type": "int64",
              "value": {
                "type": "bigint",
                "value": "1"
              }
            }
          ],
          "type": {
            "name": "Conv",
            "module": "ai.onnx",
            "version": 11,
            "description": "The convolution operator consumes an input tensor and a filter, and\ncomputes the output.",
            "attributes": [
              {
                "name": "auto_pad",
                "type": "string",
                "required": false,
                "default": "NOTSET",
                "description": "auto_pad must be either NOTSET, SAME_UPPER, SAME_LOWER or VALID. Where default value is NOTSET, which means explicit padding is used. SAME_UPPER or SAME_LOWER mean pad the input so that `output_shape[i] = ceil(input_shape[i] / strides[i])` for each axis `i`. The padding is split between the two sides equally or almost equally (depending on whether it is even or odd). In case the padding is an odd number, the extra padding is added at the end for SAME_UPPER and at the beginning for SAME_LOWER."
              },
              {
                "name": "dilations",
                "type": "int64[]",
                "required": false,
                "description": "dilation value along each spatial axis of the filter. If not present, the dilation defaults is 1 along each spatial axis."
              },
              {
                "name": "group",
                "type": "int64",
                "required": false,
                "default": 1,
                "description": "number of groups input channels and output channels are divided into."
              },
              {
                "name": "kernel_shape",
                "type": "int64[]",
                "required": false,
                "description": "The shape of the convolution kernel. If not present, should be inferred from input W."
              },
              {
                "name": "pads",
                "type": "int64[]",
                "required": false,
                "description": "Padding for the beginning and ending along each spatial axis, it can take any value greater than or equal to 0. The value represent the number of pixels added to the beginning and end part of the corresponding axis. `pads` format should be as follow [x1_begin, x2_begin...x1_end, x2_end,...], where xi_begin the number of pixels added at the beginning of axis `i` and xi_end, the number of pixels added at the end of axis `i`. This attribute cannot be used simultaneously with auto_pad attribute. If not present, the padding defaults to 0 along start and end of each spatial axis."
              },
              {
                "name": "strides",
                "type": "int64[]",
                "required": false,
                "description": "Stride along each spatial axis. If not present, the stride defaults is 1 along each spatial axis."
              }
            ],
            "inputs": [
              {
                "name": "X",
                "type": "T",
                "description": "Input data tensor from previous layer; has size (N x C x H x W), where N is the batch size, C is the number of channels, and H and W are the height and width. Note that this is for the 2D image. Otherwise the size is (N x C x D1 x D2 ... x Dn). Optionally, if dimension denotation is in effect, the operation expects input data tensor to arrive with the dimension denotation of [DATA_BATCH, DATA_CHANNEL, DATA_FEATURE, DATA_FEATURE ...]."
              },
              {
                "name": "W",
                "type": "T",
                "description": "The weight tensor that will be used in the convolutions; has size (M x C/group x kH x kW), where C is the number of channels, and kH and kW are the height and width of the kernel, and M is the number of feature maps. For more than 2 dimensions, the kernel shape will be (M x C/group x k1 x k2 x ... x kn), where (k1 x k2 x ... kn) is the dimension of the kernel. Optionally, if dimension denotation is in effect, the operation expects the weight tensor to arrive with the dimension denotation of [FILTER_OUT_CHANNEL, FILTER_IN_CHANNEL, FILTER_SPATIAL, FILTER_SPATIAL ...]. Assuming zero based indices for the shape array, X.shape[1] == (W.shape[1] * group) == C and W.shape[0] mod G == 0. Or in other words FILTER_IN_CHANNEL multiplied by the number of groups should be equal to DATA_CHANNEL and the number of feature maps M should be a multiple of the number of groups G."
              },
              {
                "name": "B",
                "type": "T",
                "option": "optional",
                "description": "Optional 1D bias to be added to the convolution, has size of M."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "Y",
                "type": "T",
                "description": "Output data tensor that contains the result of the convolution. The output dimensions are functions of the kernel size, stride size, and pad lengths."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain input and output types to float tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "conv",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[1, 1, 1, 1],\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 21.0, 27.0, 33.0, 24.0],  # (1, 1, 5, 5) output tensor\n                [33.0, 54.0, 63.0, 72.0, 51.0],\n                [63.0, 99.0, 108.0, 117.0, 81.0],\n                [93.0, 144.0, 153.0, 162.0, 111.0],\n                [72.0, 111.0, 117.0, 123.0, 84.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_basic_conv_with_padding\",\n)\n\n# Convolution without padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[0, 0, 0, 0],\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 63.0, 72.0],  # (1, 1, 3, 3) output tensor\n                [99.0, 108.0, 117.0],\n                [144.0, 153.0, 162.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_basic_conv_without_padding\",\n)"
              },
              {
                "summary": "conv_with_autopad_same",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with auto_pad='SAME_LOWER' and strides=2\nnode = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    auto_pad=\"SAME_LOWER\",\n    kernel_shape=[3, 3],\n    strides=[2, 2],\n)\ny = np.array(\n    [[[[12.0, 27.0, 24.0], [63.0, 108.0, 81.0], [72.0, 117.0, 84.0]]]]\n).astype(np.float32)\nexpect(node, inputs=[x, W], outputs=[y], name=\"test_conv_with_autopad_same\")"
              },
              {
                "summary": "conv_with_strides",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 7, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n                [25.0, 26.0, 27.0, 28.0, 29.0],\n                [30.0, 31.0, 32.0, 33.0, 34.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with strides=2 and padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 1, 1, 1],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 27.0, 24.0],  # (1, 1, 4, 3) output tensor\n                [63.0, 108.0, 81.0],\n                [123.0, 198.0, 141.0],\n                [112.0, 177.0, 124.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_conv_with_strides_padding\",\n)\n\n# Convolution with strides=2 and no padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[0, 0, 0, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 72.0],  # (1, 1, 3, 2) output tensor\n                [144.0, 162.0],\n                [234.0, 252.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_conv_with_strides_no_padding\",\n)\n\n# Convolution with strides=2 and padding only along one dimension (the H dimension in NxCxHxW tensor)\nnode_with_asymmetric_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 0, 1, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_asymmetric_padding = np.array(\n    [\n        [\n            [\n                [21.0, 33.0],  # (1, 1, 4, 2) output tensor\n                [99.0, 117.0],\n                [189.0, 207.0],\n                [171.0, 183.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_asymmetric_padding,\n    inputs=[x, W],\n    outputs=[y_with_asymmetric_padding],\n    name=\"test_conv_with_strides_and_asymmetric_padding\",\n)"
              }
            ],
            "category": "Layer"
          }
        },
        {
          "name": "re_lu_14",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "X",
              "value": [
                {
                  "name": "Conv__245:0",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        24,
                        18,
                        32
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "Y",
              "value": [
                {
                  "name": "re_lu_14:0",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        24,
                        18,
                        32
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "Relu",
            "module": "ai.onnx",
            "version": 14,
            "description": "Relu takes one input data (Tensor<T>) and produces one output data\n(Tensor<T>) where the rectified linear function, y = max(0, x), is applied to\nthe tensor elementwise.\n",
            "inputs": [
              {
                "name": "X",
                "type": "T",
                "description": "Input tensor"
              }
            ],
            "min_input": 1,
            "max_input": 1,
            "outputs": [
              {
                "name": "Y",
                "type": "T",
                "description": "Output tensor"
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "type_constraints": [
              {
                "description": "Constrain input and output types to signed numeric tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(float)",
                  "tensor(int32)",
                  "tensor(int8)",
                  "tensor(int16)",
                  "tensor(int64)",
                  "tensor(float16)",
                  "tensor(double)",
                  "tensor(bfloat16)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "relu",
                "code": "node = onnx.helper.make_node(\n    \"Relu\",\n    inputs=[\"x\"],\n    outputs=[\"y\"],\n)\nx = np.random.randn(3, 4, 5).astype(np.float32)\ny = np.clip(x, 0, np.inf)\n\nexpect(node, inputs=[x], outputs=[y], name=\"test_relu\")"
              }
            ],
            "category": "Activation"
          }
        },
        {
          "name": "Conv__248",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "X",
              "value": [
                {
                  "name": "re_lu_14:0",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        24,
                        18,
                        32
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "W",
              "value": [
                {
                  "name": "const_fold_opt__394",
                  "initializer": {
                    "name": "const_fold_opt__394",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float32",
                      "shape": {
                        "dimensions": [
                          24,
                          1,
                          3,
                          3
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        24,
                        1,
                        3,
                        3
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "B",
              "value": [
                {
                  "name": "depthwise_conv2d_8/y:0",
                  "initializer": {
                    "name": "depthwise_conv2d_8/y:0",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float32",
                      "shape": {
                        "dimensions": [
                          24
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        24
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "Y",
              "value": [
                {
                  "name": "Conv__248:0",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        24,
                        18,
                        32
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [
            {
              "name": "dilations",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "strides",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "kernel_shape",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "3",
                  "3"
                ]
              }
            },
            {
              "name": "group",
              "type": "int64",
              "value": {
                "type": "bigint",
                "value": "24"
              }
            },
            {
              "name": "pads",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1",
                  "1",
                  "1"
                ]
              }
            }
          ],
          "type": {
            "name": "Conv",
            "module": "ai.onnx",
            "version": 11,
            "description": "The convolution operator consumes an input tensor and a filter, and\ncomputes the output.",
            "attributes": [
              {
                "name": "auto_pad",
                "type": "string",
                "required": false,
                "default": "NOTSET",
                "description": "auto_pad must be either NOTSET, SAME_UPPER, SAME_LOWER or VALID. Where default value is NOTSET, which means explicit padding is used. SAME_UPPER or SAME_LOWER mean pad the input so that `output_shape[i] = ceil(input_shape[i] / strides[i])` for each axis `i`. The padding is split between the two sides equally or almost equally (depending on whether it is even or odd). In case the padding is an odd number, the extra padding is added at the end for SAME_UPPER and at the beginning for SAME_LOWER."
              },
              {
                "name": "dilations",
                "type": "int64[]",
                "required": false,
                "description": "dilation value along each spatial axis of the filter. If not present, the dilation defaults is 1 along each spatial axis."
              },
              {
                "name": "group",
                "type": "int64",
                "required": false,
                "default": 1,
                "description": "number of groups input channels and output channels are divided into."
              },
              {
                "name": "kernel_shape",
                "type": "int64[]",
                "required": false,
                "description": "The shape of the convolution kernel. If not present, should be inferred from input W."
              },
              {
                "name": "pads",
                "type": "int64[]",
                "required": false,
                "description": "Padding for the beginning and ending along each spatial axis, it can take any value greater than or equal to 0. The value represent the number of pixels added to the beginning and end part of the corresponding axis. `pads` format should be as follow [x1_begin, x2_begin...x1_end, x2_end,...], where xi_begin the number of pixels added at the beginning of axis `i` and xi_end, the number of pixels added at the end of axis `i`. This attribute cannot be used simultaneously with auto_pad attribute. If not present, the padding defaults to 0 along start and end of each spatial axis."
              },
              {
                "name": "strides",
                "type": "int64[]",
                "required": false,
                "description": "Stride along each spatial axis. If not present, the stride defaults is 1 along each spatial axis."
              }
            ],
            "inputs": [
              {
                "name": "X",
                "type": "T",
                "description": "Input data tensor from previous layer; has size (N x C x H x W), where N is the batch size, C is the number of channels, and H and W are the height and width. Note that this is for the 2D image. Otherwise the size is (N x C x D1 x D2 ... x Dn). Optionally, if dimension denotation is in effect, the operation expects input data tensor to arrive with the dimension denotation of [DATA_BATCH, DATA_CHANNEL, DATA_FEATURE, DATA_FEATURE ...]."
              },
              {
                "name": "W",
                "type": "T",
                "description": "The weight tensor that will be used in the convolutions; has size (M x C/group x kH x kW), where C is the number of channels, and kH and kW are the height and width of the kernel, and M is the number of feature maps. For more than 2 dimensions, the kernel shape will be (M x C/group x k1 x k2 x ... x kn), where (k1 x k2 x ... kn) is the dimension of the kernel. Optionally, if dimension denotation is in effect, the operation expects the weight tensor to arrive with the dimension denotation of [FILTER_OUT_CHANNEL, FILTER_IN_CHANNEL, FILTER_SPATIAL, FILTER_SPATIAL ...]. Assuming zero based indices for the shape array, X.shape[1] == (W.shape[1] * group) == C and W.shape[0] mod G == 0. Or in other words FILTER_IN_CHANNEL multiplied by the number of groups should be equal to DATA_CHANNEL and the number of feature maps M should be a multiple of the number of groups G."
              },
              {
                "name": "B",
                "type": "T",
                "option": "optional",
                "description": "Optional 1D bias to be added to the convolution, has size of M."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "Y",
                "type": "T",
                "description": "Output data tensor that contains the result of the convolution. The output dimensions are functions of the kernel size, stride size, and pad lengths."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain input and output types to float tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "conv",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[1, 1, 1, 1],\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 21.0, 27.0, 33.0, 24.0],  # (1, 1, 5, 5) output tensor\n                [33.0, 54.0, 63.0, 72.0, 51.0],\n                [63.0, 99.0, 108.0, 117.0, 81.0],\n                [93.0, 144.0, 153.0, 162.0, 111.0],\n                [72.0, 111.0, 117.0, 123.0, 84.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_basic_conv_with_padding\",\n)\n\n# Convolution without padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[0, 0, 0, 0],\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 63.0, 72.0],  # (1, 1, 3, 3) output tensor\n                [99.0, 108.0, 117.0],\n                [144.0, 153.0, 162.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_basic_conv_without_padding\",\n)"
              },
              {
                "summary": "conv_with_autopad_same",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with auto_pad='SAME_LOWER' and strides=2\nnode = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    auto_pad=\"SAME_LOWER\",\n    kernel_shape=[3, 3],\n    strides=[2, 2],\n)\ny = np.array(\n    [[[[12.0, 27.0, 24.0], [63.0, 108.0, 81.0], [72.0, 117.0, 84.0]]]]\n).astype(np.float32)\nexpect(node, inputs=[x, W], outputs=[y], name=\"test_conv_with_autopad_same\")"
              },
              {
                "summary": "conv_with_strides",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 7, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n                [25.0, 26.0, 27.0, 28.0, 29.0],\n                [30.0, 31.0, 32.0, 33.0, 34.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with strides=2 and padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 1, 1, 1],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 27.0, 24.0],  # (1, 1, 4, 3) output tensor\n                [63.0, 108.0, 81.0],\n                [123.0, 198.0, 141.0],\n                [112.0, 177.0, 124.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_conv_with_strides_padding\",\n)\n\n# Convolution with strides=2 and no padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[0, 0, 0, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 72.0],  # (1, 1, 3, 2) output tensor\n                [144.0, 162.0],\n                [234.0, 252.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_conv_with_strides_no_padding\",\n)\n\n# Convolution with strides=2 and padding only along one dimension (the H dimension in NxCxHxW tensor)\nnode_with_asymmetric_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 0, 1, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_asymmetric_padding = np.array(\n    [\n        [\n            [\n                [21.0, 33.0],  # (1, 1, 4, 2) output tensor\n                [99.0, 117.0],\n                [189.0, 207.0],\n                [171.0, 183.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_asymmetric_padding,\n    inputs=[x, W],\n    outputs=[y_with_asymmetric_padding],\n    name=\"test_conv_with_strides_and_asymmetric_padding\",\n)"
              }
            ],
            "category": "Layer"
          }
        },
        {
          "name": "re_lu_15",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "X",
              "value": [
                {
                  "name": "Conv__248:0",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        24,
                        18,
                        32
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "Y",
              "value": [
                {
                  "name": "re_lu_15:0",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        24,
                        18,
                        32
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "Relu",
            "module": "ai.onnx",
            "version": 14,
            "description": "Relu takes one input data (Tensor<T>) and produces one output data\n(Tensor<T>) where the rectified linear function, y = max(0, x), is applied to\nthe tensor elementwise.\n",
            "inputs": [
              {
                "name": "X",
                "type": "T",
                "description": "Input tensor"
              }
            ],
            "min_input": 1,
            "max_input": 1,
            "outputs": [
              {
                "name": "Y",
                "type": "T",
                "description": "Output tensor"
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "type_constraints": [
              {
                "description": "Constrain input and output types to signed numeric tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(float)",
                  "tensor(int32)",
                  "tensor(int8)",
                  "tensor(int16)",
                  "tensor(int64)",
                  "tensor(float16)",
                  "tensor(double)",
                  "tensor(bfloat16)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "relu",
                "code": "node = onnx.helper.make_node(\n    \"Relu\",\n    inputs=[\"x\"],\n    outputs=[\"y\"],\n)\nx = np.random.randn(3, 4, 5).astype(np.float32)\ny = np.clip(x, 0, np.inf)\n\nexpect(node, inputs=[x], outputs=[y], name=\"test_relu\")"
              }
            ],
            "category": "Activation"
          }
        },
        {
          "name": "add_7__xeno_compat__1",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "A",
              "value": [
                {
                  "name": "re_lu_14:0",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        24,
                        18,
                        32
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "B",
              "value": [
                {
                  "name": "re_lu_15:0",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        24,
                        18,
                        32
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "C",
              "value": [
                {
                  "name": "add_7__xeno_compat__1:0",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        24,
                        18,
                        32
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "Add",
            "module": "ai.onnx",
            "version": 14,
            "description": "Performs element-wise binary addition (with Numpy-style broadcasting support).\n\nThis operator supports **multidirectional (i.e., Numpy-style) broadcasting**; for more details please check [the doc](https://github.com/onnx/onnx/blob/master/docs/Broadcasting.md).\n\n(Opset 14 change): Extend supported types to include uint8, int8, uint16, and int16.\n",
            "inputs": [
              {
                "name": "A",
                "type": "T",
                "description": "First operand."
              },
              {
                "name": "B",
                "type": "T",
                "description": "Second operand."
              }
            ],
            "min_input": 2,
            "max_input": 2,
            "outputs": [
              {
                "name": "C",
                "type": "T",
                "description": "Result, has same element type as two inputs"
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "type_constraints": [
              {
                "description": "Constrain input and output types to all numeric tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(uint8)",
                  "tensor(uint16)",
                  "tensor(uint32)",
                  "tensor(uint64)",
                  "tensor(int8)",
                  "tensor(int16)",
                  "tensor(int32)",
                  "tensor(int64)",
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)",
                  "tensor(bfloat16)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "add",
                "code": "node = onnx.helper.make_node(\n    \"Add\",\n    inputs=[\"x\", \"y\"],\n    outputs=[\"sum\"],\n)\n\nx = np.random.randn(3, 4, 5).astype(np.float32)\ny = np.random.randn(3, 4, 5).astype(np.float32)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add\")\n\nx = np.random.randint(24, size=(3, 4, 5), dtype=np.int8)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.int8)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add_int8\")\n\nx = np.random.randint(24, size=(3, 4, 5), dtype=np.int16)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.int16)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add_int16\")\n\nx = np.random.randint(24, size=(3, 4, 5), dtype=np.uint8)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.uint8)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add_uint8\")\n\nx = np.random.randint(24, size=(3, 4, 5), dtype=np.uint16)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.uint16)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add_uint16\")\n\nx = np.random.randint(24, size=(3, 4, 5), dtype=np.uint32)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.uint32)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add_uint32\")\n\nx = np.random.randint(24, size=(3, 4, 5), dtype=np.uint64)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.uint64)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add_uint64\")"
              },
              {
                "summary": "add_broadcast",
                "code": "node = onnx.helper.make_node(\n    \"Add\",\n    inputs=[\"x\", \"y\"],\n    outputs=[\"sum\"],\n)\n\nx = np.random.randn(3, 4, 5).astype(np.float32)\ny = np.random.randn(5).astype(np.float32)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add_bcast\")"
              }
            ]
          }
        },
        {
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "X",
              "value": [
                {
                  "name": "add_7__xeno_compat__1:0",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        24,
                        18,
                        32
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "roi",
              "value": [
                {
                  "name": "315",
                  "initializer": {
                    "category": "Constant",
                    "encoding": "|",
                    "values": {
                      "0": 0,
                      "1": 0,
                      "2": 0,
                      "3": 0,
                      "4": 1,
                      "5": 1,
                      "6": 1,
                      "7": 1
                    },
                    "type": {
                      "dataType": "float32",
                      "shape": {
                        "dimensions": [
                          8
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        8
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "scales",
              "value": [
                {
                  "name": "scales__125",
                  "initializer": {
                    "name": "scales__125",
                    "category": "Initializer",
                    "encoding": "|",
                    "values": {
                      "0": 1,
                      "1": 1,
                      "2": 2,
                      "3": 2
                    },
                    "type": {
                      "dataType": "float32",
                      "shape": {
                        "dimensions": [
                          4
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        4
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "Y",
              "value": [
                {
                  "name": "290",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        24,
                        36,
                        64
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [
            {
              "name": "mode",
              "type": "string",
              "value": "linear"
            }
          ],
          "type": {
            "name": "Resize",
            "module": "ai.onnx",
            "version": 19,
            "description": "Resize the input tensor. In general, it calculates every value in the output tensor as a weighted average of neighborhood (a.k.a. sampling locations) in the input tensor.\nEach dimension value of the output tensor is:\n```\noutput_dimension = floor(input_dimension * (roi_end - roi_start) * scale)\n```\nif input \\\"sizes\\\" is not specified.\n",
            "attributes": [
              {
                "name": "antialias",
                "type": "int64",
                "required": false,
                "description": "If set to 1, \"linear\" and \"cubic\" interpolation modes will use an antialiasing filter when downscaling. Antialiasing is achieved by stretching the resampling filter by a factor max(1, 1 / scale), which means that when downsampling, more input pixels contribute to an output pixel."
              },
              {
                "name": "axes",
                "type": "int64[]",
                "required": false,
                "description": "If provided, it specifies a subset of axes that 'roi', 'scales' and 'sizes' refer to. If not provided, all axes are assumed [0, 1, ..., r-1], where r = rank(data). Non-specified dimensions are interpreted as non-resizable. Negative value means counting dimensions from the back. Accepted range is [-r, r-1], where r = rank(data). Behavior is undefined if an axis is repeated."
              },
              {
                "name": "coordinate_transformation_mode",
                "type": "string",
                "required": false,
                "default": "half_pixel",
                "description": "\nThis attribute describes how to transform the coordinate in the resized tensor to the coordinate in the original tensor.\n\nThe coordinate of each dimension is transformed individually. Let's describe a case using axis x as an example.\nDenote `x_resized` as the coordinate of axis x in the resized tensor,\n `x_original` as the coordinate of axis x in the original tensor,\n `length_original` as the length of the original tensor in axis x,\n `length_resized` as the length of the resized tensor in axis x,\n `scale = length_resized / length_original`,\n `output_width` the target length on the axis x which can be a fractional number when it is calculated out of a scale factor,\n and `output_width_int` the effective output width as an integer.\n\nif coordinate_transformation_mode is `\"half_pixel\"`,\n```\nx_original = (x_resized + 0.5) / scale - 0.5\n```\n\nif coordinate_transformation_mode is `\"half_pixel_symmetric\"`,\n```\nadjustment = output_width_int / output_width\ncenter = input_width / 2\noffset = center * (1 - adjustment)\nx_ori = offset + (x + 0.5) / scale - 0.5\n```\n\nif coordinate_transformation_mode is `\"pytorch_half_pixel\"`,\n```\nx_original = length_resized > 1 ? (x_resized + 0.5) / scale - 0.5 : 0\n```\n\nif coordinate_transformation_mode is `\"align_corners\"`,\n```\nx_original = x_resized * (length_original - 1) / (length_resized - 1)\n```\n\nif coordinate_transformation_mode is `\"asymmetric\"`,\n```\nx_original = x_resized / scale\n```\n\nif coordinate_transformation_mode is `\"tf_crop_and_resize\"`,\n```\nx_original = length_resized > 1 ? start_x * (length_original - 1) + x_resized * (end_x - start_x) * (length_original - 1) / (length_resized - 1) : 0.5 * (start_x + end_x) * (length_original - 1)\n```\n."
              },
              {
                "name": "cubic_coeff_a",
                "type": "float32",
                "required": false,
                "default": -0.75,
                "description": "The coefficient 'a' used in cubic interpolation. Two common choice are -0.5 (in some cases of TensorFlow) and -0.75 (in PyTorch). Check out Equation (4) in https://ieeexplore.ieee.org/document/1163711 for the details. This attribute is valid only if mode is \"cubic\"."
              },
              {
                "name": "exclude_outside",
                "type": "int64",
                "required": false,
                "description": "If set to 1, the weight of sampling locations outside the tensor will be set to 0 and the weight will be renormalized so that their sum is 1.0. The default value is 0."
              },
              {
                "name": "extrapolation_value",
                "type": "float32",
                "required": false,
                "description": "When coordinate_transformation_mode is \"tf_crop_and_resize\" and x_original is outside the range [0, length_original - 1], this value is used as the corresponding output value. Default is 0.0f."
              },
              {
                "name": "keep_aspect_ratio_policy",
                "type": "string",
                "required": false,
                "default": "stretch",
                "description": "\nThis attribute describes how to interpret the `sizes` input with regard to keeping the original aspect ratio of the input, and it is not applicable when\nthe `scales` input is used.\n\nGiven a set of `sizes`, associated with a subset of `axes` (explicitly provided or default), and assuming `d = axes[i]`, with `i` being the index of the provided `sizes`.\n\nIf `keep_aspect_ratio_policy` is `\"stretch\"`, the original aspect ratio is disregarded, and the input is resized to the specified size:\n`out_size[d] = sizes[i]`\n\nIf `keep_aspect_ratio_policy` is `\"not_larger\"`, the sizes are adjusted so that no extent of the output is larger than the specified size, while keeping the original aspect ratio:\n```\nscale = Min(sizes[i] / in_size[d])\nout_size[d] = round_int(scale * in_size[i])\n```\n\nIf `keep_aspect_ratio_policy` is `\"not_smaller\"`, the sizes are adjusted so that no extent of the output is smaller than the specified size, while keeping the original aspect ratio:\n```\nscale = Max(sizes[i] / in_size[d])\nout_size[d] = round_int(scale * in_size[i])\n```\n\nFor non-resizable axes (those not specified in `axes`), the output size will be equal to the input size.\n\nNote: `round_int` stands for computing the nearest integer value, rounding halfway cases up."
              },
              {
                "name": "mode",
                "type": "string",
                "required": false,
                "default": "nearest",
                "description": "Three interpolation modes: \"nearest\" (default), \"linear\" and \"cubic\". The \"linear\" mode includes linear interpolation for 1D tensor and N-linear interpolation for N-D tensor (for example, bilinear interpolation for 2D tensor). The \"cubic\" mode includes cubic interpolation for 1D tensor and N-cubic interpolation for N-D tensor (for example, bicubic interpolation for 2D tensor)."
              },
              {
                "name": "nearest_mode",
                "type": "string",
                "required": false,
                "default": "round_prefer_floor",
                "description": "Four modes: \"round_prefer_floor\" (default, as known as round half down), \"round_prefer_ceil\" (as known as round half up), \"floor\", \"ceil\". Only used by nearest interpolation. It indicates how to get \"nearest\" pixel in input tensor from x_original, so this attribute is valid only if \"mode\" is \"nearest\"."
              }
            ],
            "inputs": [
              {
                "name": "X",
                "type": "T1",
                "description": "N-D tensor"
              },
              {
                "name": "roi",
                "type": "T2",
                "option": "optional",
                "description": "1-D tensor given as [start1, ..., startN, end1, ..., endN], where N is the rank of X or the length of axes, if provided. The RoIs' coordinates are normalized in the coordinate system of the input image. It only takes effect when coordinate_transformation_mode is \"tf_crop_and_resize\""
              },
              {
                "name": "scales",
                "type": "tensor(float)",
                "option": "optional",
                "description": "The scale array along each dimension. It takes value greater than 0. If it's less than 1, it's sampling down, otherwise, it's upsampling. The number of elements of 'scales' should be the same as the rank of input 'X' or the length of 'axes', if provided. One of 'scales' and 'sizes' MUST be specified and it is an error if both are specified. If 'sizes' is needed, the user can use an empty string as the name of 'scales' in this operator's input list."
              },
              {
                "name": "sizes",
                "type": "tensor(int64)",
                "option": "optional",
                "description": "Target size of the output tensor. Its interpretation depends on the 'keep_aspect_ratio_policy' value.The number of elements of 'sizes' should be the same as the rank of input 'X', or the length of 'axes', if provided. Only one of 'scales' and 'sizes' can be specified. "
              }
            ],
            "min_input": 1,
            "max_input": 4,
            "outputs": [
              {
                "name": "Y",
                "type": "T1",
                "description": "N-D tensor after resizing"
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "1 - 4",
            "type_constraints": [
              {
                "description": "Constrain input 'X' and output 'Y' to all tensor types.",
                "type_param_str": "T1",
                "allowed_type_strs": [
                  "tensor(uint8)",
                  "tensor(uint16)",
                  "tensor(uint32)",
                  "tensor(uint64)",
                  "tensor(int8)",
                  "tensor(int16)",
                  "tensor(int32)",
                  "tensor(int64)",
                  "tensor(bfloat16)",
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)",
                  "tensor(string)",
                  "tensor(bool)",
                  "tensor(complex64)",
                  "tensor(complex128)"
                ]
              },
              {
                "description": "Constrain roi type to float or double.",
                "type_param_str": "T2",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "resize_downsample_scales_cubic",
                "code": "node = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"\", \"scales\"],\n    outputs=[\"Y\"],\n    mode=\"cubic\",\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2, 3, 4],\n                [5, 6, 7, 8],\n                [9, 10, 11, 12],\n                [13, 14, 15, 16],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\nscales = np.array([1.0, 1.0, 0.8, 0.8], dtype=np.float32)\n\n# [[[[ 1.47119141  2.78125     4.08251953]\n#    [ 6.71142578  8.02148438  9.32275391]\n#    [11.91650391 13.2265625  14.52783203]]]]\noutput = interpolate_nd(\n    data, lambda x, _: cubic_coeffs(x), scale_factors=scales\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, scales],\n    outputs=[output],\n    name=\"test_resize_downsample_scales_cubic\",\n)"
              },
              {
                "summary": "resize_downsample_scales_cubic_A_n0p5_exclude_outside",
                "code": "node = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"\", \"scales\"],\n    outputs=[\"Y\"],\n    mode=\"cubic\",\n    cubic_coeff_a=-0.5,\n    exclude_outside=True,\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2, 3, 4],\n                [5, 6, 7, 8],\n                [9, 10, 11, 12],\n                [13, 14, 15, 16],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\nscales = np.array([1.0, 1.0, 0.8, 0.8], dtype=np.float32)\n\n# [[[[ 1.36812675  2.6695014   4.0133367 ]\n#    [ 6.57362535  7.875       9.2188353 ]\n#    [11.94896657 13.25034122 14.59417652]]]]\noutput = interpolate_nd(\n    data,\n    lambda x, _: cubic_coeffs(x, A=-0.5),\n    scale_factors=scales,\n    exclude_outside=True,\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, scales],\n    outputs=[output],\n    name=\"test_resize_downsample_scales_cubic_A_n0p5_exclude_outside\",\n)"
              },
              {
                "summary": "resize_downsample_scales_cubic_align_corners",
                "code": "node = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"\", \"scales\"],\n    outputs=[\"Y\"],\n    mode=\"cubic\",\n    coordinate_transformation_mode=\"align_corners\",\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2, 3, 4],\n                [5, 6, 7, 8],\n                [9, 10, 11, 12],\n                [13, 14, 15, 16],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\nscales = np.array([1.0, 1.0, 0.8, 0.8], dtype=np.float32)\n\n# [[[[ 1.          2.39519159  3.79038317]\n#    [ 6.58076634  7.97595793  9.37114951]\n#    [12.16153268 13.55672427 14.95191585]]]]\noutput = interpolate_nd(\n    data,\n    lambda x, _: cubic_coeffs(x),\n    scale_factors=scales,\n    coordinate_transformation_mode=\"align_corners\",\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, scales],\n    outputs=[output],\n    name=\"test_resize_downsample_scales_cubic_align_corners\",\n)"
              },
              {
                "summary": "resize_downsample_scales_cubic_antialias",
                "code": "node = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"\", \"scales\"],\n    outputs=[\"Y\"],\n    mode=\"cubic\",\n    antialias=1,\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2, 3, 4],\n                [5, 6, 7, 8],\n                [9, 10, 11, 12],\n                [13, 14, 15, 16],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\nscales = np.array([1.0, 1.0, 0.6, 0.6], dtype=np.float32)\n\n# [[[[ 2.5180721  4.2858863]\n#    [ 9.589329  11.357142 ]]]]\noutput = interpolate_nd(\n    data, cubic_coeffs_antialias, scale_factors=scales\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, scales],\n    outputs=[output],\n    name=\"test_resize_downsample_scales_cubic_antialias\",\n)"
              },
              {
                "summary": "resize_downsample_scales_linear",
                "code": "node = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"\", \"scales\"],\n    outputs=[\"Y\"],\n    mode=\"linear\",\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2, 3, 4],\n                [5, 6, 7, 8],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\nscales = np.array([1.0, 1.0, 0.6, 0.6], dtype=np.float32)\n\n# [[[[2.6666665 4.3333331]]]]\noutput = interpolate_nd(\n    data, lambda x, _: linear_coeffs(x), scale_factors=scales\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, scales],\n    outputs=[output],\n    name=\"test_resize_downsample_scales_linear\",\n)"
              },
              {
                "summary": "resize_downsample_scales_linear_align_corners",
                "code": "node = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"\", \"scales\"],\n    outputs=[\"Y\"],\n    mode=\"linear\",\n    coordinate_transformation_mode=\"align_corners\",\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2, 3, 4],\n                [5, 6, 7, 8],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\nscales = np.array([1.0, 1.0, 0.6, 0.6], dtype=np.float32)\n\n# [[[[1.       3.142857]]]]\noutput = interpolate_nd(\n    data,\n    lambda x, _: linear_coeffs(x),\n    scale_factors=scales,\n    coordinate_transformation_mode=\"align_corners\",\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, scales],\n    outputs=[output],\n    name=\"test_resize_downsample_scales_linear_align_corners\",\n)"
              },
              {
                "summary": "resize_downsample_scales_linear_antialias",
                "code": "node = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"\", \"scales\"],\n    outputs=[\"Y\"],\n    mode=\"linear\",\n    antialias=1,\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2, 3, 4],\n                [5, 6, 7, 8],\n                [9, 10, 11, 12],\n                [13, 14, 15, 16],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\nscales = np.array([1.0, 1.0, 0.6, 0.6], dtype=np.float32)\n\n# [[[[ 2.875  4.5  ]\n#    [ 9.375 11.   ]]]]\noutput = interpolate_nd(\n    data, linear_coeffs_antialias, scale_factors=scales\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, scales],\n    outputs=[output],\n    name=\"test_resize_downsample_scales_linear_antialias\",\n)"
              },
              {
                "summary": "resize_downsample_scales_linear_half_pixel_symmetric",
                "code": "node = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"\", \"scales\"],\n    outputs=[\"Y\"],\n    mode=\"linear\",\n    coordinate_transformation_mode=\"half_pixel_symmetric\",\n)\n\ndata = np.array([[[[1, 2, 3, 4]]]], dtype=np.float32)\nscales = np.array([1.0, 1.0, 1.0, 0.6], dtype=np.float32)\n\n# [[[[1.6666667, 3.3333333]]]]\noutput = interpolate_nd(\n    data,\n    lambda x, _: linear_coeffs(x),\n    scale_factors=scales,\n    coordinate_transformation_mode=\"half_pixel_symmetric\",\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, scales],\n    outputs=[output],\n    name=\"test_resize_downsample_scales_linear_half_pixel_symmetric\",\n)"
              },
              {
                "summary": "resize_downsample_scales_nearest",
                "code": "node = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"\", \"scales\"],\n    outputs=[\"Y\"],\n    mode=\"nearest\",\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2, 3, 4],\n                [5, 6, 7, 8],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\nscales = np.array([1.0, 1.0, 0.6, 0.6], dtype=np.float32)\n\n# [[[[1. 3.]]]]\noutput = interpolate_nd(\n    data, lambda x, _: nearest_coeffs(x), scale_factors=scales\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, scales],\n    outputs=[output],\n    name=\"test_resize_downsample_scales_nearest\",\n)"
              },
              {
                "summary": "resize_downsample_sizes_cubic",
                "code": "node = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"\", \"\", \"sizes\"],\n    outputs=[\"Y\"],\n    mode=\"cubic\",\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2, 3, 4],\n                [5, 6, 7, 8],\n                [9, 10, 11, 12],\n                [13, 14, 15, 16],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\nsizes = np.array([1, 1, 3, 3], dtype=np.int64)\n\n# [[[[ 1.63078704  3.00462963  4.37847222]\n#    [ 7.12615741  8.5         9.87384259]\n#    [12.62152778 13.99537037 15.36921296]]]]\noutput = interpolate_nd(\n    data, lambda x, _: cubic_coeffs(x), output_size=sizes\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, sizes],\n    outputs=[output],\n    name=\"test_resize_downsample_sizes_cubic\",\n)"
              },
              {
                "summary": "resize_downsample_sizes_cubic_antialias",
                "code": "node = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"\", \"\", \"sizes\"],\n    outputs=[\"Y\"],\n    mode=\"cubic\",\n    antialias=1,\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2, 3, 4],\n                [5, 6, 7, 8],\n                [9, 10, 11, 12],\n                [13, 14, 15, 16],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\nsizes = np.array([1, 1, 3, 3], dtype=np.int64)\n\n# [[[[ 1.7750092  3.1200073  4.4650054]\n#    [ 7.1550016  8.5        9.844998 ]\n#    [12.534994  13.8799925 15.224991 ]]]]\noutput = interpolate_nd(data, cubic_coeffs_antialias, output_size=sizes).astype(\n    np.float32\n)\n\nexpect(\n    node,\n    inputs=[data, sizes],\n    outputs=[output],\n    name=\"test_resize_downsample_sizes_cubic_antialias\",\n)"
              },
              {
                "summary": "resize_downsample_sizes_linear_antialias",
                "code": "node = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"\", \"\", \"sizes\"],\n    outputs=[\"Y\"],\n    mode=\"linear\",\n    antialias=1,\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2, 3, 4],\n                [5, 6, 7, 8],\n                [9, 10, 11, 12],\n                [13, 14, 15, 16],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\nsizes = np.array([1, 1, 3, 3], dtype=np.int64)\n\n# [[[[ 2.3636363  3.590909   4.818182 ]\n#    [ 7.2727275  8.5        9.727273 ]\n#    [12.181818  13.409091  14.636364 ]]]]\noutput = interpolate_nd(\n    data, linear_coeffs_antialias, output_size=sizes\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, sizes],\n    outputs=[output],\n    name=\"test_resize_downsample_sizes_linear_antialias\",\n)"
              },
              {
                "summary": "resize_downsample_sizes_linear_pytorch_half_pixel",
                "code": "node = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"\", \"\", \"sizes\"],\n    outputs=[\"Y\"],\n    mode=\"linear\",\n    coordinate_transformation_mode=\"pytorch_half_pixel\",\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2, 3, 4],\n                [5, 6, 7, 8],\n                [9, 10, 11, 12],\n                [13, 14, 15, 16],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\nsizes = np.array([1, 1, 3, 1], dtype=np.int64)\n\n# [[[[ 1.6666666]\n#    [ 7.       ]\n#    [12.333333 ]]]]\noutput = interpolate_nd(\n    data,\n    lambda x, _: linear_coeffs(x),\n    output_size=sizes,\n    coordinate_transformation_mode=\"pytorch_half_pixel\",\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, sizes],\n    outputs=[output],\n    name=\"test_resize_downsample_sizes_linear_pytorch_half_pixel\",\n)"
              },
              {
                "summary": "resize_downsample_sizes_nearest",
                "code": "node = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"\", \"\", \"sizes\"],\n    outputs=[\"Y\"],\n    mode=\"nearest\",\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2, 3, 4],\n                [5, 6, 7, 8],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\nsizes = np.array([1, 1, 1, 3], dtype=np.int64)\n\n# [[[[1. 2. 4.]]]]\noutput = interpolate_nd(\n    data, lambda x, _: nearest_coeffs(x), output_size=sizes\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, sizes],\n    outputs=[output],\n    name=\"test_resize_downsample_sizes_nearest\",\n)"
              },
              {
                "summary": "resize_downsample_sizes_nearest_not_larger",
                "code": "keep_aspect_ratio_policy = \"not_larger\"\naxes = [2, 3]\nnode = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"\", \"\", \"sizes\"],\n    outputs=[\"Y\"],\n    mode=\"nearest\",\n    axes=axes,\n    keep_aspect_ratio_policy=keep_aspect_ratio_policy,\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2, 3, 4],\n                [5, 6, 7, 8],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\nsizes = np.array([1, 3], dtype=np.int64)  # Results in 1x2\n\n# [[[[1. 3.]]]]\noutput = interpolate_nd(\n    data,\n    lambda x, _: nearest_coeffs(x),\n    output_size=sizes,\n    axes=axes,\n    keep_aspect_ratio_policy=keep_aspect_ratio_policy,\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, sizes],\n    outputs=[output],\n    name=\"test_resize_downsample_sizes_nearest_not_larger\",\n)"
              },
              {
                "summary": "resize_downsample_sizes_nearest_not_smaller",
                "code": "keep_aspect_ratio_policy = \"not_smaller\"\naxes = [2, 3]\nnode = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"\", \"\", \"sizes\"],\n    outputs=[\"Y\"],\n    mode=\"nearest\",\n    axes=axes,\n    keep_aspect_ratio_policy=keep_aspect_ratio_policy,\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2, 3, 4],\n                [5, 6, 7, 8],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\nsizes = np.array([1, 3], dtype=np.int64)  # Results in 2x3\n\n# [[[[1. 2. 4.]\n#    [5. 6. 8.]]]]\noutput = interpolate_nd(\n    data,\n    lambda x, _: nearest_coeffs(x),\n    output_size=sizes,\n    axes=axes,\n    keep_aspect_ratio_policy=keep_aspect_ratio_policy,\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, sizes],\n    outputs=[output],\n    name=\"test_resize_downsample_sizes_nearest_not_smaller\",\n)"
              },
              {
                "summary": "resize_tf_crop_and_resize",
                "code": "node = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"roi\", \"\", \"sizes\"],\n    outputs=[\"Y\"],\n    mode=\"linear\",\n    coordinate_transformation_mode=\"tf_crop_and_resize\",\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2, 3, 4],\n                [5, 6, 7, 8],\n                [9, 10, 11, 12],\n                [13, 14, 15, 16],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\n# Note: for some rois, the result may be different with that of TF for inaccurate floating point\nroi = np.array([0, 0, 0.4, 0.6, 1, 1, 0.6, 0.8], dtype=np.float32)\nsizes = np.array([1, 1, 3, 3], dtype=np.int64)\n\n# [[[[ 7.6000004  7.9        8.2      ]\n#    [ 8.8        9.1        9.400001 ]\n#    [10.        10.3       10.6      ]]]]\noutput = interpolate_nd(\n    data,\n    lambda x, _: linear_coeffs(x),\n    output_size=sizes,\n    roi=roi,\n    coordinate_transformation_mode=\"tf_crop_and_resize\",\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, roi, sizes],\n    outputs=[output],\n    name=\"test_resize_tf_crop_and_resize\",\n)"
              },
              {
                "summary": "resize_tf_crop_and_resize_axes_2_3",
                "code": "axes = [2, 3]\nnode = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"roi\", \"\", \"sizes\"],\n    outputs=[\"Y\"],\n    mode=\"linear\",\n    coordinate_transformation_mode=\"tf_crop_and_resize\",\n    axes=axes,\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2, 3, 4],\n                [5, 6, 7, 8],\n                [9, 10, 11, 12],\n                [13, 14, 15, 16],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\n# Note: for some rois, the result may be different with that of TF for inaccurate floating point\nroi = np.array([0.4, 0.6, 0.6, 0.8], dtype=np.float32)\nsizes = np.array([3, 3], dtype=np.int64)\n\n# [[[[ 7.6000004  7.9        8.2      ]\n#    [ 8.8        9.1        9.400001 ]\n#    [10.        10.3       10.6      ]]]]\noutput = interpolate_nd(\n    data,\n    lambda x, _: linear_coeffs(x),\n    output_size=sizes,\n    roi=roi,\n    axes=axes,\n    coordinate_transformation_mode=\"tf_crop_and_resize\",\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, roi, sizes],\n    outputs=[output],\n    name=\"test_resize_tf_crop_and_resize_axes_2_3\",\n)"
              },
              {
                "summary": "resize_tf_crop_and_resize_axes_3_2",
                "code": "axes = [3, 2]\nnode = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"roi\", \"\", \"sizes\"],\n    outputs=[\"Y\"],\n    mode=\"linear\",\n    coordinate_transformation_mode=\"tf_crop_and_resize\",\n    axes=axes,\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2, 3, 4],\n                [5, 6, 7, 8],\n                [9, 10, 11, 12],\n                [13, 14, 15, 16],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\n# Note: for some rois, the result may be different with that of TF for inaccurate floating point\nroi = np.array([0.6, 0.4, 0.8, 0.6], dtype=np.float32)\nsizes = np.array([3, 3], dtype=np.int64)\n\n# [[[[ 7.6000004  7.9        8.2      ]\n#    [ 8.8        9.1        9.400001 ]\n#    [10.        10.3       10.6      ]]]]\noutput = interpolate_nd(\n    data,\n    lambda x, _: linear_coeffs(x),\n    output_size=sizes,\n    roi=roi,\n    axes=axes,\n    coordinate_transformation_mode=\"tf_crop_and_resize\",\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, roi, sizes],\n    outputs=[output],\n    name=\"test_resize_tf_crop_and_resize_axes_3_2\",\n)"
              },
              {
                "summary": "resize_tf_crop_and_resize_extrapolation_value",
                "code": "node = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"roi\", \"\", \"sizes\"],\n    outputs=[\"Y\"],\n    mode=\"linear\",\n    coordinate_transformation_mode=\"tf_crop_and_resize\",\n    extrapolation_value=10.0,\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2, 3, 4],\n                [5, 6, 7, 8],\n                [9, 10, 11, 12],\n                [13, 14, 15, 16],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\n# Note: for some rois, the result may be different with that of TF for inaccurate floating point\nroi = np.array([0, 0, 0.4, 0.6, 1, 1, 1.2, 1.7], dtype=np.float32)\nsizes = np.array([1, 1, 3, 3], dtype=np.int64)\n\n# [[[[ 7.6000004 10.        10.       ]\n#    [12.400001  10.        10.       ]\n#    [10.        10.        10.       ]]]]\noutput = interpolate_nd(\n    data,\n    lambda x, _: linear_coeffs(x),\n    output_size=sizes,\n    roi=roi,\n    coordinate_transformation_mode=\"tf_crop_and_resize\",\n    extrapolation_value=10.0,\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, roi, sizes],\n    outputs=[output],\n    name=\"test_resize_tf_crop_and_resize_extrapolation_value\",\n)"
              },
              {
                "summary": "resize_upsample_scales_cubic",
                "code": "node = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"\", \"scales\"],\n    outputs=[\"Y\"],\n    mode=\"cubic\",\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2, 3, 4],\n                [5, 6, 7, 8],\n                [9, 10, 11, 12],\n                [13, 14, 15, 16],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\nscales = np.array([1.0, 1.0, 2.0, 2.0], dtype=np.float32)\n\n# [[[[ 0.47265625  0.76953125  1.24609375  1.875       2.28125\n#      2.91015625  3.38671875  3.68359375]\n#    [ 1.66015625  1.95703125  2.43359375  3.0625      3.46875\n#      4.09765625  4.57421875  4.87109375]\n#    [ 3.56640625  3.86328125  4.33984375  4.96875     5.375\n#      6.00390625  6.48046875  6.77734375]\n#    [ 6.08203125  6.37890625  6.85546875  7.484375    7.890625\n#      8.51953125  8.99609375  9.29296875]\n#    [ 7.70703125  8.00390625  8.48046875  9.109375    9.515625\n#     10.14453125 10.62109375 10.91796875]\n#    [10.22265625 10.51953125 10.99609375 11.625      12.03125\n#     12.66015625 13.13671875 13.43359375]\n#    [12.12890625 12.42578125 12.90234375 13.53125    13.9375\n#     14.56640625 15.04296875 15.33984375]\n#    [13.31640625 13.61328125 14.08984375 14.71875    15.125\n#     15.75390625 16.23046875 16.52734375]]]]\noutput = interpolate_nd(\n    data, lambda x, _: cubic_coeffs(x), scale_factors=scales\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, scales],\n    outputs=[output],\n    name=\"test_resize_upsample_scales_cubic\",\n)"
              },
              {
                "summary": "resize_upsample_scales_cubic_A_n0p5_exclude_outside",
                "code": "node = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"\", \"scales\"],\n    outputs=[\"Y\"],\n    mode=\"cubic\",\n    cubic_coeff_a=-0.5,\n    exclude_outside=True,\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2, 3, 4],\n                [5, 6, 7, 8],\n                [9, 10, 11, 12],\n                [13, 14, 15, 16],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\nscales = np.array([1.0, 1.0, 2.0, 2.0], dtype=np.float32)\n\n# [[[[ 0.55882353  0.81494204  1.35698249  1.89705882  2.39705882\n#      2.93713516  3.47917561  3.73529412]\n#    [ 1.58329755  1.83941606  2.38145651  2.92153285  3.42153285\n#      3.96160918  4.50364964  4.75976814]\n#    [ 3.75145936  4.00757787  4.54961832  5.08969466  5.58969466\n#      6.12977099  6.67181144  6.92792995]\n#    [ 5.91176471  6.16788321  6.70992366  7.25        7.75\n#      8.29007634  8.83211679  9.08823529]\n#    [ 7.91176471  8.16788321  8.70992366  9.25        9.75\n#     10.29007634 10.83211679 11.08823529]\n#    [10.07207005 10.32818856 10.87022901 11.41030534 11.91030534\n#     12.45038168 12.99242213 13.24854064]\n#    [12.24023186 12.49635036 13.03839082 13.57846715 14.07846715\n#     14.61854349 15.16058394 15.41670245]\n#    [13.26470588 13.52082439 14.06286484 14.60294118 15.10294118\n#     15.64301751 16.18505796 16.44117647]]]]\noutput = interpolate_nd(\n    data,\n    lambda x, _: cubic_coeffs(x, A=-0.5),\n    scale_factors=scales,\n    exclude_outside=True,\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, scales],\n    outputs=[output],\n    name=\"test_resize_upsample_scales_cubic_A_n0p5_exclude_outside\",\n)"
              },
              {
                "summary": "resize_upsample_scales_cubic_align_corners",
                "code": "node = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"\", \"scales\"],\n    outputs=[\"Y\"],\n    mode=\"cubic\",\n    coordinate_transformation_mode=\"align_corners\",\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2, 3, 4],\n                [5, 6, 7, 8],\n                [9, 10, 11, 12],\n                [13, 14, 15, 16],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\nscales = np.array([1.0, 1.0, 2.0, 2.0], dtype=np.float32)\n\n# [[[[ 1.          1.34110787  1.80029155  2.32944606  2.67055394\n#      3.19970845  3.65889213  4.        ]\n#    [ 2.36443149  2.70553936  3.16472303  3.69387755  4.03498542\n#      4.56413994  5.02332362  5.36443149]\n#    [ 4.20116618  4.54227405  5.00145773  5.53061224  5.87172012\n#      6.40087464  6.86005831  7.20116618]\n#    [ 6.31778426  6.65889213  7.1180758   7.64723032  7.98833819\n#      8.51749271  8.97667638  9.31778426]\n#    [ 7.68221574  8.02332362  8.48250729  9.01166181  9.35276968\n#      9.8819242  10.34110787 10.68221574]\n#    [ 9.79883382 10.13994169 10.59912536 11.12827988 11.46938776\n#     11.99854227 12.45772595 12.79883382]\n#    [11.63556851 11.97667638 12.43586006 12.96501458 13.30612245\n#     13.83527697 14.29446064 14.63556851]\n#    [13.         13.34110787 13.80029155 14.32944606 14.67055394\n#     15.19970845 15.65889213 16.        ]]]]\noutput = interpolate_nd(\n    data,\n    lambda x, _: cubic_coeffs(x),\n    scale_factors=scales,\n    coordinate_transformation_mode=\"align_corners\",\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, scales],\n    outputs=[output],\n    name=\"test_resize_upsample_scales_cubic_align_corners\",\n)"
              },
              {
                "summary": "resize_upsample_scales_cubic_asymmetric",
                "code": "node = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"\", \"scales\"],\n    outputs=[\"Y\"],\n    mode=\"cubic\",\n    coordinate_transformation_mode=\"asymmetric\",\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2, 3, 4],\n                [5, 6, 7, 8],\n                [9, 10, 11, 12],\n                [13, 14, 15, 16],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\nscales = np.array([1.0, 1.0, 2.0, 2.0], dtype=np.float32)\n\n# [[[[ 1.       1.40625  2.       2.5      3.       3.59375  4.\n#      4.09375]\n#    [ 2.625    3.03125  3.625    4.125    4.625    5.21875  5.625\n#      5.71875]\n#    [ 5.       5.40625  6.       6.5      7.       7.59375  8.\n#      8.09375]\n#    [ 7.       7.40625  8.       8.5      9.       9.59375 10.\n#     10.09375]\n#    [ 9.       9.40625 10.      10.5     11.      11.59375 12.\n#     12.09375]\n#    [11.375   11.78125 12.375   12.875   13.375   13.96875 14.375\n#     14.46875]\n#    [13.      13.40625 14.      14.5     15.      15.59375 16.\n#     16.09375]\n#    [13.375   13.78125 14.375   14.875   15.375   15.96875 16.375\n#     16.46875]]]]\noutput = interpolate_nd(\n    data,\n    lambda x, _: cubic_coeffs(x, A=-0.75),\n    scale_factors=scales,\n    coordinate_transformation_mode=\"asymmetric\",\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, scales],\n    outputs=[output],\n    name=\"test_resize_upsample_scales_cubic_asymmetric\",\n)"
              },
              {
                "summary": "resize_upsample_scales_linear",
                "code": "node = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"\", \"scales\"],\n    outputs=[\"Y\"],\n    mode=\"linear\",\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2],\n                [3, 4],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\nscales = np.array([1.0, 1.0, 2.0, 2.0], dtype=np.float32)\n\n# [[[[1.   1.25 1.75 2.  ]\n#    [1.5  1.75 2.25 2.5 ]\n#    [2.5  2.75 3.25 3.5 ]\n#    [3.   3.25 3.75 4.  ]]]]\noutput = interpolate_nd(\n    data, lambda x, _: linear_coeffs(x), scale_factors=scales\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, scales],\n    outputs=[output],\n    name=\"test_resize_upsample_scales_linear\",\n)"
              },
              {
                "summary": "resize_upsample_scales_linear_align_corners",
                "code": "node = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"\", \"scales\"],\n    outputs=[\"Y\"],\n    mode=\"linear\",\n    coordinate_transformation_mode=\"align_corners\",\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2],\n                [3, 4],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\nscales = np.array([1.0, 1.0, 2.0, 2.0], dtype=np.float32)\n\n# [[[[1.         1.33333333 1.66666667 2.        ]\n#    [1.66666667 2.         2.33333333 2.66666667]\n#    [2.33333333 2.66666667 3.         3.33333333]\n#    [3.         3.33333333 3.66666667 4.        ]]]]\noutput = interpolate_nd(\n    data,\n    lambda x, _: linear_coeffs(x),\n    scale_factors=scales,\n    coordinate_transformation_mode=\"align_corners\",\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, scales],\n    outputs=[output],\n    name=\"test_resize_upsample_scales_linear_align_corners\",\n)"
              },
              {
                "summary": "resize_upsample_scales_linear_half_pixel_symmetric",
                "code": "node = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"\", \"scales\"],\n    outputs=[\"Y\"],\n    mode=\"linear\",\n    coordinate_transformation_mode=\"half_pixel_symmetric\",\n)\n\ndata = np.array([[[[1, 2], [3, 4]]]], dtype=np.float32)\nscales = np.array([1.0, 1.0, 2.3, 2.94], dtype=np.float32)\n\n# [[[[1.        , 1.15986395, 1.5       , 1.84013605, 2.        ],\n#    [1.56521738, 1.72508133, 2.06521738, 2.40535343, 2.56521738],\n#    [2.43478262, 2.59464657, 2.93478262, 3.27491867, 3.43478262],\n#    [3.        , 3.15986395, 3.5       , 3.84013605, 4.        ]]]]\noutput = interpolate_nd(\n    data,\n    lambda x, _: linear_coeffs(x),\n    scale_factors=scales,\n    coordinate_transformation_mode=\"half_pixel_symmetric\",\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, scales],\n    outputs=[output],\n    name=\"test_resize_upsample_scales_linear_half_pixel_symmetric\",\n)"
              },
              {
                "summary": "resize_upsample_scales_nearest",
                "code": "node = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"\", \"scales\"],\n    outputs=[\"Y\"],\n    mode=\"nearest\",\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2],\n                [3, 4],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\nscales = np.array([1.0, 1.0, 2.0, 3.0], dtype=np.float32)\n\n# [[[[1. 1. 1. 2. 2. 2.]\n#    [1. 1. 1. 2. 2. 2.]\n#    [3. 3. 3. 4. 4. 4.]\n#    [3. 3. 3. 4. 4. 4.]]]]\noutput = interpolate_nd(\n    data, lambda x, _: nearest_coeffs(x), scale_factors=scales\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, scales],\n    outputs=[output],\n    name=\"test_resize_upsample_scales_nearest\",\n)"
              },
              {
                "summary": "resize_upsample_scales_nearest_axes_2_3",
                "code": "axes = [2, 3]\nnode = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"\", \"scales\"],\n    outputs=[\"Y\"],\n    mode=\"nearest\",\n    axes=axes,\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2],\n                [3, 4],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\nscales = np.array([2.0, 3.0], dtype=np.float32)\n\n# [[[[1. 1. 1. 2. 2. 2.]\n#    [1. 1. 1. 2. 2. 2.]\n#    [3. 3. 3. 4. 4. 4.]\n#    [3. 3. 3. 4. 4. 4.]]]]\noutput = interpolate_nd(\n    data, lambda x, _: nearest_coeffs(x), scale_factors=scales, axes=axes\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, scales],\n    outputs=[output],\n    name=\"test_resize_upsample_scales_nearest_axes_2_3\",\n)"
              },
              {
                "summary": "resize_upsample_scales_nearest_axes_3_2",
                "code": "axes = [3, 2]\nnode = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"\", \"scales\"],\n    outputs=[\"Y\"],\n    mode=\"nearest\",\n    axes=axes,\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2],\n                [3, 4],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\nscales = np.array([3.0, 2.0], dtype=np.float32)\n\n# [[[[1. 1. 1. 2. 2. 2.]\n#    [1. 1. 1. 2. 2. 2.]\n#    [3. 3. 3. 4. 4. 4.]\n#    [3. 3. 3. 4. 4. 4.]]]]\noutput = interpolate_nd(\n    data, lambda x, _: nearest_coeffs(x), scale_factors=scales, axes=axes\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, scales],\n    outputs=[output],\n    name=\"test_resize_upsample_scales_nearest_axes_3_2\",\n)"
              },
              {
                "summary": "resize_upsample_sizes_cubic",
                "code": "node = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"\", \"\", \"sizes\"],\n    outputs=[\"Y\"],\n    mode=\"cubic\",\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2, 3, 4],\n                [5, 6, 7, 8],\n                [9, 10, 11, 12],\n                [13, 14, 15, 16],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\nsizes = np.array([1, 1, 9, 10], dtype=np.int64)\n\n# [[[[ 0.45507922  0.64057922  0.97157922  1.42257922  1.90732922\n#      2.22332922  2.70807922  3.15907922  3.49007922  3.67557922]\n#    [ 1.39437963  1.57987963  1.91087963  2.36187963  2.84662963\n#      3.16262963  3.64737963  4.09837963  4.42937963  4.61487963]\n#    [ 2.95130693  3.13680693  3.46780693  3.91880693  4.40355693\n#      4.71955693  5.20430693  5.65530693  5.98630693  6.17180693]\n#    [ 5.20525069  5.39075069  5.72175069  6.17275069  6.65750069\n#      6.97350069  7.45825069  7.90925069  8.24025069  8.42575069]\n#    [ 6.88975     7.07525     7.40625     7.85725     8.342\n#      8.658       9.14275     9.59375     9.92475    10.11025   ]\n#    [ 8.57424931  8.75974931  9.09074931  9.54174931 10.02649931\n#     10.34249931 10.82724931 11.27824931 11.60924931 11.79474931]\n#    [10.82819307 11.01369307 11.34469307 11.79569307 12.28044307\n#     12.59644307 13.08119307 13.53219307 13.86319307 14.04869307]\n#    [12.38512037 12.57062037 12.90162037 13.35262037 13.83737037\n#     14.15337037 14.63812037 15.08912037 15.42012037 15.60562037]\n#    [13.32442078 13.50992078 13.84092078 14.29192078 14.77667078\n#     15.09267078 15.57742078 16.02842078 16.35942078 16.54492078]]]]\noutput = interpolate_nd(\n    data, lambda x, _: cubic_coeffs(x), output_size=sizes\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, sizes],\n    outputs=[output],\n    name=\"test_resize_upsample_sizes_cubic\",\n)"
              },
              {
                "summary": "resize_upsample_sizes_nearest",
                "code": "node = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"\", \"\", \"sizes\"],\n    outputs=[\"Y\"],\n    mode=\"nearest\",\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2],\n                [3, 4],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\nsizes = np.array([1, 1, 7, 8], dtype=np.int64)\n\n# [[[[1. 1. 1. 1. 2. 2. 2. 2.]\n#    [1. 1. 1. 1. 2. 2. 2. 2.]\n#    [1. 1. 1. 1. 2. 2. 2. 2.]\n#    [1. 1. 1. 1. 2. 2. 2. 2.]\n#    [3. 3. 3. 3. 4. 4. 4. 4.]\n#    [3. 3. 3. 3. 4. 4. 4. 4.]\n#    [3. 3. 3. 3. 4. 4. 4. 4.]]]]\noutput = interpolate_nd(\n    data, lambda x, _: nearest_coeffs(x), output_size=sizes\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, sizes],\n    outputs=[output],\n    name=\"test_resize_upsample_sizes_nearest\",\n)"
              },
              {
                "summary": "resize_upsample_sizes_nearest_axes_2_3",
                "code": "axes = [2, 3]\nnode = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"\", \"\", \"sizes\"],\n    outputs=[\"Y\"],\n    mode=\"nearest\",\n    axes=axes,\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2],\n                [3, 4],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\nsizes = np.array([7, 8], dtype=np.int64)\n\n# [[[[1. 1. 1. 1. 2. 2. 2. 2.]\n#    [1. 1. 1. 1. 2. 2. 2. 2.]\n#    [1. 1. 1. 1. 2. 2. 2. 2.]\n#    [1. 1. 1. 1. 2. 2. 2. 2.]\n#    [3. 3. 3. 3. 4. 4. 4. 4.]\n#    [3. 3. 3. 3. 4. 4. 4. 4.]\n#    [3. 3. 3. 3. 4. 4. 4. 4.]]]]\noutput = interpolate_nd(\n    data, lambda x, _: nearest_coeffs(x), output_size=sizes, axes=axes\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, sizes],\n    outputs=[output],\n    name=\"test_resize_upsample_sizes_nearest_axes_2_3\",\n)"
              },
              {
                "summary": "resize_upsample_sizes_nearest_axes_3_2",
                "code": "axes = [3, 2]\nnode = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"\", \"\", \"sizes\"],\n    outputs=[\"Y\"],\n    mode=\"nearest\",\n    axes=axes,\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2],\n                [3, 4],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\nsizes = np.array([8, 7], dtype=np.int64)\n\n# [[[[1. 1. 1. 1. 2. 2. 2. 2.]\n#    [1. 1. 1. 1. 2. 2. 2. 2.]\n#    [1. 1. 1. 1. 2. 2. 2. 2.]\n#    [1. 1. 1. 1. 2. 2. 2. 2.]\n#    [3. 3. 3. 3. 4. 4. 4. 4.]\n#    [3. 3. 3. 3. 4. 4. 4. 4.]\n#    [3. 3. 3. 3. 4. 4. 4. 4.]]]]\noutput = interpolate_nd(\n    data, lambda x, _: nearest_coeffs(x), output_size=sizes, axes=axes\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, sizes],\n    outputs=[output],\n    name=\"test_resize_upsample_sizes_nearest_axes_3_2\",\n)"
              },
              {
                "summary": "resize_upsample_sizes_nearest_ceil_half_pixel",
                "code": "node = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"\", \"\", \"sizes\"],\n    outputs=[\"Y\"],\n    mode=\"nearest\",\n    coordinate_transformation_mode=\"half_pixel\",\n    nearest_mode=\"ceil\",\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2, 3, 4],\n                [5, 6, 7, 8],\n                [9, 10, 11, 12],\n                [13, 14, 15, 16],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\nsizes = np.array([1, 1, 8, 8], dtype=np.int64)\n\n# [[[[ 1.  2.  2.  3.  3.  4.  4.  4.]\n#    [ 5.  6.  6.  7.  7.  8.  8.  8.]\n#    [ 5.  6.  6.  7.  7.  8.  8.  8.]\n#    [ 9. 10. 10. 11. 11. 12. 12. 12.]\n#    [ 9. 10. 10. 11. 11. 12. 12. 12.]\n#    [13. 14. 14. 15. 15. 16. 16. 16.]\n#    [13. 14. 14. 15. 15. 16. 16. 16.]\n#    [13. 14. 14. 15. 15. 16. 16. 16.]]]]\noutput = interpolate_nd(\n    data, lambda x, _: nearest_coeffs(x, mode=\"ceil\"), output_size=sizes\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, sizes],\n    outputs=[output],\n    name=\"test_resize_upsample_sizes_nearest_ceil_half_pixel\",\n)"
              },
              {
                "summary": "resize_upsample_sizes_nearest_floor_align_corners",
                "code": "node = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"\", \"\", \"sizes\"],\n    outputs=[\"Y\"],\n    mode=\"nearest\",\n    coordinate_transformation_mode=\"align_corners\",\n    nearest_mode=\"floor\",\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2, 3, 4],\n                [5, 6, 7, 8],\n                [9, 10, 11, 12],\n                [13, 14, 15, 16],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\nsizes = np.array([1, 1, 8, 8], dtype=np.int64)\n\n# [[[[ 1.  1.  1.  2.  2.  3.  3.  4.]\n#    [ 1.  1.  1.  2.  2.  3.  3.  4.]\n#    [ 1.  1.  1.  2.  2.  3.  3.  4.]\n#    [ 5.  5.  5.  6.  6.  7.  7.  8.]\n#    [ 5.  5.  5.  6.  6.  7.  7.  8.]\n#    [ 9.  9.  9. 10. 10. 11. 11. 12.]\n#    [ 9.  9.  9. 10. 10. 11. 11. 12.]\n#    [13. 13. 13. 14. 14. 15. 15. 16.]]]]\noutput = interpolate_nd(\n    data,\n    lambda x, _: nearest_coeffs(x, mode=\"floor\"),\n    output_size=sizes,\n    coordinate_transformation_mode=\"align_corners\",\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, sizes],\n    outputs=[output],\n    name=\"test_resize_upsample_sizes_nearest_floor_align_corners\",\n)"
              },
              {
                "summary": "resize_upsample_sizes_nearest_not_larger",
                "code": "keep_aspect_ratio_policy = \"not_larger\"\naxes = [2, 3]\nnode = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"\", \"\", \"sizes\"],\n    outputs=[\"Y\"],\n    mode=\"nearest\",\n    axes=axes,\n    keep_aspect_ratio_policy=keep_aspect_ratio_policy,\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2],\n                [3, 4],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\nsizes = np.array([7, 8], dtype=np.int64)  # Results in 7x7\n\n# [[[[1. 1. 1. 1. 2. 2. 2.]\n#    [1. 1. 1. 1. 2. 2. 2.]\n#    [1. 1. 1. 1. 2. 2. 2.]\n#    [1. 1. 1. 1. 2. 2. 2.]\n#    [3. 3. 3. 3. 4. 4. 4.]\n#    [3. 3. 3. 3. 4. 4. 4.]\n#    [3. 3. 3. 3. 4. 4. 4.]]]]\noutput = interpolate_nd(\n    data,\n    lambda x, _: nearest_coeffs(x),\n    output_size=sizes,\n    axes=axes,\n    keep_aspect_ratio_policy=keep_aspect_ratio_policy,\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, sizes],\n    outputs=[output],\n    name=\"test_resize_upsample_sizes_nearest_not_larger\",\n)"
              },
              {
                "summary": "resize_upsample_sizes_nearest_not_smaller",
                "code": "keep_aspect_ratio_policy = \"not_smaller\"\naxes = [2, 3]\nnode = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"\", \"\", \"sizes\"],\n    outputs=[\"Y\"],\n    mode=\"nearest\",\n    axes=axes,\n    keep_aspect_ratio_policy=keep_aspect_ratio_policy,\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2],\n                [3, 4],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\nsizes = np.array([7, 8], dtype=np.int64)  # Results in 8x8\n\n# [[[[1. 1. 1. 1. 2. 2. 2. 2.]\n#    [1. 1. 1. 1. 2. 2. 2. 2.]\n#    [1. 1. 1. 1. 2. 2. 2. 2.]\n#    [1. 1. 1. 1. 2. 2. 2. 2.]\n#    [3. 3. 3. 3. 4. 4. 4. 4.]\n#    [3. 3. 3. 3. 4. 4. 4. 4.]\n#    [3. 3. 3. 3. 4. 4. 4. 4.]]]]\noutput = interpolate_nd(\n    data,\n    lambda x, _: nearest_coeffs(x),\n    output_size=sizes,\n    axes=axes,\n    keep_aspect_ratio_policy=keep_aspect_ratio_policy,\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, sizes],\n    outputs=[output],\n    name=\"test_resize_upsample_sizes_nearest_not_smaller\",\n)"
              },
              {
                "summary": "resize_upsample_sizes_nearest_round_prefer_ceil_asymmetric",
                "code": "node = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"\", \"\", \"sizes\"],\n    outputs=[\"Y\"],\n    mode=\"nearest\",\n    coordinate_transformation_mode=\"asymmetric\",\n    nearest_mode=\"round_prefer_ceil\",\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2, 3, 4],\n                [5, 6, 7, 8],\n                [9, 10, 11, 12],\n                [13, 14, 15, 16],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\nsizes = np.array([1, 1, 8, 8], dtype=np.int64)\n\n# [[[[ 1.  2.  2.  3.  3.  4.  4.  4.]\n#    [ 5.  6.  6.  7.  7.  8.  8.  8.]\n#    [ 5.  6.  6.  7.  7.  8.  8.  8.]\n#    [ 9. 10. 10. 11. 11. 12. 12. 12.]\n#    [ 9. 10. 10. 11. 11. 12. 12. 12.]\n#    [13. 14. 14. 15. 15. 16. 16. 16.]\n#    [13. 14. 14. 15. 15. 16. 16. 16.]\n#    [13. 14. 14. 15. 15. 16. 16. 16.]]]]\noutput = interpolate_nd(\n    data,\n    lambda x, _: nearest_coeffs(x, mode=\"round_prefer_ceil\"),\n    output_size=sizes,\n    coordinate_transformation_mode=\"asymmetric\",\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, sizes],\n    outputs=[output],\n    name=\"test_resize_upsample_sizes_nearest_round_prefer_ceil_asymmetric\",\n)"
              }
            ]
          }
        },
        {
          "name": "Conv__249",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "X",
              "value": [
                {
                  "name": "290",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        24,
                        36,
                        64
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "W",
              "value": [
                {
                  "name": "Conv2D_36/filter:0",
                  "initializer": {
                    "name": "Conv2D_36/filter:0",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float32",
                      "shape": {
                        "dimensions": [
                          16,
                          24,
                          1,
                          1
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        16,
                        24,
                        1,
                        1
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "B",
              "value": [
                {
                  "name": "conv2d_35_1/y:0",
                  "initializer": {
                    "name": "conv2d_35_1/y:0",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float32",
                      "shape": {
                        "dimensions": [
                          16
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        16
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "Y",
              "value": [
                {
                  "name": "Conv__249:0",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        16,
                        36,
                        64
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [
            {
              "name": "dilations",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "strides",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "kernel_shape",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "group",
              "type": "int64",
              "value": {
                "type": "bigint",
                "value": "1"
              }
            }
          ],
          "type": {
            "name": "Conv",
            "module": "ai.onnx",
            "version": 11,
            "description": "The convolution operator consumes an input tensor and a filter, and\ncomputes the output.",
            "attributes": [
              {
                "name": "auto_pad",
                "type": "string",
                "required": false,
                "default": "NOTSET",
                "description": "auto_pad must be either NOTSET, SAME_UPPER, SAME_LOWER or VALID. Where default value is NOTSET, which means explicit padding is used. SAME_UPPER or SAME_LOWER mean pad the input so that `output_shape[i] = ceil(input_shape[i] / strides[i])` for each axis `i`. The padding is split between the two sides equally or almost equally (depending on whether it is even or odd). In case the padding is an odd number, the extra padding is added at the end for SAME_UPPER and at the beginning for SAME_LOWER."
              },
              {
                "name": "dilations",
                "type": "int64[]",
                "required": false,
                "description": "dilation value along each spatial axis of the filter. If not present, the dilation defaults is 1 along each spatial axis."
              },
              {
                "name": "group",
                "type": "int64",
                "required": false,
                "default": 1,
                "description": "number of groups input channels and output channels are divided into."
              },
              {
                "name": "kernel_shape",
                "type": "int64[]",
                "required": false,
                "description": "The shape of the convolution kernel. If not present, should be inferred from input W."
              },
              {
                "name": "pads",
                "type": "int64[]",
                "required": false,
                "description": "Padding for the beginning and ending along each spatial axis, it can take any value greater than or equal to 0. The value represent the number of pixels added to the beginning and end part of the corresponding axis. `pads` format should be as follow [x1_begin, x2_begin...x1_end, x2_end,...], where xi_begin the number of pixels added at the beginning of axis `i` and xi_end, the number of pixels added at the end of axis `i`. This attribute cannot be used simultaneously with auto_pad attribute. If not present, the padding defaults to 0 along start and end of each spatial axis."
              },
              {
                "name": "strides",
                "type": "int64[]",
                "required": false,
                "description": "Stride along each spatial axis. If not present, the stride defaults is 1 along each spatial axis."
              }
            ],
            "inputs": [
              {
                "name": "X",
                "type": "T",
                "description": "Input data tensor from previous layer; has size (N x C x H x W), where N is the batch size, C is the number of channels, and H and W are the height and width. Note that this is for the 2D image. Otherwise the size is (N x C x D1 x D2 ... x Dn). Optionally, if dimension denotation is in effect, the operation expects input data tensor to arrive with the dimension denotation of [DATA_BATCH, DATA_CHANNEL, DATA_FEATURE, DATA_FEATURE ...]."
              },
              {
                "name": "W",
                "type": "T",
                "description": "The weight tensor that will be used in the convolutions; has size (M x C/group x kH x kW), where C is the number of channels, and kH and kW are the height and width of the kernel, and M is the number of feature maps. For more than 2 dimensions, the kernel shape will be (M x C/group x k1 x k2 x ... x kn), where (k1 x k2 x ... kn) is the dimension of the kernel. Optionally, if dimension denotation is in effect, the operation expects the weight tensor to arrive with the dimension denotation of [FILTER_OUT_CHANNEL, FILTER_IN_CHANNEL, FILTER_SPATIAL, FILTER_SPATIAL ...]. Assuming zero based indices for the shape array, X.shape[1] == (W.shape[1] * group) == C and W.shape[0] mod G == 0. Or in other words FILTER_IN_CHANNEL multiplied by the number of groups should be equal to DATA_CHANNEL and the number of feature maps M should be a multiple of the number of groups G."
              },
              {
                "name": "B",
                "type": "T",
                "option": "optional",
                "description": "Optional 1D bias to be added to the convolution, has size of M."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "Y",
                "type": "T",
                "description": "Output data tensor that contains the result of the convolution. The output dimensions are functions of the kernel size, stride size, and pad lengths."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain input and output types to float tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "conv",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[1, 1, 1, 1],\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 21.0, 27.0, 33.0, 24.0],  # (1, 1, 5, 5) output tensor\n                [33.0, 54.0, 63.0, 72.0, 51.0],\n                [63.0, 99.0, 108.0, 117.0, 81.0],\n                [93.0, 144.0, 153.0, 162.0, 111.0],\n                [72.0, 111.0, 117.0, 123.0, 84.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_basic_conv_with_padding\",\n)\n\n# Convolution without padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[0, 0, 0, 0],\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 63.0, 72.0],  # (1, 1, 3, 3) output tensor\n                [99.0, 108.0, 117.0],\n                [144.0, 153.0, 162.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_basic_conv_without_padding\",\n)"
              },
              {
                "summary": "conv_with_autopad_same",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with auto_pad='SAME_LOWER' and strides=2\nnode = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    auto_pad=\"SAME_LOWER\",\n    kernel_shape=[3, 3],\n    strides=[2, 2],\n)\ny = np.array(\n    [[[[12.0, 27.0, 24.0], [63.0, 108.0, 81.0], [72.0, 117.0, 84.0]]]]\n).astype(np.float32)\nexpect(node, inputs=[x, W], outputs=[y], name=\"test_conv_with_autopad_same\")"
              },
              {
                "summary": "conv_with_strides",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 7, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n                [25.0, 26.0, 27.0, 28.0, 29.0],\n                [30.0, 31.0, 32.0, 33.0, 34.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with strides=2 and padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 1, 1, 1],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 27.0, 24.0],  # (1, 1, 4, 3) output tensor\n                [63.0, 108.0, 81.0],\n                [123.0, 198.0, 141.0],\n                [112.0, 177.0, 124.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_conv_with_strides_padding\",\n)\n\n# Convolution with strides=2 and no padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[0, 0, 0, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 72.0],  # (1, 1, 3, 2) output tensor\n                [144.0, 162.0],\n                [234.0, 252.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_conv_with_strides_no_padding\",\n)\n\n# Convolution with strides=2 and padding only along one dimension (the H dimension in NxCxHxW tensor)\nnode_with_asymmetric_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 0, 1, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_asymmetric_padding = np.array(\n    [\n        [\n            [\n                [21.0, 33.0],  # (1, 1, 4, 2) output tensor\n                [99.0, 117.0],\n                [189.0, 207.0],\n                [171.0, 183.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_asymmetric_padding,\n    inputs=[x, W],\n    outputs=[y_with_asymmetric_padding],\n    name=\"test_conv_with_strides_and_asymmetric_padding\",\n)"
              }
            ],
            "category": "Layer"
          }
        },
        {
          "name": "add_8__xeno_compat__1",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "A",
              "value": [
                {
                  "name": "Conv__167:0",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        16,
                        36,
                        64
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "B",
              "value": [
                {
                  "name": "Conv__249:0",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        16,
                        36,
                        64
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "C",
              "value": [
                {
                  "name": "add_8__xeno_compat__1:0",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        16,
                        36,
                        64
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "Add",
            "module": "ai.onnx",
            "version": 14,
            "description": "Performs element-wise binary addition (with Numpy-style broadcasting support).\n\nThis operator supports **multidirectional (i.e., Numpy-style) broadcasting**; for more details please check [the doc](https://github.com/onnx/onnx/blob/master/docs/Broadcasting.md).\n\n(Opset 14 change): Extend supported types to include uint8, int8, uint16, and int16.\n",
            "inputs": [
              {
                "name": "A",
                "type": "T",
                "description": "First operand."
              },
              {
                "name": "B",
                "type": "T",
                "description": "Second operand."
              }
            ],
            "min_input": 2,
            "max_input": 2,
            "outputs": [
              {
                "name": "C",
                "type": "T",
                "description": "Result, has same element type as two inputs"
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "type_constraints": [
              {
                "description": "Constrain input and output types to all numeric tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(uint8)",
                  "tensor(uint16)",
                  "tensor(uint32)",
                  "tensor(uint64)",
                  "tensor(int8)",
                  "tensor(int16)",
                  "tensor(int32)",
                  "tensor(int64)",
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)",
                  "tensor(bfloat16)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "add",
                "code": "node = onnx.helper.make_node(\n    \"Add\",\n    inputs=[\"x\", \"y\"],\n    outputs=[\"sum\"],\n)\n\nx = np.random.randn(3, 4, 5).astype(np.float32)\ny = np.random.randn(3, 4, 5).astype(np.float32)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add\")\n\nx = np.random.randint(24, size=(3, 4, 5), dtype=np.int8)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.int8)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add_int8\")\n\nx = np.random.randint(24, size=(3, 4, 5), dtype=np.int16)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.int16)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add_int16\")\n\nx = np.random.randint(24, size=(3, 4, 5), dtype=np.uint8)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.uint8)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add_uint8\")\n\nx = np.random.randint(24, size=(3, 4, 5), dtype=np.uint16)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.uint16)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add_uint16\")\n\nx = np.random.randint(24, size=(3, 4, 5), dtype=np.uint32)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.uint32)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add_uint32\")\n\nx = np.random.randint(24, size=(3, 4, 5), dtype=np.uint64)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.uint64)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add_uint64\")"
              },
              {
                "summary": "add_broadcast",
                "code": "node = onnx.helper.make_node(\n    \"Add\",\n    inputs=[\"x\", \"y\"],\n    outputs=[\"sum\"],\n)\n\nx = np.random.randn(3, 4, 5).astype(np.float32)\ny = np.random.randn(5).astype(np.float32)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add_bcast\")"
              }
            ]
          }
        },
        {
          "name": "global_average_pooling2d_8",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "X",
              "value": [
                {
                  "name": "add_8__xeno_compat__1:0",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        16,
                        36,
                        64
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "Y",
              "value": [
                {
                  "name": "global_average_pooling2d_8:0",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        16,
                        1,
                        1
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "GlobalAveragePool",
            "module": "ai.onnx",
            "version": 1,
            "description": "GlobalAveragePool consumes an input tensor X and applies average pooling across\n the values in the same channel. This is equivalent to AveragePool with kernel size\n equal to the spatial dimension of input tensor.",
            "inputs": [
              {
                "name": "X",
                "type": "T",
                "description": "Input data tensor from the previous operator; dimensions for image case are (N x C x H x W), where N is the batch size, C is the number of channels, and H and W are the height and the width of the data. For non image case, the dimensions are in the form of (N x C x D1 x D2 ... Dn), where N is the batch size."
              }
            ],
            "min_input": 1,
            "max_input": 1,
            "outputs": [
              {
                "name": "Y",
                "type": "T",
                "description": "Output data tensor from pooling across the input tensor. The output tensor has the same rank as the input. The first two dimensions of output shape are the same as the input (N x C), while the other dimensions are all 1."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "type_constraints": [
              {
                "description": "Constrain input and output types to float tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "globalaveragepool",
                "code": "node = onnx.helper.make_node(\n    \"GlobalAveragePool\",\n    inputs=[\"x\"],\n    outputs=[\"y\"],\n)\nx = np.random.randn(1, 3, 5, 5).astype(np.float32)\ny = np.mean(x, axis=tuple(range(2, np.ndim(x))), keepdims=True)\nexpect(node, inputs=[x], outputs=[y], name=\"test_globalaveragepool\")"
              },
              {
                "summary": "globalaveragepool_precomputed",
                "code": "node = onnx.helper.make_node(\n    \"GlobalAveragePool\",\n    inputs=[\"x\"],\n    outputs=[\"y\"],\n)\nx = np.array(\n    [\n        [\n            [\n                [1, 2, 3],\n                [4, 5, 6],\n                [7, 8, 9],\n            ]\n        ]\n    ]\n).astype(np.float32)\ny = np.array([[[[5]]]]).astype(np.float32)\nexpect(node, inputs=[x], outputs=[y], name=\"test_globalaveragepool_precomputed\")"
              }
            ],
            "category": "Pool"
          }
        },
        {
          "name": "Conv__252",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "X",
              "value": [
                {
                  "name": "global_average_pooling2d_8:0",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        16,
                        1,
                        1
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "W",
              "value": [
                {
                  "name": "Conv2D_37/filter:0",
                  "initializer": {
                    "name": "Conv2D_37/filter:0",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float32",
                      "shape": {
                        "dimensions": [
                          16,
                          16,
                          1,
                          1
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        16,
                        16,
                        1,
                        1
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "B",
              "value": [
                {
                  "name": "conv2d_36_1/y:0",
                  "initializer": {
                    "name": "conv2d_36_1/y:0",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float32",
                      "shape": {
                        "dimensions": [
                          16
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        16
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "Y",
              "value": [
                {
                  "name": "Conv__252:0",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        16,
                        1,
                        1
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [
            {
              "name": "dilations",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "strides",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "kernel_shape",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "group",
              "type": "int64",
              "value": {
                "type": "bigint",
                "value": "1"
              }
            }
          ],
          "type": {
            "name": "Conv",
            "module": "ai.onnx",
            "version": 11,
            "description": "The convolution operator consumes an input tensor and a filter, and\ncomputes the output.",
            "attributes": [
              {
                "name": "auto_pad",
                "type": "string",
                "required": false,
                "default": "NOTSET",
                "description": "auto_pad must be either NOTSET, SAME_UPPER, SAME_LOWER or VALID. Where default value is NOTSET, which means explicit padding is used. SAME_UPPER or SAME_LOWER mean pad the input so that `output_shape[i] = ceil(input_shape[i] / strides[i])` for each axis `i`. The padding is split between the two sides equally or almost equally (depending on whether it is even or odd). In case the padding is an odd number, the extra padding is added at the end for SAME_UPPER and at the beginning for SAME_LOWER."
              },
              {
                "name": "dilations",
                "type": "int64[]",
                "required": false,
                "description": "dilation value along each spatial axis of the filter. If not present, the dilation defaults is 1 along each spatial axis."
              },
              {
                "name": "group",
                "type": "int64",
                "required": false,
                "default": 1,
                "description": "number of groups input channels and output channels are divided into."
              },
              {
                "name": "kernel_shape",
                "type": "int64[]",
                "required": false,
                "description": "The shape of the convolution kernel. If not present, should be inferred from input W."
              },
              {
                "name": "pads",
                "type": "int64[]",
                "required": false,
                "description": "Padding for the beginning and ending along each spatial axis, it can take any value greater than or equal to 0. The value represent the number of pixels added to the beginning and end part of the corresponding axis. `pads` format should be as follow [x1_begin, x2_begin...x1_end, x2_end,...], where xi_begin the number of pixels added at the beginning of axis `i` and xi_end, the number of pixels added at the end of axis `i`. This attribute cannot be used simultaneously with auto_pad attribute. If not present, the padding defaults to 0 along start and end of each spatial axis."
              },
              {
                "name": "strides",
                "type": "int64[]",
                "required": false,
                "description": "Stride along each spatial axis. If not present, the stride defaults is 1 along each spatial axis."
              }
            ],
            "inputs": [
              {
                "name": "X",
                "type": "T",
                "description": "Input data tensor from previous layer; has size (N x C x H x W), where N is the batch size, C is the number of channels, and H and W are the height and width. Note that this is for the 2D image. Otherwise the size is (N x C x D1 x D2 ... x Dn). Optionally, if dimension denotation is in effect, the operation expects input data tensor to arrive with the dimension denotation of [DATA_BATCH, DATA_CHANNEL, DATA_FEATURE, DATA_FEATURE ...]."
              },
              {
                "name": "W",
                "type": "T",
                "description": "The weight tensor that will be used in the convolutions; has size (M x C/group x kH x kW), where C is the number of channels, and kH and kW are the height and width of the kernel, and M is the number of feature maps. For more than 2 dimensions, the kernel shape will be (M x C/group x k1 x k2 x ... x kn), where (k1 x k2 x ... kn) is the dimension of the kernel. Optionally, if dimension denotation is in effect, the operation expects the weight tensor to arrive with the dimension denotation of [FILTER_OUT_CHANNEL, FILTER_IN_CHANNEL, FILTER_SPATIAL, FILTER_SPATIAL ...]. Assuming zero based indices for the shape array, X.shape[1] == (W.shape[1] * group) == C and W.shape[0] mod G == 0. Or in other words FILTER_IN_CHANNEL multiplied by the number of groups should be equal to DATA_CHANNEL and the number of feature maps M should be a multiple of the number of groups G."
              },
              {
                "name": "B",
                "type": "T",
                "option": "optional",
                "description": "Optional 1D bias to be added to the convolution, has size of M."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "Y",
                "type": "T",
                "description": "Output data tensor that contains the result of the convolution. The output dimensions are functions of the kernel size, stride size, and pad lengths."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain input and output types to float tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "conv",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[1, 1, 1, 1],\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 21.0, 27.0, 33.0, 24.0],  # (1, 1, 5, 5) output tensor\n                [33.0, 54.0, 63.0, 72.0, 51.0],\n                [63.0, 99.0, 108.0, 117.0, 81.0],\n                [93.0, 144.0, 153.0, 162.0, 111.0],\n                [72.0, 111.0, 117.0, 123.0, 84.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_basic_conv_with_padding\",\n)\n\n# Convolution without padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[0, 0, 0, 0],\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 63.0, 72.0],  # (1, 1, 3, 3) output tensor\n                [99.0, 108.0, 117.0],\n                [144.0, 153.0, 162.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_basic_conv_without_padding\",\n)"
              },
              {
                "summary": "conv_with_autopad_same",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with auto_pad='SAME_LOWER' and strides=2\nnode = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    auto_pad=\"SAME_LOWER\",\n    kernel_shape=[3, 3],\n    strides=[2, 2],\n)\ny = np.array(\n    [[[[12.0, 27.0, 24.0], [63.0, 108.0, 81.0], [72.0, 117.0, 84.0]]]]\n).astype(np.float32)\nexpect(node, inputs=[x, W], outputs=[y], name=\"test_conv_with_autopad_same\")"
              },
              {
                "summary": "conv_with_strides",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 7, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n                [25.0, 26.0, 27.0, 28.0, 29.0],\n                [30.0, 31.0, 32.0, 33.0, 34.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with strides=2 and padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 1, 1, 1],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 27.0, 24.0],  # (1, 1, 4, 3) output tensor\n                [63.0, 108.0, 81.0],\n                [123.0, 198.0, 141.0],\n                [112.0, 177.0, 124.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_conv_with_strides_padding\",\n)\n\n# Convolution with strides=2 and no padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[0, 0, 0, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 72.0],  # (1, 1, 3, 2) output tensor\n                [144.0, 162.0],\n                [234.0, 252.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_conv_with_strides_no_padding\",\n)\n\n# Convolution with strides=2 and padding only along one dimension (the H dimension in NxCxHxW tensor)\nnode_with_asymmetric_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 0, 1, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_asymmetric_padding = np.array(\n    [\n        [\n            [\n                [21.0, 33.0],  # (1, 1, 4, 2) output tensor\n                [99.0, 117.0],\n                [189.0, 207.0],\n                [171.0, 183.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_asymmetric_padding,\n    inputs=[x, W],\n    outputs=[y_with_asymmetric_padding],\n    name=\"test_conv_with_strides_and_asymmetric_padding\",\n)"
              }
            ],
            "category": "Layer"
          }
        },
        {
          "name": "re_lu_16",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "X",
              "value": [
                {
                  "name": "Conv__252:0",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        16,
                        1,
                        1
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "Y",
              "value": [
                {
                  "name": "re_lu_16:0",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        16,
                        1,
                        1
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "Relu",
            "module": "ai.onnx",
            "version": 14,
            "description": "Relu takes one input data (Tensor<T>) and produces one output data\n(Tensor<T>) where the rectified linear function, y = max(0, x), is applied to\nthe tensor elementwise.\n",
            "inputs": [
              {
                "name": "X",
                "type": "T",
                "description": "Input tensor"
              }
            ],
            "min_input": 1,
            "max_input": 1,
            "outputs": [
              {
                "name": "Y",
                "type": "T",
                "description": "Output tensor"
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "type_constraints": [
              {
                "description": "Constrain input and output types to signed numeric tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(float)",
                  "tensor(int32)",
                  "tensor(int8)",
                  "tensor(int16)",
                  "tensor(int64)",
                  "tensor(float16)",
                  "tensor(double)",
                  "tensor(bfloat16)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "relu",
                "code": "node = onnx.helper.make_node(\n    \"Relu\",\n    inputs=[\"x\"],\n    outputs=[\"y\"],\n)\nx = np.random.randn(3, 4, 5).astype(np.float32)\ny = np.clip(x, 0, np.inf)\n\nexpect(node, inputs=[x], outputs=[y], name=\"test_relu\")"
              }
            ],
            "category": "Activation"
          }
        },
        {
          "name": "Conv__253",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "X",
              "value": [
                {
                  "name": "re_lu_16:0",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        16,
                        1,
                        1
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "W",
              "value": [
                {
                  "name": "Conv2D_38/filter:0",
                  "initializer": {
                    "name": "Conv2D_38/filter:0",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float32",
                      "shape": {
                        "dimensions": [
                          16,
                          16,
                          1,
                          1
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        16,
                        16,
                        1,
                        1
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "B",
              "value": [
                {
                  "name": "conv2d_37_1/y:0",
                  "initializer": {
                    "name": "conv2d_37_1/y:0",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float32",
                      "shape": {
                        "dimensions": [
                          16
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        16
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "Y",
              "value": [
                {
                  "name": "Conv__253:0",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        16,
                        1,
                        1
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [
            {
              "name": "dilations",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "strides",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "kernel_shape",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "group",
              "type": "int64",
              "value": {
                "type": "bigint",
                "value": "1"
              }
            }
          ],
          "type": {
            "name": "Conv",
            "module": "ai.onnx",
            "version": 11,
            "description": "The convolution operator consumes an input tensor and a filter, and\ncomputes the output.",
            "attributes": [
              {
                "name": "auto_pad",
                "type": "string",
                "required": false,
                "default": "NOTSET",
                "description": "auto_pad must be either NOTSET, SAME_UPPER, SAME_LOWER or VALID. Where default value is NOTSET, which means explicit padding is used. SAME_UPPER or SAME_LOWER mean pad the input so that `output_shape[i] = ceil(input_shape[i] / strides[i])` for each axis `i`. The padding is split between the two sides equally or almost equally (depending on whether it is even or odd). In case the padding is an odd number, the extra padding is added at the end for SAME_UPPER and at the beginning for SAME_LOWER."
              },
              {
                "name": "dilations",
                "type": "int64[]",
                "required": false,
                "description": "dilation value along each spatial axis of the filter. If not present, the dilation defaults is 1 along each spatial axis."
              },
              {
                "name": "group",
                "type": "int64",
                "required": false,
                "default": 1,
                "description": "number of groups input channels and output channels are divided into."
              },
              {
                "name": "kernel_shape",
                "type": "int64[]",
                "required": false,
                "description": "The shape of the convolution kernel. If not present, should be inferred from input W."
              },
              {
                "name": "pads",
                "type": "int64[]",
                "required": false,
                "description": "Padding for the beginning and ending along each spatial axis, it can take any value greater than or equal to 0. The value represent the number of pixels added to the beginning and end part of the corresponding axis. `pads` format should be as follow [x1_begin, x2_begin...x1_end, x2_end,...], where xi_begin the number of pixels added at the beginning of axis `i` and xi_end, the number of pixels added at the end of axis `i`. This attribute cannot be used simultaneously with auto_pad attribute. If not present, the padding defaults to 0 along start and end of each spatial axis."
              },
              {
                "name": "strides",
                "type": "int64[]",
                "required": false,
                "description": "Stride along each spatial axis. If not present, the stride defaults is 1 along each spatial axis."
              }
            ],
            "inputs": [
              {
                "name": "X",
                "type": "T",
                "description": "Input data tensor from previous layer; has size (N x C x H x W), where N is the batch size, C is the number of channels, and H and W are the height and width. Note that this is for the 2D image. Otherwise the size is (N x C x D1 x D2 ... x Dn). Optionally, if dimension denotation is in effect, the operation expects input data tensor to arrive with the dimension denotation of [DATA_BATCH, DATA_CHANNEL, DATA_FEATURE, DATA_FEATURE ...]."
              },
              {
                "name": "W",
                "type": "T",
                "description": "The weight tensor that will be used in the convolutions; has size (M x C/group x kH x kW), where C is the number of channels, and kH and kW are the height and width of the kernel, and M is the number of feature maps. For more than 2 dimensions, the kernel shape will be (M x C/group x k1 x k2 x ... x kn), where (k1 x k2 x ... kn) is the dimension of the kernel. Optionally, if dimension denotation is in effect, the operation expects the weight tensor to arrive with the dimension denotation of [FILTER_OUT_CHANNEL, FILTER_IN_CHANNEL, FILTER_SPATIAL, FILTER_SPATIAL ...]. Assuming zero based indices for the shape array, X.shape[1] == (W.shape[1] * group) == C and W.shape[0] mod G == 0. Or in other words FILTER_IN_CHANNEL multiplied by the number of groups should be equal to DATA_CHANNEL and the number of feature maps M should be a multiple of the number of groups G."
              },
              {
                "name": "B",
                "type": "T",
                "option": "optional",
                "description": "Optional 1D bias to be added to the convolution, has size of M."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "Y",
                "type": "T",
                "description": "Output data tensor that contains the result of the convolution. The output dimensions are functions of the kernel size, stride size, and pad lengths."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain input and output types to float tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "conv",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[1, 1, 1, 1],\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 21.0, 27.0, 33.0, 24.0],  # (1, 1, 5, 5) output tensor\n                [33.0, 54.0, 63.0, 72.0, 51.0],\n                [63.0, 99.0, 108.0, 117.0, 81.0],\n                [93.0, 144.0, 153.0, 162.0, 111.0],\n                [72.0, 111.0, 117.0, 123.0, 84.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_basic_conv_with_padding\",\n)\n\n# Convolution without padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[0, 0, 0, 0],\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 63.0, 72.0],  # (1, 1, 3, 3) output tensor\n                [99.0, 108.0, 117.0],\n                [144.0, 153.0, 162.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_basic_conv_without_padding\",\n)"
              },
              {
                "summary": "conv_with_autopad_same",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with auto_pad='SAME_LOWER' and strides=2\nnode = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    auto_pad=\"SAME_LOWER\",\n    kernel_shape=[3, 3],\n    strides=[2, 2],\n)\ny = np.array(\n    [[[[12.0, 27.0, 24.0], [63.0, 108.0, 81.0], [72.0, 117.0, 84.0]]]]\n).astype(np.float32)\nexpect(node, inputs=[x, W], outputs=[y], name=\"test_conv_with_autopad_same\")"
              },
              {
                "summary": "conv_with_strides",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 7, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n                [25.0, 26.0, 27.0, 28.0, 29.0],\n                [30.0, 31.0, 32.0, 33.0, 34.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with strides=2 and padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 1, 1, 1],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 27.0, 24.0],  # (1, 1, 4, 3) output tensor\n                [63.0, 108.0, 81.0],\n                [123.0, 198.0, 141.0],\n                [112.0, 177.0, 124.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_conv_with_strides_padding\",\n)\n\n# Convolution with strides=2 and no padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[0, 0, 0, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 72.0],  # (1, 1, 3, 2) output tensor\n                [144.0, 162.0],\n                [234.0, 252.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_conv_with_strides_no_padding\",\n)\n\n# Convolution with strides=2 and padding only along one dimension (the H dimension in NxCxHxW tensor)\nnode_with_asymmetric_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 0, 1, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_asymmetric_padding = np.array(\n    [\n        [\n            [\n                [21.0, 33.0],  # (1, 1, 4, 2) output tensor\n                [99.0, 117.0],\n                [189.0, 207.0],\n                [171.0, 183.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_asymmetric_padding,\n    inputs=[x, W],\n    outputs=[y_with_asymmetric_padding],\n    name=\"test_conv_with_strides_and_asymmetric_padding\",\n)"
              }
            ],
            "category": "Layer"
          }
        },
        {
          "name": "activation_8",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "X",
              "value": [
                {
                  "name": "Conv__253:0",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        16,
                        1,
                        1
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "Y",
              "value": [
                {
                  "name": "activation_8:0",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        16,
                        1,
                        1
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "Sigmoid",
            "module": "ai.onnx",
            "version": 13,
            "description": "Sigmoid takes one input data (Tensor<T>) and produces one output data\n(Tensor<T>) where the sigmoid function, y = 1 / (1 + exp(-x)), is applied to the\ntensor elementwise.\n",
            "inputs": [
              {
                "name": "X",
                "type": "T",
                "description": "Input tensor"
              }
            ],
            "min_input": 1,
            "max_input": 1,
            "outputs": [
              {
                "name": "Y",
                "type": "T",
                "description": "Output tensor"
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "type_constraints": [
              {
                "description": "Constrain input and output types to float tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)",
                  "tensor(bfloat16)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "sigmoid",
                "code": "node = onnx.helper.make_node(\n    \"Sigmoid\",\n    inputs=[\"x\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([-1, 0, 1]).astype(np.float32)\ny = 1.0 / (\n    1.0 + np.exp(np.negative(x))\n)  # expected output [0.26894143, 0.5, 0.7310586]\nexpect(node, inputs=[x], outputs=[y], name=\"test_sigmoid_example\")\n\nx = np.random.randn(3, 4, 5).astype(np.float32)\ny = 1.0 / (1.0 + np.exp(np.negative(x)))\nexpect(node, inputs=[x], outputs=[y], name=\"test_sigmoid\")"
              }
            ],
            "category": "Activation"
          }
        },
        {
          "name": "multiply_8",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "A",
              "value": [
                {
                  "name": "Conv__167:0",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        16,
                        36,
                        64
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "B",
              "value": [
                {
                  "name": "activation_8:0",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        16,
                        1,
                        1
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "C",
              "value": [
                {
                  "name": "multiply_8:0",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        16,
                        36,
                        64
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "Mul",
            "module": "ai.onnx",
            "version": 14,
            "description": "Performs element-wise binary multiplication (with Numpy-style broadcasting support).\n\nThis operator supports **multidirectional (i.e., Numpy-style) broadcasting**; for more details please check [the doc](https://github.com/onnx/onnx/blob/master/docs/Broadcasting.md).\n\n(Opset 14 change): Extend supported types to include uint8, int8, uint16, and int16.\n",
            "inputs": [
              {
                "name": "A",
                "type": "T",
                "description": "First operand."
              },
              {
                "name": "B",
                "type": "T",
                "description": "Second operand."
              }
            ],
            "min_input": 2,
            "max_input": 2,
            "outputs": [
              {
                "name": "C",
                "type": "T",
                "description": "Result, has same element type as two inputs"
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "type_constraints": [
              {
                "description": "Constrain input and output types to all numeric tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(uint8)",
                  "tensor(uint16)",
                  "tensor(uint32)",
                  "tensor(uint64)",
                  "tensor(int8)",
                  "tensor(int16)",
                  "tensor(int32)",
                  "tensor(int64)",
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)",
                  "tensor(bfloat16)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "mul",
                "code": "node = onnx.helper.make_node(\n    \"Mul\",\n    inputs=[\"x\", \"y\"],\n    outputs=[\"z\"],\n)\n\nx = np.array([1, 2, 3]).astype(np.float32)\ny = np.array([4, 5, 6]).astype(np.float32)\nz = x * y  # expected output [4., 10., 18.]\nexpect(node, inputs=[x, y], outputs=[z], name=\"test_mul_example\")\n\nx = np.random.randn(3, 4, 5).astype(np.float32)\ny = np.random.randn(3, 4, 5).astype(np.float32)\nz = x * y\nexpect(node, inputs=[x, y], outputs=[z], name=\"test_mul\")\n\nx = np.random.randint(4, size=(3, 4, 5), dtype=np.int8)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.int8)\nz = x * y\nexpect(node, inputs=[x, y], outputs=[z], name=\"test_mul_int8\")\n\nx = np.random.randint(4, size=(3, 4, 5), dtype=np.int16)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.int16)\nz = x * y\nexpect(node, inputs=[x, y], outputs=[z], name=\"test_mul_int16\")\n\nx = np.random.randint(4, size=(3, 4, 5), dtype=np.uint8)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.uint8)\nz = x * y\nexpect(node, inputs=[x, y], outputs=[z], name=\"test_mul_uint8\")\n\nx = np.random.randint(4, size=(3, 4, 5), dtype=np.uint16)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.uint16)\nz = x * y\nexpect(node, inputs=[x, y], outputs=[z], name=\"test_mul_uint16\")\n\nx = np.random.randint(4, size=(3, 4, 5), dtype=np.uint32)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.uint32)\nz = x * y\nexpect(node, inputs=[x, y], outputs=[z], name=\"test_mul_uint32\")\n\nx = np.random.randint(4, size=(3, 4, 5), dtype=np.uint64)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.uint64)\nz = x * y\nexpect(node, inputs=[x, y], outputs=[z], name=\"test_mul_uint64\")"
              },
              {
                "summary": "mul_broadcast",
                "code": "node = onnx.helper.make_node(\n    \"Mul\",\n    inputs=[\"x\", \"y\"],\n    outputs=[\"z\"],\n)\n\nx = np.random.randn(3, 4, 5).astype(np.float32)\ny = np.random.randn(5).astype(np.float32)\nz = x * y\nexpect(node, inputs=[x, y], outputs=[z], name=\"test_mul_bcast\")"
              }
            ]
          }
        },
        {
          "name": "add_9__xeno_compat__1",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "A",
              "value": [
                {
                  "name": "multiply_8:0",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        16,
                        36,
                        64
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "B",
              "value": [
                {
                  "name": "Conv__249:0",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        16,
                        36,
                        64
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "C",
              "value": [
                {
                  "name": "add_9__xeno_compat__1:0",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        16,
                        36,
                        64
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "Add",
            "module": "ai.onnx",
            "version": 14,
            "description": "Performs element-wise binary addition (with Numpy-style broadcasting support).\n\nThis operator supports **multidirectional (i.e., Numpy-style) broadcasting**; for more details please check [the doc](https://github.com/onnx/onnx/blob/master/docs/Broadcasting.md).\n\n(Opset 14 change): Extend supported types to include uint8, int8, uint16, and int16.\n",
            "inputs": [
              {
                "name": "A",
                "type": "T",
                "description": "First operand."
              },
              {
                "name": "B",
                "type": "T",
                "description": "Second operand."
              }
            ],
            "min_input": 2,
            "max_input": 2,
            "outputs": [
              {
                "name": "C",
                "type": "T",
                "description": "Result, has same element type as two inputs"
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "type_constraints": [
              {
                "description": "Constrain input and output types to all numeric tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(uint8)",
                  "tensor(uint16)",
                  "tensor(uint32)",
                  "tensor(uint64)",
                  "tensor(int8)",
                  "tensor(int16)",
                  "tensor(int32)",
                  "tensor(int64)",
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)",
                  "tensor(bfloat16)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "add",
                "code": "node = onnx.helper.make_node(\n    \"Add\",\n    inputs=[\"x\", \"y\"],\n    outputs=[\"sum\"],\n)\n\nx = np.random.randn(3, 4, 5).astype(np.float32)\ny = np.random.randn(3, 4, 5).astype(np.float32)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add\")\n\nx = np.random.randint(24, size=(3, 4, 5), dtype=np.int8)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.int8)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add_int8\")\n\nx = np.random.randint(24, size=(3, 4, 5), dtype=np.int16)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.int16)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add_int16\")\n\nx = np.random.randint(24, size=(3, 4, 5), dtype=np.uint8)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.uint8)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add_uint8\")\n\nx = np.random.randint(24, size=(3, 4, 5), dtype=np.uint16)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.uint16)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add_uint16\")\n\nx = np.random.randint(24, size=(3, 4, 5), dtype=np.uint32)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.uint32)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add_uint32\")\n\nx = np.random.randint(24, size=(3, 4, 5), dtype=np.uint64)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.uint64)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add_uint64\")"
              },
              {
                "summary": "add_broadcast",
                "code": "node = onnx.helper.make_node(\n    \"Add\",\n    inputs=[\"x\", \"y\"],\n    outputs=[\"sum\"],\n)\n\nx = np.random.randn(3, 4, 5).astype(np.float32)\ny = np.random.randn(5).astype(np.float32)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add_bcast\")"
              }
            ]
          }
        },
        {
          "name": "Conv__254",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "X",
              "value": [
                {
                  "name": "add_9__xeno_compat__1:0",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        16,
                        36,
                        64
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "W",
              "value": [
                {
                  "name": "Conv2D_39/filter:0",
                  "initializer": {
                    "name": "Conv2D_39/filter:0",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float32",
                      "shape": {
                        "dimensions": [
                          16,
                          16,
                          1,
                          1
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        16,
                        16,
                        1,
                        1
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "B",
              "value": [
                {
                  "name": "conv2d_38_1/y:0",
                  "initializer": {
                    "name": "conv2d_38_1/y:0",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float32",
                      "shape": {
                        "dimensions": [
                          16
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        16
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "Y",
              "value": [
                {
                  "name": "Conv__254:0",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        16,
                        36,
                        64
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [
            {
              "name": "dilations",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "strides",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "kernel_shape",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "group",
              "type": "int64",
              "value": {
                "type": "bigint",
                "value": "1"
              }
            }
          ],
          "type": {
            "name": "Conv",
            "module": "ai.onnx",
            "version": 11,
            "description": "The convolution operator consumes an input tensor and a filter, and\ncomputes the output.",
            "attributes": [
              {
                "name": "auto_pad",
                "type": "string",
                "required": false,
                "default": "NOTSET",
                "description": "auto_pad must be either NOTSET, SAME_UPPER, SAME_LOWER or VALID. Where default value is NOTSET, which means explicit padding is used. SAME_UPPER or SAME_LOWER mean pad the input so that `output_shape[i] = ceil(input_shape[i] / strides[i])` for each axis `i`. The padding is split between the two sides equally or almost equally (depending on whether it is even or odd). In case the padding is an odd number, the extra padding is added at the end for SAME_UPPER and at the beginning for SAME_LOWER."
              },
              {
                "name": "dilations",
                "type": "int64[]",
                "required": false,
                "description": "dilation value along each spatial axis of the filter. If not present, the dilation defaults is 1 along each spatial axis."
              },
              {
                "name": "group",
                "type": "int64",
                "required": false,
                "default": 1,
                "description": "number of groups input channels and output channels are divided into."
              },
              {
                "name": "kernel_shape",
                "type": "int64[]",
                "required": false,
                "description": "The shape of the convolution kernel. If not present, should be inferred from input W."
              },
              {
                "name": "pads",
                "type": "int64[]",
                "required": false,
                "description": "Padding for the beginning and ending along each spatial axis, it can take any value greater than or equal to 0. The value represent the number of pixels added to the beginning and end part of the corresponding axis. `pads` format should be as follow [x1_begin, x2_begin...x1_end, x2_end,...], where xi_begin the number of pixels added at the beginning of axis `i` and xi_end, the number of pixels added at the end of axis `i`. This attribute cannot be used simultaneously with auto_pad attribute. If not present, the padding defaults to 0 along start and end of each spatial axis."
              },
              {
                "name": "strides",
                "type": "int64[]",
                "required": false,
                "description": "Stride along each spatial axis. If not present, the stride defaults is 1 along each spatial axis."
              }
            ],
            "inputs": [
              {
                "name": "X",
                "type": "T",
                "description": "Input data tensor from previous layer; has size (N x C x H x W), where N is the batch size, C is the number of channels, and H and W are the height and width. Note that this is for the 2D image. Otherwise the size is (N x C x D1 x D2 ... x Dn). Optionally, if dimension denotation is in effect, the operation expects input data tensor to arrive with the dimension denotation of [DATA_BATCH, DATA_CHANNEL, DATA_FEATURE, DATA_FEATURE ...]."
              },
              {
                "name": "W",
                "type": "T",
                "description": "The weight tensor that will be used in the convolutions; has size (M x C/group x kH x kW), where C is the number of channels, and kH and kW are the height and width of the kernel, and M is the number of feature maps. For more than 2 dimensions, the kernel shape will be (M x C/group x k1 x k2 x ... x kn), where (k1 x k2 x ... kn) is the dimension of the kernel. Optionally, if dimension denotation is in effect, the operation expects the weight tensor to arrive with the dimension denotation of [FILTER_OUT_CHANNEL, FILTER_IN_CHANNEL, FILTER_SPATIAL, FILTER_SPATIAL ...]. Assuming zero based indices for the shape array, X.shape[1] == (W.shape[1] * group) == C and W.shape[0] mod G == 0. Or in other words FILTER_IN_CHANNEL multiplied by the number of groups should be equal to DATA_CHANNEL and the number of feature maps M should be a multiple of the number of groups G."
              },
              {
                "name": "B",
                "type": "T",
                "option": "optional",
                "description": "Optional 1D bias to be added to the convolution, has size of M."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "Y",
                "type": "T",
                "description": "Output data tensor that contains the result of the convolution. The output dimensions are functions of the kernel size, stride size, and pad lengths."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain input and output types to float tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "conv",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[1, 1, 1, 1],\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 21.0, 27.0, 33.0, 24.0],  # (1, 1, 5, 5) output tensor\n                [33.0, 54.0, 63.0, 72.0, 51.0],\n                [63.0, 99.0, 108.0, 117.0, 81.0],\n                [93.0, 144.0, 153.0, 162.0, 111.0],\n                [72.0, 111.0, 117.0, 123.0, 84.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_basic_conv_with_padding\",\n)\n\n# Convolution without padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[0, 0, 0, 0],\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 63.0, 72.0],  # (1, 1, 3, 3) output tensor\n                [99.0, 108.0, 117.0],\n                [144.0, 153.0, 162.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_basic_conv_without_padding\",\n)"
              },
              {
                "summary": "conv_with_autopad_same",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with auto_pad='SAME_LOWER' and strides=2\nnode = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    auto_pad=\"SAME_LOWER\",\n    kernel_shape=[3, 3],\n    strides=[2, 2],\n)\ny = np.array(\n    [[[[12.0, 27.0, 24.0], [63.0, 108.0, 81.0], [72.0, 117.0, 84.0]]]]\n).astype(np.float32)\nexpect(node, inputs=[x, W], outputs=[y], name=\"test_conv_with_autopad_same\")"
              },
              {
                "summary": "conv_with_strides",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 7, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n                [25.0, 26.0, 27.0, 28.0, 29.0],\n                [30.0, 31.0, 32.0, 33.0, 34.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with strides=2 and padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 1, 1, 1],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 27.0, 24.0],  # (1, 1, 4, 3) output tensor\n                [63.0, 108.0, 81.0],\n                [123.0, 198.0, 141.0],\n                [112.0, 177.0, 124.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_conv_with_strides_padding\",\n)\n\n# Convolution with strides=2 and no padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[0, 0, 0, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 72.0],  # (1, 1, 3, 2) output tensor\n                [144.0, 162.0],\n                [234.0, 252.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_conv_with_strides_no_padding\",\n)\n\n# Convolution with strides=2 and padding only along one dimension (the H dimension in NxCxHxW tensor)\nnode_with_asymmetric_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 0, 1, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_asymmetric_padding = np.array(\n    [\n        [\n            [\n                [21.0, 33.0],  # (1, 1, 4, 2) output tensor\n                [99.0, 117.0],\n                [189.0, 207.0],\n                [171.0, 183.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_asymmetric_padding,\n    inputs=[x, W],\n    outputs=[y_with_asymmetric_padding],\n    name=\"test_conv_with_strides_and_asymmetric_padding\",\n)"
              }
            ],
            "category": "Layer"
          }
        },
        {
          "name": "re_lu_17",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "X",
              "value": [
                {
                  "name": "Conv__254:0",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        16,
                        36,
                        64
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "Y",
              "value": [
                {
                  "name": "re_lu_17:0",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        16,
                        36,
                        64
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "Relu",
            "module": "ai.onnx",
            "version": 14,
            "description": "Relu takes one input data (Tensor<T>) and produces one output data\n(Tensor<T>) where the rectified linear function, y = max(0, x), is applied to\nthe tensor elementwise.\n",
            "inputs": [
              {
                "name": "X",
                "type": "T",
                "description": "Input tensor"
              }
            ],
            "min_input": 1,
            "max_input": 1,
            "outputs": [
              {
                "name": "Y",
                "type": "T",
                "description": "Output tensor"
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "type_constraints": [
              {
                "description": "Constrain input and output types to signed numeric tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(float)",
                  "tensor(int32)",
                  "tensor(int8)",
                  "tensor(int16)",
                  "tensor(int64)",
                  "tensor(float16)",
                  "tensor(double)",
                  "tensor(bfloat16)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "relu",
                "code": "node = onnx.helper.make_node(\n    \"Relu\",\n    inputs=[\"x\"],\n    outputs=[\"y\"],\n)\nx = np.random.randn(3, 4, 5).astype(np.float32)\ny = np.clip(x, 0, np.inf)\n\nexpect(node, inputs=[x], outputs=[y], name=\"test_relu\")"
              }
            ],
            "category": "Activation"
          }
        },
        {
          "name": "Conv__257",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "X",
              "value": [
                {
                  "name": "re_lu_17:0",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        16,
                        36,
                        64
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "W",
              "value": [
                {
                  "name": "const_fold_opt__391",
                  "initializer": {
                    "name": "const_fold_opt__391",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float32",
                      "shape": {
                        "dimensions": [
                          16,
                          1,
                          3,
                          3
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        16,
                        1,
                        3,
                        3
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "B",
              "value": [
                {
                  "name": "depthwise_conv2d_9/y:0",
                  "initializer": {
                    "name": "depthwise_conv2d_9/y:0",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float32",
                      "shape": {
                        "dimensions": [
                          16
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        16
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "Y",
              "value": [
                {
                  "name": "Conv__257:0",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        16,
                        36,
                        64
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [
            {
              "name": "dilations",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "strides",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "kernel_shape",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "3",
                  "3"
                ]
              }
            },
            {
              "name": "group",
              "type": "int64",
              "value": {
                "type": "bigint",
                "value": "16"
              }
            },
            {
              "name": "pads",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1",
                  "1",
                  "1"
                ]
              }
            }
          ],
          "type": {
            "name": "Conv",
            "module": "ai.onnx",
            "version": 11,
            "description": "The convolution operator consumes an input tensor and a filter, and\ncomputes the output.",
            "attributes": [
              {
                "name": "auto_pad",
                "type": "string",
                "required": false,
                "default": "NOTSET",
                "description": "auto_pad must be either NOTSET, SAME_UPPER, SAME_LOWER or VALID. Where default value is NOTSET, which means explicit padding is used. SAME_UPPER or SAME_LOWER mean pad the input so that `output_shape[i] = ceil(input_shape[i] / strides[i])` for each axis `i`. The padding is split between the two sides equally or almost equally (depending on whether it is even or odd). In case the padding is an odd number, the extra padding is added at the end for SAME_UPPER and at the beginning for SAME_LOWER."
              },
              {
                "name": "dilations",
                "type": "int64[]",
                "required": false,
                "description": "dilation value along each spatial axis of the filter. If not present, the dilation defaults is 1 along each spatial axis."
              },
              {
                "name": "group",
                "type": "int64",
                "required": false,
                "default": 1,
                "description": "number of groups input channels and output channels are divided into."
              },
              {
                "name": "kernel_shape",
                "type": "int64[]",
                "required": false,
                "description": "The shape of the convolution kernel. If not present, should be inferred from input W."
              },
              {
                "name": "pads",
                "type": "int64[]",
                "required": false,
                "description": "Padding for the beginning and ending along each spatial axis, it can take any value greater than or equal to 0. The value represent the number of pixels added to the beginning and end part of the corresponding axis. `pads` format should be as follow [x1_begin, x2_begin...x1_end, x2_end,...], where xi_begin the number of pixels added at the beginning of axis `i` and xi_end, the number of pixels added at the end of axis `i`. This attribute cannot be used simultaneously with auto_pad attribute. If not present, the padding defaults to 0 along start and end of each spatial axis."
              },
              {
                "name": "strides",
                "type": "int64[]",
                "required": false,
                "description": "Stride along each spatial axis. If not present, the stride defaults is 1 along each spatial axis."
              }
            ],
            "inputs": [
              {
                "name": "X",
                "type": "T",
                "description": "Input data tensor from previous layer; has size (N x C x H x W), where N is the batch size, C is the number of channels, and H and W are the height and width. Note that this is for the 2D image. Otherwise the size is (N x C x D1 x D2 ... x Dn). Optionally, if dimension denotation is in effect, the operation expects input data tensor to arrive with the dimension denotation of [DATA_BATCH, DATA_CHANNEL, DATA_FEATURE, DATA_FEATURE ...]."
              },
              {
                "name": "W",
                "type": "T",
                "description": "The weight tensor that will be used in the convolutions; has size (M x C/group x kH x kW), where C is the number of channels, and kH and kW are the height and width of the kernel, and M is the number of feature maps. For more than 2 dimensions, the kernel shape will be (M x C/group x k1 x k2 x ... x kn), where (k1 x k2 x ... kn) is the dimension of the kernel. Optionally, if dimension denotation is in effect, the operation expects the weight tensor to arrive with the dimension denotation of [FILTER_OUT_CHANNEL, FILTER_IN_CHANNEL, FILTER_SPATIAL, FILTER_SPATIAL ...]. Assuming zero based indices for the shape array, X.shape[1] == (W.shape[1] * group) == C and W.shape[0] mod G == 0. Or in other words FILTER_IN_CHANNEL multiplied by the number of groups should be equal to DATA_CHANNEL and the number of feature maps M should be a multiple of the number of groups G."
              },
              {
                "name": "B",
                "type": "T",
                "option": "optional",
                "description": "Optional 1D bias to be added to the convolution, has size of M."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "Y",
                "type": "T",
                "description": "Output data tensor that contains the result of the convolution. The output dimensions are functions of the kernel size, stride size, and pad lengths."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain input and output types to float tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "conv",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[1, 1, 1, 1],\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 21.0, 27.0, 33.0, 24.0],  # (1, 1, 5, 5) output tensor\n                [33.0, 54.0, 63.0, 72.0, 51.0],\n                [63.0, 99.0, 108.0, 117.0, 81.0],\n                [93.0, 144.0, 153.0, 162.0, 111.0],\n                [72.0, 111.0, 117.0, 123.0, 84.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_basic_conv_with_padding\",\n)\n\n# Convolution without padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[0, 0, 0, 0],\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 63.0, 72.0],  # (1, 1, 3, 3) output tensor\n                [99.0, 108.0, 117.0],\n                [144.0, 153.0, 162.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_basic_conv_without_padding\",\n)"
              },
              {
                "summary": "conv_with_autopad_same",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with auto_pad='SAME_LOWER' and strides=2\nnode = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    auto_pad=\"SAME_LOWER\",\n    kernel_shape=[3, 3],\n    strides=[2, 2],\n)\ny = np.array(\n    [[[[12.0, 27.0, 24.0], [63.0, 108.0, 81.0], [72.0, 117.0, 84.0]]]]\n).astype(np.float32)\nexpect(node, inputs=[x, W], outputs=[y], name=\"test_conv_with_autopad_same\")"
              },
              {
                "summary": "conv_with_strides",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 7, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n                [25.0, 26.0, 27.0, 28.0, 29.0],\n                [30.0, 31.0, 32.0, 33.0, 34.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with strides=2 and padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 1, 1, 1],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 27.0, 24.0],  # (1, 1, 4, 3) output tensor\n                [63.0, 108.0, 81.0],\n                [123.0, 198.0, 141.0],\n                [112.0, 177.0, 124.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_conv_with_strides_padding\",\n)\n\n# Convolution with strides=2 and no padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[0, 0, 0, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 72.0],  # (1, 1, 3, 2) output tensor\n                [144.0, 162.0],\n                [234.0, 252.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_conv_with_strides_no_padding\",\n)\n\n# Convolution with strides=2 and padding only along one dimension (the H dimension in NxCxHxW tensor)\nnode_with_asymmetric_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 0, 1, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_asymmetric_padding = np.array(\n    [\n        [\n            [\n                [21.0, 33.0],  # (1, 1, 4, 2) output tensor\n                [99.0, 117.0],\n                [189.0, 207.0],\n                [171.0, 183.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_asymmetric_padding,\n    inputs=[x, W],\n    outputs=[y_with_asymmetric_padding],\n    name=\"test_conv_with_strides_and_asymmetric_padding\",\n)"
              }
            ],
            "category": "Layer"
          }
        },
        {
          "name": "re_lu_18",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "X",
              "value": [
                {
                  "name": "Conv__257:0",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        16,
                        36,
                        64
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "Y",
              "value": [
                {
                  "name": "re_lu_18:0",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        16,
                        36,
                        64
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "Relu",
            "module": "ai.onnx",
            "version": 14,
            "description": "Relu takes one input data (Tensor<T>) and produces one output data\n(Tensor<T>) where the rectified linear function, y = max(0, x), is applied to\nthe tensor elementwise.\n",
            "inputs": [
              {
                "name": "X",
                "type": "T",
                "description": "Input tensor"
              }
            ],
            "min_input": 1,
            "max_input": 1,
            "outputs": [
              {
                "name": "Y",
                "type": "T",
                "description": "Output tensor"
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "type_constraints": [
              {
                "description": "Constrain input and output types to signed numeric tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(float)",
                  "tensor(int32)",
                  "tensor(int8)",
                  "tensor(int16)",
                  "tensor(int64)",
                  "tensor(float16)",
                  "tensor(double)",
                  "tensor(bfloat16)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "relu",
                "code": "node = onnx.helper.make_node(\n    \"Relu\",\n    inputs=[\"x\"],\n    outputs=[\"y\"],\n)\nx = np.random.randn(3, 4, 5).astype(np.float32)\ny = np.clip(x, 0, np.inf)\n\nexpect(node, inputs=[x], outputs=[y], name=\"test_relu\")"
              }
            ],
            "category": "Activation"
          }
        },
        {
          "name": "add_10__xeno_compat__1",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "A",
              "value": [
                {
                  "name": "re_lu_17:0",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        16,
                        36,
                        64
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "B",
              "value": [
                {
                  "name": "re_lu_18:0",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        16,
                        36,
                        64
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "C",
              "value": [
                {
                  "name": "add_10__xeno_compat__1:0",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        16,
                        36,
                        64
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "Add",
            "module": "ai.onnx",
            "version": 14,
            "description": "Performs element-wise binary addition (with Numpy-style broadcasting support).\n\nThis operator supports **multidirectional (i.e., Numpy-style) broadcasting**; for more details please check [the doc](https://github.com/onnx/onnx/blob/master/docs/Broadcasting.md).\n\n(Opset 14 change): Extend supported types to include uint8, int8, uint16, and int16.\n",
            "inputs": [
              {
                "name": "A",
                "type": "T",
                "description": "First operand."
              },
              {
                "name": "B",
                "type": "T",
                "description": "Second operand."
              }
            ],
            "min_input": 2,
            "max_input": 2,
            "outputs": [
              {
                "name": "C",
                "type": "T",
                "description": "Result, has same element type as two inputs"
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "type_constraints": [
              {
                "description": "Constrain input and output types to all numeric tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(uint8)",
                  "tensor(uint16)",
                  "tensor(uint32)",
                  "tensor(uint64)",
                  "tensor(int8)",
                  "tensor(int16)",
                  "tensor(int32)",
                  "tensor(int64)",
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)",
                  "tensor(bfloat16)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "add",
                "code": "node = onnx.helper.make_node(\n    \"Add\",\n    inputs=[\"x\", \"y\"],\n    outputs=[\"sum\"],\n)\n\nx = np.random.randn(3, 4, 5).astype(np.float32)\ny = np.random.randn(3, 4, 5).astype(np.float32)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add\")\n\nx = np.random.randint(24, size=(3, 4, 5), dtype=np.int8)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.int8)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add_int8\")\n\nx = np.random.randint(24, size=(3, 4, 5), dtype=np.int16)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.int16)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add_int16\")\n\nx = np.random.randint(24, size=(3, 4, 5), dtype=np.uint8)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.uint8)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add_uint8\")\n\nx = np.random.randint(24, size=(3, 4, 5), dtype=np.uint16)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.uint16)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add_uint16\")\n\nx = np.random.randint(24, size=(3, 4, 5), dtype=np.uint32)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.uint32)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add_uint32\")\n\nx = np.random.randint(24, size=(3, 4, 5), dtype=np.uint64)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.uint64)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add_uint64\")"
              },
              {
                "summary": "add_broadcast",
                "code": "node = onnx.helper.make_node(\n    \"Add\",\n    inputs=[\"x\", \"y\"],\n    outputs=[\"sum\"],\n)\n\nx = np.random.randn(3, 4, 5).astype(np.float32)\ny = np.random.randn(5).astype(np.float32)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add_bcast\")"
              }
            ]
          }
        },
        {
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "X",
              "value": [
                {
                  "name": "add_10__xeno_compat__1:0",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        16,
                        36,
                        64
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "roi",
              "value": [
                {
                  "name": "316",
                  "initializer": {
                    "category": "Constant",
                    "encoding": "|",
                    "values": {
                      "0": 0,
                      "1": 0,
                      "2": 0,
                      "3": 0,
                      "4": 1,
                      "5": 1,
                      "6": 1,
                      "7": 1
                    },
                    "type": {
                      "dataType": "float32",
                      "shape": {
                        "dimensions": [
                          8
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        8
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "scales",
              "value": [
                {
                  "name": "scales__125",
                  "initializer": {
                    "name": "scales__125",
                    "category": "Initializer",
                    "encoding": "|",
                    "values": {
                      "0": 1,
                      "1": 1,
                      "2": 2,
                      "3": 2
                    },
                    "type": {
                      "dataType": "float32",
                      "shape": {
                        "dimensions": [
                          4
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        4
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "Y",
              "value": [
                {
                  "name": "291",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        16,
                        72,
                        128
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [
            {
              "name": "mode",
              "type": "string",
              "value": "linear"
            }
          ],
          "type": {
            "name": "Resize",
            "module": "ai.onnx",
            "version": 19,
            "description": "Resize the input tensor. In general, it calculates every value in the output tensor as a weighted average of neighborhood (a.k.a. sampling locations) in the input tensor.\nEach dimension value of the output tensor is:\n```\noutput_dimension = floor(input_dimension * (roi_end - roi_start) * scale)\n```\nif input \\\"sizes\\\" is not specified.\n",
            "attributes": [
              {
                "name": "antialias",
                "type": "int64",
                "required": false,
                "description": "If set to 1, \"linear\" and \"cubic\" interpolation modes will use an antialiasing filter when downscaling. Antialiasing is achieved by stretching the resampling filter by a factor max(1, 1 / scale), which means that when downsampling, more input pixels contribute to an output pixel."
              },
              {
                "name": "axes",
                "type": "int64[]",
                "required": false,
                "description": "If provided, it specifies a subset of axes that 'roi', 'scales' and 'sizes' refer to. If not provided, all axes are assumed [0, 1, ..., r-1], where r = rank(data). Non-specified dimensions are interpreted as non-resizable. Negative value means counting dimensions from the back. Accepted range is [-r, r-1], where r = rank(data). Behavior is undefined if an axis is repeated."
              },
              {
                "name": "coordinate_transformation_mode",
                "type": "string",
                "required": false,
                "default": "half_pixel",
                "description": "\nThis attribute describes how to transform the coordinate in the resized tensor to the coordinate in the original tensor.\n\nThe coordinate of each dimension is transformed individually. Let's describe a case using axis x as an example.\nDenote `x_resized` as the coordinate of axis x in the resized tensor,\n `x_original` as the coordinate of axis x in the original tensor,\n `length_original` as the length of the original tensor in axis x,\n `length_resized` as the length of the resized tensor in axis x,\n `scale = length_resized / length_original`,\n `output_width` the target length on the axis x which can be a fractional number when it is calculated out of a scale factor,\n and `output_width_int` the effective output width as an integer.\n\nif coordinate_transformation_mode is `\"half_pixel\"`,\n```\nx_original = (x_resized + 0.5) / scale - 0.5\n```\n\nif coordinate_transformation_mode is `\"half_pixel_symmetric\"`,\n```\nadjustment = output_width_int / output_width\ncenter = input_width / 2\noffset = center * (1 - adjustment)\nx_ori = offset + (x + 0.5) / scale - 0.5\n```\n\nif coordinate_transformation_mode is `\"pytorch_half_pixel\"`,\n```\nx_original = length_resized > 1 ? (x_resized + 0.5) / scale - 0.5 : 0\n```\n\nif coordinate_transformation_mode is `\"align_corners\"`,\n```\nx_original = x_resized * (length_original - 1) / (length_resized - 1)\n```\n\nif coordinate_transformation_mode is `\"asymmetric\"`,\n```\nx_original = x_resized / scale\n```\n\nif coordinate_transformation_mode is `\"tf_crop_and_resize\"`,\n```\nx_original = length_resized > 1 ? start_x * (length_original - 1) + x_resized * (end_x - start_x) * (length_original - 1) / (length_resized - 1) : 0.5 * (start_x + end_x) * (length_original - 1)\n```\n."
              },
              {
                "name": "cubic_coeff_a",
                "type": "float32",
                "required": false,
                "default": -0.75,
                "description": "The coefficient 'a' used in cubic interpolation. Two common choice are -0.5 (in some cases of TensorFlow) and -0.75 (in PyTorch). Check out Equation (4) in https://ieeexplore.ieee.org/document/1163711 for the details. This attribute is valid only if mode is \"cubic\"."
              },
              {
                "name": "exclude_outside",
                "type": "int64",
                "required": false,
                "description": "If set to 1, the weight of sampling locations outside the tensor will be set to 0 and the weight will be renormalized so that their sum is 1.0. The default value is 0."
              },
              {
                "name": "extrapolation_value",
                "type": "float32",
                "required": false,
                "description": "When coordinate_transformation_mode is \"tf_crop_and_resize\" and x_original is outside the range [0, length_original - 1], this value is used as the corresponding output value. Default is 0.0f."
              },
              {
                "name": "keep_aspect_ratio_policy",
                "type": "string",
                "required": false,
                "default": "stretch",
                "description": "\nThis attribute describes how to interpret the `sizes` input with regard to keeping the original aspect ratio of the input, and it is not applicable when\nthe `scales` input is used.\n\nGiven a set of `sizes`, associated with a subset of `axes` (explicitly provided or default), and assuming `d = axes[i]`, with `i` being the index of the provided `sizes`.\n\nIf `keep_aspect_ratio_policy` is `\"stretch\"`, the original aspect ratio is disregarded, and the input is resized to the specified size:\n`out_size[d] = sizes[i]`\n\nIf `keep_aspect_ratio_policy` is `\"not_larger\"`, the sizes are adjusted so that no extent of the output is larger than the specified size, while keeping the original aspect ratio:\n```\nscale = Min(sizes[i] / in_size[d])\nout_size[d] = round_int(scale * in_size[i])\n```\n\nIf `keep_aspect_ratio_policy` is `\"not_smaller\"`, the sizes are adjusted so that no extent of the output is smaller than the specified size, while keeping the original aspect ratio:\n```\nscale = Max(sizes[i] / in_size[d])\nout_size[d] = round_int(scale * in_size[i])\n```\n\nFor non-resizable axes (those not specified in `axes`), the output size will be equal to the input size.\n\nNote: `round_int` stands for computing the nearest integer value, rounding halfway cases up."
              },
              {
                "name": "mode",
                "type": "string",
                "required": false,
                "default": "nearest",
                "description": "Three interpolation modes: \"nearest\" (default), \"linear\" and \"cubic\". The \"linear\" mode includes linear interpolation for 1D tensor and N-linear interpolation for N-D tensor (for example, bilinear interpolation for 2D tensor). The \"cubic\" mode includes cubic interpolation for 1D tensor and N-cubic interpolation for N-D tensor (for example, bicubic interpolation for 2D tensor)."
              },
              {
                "name": "nearest_mode",
                "type": "string",
                "required": false,
                "default": "round_prefer_floor",
                "description": "Four modes: \"round_prefer_floor\" (default, as known as round half down), \"round_prefer_ceil\" (as known as round half up), \"floor\", \"ceil\". Only used by nearest interpolation. It indicates how to get \"nearest\" pixel in input tensor from x_original, so this attribute is valid only if \"mode\" is \"nearest\"."
              }
            ],
            "inputs": [
              {
                "name": "X",
                "type": "T1",
                "description": "N-D tensor"
              },
              {
                "name": "roi",
                "type": "T2",
                "option": "optional",
                "description": "1-D tensor given as [start1, ..., startN, end1, ..., endN], where N is the rank of X or the length of axes, if provided. The RoIs' coordinates are normalized in the coordinate system of the input image. It only takes effect when coordinate_transformation_mode is \"tf_crop_and_resize\""
              },
              {
                "name": "scales",
                "type": "tensor(float)",
                "option": "optional",
                "description": "The scale array along each dimension. It takes value greater than 0. If it's less than 1, it's sampling down, otherwise, it's upsampling. The number of elements of 'scales' should be the same as the rank of input 'X' or the length of 'axes', if provided. One of 'scales' and 'sizes' MUST be specified and it is an error if both are specified. If 'sizes' is needed, the user can use an empty string as the name of 'scales' in this operator's input list."
              },
              {
                "name": "sizes",
                "type": "tensor(int64)",
                "option": "optional",
                "description": "Target size of the output tensor. Its interpretation depends on the 'keep_aspect_ratio_policy' value.The number of elements of 'sizes' should be the same as the rank of input 'X', or the length of 'axes', if provided. Only one of 'scales' and 'sizes' can be specified. "
              }
            ],
            "min_input": 1,
            "max_input": 4,
            "outputs": [
              {
                "name": "Y",
                "type": "T1",
                "description": "N-D tensor after resizing"
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "1 - 4",
            "type_constraints": [
              {
                "description": "Constrain input 'X' and output 'Y' to all tensor types.",
                "type_param_str": "T1",
                "allowed_type_strs": [
                  "tensor(uint8)",
                  "tensor(uint16)",
                  "tensor(uint32)",
                  "tensor(uint64)",
                  "tensor(int8)",
                  "tensor(int16)",
                  "tensor(int32)",
                  "tensor(int64)",
                  "tensor(bfloat16)",
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)",
                  "tensor(string)",
                  "tensor(bool)",
                  "tensor(complex64)",
                  "tensor(complex128)"
                ]
              },
              {
                "description": "Constrain roi type to float or double.",
                "type_param_str": "T2",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "resize_downsample_scales_cubic",
                "code": "node = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"\", \"scales\"],\n    outputs=[\"Y\"],\n    mode=\"cubic\",\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2, 3, 4],\n                [5, 6, 7, 8],\n                [9, 10, 11, 12],\n                [13, 14, 15, 16],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\nscales = np.array([1.0, 1.0, 0.8, 0.8], dtype=np.float32)\n\n# [[[[ 1.47119141  2.78125     4.08251953]\n#    [ 6.71142578  8.02148438  9.32275391]\n#    [11.91650391 13.2265625  14.52783203]]]]\noutput = interpolate_nd(\n    data, lambda x, _: cubic_coeffs(x), scale_factors=scales\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, scales],\n    outputs=[output],\n    name=\"test_resize_downsample_scales_cubic\",\n)"
              },
              {
                "summary": "resize_downsample_scales_cubic_A_n0p5_exclude_outside",
                "code": "node = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"\", \"scales\"],\n    outputs=[\"Y\"],\n    mode=\"cubic\",\n    cubic_coeff_a=-0.5,\n    exclude_outside=True,\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2, 3, 4],\n                [5, 6, 7, 8],\n                [9, 10, 11, 12],\n                [13, 14, 15, 16],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\nscales = np.array([1.0, 1.0, 0.8, 0.8], dtype=np.float32)\n\n# [[[[ 1.36812675  2.6695014   4.0133367 ]\n#    [ 6.57362535  7.875       9.2188353 ]\n#    [11.94896657 13.25034122 14.59417652]]]]\noutput = interpolate_nd(\n    data,\n    lambda x, _: cubic_coeffs(x, A=-0.5),\n    scale_factors=scales,\n    exclude_outside=True,\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, scales],\n    outputs=[output],\n    name=\"test_resize_downsample_scales_cubic_A_n0p5_exclude_outside\",\n)"
              },
              {
                "summary": "resize_downsample_scales_cubic_align_corners",
                "code": "node = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"\", \"scales\"],\n    outputs=[\"Y\"],\n    mode=\"cubic\",\n    coordinate_transformation_mode=\"align_corners\",\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2, 3, 4],\n                [5, 6, 7, 8],\n                [9, 10, 11, 12],\n                [13, 14, 15, 16],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\nscales = np.array([1.0, 1.0, 0.8, 0.8], dtype=np.float32)\n\n# [[[[ 1.          2.39519159  3.79038317]\n#    [ 6.58076634  7.97595793  9.37114951]\n#    [12.16153268 13.55672427 14.95191585]]]]\noutput = interpolate_nd(\n    data,\n    lambda x, _: cubic_coeffs(x),\n    scale_factors=scales,\n    coordinate_transformation_mode=\"align_corners\",\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, scales],\n    outputs=[output],\n    name=\"test_resize_downsample_scales_cubic_align_corners\",\n)"
              },
              {
                "summary": "resize_downsample_scales_cubic_antialias",
                "code": "node = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"\", \"scales\"],\n    outputs=[\"Y\"],\n    mode=\"cubic\",\n    antialias=1,\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2, 3, 4],\n                [5, 6, 7, 8],\n                [9, 10, 11, 12],\n                [13, 14, 15, 16],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\nscales = np.array([1.0, 1.0, 0.6, 0.6], dtype=np.float32)\n\n# [[[[ 2.5180721  4.2858863]\n#    [ 9.589329  11.357142 ]]]]\noutput = interpolate_nd(\n    data, cubic_coeffs_antialias, scale_factors=scales\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, scales],\n    outputs=[output],\n    name=\"test_resize_downsample_scales_cubic_antialias\",\n)"
              },
              {
                "summary": "resize_downsample_scales_linear",
                "code": "node = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"\", \"scales\"],\n    outputs=[\"Y\"],\n    mode=\"linear\",\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2, 3, 4],\n                [5, 6, 7, 8],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\nscales = np.array([1.0, 1.0, 0.6, 0.6], dtype=np.float32)\n\n# [[[[2.6666665 4.3333331]]]]\noutput = interpolate_nd(\n    data, lambda x, _: linear_coeffs(x), scale_factors=scales\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, scales],\n    outputs=[output],\n    name=\"test_resize_downsample_scales_linear\",\n)"
              },
              {
                "summary": "resize_downsample_scales_linear_align_corners",
                "code": "node = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"\", \"scales\"],\n    outputs=[\"Y\"],\n    mode=\"linear\",\n    coordinate_transformation_mode=\"align_corners\",\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2, 3, 4],\n                [5, 6, 7, 8],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\nscales = np.array([1.0, 1.0, 0.6, 0.6], dtype=np.float32)\n\n# [[[[1.       3.142857]]]]\noutput = interpolate_nd(\n    data,\n    lambda x, _: linear_coeffs(x),\n    scale_factors=scales,\n    coordinate_transformation_mode=\"align_corners\",\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, scales],\n    outputs=[output],\n    name=\"test_resize_downsample_scales_linear_align_corners\",\n)"
              },
              {
                "summary": "resize_downsample_scales_linear_antialias",
                "code": "node = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"\", \"scales\"],\n    outputs=[\"Y\"],\n    mode=\"linear\",\n    antialias=1,\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2, 3, 4],\n                [5, 6, 7, 8],\n                [9, 10, 11, 12],\n                [13, 14, 15, 16],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\nscales = np.array([1.0, 1.0, 0.6, 0.6], dtype=np.float32)\n\n# [[[[ 2.875  4.5  ]\n#    [ 9.375 11.   ]]]]\noutput = interpolate_nd(\n    data, linear_coeffs_antialias, scale_factors=scales\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, scales],\n    outputs=[output],\n    name=\"test_resize_downsample_scales_linear_antialias\",\n)"
              },
              {
                "summary": "resize_downsample_scales_linear_half_pixel_symmetric",
                "code": "node = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"\", \"scales\"],\n    outputs=[\"Y\"],\n    mode=\"linear\",\n    coordinate_transformation_mode=\"half_pixel_symmetric\",\n)\n\ndata = np.array([[[[1, 2, 3, 4]]]], dtype=np.float32)\nscales = np.array([1.0, 1.0, 1.0, 0.6], dtype=np.float32)\n\n# [[[[1.6666667, 3.3333333]]]]\noutput = interpolate_nd(\n    data,\n    lambda x, _: linear_coeffs(x),\n    scale_factors=scales,\n    coordinate_transformation_mode=\"half_pixel_symmetric\",\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, scales],\n    outputs=[output],\n    name=\"test_resize_downsample_scales_linear_half_pixel_symmetric\",\n)"
              },
              {
                "summary": "resize_downsample_scales_nearest",
                "code": "node = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"\", \"scales\"],\n    outputs=[\"Y\"],\n    mode=\"nearest\",\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2, 3, 4],\n                [5, 6, 7, 8],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\nscales = np.array([1.0, 1.0, 0.6, 0.6], dtype=np.float32)\n\n# [[[[1. 3.]]]]\noutput = interpolate_nd(\n    data, lambda x, _: nearest_coeffs(x), scale_factors=scales\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, scales],\n    outputs=[output],\n    name=\"test_resize_downsample_scales_nearest\",\n)"
              },
              {
                "summary": "resize_downsample_sizes_cubic",
                "code": "node = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"\", \"\", \"sizes\"],\n    outputs=[\"Y\"],\n    mode=\"cubic\",\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2, 3, 4],\n                [5, 6, 7, 8],\n                [9, 10, 11, 12],\n                [13, 14, 15, 16],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\nsizes = np.array([1, 1, 3, 3], dtype=np.int64)\n\n# [[[[ 1.63078704  3.00462963  4.37847222]\n#    [ 7.12615741  8.5         9.87384259]\n#    [12.62152778 13.99537037 15.36921296]]]]\noutput = interpolate_nd(\n    data, lambda x, _: cubic_coeffs(x), output_size=sizes\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, sizes],\n    outputs=[output],\n    name=\"test_resize_downsample_sizes_cubic\",\n)"
              },
              {
                "summary": "resize_downsample_sizes_cubic_antialias",
                "code": "node = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"\", \"\", \"sizes\"],\n    outputs=[\"Y\"],\n    mode=\"cubic\",\n    antialias=1,\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2, 3, 4],\n                [5, 6, 7, 8],\n                [9, 10, 11, 12],\n                [13, 14, 15, 16],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\nsizes = np.array([1, 1, 3, 3], dtype=np.int64)\n\n# [[[[ 1.7750092  3.1200073  4.4650054]\n#    [ 7.1550016  8.5        9.844998 ]\n#    [12.534994  13.8799925 15.224991 ]]]]\noutput = interpolate_nd(data, cubic_coeffs_antialias, output_size=sizes).astype(\n    np.float32\n)\n\nexpect(\n    node,\n    inputs=[data, sizes],\n    outputs=[output],\n    name=\"test_resize_downsample_sizes_cubic_antialias\",\n)"
              },
              {
                "summary": "resize_downsample_sizes_linear_antialias",
                "code": "node = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"\", \"\", \"sizes\"],\n    outputs=[\"Y\"],\n    mode=\"linear\",\n    antialias=1,\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2, 3, 4],\n                [5, 6, 7, 8],\n                [9, 10, 11, 12],\n                [13, 14, 15, 16],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\nsizes = np.array([1, 1, 3, 3], dtype=np.int64)\n\n# [[[[ 2.3636363  3.590909   4.818182 ]\n#    [ 7.2727275  8.5        9.727273 ]\n#    [12.181818  13.409091  14.636364 ]]]]\noutput = interpolate_nd(\n    data, linear_coeffs_antialias, output_size=sizes\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, sizes],\n    outputs=[output],\n    name=\"test_resize_downsample_sizes_linear_antialias\",\n)"
              },
              {
                "summary": "resize_downsample_sizes_linear_pytorch_half_pixel",
                "code": "node = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"\", \"\", \"sizes\"],\n    outputs=[\"Y\"],\n    mode=\"linear\",\n    coordinate_transformation_mode=\"pytorch_half_pixel\",\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2, 3, 4],\n                [5, 6, 7, 8],\n                [9, 10, 11, 12],\n                [13, 14, 15, 16],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\nsizes = np.array([1, 1, 3, 1], dtype=np.int64)\n\n# [[[[ 1.6666666]\n#    [ 7.       ]\n#    [12.333333 ]]]]\noutput = interpolate_nd(\n    data,\n    lambda x, _: linear_coeffs(x),\n    output_size=sizes,\n    coordinate_transformation_mode=\"pytorch_half_pixel\",\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, sizes],\n    outputs=[output],\n    name=\"test_resize_downsample_sizes_linear_pytorch_half_pixel\",\n)"
              },
              {
                "summary": "resize_downsample_sizes_nearest",
                "code": "node = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"\", \"\", \"sizes\"],\n    outputs=[\"Y\"],\n    mode=\"nearest\",\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2, 3, 4],\n                [5, 6, 7, 8],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\nsizes = np.array([1, 1, 1, 3], dtype=np.int64)\n\n# [[[[1. 2. 4.]]]]\noutput = interpolate_nd(\n    data, lambda x, _: nearest_coeffs(x), output_size=sizes\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, sizes],\n    outputs=[output],\n    name=\"test_resize_downsample_sizes_nearest\",\n)"
              },
              {
                "summary": "resize_downsample_sizes_nearest_not_larger",
                "code": "keep_aspect_ratio_policy = \"not_larger\"\naxes = [2, 3]\nnode = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"\", \"\", \"sizes\"],\n    outputs=[\"Y\"],\n    mode=\"nearest\",\n    axes=axes,\n    keep_aspect_ratio_policy=keep_aspect_ratio_policy,\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2, 3, 4],\n                [5, 6, 7, 8],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\nsizes = np.array([1, 3], dtype=np.int64)  # Results in 1x2\n\n# [[[[1. 3.]]]]\noutput = interpolate_nd(\n    data,\n    lambda x, _: nearest_coeffs(x),\n    output_size=sizes,\n    axes=axes,\n    keep_aspect_ratio_policy=keep_aspect_ratio_policy,\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, sizes],\n    outputs=[output],\n    name=\"test_resize_downsample_sizes_nearest_not_larger\",\n)"
              },
              {
                "summary": "resize_downsample_sizes_nearest_not_smaller",
                "code": "keep_aspect_ratio_policy = \"not_smaller\"\naxes = [2, 3]\nnode = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"\", \"\", \"sizes\"],\n    outputs=[\"Y\"],\n    mode=\"nearest\",\n    axes=axes,\n    keep_aspect_ratio_policy=keep_aspect_ratio_policy,\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2, 3, 4],\n                [5, 6, 7, 8],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\nsizes = np.array([1, 3], dtype=np.int64)  # Results in 2x3\n\n# [[[[1. 2. 4.]\n#    [5. 6. 8.]]]]\noutput = interpolate_nd(\n    data,\n    lambda x, _: nearest_coeffs(x),\n    output_size=sizes,\n    axes=axes,\n    keep_aspect_ratio_policy=keep_aspect_ratio_policy,\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, sizes],\n    outputs=[output],\n    name=\"test_resize_downsample_sizes_nearest_not_smaller\",\n)"
              },
              {
                "summary": "resize_tf_crop_and_resize",
                "code": "node = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"roi\", \"\", \"sizes\"],\n    outputs=[\"Y\"],\n    mode=\"linear\",\n    coordinate_transformation_mode=\"tf_crop_and_resize\",\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2, 3, 4],\n                [5, 6, 7, 8],\n                [9, 10, 11, 12],\n                [13, 14, 15, 16],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\n# Note: for some rois, the result may be different with that of TF for inaccurate floating point\nroi = np.array([0, 0, 0.4, 0.6, 1, 1, 0.6, 0.8], dtype=np.float32)\nsizes = np.array([1, 1, 3, 3], dtype=np.int64)\n\n# [[[[ 7.6000004  7.9        8.2      ]\n#    [ 8.8        9.1        9.400001 ]\n#    [10.        10.3       10.6      ]]]]\noutput = interpolate_nd(\n    data,\n    lambda x, _: linear_coeffs(x),\n    output_size=sizes,\n    roi=roi,\n    coordinate_transformation_mode=\"tf_crop_and_resize\",\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, roi, sizes],\n    outputs=[output],\n    name=\"test_resize_tf_crop_and_resize\",\n)"
              },
              {
                "summary": "resize_tf_crop_and_resize_axes_2_3",
                "code": "axes = [2, 3]\nnode = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"roi\", \"\", \"sizes\"],\n    outputs=[\"Y\"],\n    mode=\"linear\",\n    coordinate_transformation_mode=\"tf_crop_and_resize\",\n    axes=axes,\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2, 3, 4],\n                [5, 6, 7, 8],\n                [9, 10, 11, 12],\n                [13, 14, 15, 16],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\n# Note: for some rois, the result may be different with that of TF for inaccurate floating point\nroi = np.array([0.4, 0.6, 0.6, 0.8], dtype=np.float32)\nsizes = np.array([3, 3], dtype=np.int64)\n\n# [[[[ 7.6000004  7.9        8.2      ]\n#    [ 8.8        9.1        9.400001 ]\n#    [10.        10.3       10.6      ]]]]\noutput = interpolate_nd(\n    data,\n    lambda x, _: linear_coeffs(x),\n    output_size=sizes,\n    roi=roi,\n    axes=axes,\n    coordinate_transformation_mode=\"tf_crop_and_resize\",\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, roi, sizes],\n    outputs=[output],\n    name=\"test_resize_tf_crop_and_resize_axes_2_3\",\n)"
              },
              {
                "summary": "resize_tf_crop_and_resize_axes_3_2",
                "code": "axes = [3, 2]\nnode = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"roi\", \"\", \"sizes\"],\n    outputs=[\"Y\"],\n    mode=\"linear\",\n    coordinate_transformation_mode=\"tf_crop_and_resize\",\n    axes=axes,\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2, 3, 4],\n                [5, 6, 7, 8],\n                [9, 10, 11, 12],\n                [13, 14, 15, 16],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\n# Note: for some rois, the result may be different with that of TF for inaccurate floating point\nroi = np.array([0.6, 0.4, 0.8, 0.6], dtype=np.float32)\nsizes = np.array([3, 3], dtype=np.int64)\n\n# [[[[ 7.6000004  7.9        8.2      ]\n#    [ 8.8        9.1        9.400001 ]\n#    [10.        10.3       10.6      ]]]]\noutput = interpolate_nd(\n    data,\n    lambda x, _: linear_coeffs(x),\n    output_size=sizes,\n    roi=roi,\n    axes=axes,\n    coordinate_transformation_mode=\"tf_crop_and_resize\",\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, roi, sizes],\n    outputs=[output],\n    name=\"test_resize_tf_crop_and_resize_axes_3_2\",\n)"
              },
              {
                "summary": "resize_tf_crop_and_resize_extrapolation_value",
                "code": "node = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"roi\", \"\", \"sizes\"],\n    outputs=[\"Y\"],\n    mode=\"linear\",\n    coordinate_transformation_mode=\"tf_crop_and_resize\",\n    extrapolation_value=10.0,\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2, 3, 4],\n                [5, 6, 7, 8],\n                [9, 10, 11, 12],\n                [13, 14, 15, 16],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\n# Note: for some rois, the result may be different with that of TF for inaccurate floating point\nroi = np.array([0, 0, 0.4, 0.6, 1, 1, 1.2, 1.7], dtype=np.float32)\nsizes = np.array([1, 1, 3, 3], dtype=np.int64)\n\n# [[[[ 7.6000004 10.        10.       ]\n#    [12.400001  10.        10.       ]\n#    [10.        10.        10.       ]]]]\noutput = interpolate_nd(\n    data,\n    lambda x, _: linear_coeffs(x),\n    output_size=sizes,\n    roi=roi,\n    coordinate_transformation_mode=\"tf_crop_and_resize\",\n    extrapolation_value=10.0,\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, roi, sizes],\n    outputs=[output],\n    name=\"test_resize_tf_crop_and_resize_extrapolation_value\",\n)"
              },
              {
                "summary": "resize_upsample_scales_cubic",
                "code": "node = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"\", \"scales\"],\n    outputs=[\"Y\"],\n    mode=\"cubic\",\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2, 3, 4],\n                [5, 6, 7, 8],\n                [9, 10, 11, 12],\n                [13, 14, 15, 16],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\nscales = np.array([1.0, 1.0, 2.0, 2.0], dtype=np.float32)\n\n# [[[[ 0.47265625  0.76953125  1.24609375  1.875       2.28125\n#      2.91015625  3.38671875  3.68359375]\n#    [ 1.66015625  1.95703125  2.43359375  3.0625      3.46875\n#      4.09765625  4.57421875  4.87109375]\n#    [ 3.56640625  3.86328125  4.33984375  4.96875     5.375\n#      6.00390625  6.48046875  6.77734375]\n#    [ 6.08203125  6.37890625  6.85546875  7.484375    7.890625\n#      8.51953125  8.99609375  9.29296875]\n#    [ 7.70703125  8.00390625  8.48046875  9.109375    9.515625\n#     10.14453125 10.62109375 10.91796875]\n#    [10.22265625 10.51953125 10.99609375 11.625      12.03125\n#     12.66015625 13.13671875 13.43359375]\n#    [12.12890625 12.42578125 12.90234375 13.53125    13.9375\n#     14.56640625 15.04296875 15.33984375]\n#    [13.31640625 13.61328125 14.08984375 14.71875    15.125\n#     15.75390625 16.23046875 16.52734375]]]]\noutput = interpolate_nd(\n    data, lambda x, _: cubic_coeffs(x), scale_factors=scales\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, scales],\n    outputs=[output],\n    name=\"test_resize_upsample_scales_cubic\",\n)"
              },
              {
                "summary": "resize_upsample_scales_cubic_A_n0p5_exclude_outside",
                "code": "node = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"\", \"scales\"],\n    outputs=[\"Y\"],\n    mode=\"cubic\",\n    cubic_coeff_a=-0.5,\n    exclude_outside=True,\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2, 3, 4],\n                [5, 6, 7, 8],\n                [9, 10, 11, 12],\n                [13, 14, 15, 16],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\nscales = np.array([1.0, 1.0, 2.0, 2.0], dtype=np.float32)\n\n# [[[[ 0.55882353  0.81494204  1.35698249  1.89705882  2.39705882\n#      2.93713516  3.47917561  3.73529412]\n#    [ 1.58329755  1.83941606  2.38145651  2.92153285  3.42153285\n#      3.96160918  4.50364964  4.75976814]\n#    [ 3.75145936  4.00757787  4.54961832  5.08969466  5.58969466\n#      6.12977099  6.67181144  6.92792995]\n#    [ 5.91176471  6.16788321  6.70992366  7.25        7.75\n#      8.29007634  8.83211679  9.08823529]\n#    [ 7.91176471  8.16788321  8.70992366  9.25        9.75\n#     10.29007634 10.83211679 11.08823529]\n#    [10.07207005 10.32818856 10.87022901 11.41030534 11.91030534\n#     12.45038168 12.99242213 13.24854064]\n#    [12.24023186 12.49635036 13.03839082 13.57846715 14.07846715\n#     14.61854349 15.16058394 15.41670245]\n#    [13.26470588 13.52082439 14.06286484 14.60294118 15.10294118\n#     15.64301751 16.18505796 16.44117647]]]]\noutput = interpolate_nd(\n    data,\n    lambda x, _: cubic_coeffs(x, A=-0.5),\n    scale_factors=scales,\n    exclude_outside=True,\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, scales],\n    outputs=[output],\n    name=\"test_resize_upsample_scales_cubic_A_n0p5_exclude_outside\",\n)"
              },
              {
                "summary": "resize_upsample_scales_cubic_align_corners",
                "code": "node = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"\", \"scales\"],\n    outputs=[\"Y\"],\n    mode=\"cubic\",\n    coordinate_transformation_mode=\"align_corners\",\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2, 3, 4],\n                [5, 6, 7, 8],\n                [9, 10, 11, 12],\n                [13, 14, 15, 16],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\nscales = np.array([1.0, 1.0, 2.0, 2.0], dtype=np.float32)\n\n# [[[[ 1.          1.34110787  1.80029155  2.32944606  2.67055394\n#      3.19970845  3.65889213  4.        ]\n#    [ 2.36443149  2.70553936  3.16472303  3.69387755  4.03498542\n#      4.56413994  5.02332362  5.36443149]\n#    [ 4.20116618  4.54227405  5.00145773  5.53061224  5.87172012\n#      6.40087464  6.86005831  7.20116618]\n#    [ 6.31778426  6.65889213  7.1180758   7.64723032  7.98833819\n#      8.51749271  8.97667638  9.31778426]\n#    [ 7.68221574  8.02332362  8.48250729  9.01166181  9.35276968\n#      9.8819242  10.34110787 10.68221574]\n#    [ 9.79883382 10.13994169 10.59912536 11.12827988 11.46938776\n#     11.99854227 12.45772595 12.79883382]\n#    [11.63556851 11.97667638 12.43586006 12.96501458 13.30612245\n#     13.83527697 14.29446064 14.63556851]\n#    [13.         13.34110787 13.80029155 14.32944606 14.67055394\n#     15.19970845 15.65889213 16.        ]]]]\noutput = interpolate_nd(\n    data,\n    lambda x, _: cubic_coeffs(x),\n    scale_factors=scales,\n    coordinate_transformation_mode=\"align_corners\",\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, scales],\n    outputs=[output],\n    name=\"test_resize_upsample_scales_cubic_align_corners\",\n)"
              },
              {
                "summary": "resize_upsample_scales_cubic_asymmetric",
                "code": "node = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"\", \"scales\"],\n    outputs=[\"Y\"],\n    mode=\"cubic\",\n    coordinate_transformation_mode=\"asymmetric\",\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2, 3, 4],\n                [5, 6, 7, 8],\n                [9, 10, 11, 12],\n                [13, 14, 15, 16],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\nscales = np.array([1.0, 1.0, 2.0, 2.0], dtype=np.float32)\n\n# [[[[ 1.       1.40625  2.       2.5      3.       3.59375  4.\n#      4.09375]\n#    [ 2.625    3.03125  3.625    4.125    4.625    5.21875  5.625\n#      5.71875]\n#    [ 5.       5.40625  6.       6.5      7.       7.59375  8.\n#      8.09375]\n#    [ 7.       7.40625  8.       8.5      9.       9.59375 10.\n#     10.09375]\n#    [ 9.       9.40625 10.      10.5     11.      11.59375 12.\n#     12.09375]\n#    [11.375   11.78125 12.375   12.875   13.375   13.96875 14.375\n#     14.46875]\n#    [13.      13.40625 14.      14.5     15.      15.59375 16.\n#     16.09375]\n#    [13.375   13.78125 14.375   14.875   15.375   15.96875 16.375\n#     16.46875]]]]\noutput = interpolate_nd(\n    data,\n    lambda x, _: cubic_coeffs(x, A=-0.75),\n    scale_factors=scales,\n    coordinate_transformation_mode=\"asymmetric\",\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, scales],\n    outputs=[output],\n    name=\"test_resize_upsample_scales_cubic_asymmetric\",\n)"
              },
              {
                "summary": "resize_upsample_scales_linear",
                "code": "node = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"\", \"scales\"],\n    outputs=[\"Y\"],\n    mode=\"linear\",\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2],\n                [3, 4],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\nscales = np.array([1.0, 1.0, 2.0, 2.0], dtype=np.float32)\n\n# [[[[1.   1.25 1.75 2.  ]\n#    [1.5  1.75 2.25 2.5 ]\n#    [2.5  2.75 3.25 3.5 ]\n#    [3.   3.25 3.75 4.  ]]]]\noutput = interpolate_nd(\n    data, lambda x, _: linear_coeffs(x), scale_factors=scales\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, scales],\n    outputs=[output],\n    name=\"test_resize_upsample_scales_linear\",\n)"
              },
              {
                "summary": "resize_upsample_scales_linear_align_corners",
                "code": "node = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"\", \"scales\"],\n    outputs=[\"Y\"],\n    mode=\"linear\",\n    coordinate_transformation_mode=\"align_corners\",\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2],\n                [3, 4],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\nscales = np.array([1.0, 1.0, 2.0, 2.0], dtype=np.float32)\n\n# [[[[1.         1.33333333 1.66666667 2.        ]\n#    [1.66666667 2.         2.33333333 2.66666667]\n#    [2.33333333 2.66666667 3.         3.33333333]\n#    [3.         3.33333333 3.66666667 4.        ]]]]\noutput = interpolate_nd(\n    data,\n    lambda x, _: linear_coeffs(x),\n    scale_factors=scales,\n    coordinate_transformation_mode=\"align_corners\",\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, scales],\n    outputs=[output],\n    name=\"test_resize_upsample_scales_linear_align_corners\",\n)"
              },
              {
                "summary": "resize_upsample_scales_linear_half_pixel_symmetric",
                "code": "node = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"\", \"scales\"],\n    outputs=[\"Y\"],\n    mode=\"linear\",\n    coordinate_transformation_mode=\"half_pixel_symmetric\",\n)\n\ndata = np.array([[[[1, 2], [3, 4]]]], dtype=np.float32)\nscales = np.array([1.0, 1.0, 2.3, 2.94], dtype=np.float32)\n\n# [[[[1.        , 1.15986395, 1.5       , 1.84013605, 2.        ],\n#    [1.56521738, 1.72508133, 2.06521738, 2.40535343, 2.56521738],\n#    [2.43478262, 2.59464657, 2.93478262, 3.27491867, 3.43478262],\n#    [3.        , 3.15986395, 3.5       , 3.84013605, 4.        ]]]]\noutput = interpolate_nd(\n    data,\n    lambda x, _: linear_coeffs(x),\n    scale_factors=scales,\n    coordinate_transformation_mode=\"half_pixel_symmetric\",\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, scales],\n    outputs=[output],\n    name=\"test_resize_upsample_scales_linear_half_pixel_symmetric\",\n)"
              },
              {
                "summary": "resize_upsample_scales_nearest",
                "code": "node = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"\", \"scales\"],\n    outputs=[\"Y\"],\n    mode=\"nearest\",\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2],\n                [3, 4],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\nscales = np.array([1.0, 1.0, 2.0, 3.0], dtype=np.float32)\n\n# [[[[1. 1. 1. 2. 2. 2.]\n#    [1. 1. 1. 2. 2. 2.]\n#    [3. 3. 3. 4. 4. 4.]\n#    [3. 3. 3. 4. 4. 4.]]]]\noutput = interpolate_nd(\n    data, lambda x, _: nearest_coeffs(x), scale_factors=scales\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, scales],\n    outputs=[output],\n    name=\"test_resize_upsample_scales_nearest\",\n)"
              },
              {
                "summary": "resize_upsample_scales_nearest_axes_2_3",
                "code": "axes = [2, 3]\nnode = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"\", \"scales\"],\n    outputs=[\"Y\"],\n    mode=\"nearest\",\n    axes=axes,\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2],\n                [3, 4],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\nscales = np.array([2.0, 3.0], dtype=np.float32)\n\n# [[[[1. 1. 1. 2. 2. 2.]\n#    [1. 1. 1. 2. 2. 2.]\n#    [3. 3. 3. 4. 4. 4.]\n#    [3. 3. 3. 4. 4. 4.]]]]\noutput = interpolate_nd(\n    data, lambda x, _: nearest_coeffs(x), scale_factors=scales, axes=axes\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, scales],\n    outputs=[output],\n    name=\"test_resize_upsample_scales_nearest_axes_2_3\",\n)"
              },
              {
                "summary": "resize_upsample_scales_nearest_axes_3_2",
                "code": "axes = [3, 2]\nnode = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"\", \"scales\"],\n    outputs=[\"Y\"],\n    mode=\"nearest\",\n    axes=axes,\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2],\n                [3, 4],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\nscales = np.array([3.0, 2.0], dtype=np.float32)\n\n# [[[[1. 1. 1. 2. 2. 2.]\n#    [1. 1. 1. 2. 2. 2.]\n#    [3. 3. 3. 4. 4. 4.]\n#    [3. 3. 3. 4. 4. 4.]]]]\noutput = interpolate_nd(\n    data, lambda x, _: nearest_coeffs(x), scale_factors=scales, axes=axes\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, scales],\n    outputs=[output],\n    name=\"test_resize_upsample_scales_nearest_axes_3_2\",\n)"
              },
              {
                "summary": "resize_upsample_sizes_cubic",
                "code": "node = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"\", \"\", \"sizes\"],\n    outputs=[\"Y\"],\n    mode=\"cubic\",\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2, 3, 4],\n                [5, 6, 7, 8],\n                [9, 10, 11, 12],\n                [13, 14, 15, 16],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\nsizes = np.array([1, 1, 9, 10], dtype=np.int64)\n\n# [[[[ 0.45507922  0.64057922  0.97157922  1.42257922  1.90732922\n#      2.22332922  2.70807922  3.15907922  3.49007922  3.67557922]\n#    [ 1.39437963  1.57987963  1.91087963  2.36187963  2.84662963\n#      3.16262963  3.64737963  4.09837963  4.42937963  4.61487963]\n#    [ 2.95130693  3.13680693  3.46780693  3.91880693  4.40355693\n#      4.71955693  5.20430693  5.65530693  5.98630693  6.17180693]\n#    [ 5.20525069  5.39075069  5.72175069  6.17275069  6.65750069\n#      6.97350069  7.45825069  7.90925069  8.24025069  8.42575069]\n#    [ 6.88975     7.07525     7.40625     7.85725     8.342\n#      8.658       9.14275     9.59375     9.92475    10.11025   ]\n#    [ 8.57424931  8.75974931  9.09074931  9.54174931 10.02649931\n#     10.34249931 10.82724931 11.27824931 11.60924931 11.79474931]\n#    [10.82819307 11.01369307 11.34469307 11.79569307 12.28044307\n#     12.59644307 13.08119307 13.53219307 13.86319307 14.04869307]\n#    [12.38512037 12.57062037 12.90162037 13.35262037 13.83737037\n#     14.15337037 14.63812037 15.08912037 15.42012037 15.60562037]\n#    [13.32442078 13.50992078 13.84092078 14.29192078 14.77667078\n#     15.09267078 15.57742078 16.02842078 16.35942078 16.54492078]]]]\noutput = interpolate_nd(\n    data, lambda x, _: cubic_coeffs(x), output_size=sizes\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, sizes],\n    outputs=[output],\n    name=\"test_resize_upsample_sizes_cubic\",\n)"
              },
              {
                "summary": "resize_upsample_sizes_nearest",
                "code": "node = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"\", \"\", \"sizes\"],\n    outputs=[\"Y\"],\n    mode=\"nearest\",\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2],\n                [3, 4],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\nsizes = np.array([1, 1, 7, 8], dtype=np.int64)\n\n# [[[[1. 1. 1. 1. 2. 2. 2. 2.]\n#    [1. 1. 1. 1. 2. 2. 2. 2.]\n#    [1. 1. 1. 1. 2. 2. 2. 2.]\n#    [1. 1. 1. 1. 2. 2. 2. 2.]\n#    [3. 3. 3. 3. 4. 4. 4. 4.]\n#    [3. 3. 3. 3. 4. 4. 4. 4.]\n#    [3. 3. 3. 3. 4. 4. 4. 4.]]]]\noutput = interpolate_nd(\n    data, lambda x, _: nearest_coeffs(x), output_size=sizes\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, sizes],\n    outputs=[output],\n    name=\"test_resize_upsample_sizes_nearest\",\n)"
              },
              {
                "summary": "resize_upsample_sizes_nearest_axes_2_3",
                "code": "axes = [2, 3]\nnode = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"\", \"\", \"sizes\"],\n    outputs=[\"Y\"],\n    mode=\"nearest\",\n    axes=axes,\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2],\n                [3, 4],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\nsizes = np.array([7, 8], dtype=np.int64)\n\n# [[[[1. 1. 1. 1. 2. 2. 2. 2.]\n#    [1. 1. 1. 1. 2. 2. 2. 2.]\n#    [1. 1. 1. 1. 2. 2. 2. 2.]\n#    [1. 1. 1. 1. 2. 2. 2. 2.]\n#    [3. 3. 3. 3. 4. 4. 4. 4.]\n#    [3. 3. 3. 3. 4. 4. 4. 4.]\n#    [3. 3. 3. 3. 4. 4. 4. 4.]]]]\noutput = interpolate_nd(\n    data, lambda x, _: nearest_coeffs(x), output_size=sizes, axes=axes\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, sizes],\n    outputs=[output],\n    name=\"test_resize_upsample_sizes_nearest_axes_2_3\",\n)"
              },
              {
                "summary": "resize_upsample_sizes_nearest_axes_3_2",
                "code": "axes = [3, 2]\nnode = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"\", \"\", \"sizes\"],\n    outputs=[\"Y\"],\n    mode=\"nearest\",\n    axes=axes,\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2],\n                [3, 4],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\nsizes = np.array([8, 7], dtype=np.int64)\n\n# [[[[1. 1. 1. 1. 2. 2. 2. 2.]\n#    [1. 1. 1. 1. 2. 2. 2. 2.]\n#    [1. 1. 1. 1. 2. 2. 2. 2.]\n#    [1. 1. 1. 1. 2. 2. 2. 2.]\n#    [3. 3. 3. 3. 4. 4. 4. 4.]\n#    [3. 3. 3. 3. 4. 4. 4. 4.]\n#    [3. 3. 3. 3. 4. 4. 4. 4.]]]]\noutput = interpolate_nd(\n    data, lambda x, _: nearest_coeffs(x), output_size=sizes, axes=axes\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, sizes],\n    outputs=[output],\n    name=\"test_resize_upsample_sizes_nearest_axes_3_2\",\n)"
              },
              {
                "summary": "resize_upsample_sizes_nearest_ceil_half_pixel",
                "code": "node = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"\", \"\", \"sizes\"],\n    outputs=[\"Y\"],\n    mode=\"nearest\",\n    coordinate_transformation_mode=\"half_pixel\",\n    nearest_mode=\"ceil\",\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2, 3, 4],\n                [5, 6, 7, 8],\n                [9, 10, 11, 12],\n                [13, 14, 15, 16],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\nsizes = np.array([1, 1, 8, 8], dtype=np.int64)\n\n# [[[[ 1.  2.  2.  3.  3.  4.  4.  4.]\n#    [ 5.  6.  6.  7.  7.  8.  8.  8.]\n#    [ 5.  6.  6.  7.  7.  8.  8.  8.]\n#    [ 9. 10. 10. 11. 11. 12. 12. 12.]\n#    [ 9. 10. 10. 11. 11. 12. 12. 12.]\n#    [13. 14. 14. 15. 15. 16. 16. 16.]\n#    [13. 14. 14. 15. 15. 16. 16. 16.]\n#    [13. 14. 14. 15. 15. 16. 16. 16.]]]]\noutput = interpolate_nd(\n    data, lambda x, _: nearest_coeffs(x, mode=\"ceil\"), output_size=sizes\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, sizes],\n    outputs=[output],\n    name=\"test_resize_upsample_sizes_nearest_ceil_half_pixel\",\n)"
              },
              {
                "summary": "resize_upsample_sizes_nearest_floor_align_corners",
                "code": "node = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"\", \"\", \"sizes\"],\n    outputs=[\"Y\"],\n    mode=\"nearest\",\n    coordinate_transformation_mode=\"align_corners\",\n    nearest_mode=\"floor\",\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2, 3, 4],\n                [5, 6, 7, 8],\n                [9, 10, 11, 12],\n                [13, 14, 15, 16],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\nsizes = np.array([1, 1, 8, 8], dtype=np.int64)\n\n# [[[[ 1.  1.  1.  2.  2.  3.  3.  4.]\n#    [ 1.  1.  1.  2.  2.  3.  3.  4.]\n#    [ 1.  1.  1.  2.  2.  3.  3.  4.]\n#    [ 5.  5.  5.  6.  6.  7.  7.  8.]\n#    [ 5.  5.  5.  6.  6.  7.  7.  8.]\n#    [ 9.  9.  9. 10. 10. 11. 11. 12.]\n#    [ 9.  9.  9. 10. 10. 11. 11. 12.]\n#    [13. 13. 13. 14. 14. 15. 15. 16.]]]]\noutput = interpolate_nd(\n    data,\n    lambda x, _: nearest_coeffs(x, mode=\"floor\"),\n    output_size=sizes,\n    coordinate_transformation_mode=\"align_corners\",\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, sizes],\n    outputs=[output],\n    name=\"test_resize_upsample_sizes_nearest_floor_align_corners\",\n)"
              },
              {
                "summary": "resize_upsample_sizes_nearest_not_larger",
                "code": "keep_aspect_ratio_policy = \"not_larger\"\naxes = [2, 3]\nnode = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"\", \"\", \"sizes\"],\n    outputs=[\"Y\"],\n    mode=\"nearest\",\n    axes=axes,\n    keep_aspect_ratio_policy=keep_aspect_ratio_policy,\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2],\n                [3, 4],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\nsizes = np.array([7, 8], dtype=np.int64)  # Results in 7x7\n\n# [[[[1. 1. 1. 1. 2. 2. 2.]\n#    [1. 1. 1. 1. 2. 2. 2.]\n#    [1. 1. 1. 1. 2. 2. 2.]\n#    [1. 1. 1. 1. 2. 2. 2.]\n#    [3. 3. 3. 3. 4. 4. 4.]\n#    [3. 3. 3. 3. 4. 4. 4.]\n#    [3. 3. 3. 3. 4. 4. 4.]]]]\noutput = interpolate_nd(\n    data,\n    lambda x, _: nearest_coeffs(x),\n    output_size=sizes,\n    axes=axes,\n    keep_aspect_ratio_policy=keep_aspect_ratio_policy,\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, sizes],\n    outputs=[output],\n    name=\"test_resize_upsample_sizes_nearest_not_larger\",\n)"
              },
              {
                "summary": "resize_upsample_sizes_nearest_not_smaller",
                "code": "keep_aspect_ratio_policy = \"not_smaller\"\naxes = [2, 3]\nnode = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"\", \"\", \"sizes\"],\n    outputs=[\"Y\"],\n    mode=\"nearest\",\n    axes=axes,\n    keep_aspect_ratio_policy=keep_aspect_ratio_policy,\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2],\n                [3, 4],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\nsizes = np.array([7, 8], dtype=np.int64)  # Results in 8x8\n\n# [[[[1. 1. 1. 1. 2. 2. 2. 2.]\n#    [1. 1. 1. 1. 2. 2. 2. 2.]\n#    [1. 1. 1. 1. 2. 2. 2. 2.]\n#    [1. 1. 1. 1. 2. 2. 2. 2.]\n#    [3. 3. 3. 3. 4. 4. 4. 4.]\n#    [3. 3. 3. 3. 4. 4. 4. 4.]\n#    [3. 3. 3. 3. 4. 4. 4. 4.]]]]\noutput = interpolate_nd(\n    data,\n    lambda x, _: nearest_coeffs(x),\n    output_size=sizes,\n    axes=axes,\n    keep_aspect_ratio_policy=keep_aspect_ratio_policy,\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, sizes],\n    outputs=[output],\n    name=\"test_resize_upsample_sizes_nearest_not_smaller\",\n)"
              },
              {
                "summary": "resize_upsample_sizes_nearest_round_prefer_ceil_asymmetric",
                "code": "node = onnx.helper.make_node(\n    \"Resize\",\n    inputs=[\"X\", \"\", \"\", \"sizes\"],\n    outputs=[\"Y\"],\n    mode=\"nearest\",\n    coordinate_transformation_mode=\"asymmetric\",\n    nearest_mode=\"round_prefer_ceil\",\n)\n\ndata = np.array(\n    [\n        [\n            [\n                [1, 2, 3, 4],\n                [5, 6, 7, 8],\n                [9, 10, 11, 12],\n                [13, 14, 15, 16],\n            ]\n        ]\n    ],\n    dtype=np.float32,\n)\n\nsizes = np.array([1, 1, 8, 8], dtype=np.int64)\n\n# [[[[ 1.  2.  2.  3.  3.  4.  4.  4.]\n#    [ 5.  6.  6.  7.  7.  8.  8.  8.]\n#    [ 5.  6.  6.  7.  7.  8.  8.  8.]\n#    [ 9. 10. 10. 11. 11. 12. 12. 12.]\n#    [ 9. 10. 10. 11. 11. 12. 12. 12.]\n#    [13. 14. 14. 15. 15. 16. 16. 16.]\n#    [13. 14. 14. 15. 15. 16. 16. 16.]\n#    [13. 14. 14. 15. 15. 16. 16. 16.]]]]\noutput = interpolate_nd(\n    data,\n    lambda x, _: nearest_coeffs(x, mode=\"round_prefer_ceil\"),\n    output_size=sizes,\n    coordinate_transformation_mode=\"asymmetric\",\n).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[data, sizes],\n    outputs=[output],\n    name=\"test_resize_upsample_sizes_nearest_round_prefer_ceil_asymmetric\",\n)"
              }
            ]
          }
        },
        {
          "name": "Conv__258",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "X",
              "value": [
                {
                  "name": "291",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        16,
                        72,
                        128
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "W",
              "value": [
                {
                  "name": "Conv2D_40/filter:0",
                  "initializer": {
                    "name": "Conv2D_40/filter:0",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float32",
                      "shape": {
                        "dimensions": [
                          16,
                          16,
                          1,
                          1
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        16,
                        16,
                        1,
                        1
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "B",
              "value": [
                {
                  "name": "conv2d_39_1/y:0",
                  "initializer": {
                    "name": "conv2d_39_1/y:0",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float32",
                      "shape": {
                        "dimensions": [
                          16
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        16
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "Y",
              "value": [
                {
                  "name": "Conv__258:0",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        16,
                        72,
                        128
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [
            {
              "name": "dilations",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "strides",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "kernel_shape",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "group",
              "type": "int64",
              "value": {
                "type": "bigint",
                "value": "1"
              }
            }
          ],
          "type": {
            "name": "Conv",
            "module": "ai.onnx",
            "version": 11,
            "description": "The convolution operator consumes an input tensor and a filter, and\ncomputes the output.",
            "attributes": [
              {
                "name": "auto_pad",
                "type": "string",
                "required": false,
                "default": "NOTSET",
                "description": "auto_pad must be either NOTSET, SAME_UPPER, SAME_LOWER or VALID. Where default value is NOTSET, which means explicit padding is used. SAME_UPPER or SAME_LOWER mean pad the input so that `output_shape[i] = ceil(input_shape[i] / strides[i])` for each axis `i`. The padding is split between the two sides equally or almost equally (depending on whether it is even or odd). In case the padding is an odd number, the extra padding is added at the end for SAME_UPPER and at the beginning for SAME_LOWER."
              },
              {
                "name": "dilations",
                "type": "int64[]",
                "required": false,
                "description": "dilation value along each spatial axis of the filter. If not present, the dilation defaults is 1 along each spatial axis."
              },
              {
                "name": "group",
                "type": "int64",
                "required": false,
                "default": 1,
                "description": "number of groups input channels and output channels are divided into."
              },
              {
                "name": "kernel_shape",
                "type": "int64[]",
                "required": false,
                "description": "The shape of the convolution kernel. If not present, should be inferred from input W."
              },
              {
                "name": "pads",
                "type": "int64[]",
                "required": false,
                "description": "Padding for the beginning and ending along each spatial axis, it can take any value greater than or equal to 0. The value represent the number of pixels added to the beginning and end part of the corresponding axis. `pads` format should be as follow [x1_begin, x2_begin...x1_end, x2_end,...], where xi_begin the number of pixels added at the beginning of axis `i` and xi_end, the number of pixels added at the end of axis `i`. This attribute cannot be used simultaneously with auto_pad attribute. If not present, the padding defaults to 0 along start and end of each spatial axis."
              },
              {
                "name": "strides",
                "type": "int64[]",
                "required": false,
                "description": "Stride along each spatial axis. If not present, the stride defaults is 1 along each spatial axis."
              }
            ],
            "inputs": [
              {
                "name": "X",
                "type": "T",
                "description": "Input data tensor from previous layer; has size (N x C x H x W), where N is the batch size, C is the number of channels, and H and W are the height and width. Note that this is for the 2D image. Otherwise the size is (N x C x D1 x D2 ... x Dn). Optionally, if dimension denotation is in effect, the operation expects input data tensor to arrive with the dimension denotation of [DATA_BATCH, DATA_CHANNEL, DATA_FEATURE, DATA_FEATURE ...]."
              },
              {
                "name": "W",
                "type": "T",
                "description": "The weight tensor that will be used in the convolutions; has size (M x C/group x kH x kW), where C is the number of channels, and kH and kW are the height and width of the kernel, and M is the number of feature maps. For more than 2 dimensions, the kernel shape will be (M x C/group x k1 x k2 x ... x kn), where (k1 x k2 x ... kn) is the dimension of the kernel. Optionally, if dimension denotation is in effect, the operation expects the weight tensor to arrive with the dimension denotation of [FILTER_OUT_CHANNEL, FILTER_IN_CHANNEL, FILTER_SPATIAL, FILTER_SPATIAL ...]. Assuming zero based indices for the shape array, X.shape[1] == (W.shape[1] * group) == C and W.shape[0] mod G == 0. Or in other words FILTER_IN_CHANNEL multiplied by the number of groups should be equal to DATA_CHANNEL and the number of feature maps M should be a multiple of the number of groups G."
              },
              {
                "name": "B",
                "type": "T",
                "option": "optional",
                "description": "Optional 1D bias to be added to the convolution, has size of M."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "Y",
                "type": "T",
                "description": "Output data tensor that contains the result of the convolution. The output dimensions are functions of the kernel size, stride size, and pad lengths."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain input and output types to float tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "conv",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[1, 1, 1, 1],\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 21.0, 27.0, 33.0, 24.0],  # (1, 1, 5, 5) output tensor\n                [33.0, 54.0, 63.0, 72.0, 51.0],\n                [63.0, 99.0, 108.0, 117.0, 81.0],\n                [93.0, 144.0, 153.0, 162.0, 111.0],\n                [72.0, 111.0, 117.0, 123.0, 84.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_basic_conv_with_padding\",\n)\n\n# Convolution without padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[0, 0, 0, 0],\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 63.0, 72.0],  # (1, 1, 3, 3) output tensor\n                [99.0, 108.0, 117.0],\n                [144.0, 153.0, 162.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_basic_conv_without_padding\",\n)"
              },
              {
                "summary": "conv_with_autopad_same",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with auto_pad='SAME_LOWER' and strides=2\nnode = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    auto_pad=\"SAME_LOWER\",\n    kernel_shape=[3, 3],\n    strides=[2, 2],\n)\ny = np.array(\n    [[[[12.0, 27.0, 24.0], [63.0, 108.0, 81.0], [72.0, 117.0, 84.0]]]]\n).astype(np.float32)\nexpect(node, inputs=[x, W], outputs=[y], name=\"test_conv_with_autopad_same\")"
              },
              {
                "summary": "conv_with_strides",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 7, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n                [25.0, 26.0, 27.0, 28.0, 29.0],\n                [30.0, 31.0, 32.0, 33.0, 34.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with strides=2 and padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 1, 1, 1],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 27.0, 24.0],  # (1, 1, 4, 3) output tensor\n                [63.0, 108.0, 81.0],\n                [123.0, 198.0, 141.0],\n                [112.0, 177.0, 124.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_conv_with_strides_padding\",\n)\n\n# Convolution with strides=2 and no padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[0, 0, 0, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 72.0],  # (1, 1, 3, 2) output tensor\n                [144.0, 162.0],\n                [234.0, 252.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_conv_with_strides_no_padding\",\n)\n\n# Convolution with strides=2 and padding only along one dimension (the H dimension in NxCxHxW tensor)\nnode_with_asymmetric_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 0, 1, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_asymmetric_padding = np.array(\n    [\n        [\n            [\n                [21.0, 33.0],  # (1, 1, 4, 2) output tensor\n                [99.0, 117.0],\n                [189.0, 207.0],\n                [171.0, 183.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_asymmetric_padding,\n    inputs=[x, W],\n    outputs=[y_with_asymmetric_padding],\n    name=\"test_conv_with_strides_and_asymmetric_padding\",\n)"
              }
            ],
            "category": "Layer"
          }
        },
        {
          "name": "add_11__xeno_compat__1",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "A",
              "value": [
                {
                  "name": "mul_1:0",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        16,
                        72,
                        128
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "B",
              "value": [
                {
                  "name": "Conv__258:0",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        16,
                        72,
                        128
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "C",
              "value": [
                {
                  "name": "add_11__xeno_compat__1:0",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        16,
                        72,
                        128
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "Add",
            "module": "ai.onnx",
            "version": 14,
            "description": "Performs element-wise binary addition (with Numpy-style broadcasting support).\n\nThis operator supports **multidirectional (i.e., Numpy-style) broadcasting**; for more details please check [the doc](https://github.com/onnx/onnx/blob/master/docs/Broadcasting.md).\n\n(Opset 14 change): Extend supported types to include uint8, int8, uint16, and int16.\n",
            "inputs": [
              {
                "name": "A",
                "type": "T",
                "description": "First operand."
              },
              {
                "name": "B",
                "type": "T",
                "description": "Second operand."
              }
            ],
            "min_input": 2,
            "max_input": 2,
            "outputs": [
              {
                "name": "C",
                "type": "T",
                "description": "Result, has same element type as two inputs"
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "type_constraints": [
              {
                "description": "Constrain input and output types to all numeric tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(uint8)",
                  "tensor(uint16)",
                  "tensor(uint32)",
                  "tensor(uint64)",
                  "tensor(int8)",
                  "tensor(int16)",
                  "tensor(int32)",
                  "tensor(int64)",
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)",
                  "tensor(bfloat16)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "add",
                "code": "node = onnx.helper.make_node(\n    \"Add\",\n    inputs=[\"x\", \"y\"],\n    outputs=[\"sum\"],\n)\n\nx = np.random.randn(3, 4, 5).astype(np.float32)\ny = np.random.randn(3, 4, 5).astype(np.float32)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add\")\n\nx = np.random.randint(24, size=(3, 4, 5), dtype=np.int8)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.int8)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add_int8\")\n\nx = np.random.randint(24, size=(3, 4, 5), dtype=np.int16)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.int16)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add_int16\")\n\nx = np.random.randint(24, size=(3, 4, 5), dtype=np.uint8)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.uint8)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add_uint8\")\n\nx = np.random.randint(24, size=(3, 4, 5), dtype=np.uint16)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.uint16)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add_uint16\")\n\nx = np.random.randint(24, size=(3, 4, 5), dtype=np.uint32)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.uint32)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add_uint32\")\n\nx = np.random.randint(24, size=(3, 4, 5), dtype=np.uint64)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.uint64)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add_uint64\")"
              },
              {
                "summary": "add_broadcast",
                "code": "node = onnx.helper.make_node(\n    \"Add\",\n    inputs=[\"x\", \"y\"],\n    outputs=[\"sum\"],\n)\n\nx = np.random.randn(3, 4, 5).astype(np.float32)\ny = np.random.randn(5).astype(np.float32)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add_bcast\")"
              }
            ]
          }
        },
        {
          "name": "global_average_pooling2d_9",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "X",
              "value": [
                {
                  "name": "add_11__xeno_compat__1:0",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        16,
                        72,
                        128
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "Y",
              "value": [
                {
                  "name": "global_average_pooling2d_9:0",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        16,
                        1,
                        1
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "GlobalAveragePool",
            "module": "ai.onnx",
            "version": 1,
            "description": "GlobalAveragePool consumes an input tensor X and applies average pooling across\n the values in the same channel. This is equivalent to AveragePool with kernel size\n equal to the spatial dimension of input tensor.",
            "inputs": [
              {
                "name": "X",
                "type": "T",
                "description": "Input data tensor from the previous operator; dimensions for image case are (N x C x H x W), where N is the batch size, C is the number of channels, and H and W are the height and the width of the data. For non image case, the dimensions are in the form of (N x C x D1 x D2 ... Dn), where N is the batch size."
              }
            ],
            "min_input": 1,
            "max_input": 1,
            "outputs": [
              {
                "name": "Y",
                "type": "T",
                "description": "Output data tensor from pooling across the input tensor. The output tensor has the same rank as the input. The first two dimensions of output shape are the same as the input (N x C), while the other dimensions are all 1."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "type_constraints": [
              {
                "description": "Constrain input and output types to float tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "globalaveragepool",
                "code": "node = onnx.helper.make_node(\n    \"GlobalAveragePool\",\n    inputs=[\"x\"],\n    outputs=[\"y\"],\n)\nx = np.random.randn(1, 3, 5, 5).astype(np.float32)\ny = np.mean(x, axis=tuple(range(2, np.ndim(x))), keepdims=True)\nexpect(node, inputs=[x], outputs=[y], name=\"test_globalaveragepool\")"
              },
              {
                "summary": "globalaveragepool_precomputed",
                "code": "node = onnx.helper.make_node(\n    \"GlobalAveragePool\",\n    inputs=[\"x\"],\n    outputs=[\"y\"],\n)\nx = np.array(\n    [\n        [\n            [\n                [1, 2, 3],\n                [4, 5, 6],\n                [7, 8, 9],\n            ]\n        ]\n    ]\n).astype(np.float32)\ny = np.array([[[[5]]]]).astype(np.float32)\nexpect(node, inputs=[x], outputs=[y], name=\"test_globalaveragepool_precomputed\")"
              }
            ],
            "category": "Pool"
          }
        },
        {
          "name": "Conv__261",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "X",
              "value": [
                {
                  "name": "global_average_pooling2d_9:0",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        16,
                        1,
                        1
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "W",
              "value": [
                {
                  "name": "Conv2D_41/filter:0",
                  "initializer": {
                    "name": "Conv2D_41/filter:0",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float32",
                      "shape": {
                        "dimensions": [
                          16,
                          16,
                          1,
                          1
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        16,
                        16,
                        1,
                        1
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "B",
              "value": [
                {
                  "name": "conv2d_40_1/y:0",
                  "initializer": {
                    "name": "conv2d_40_1/y:0",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float32",
                      "shape": {
                        "dimensions": [
                          16
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        16
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "Y",
              "value": [
                {
                  "name": "Conv__261:0",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        16,
                        1,
                        1
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [
            {
              "name": "dilations",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "strides",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "kernel_shape",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "group",
              "type": "int64",
              "value": {
                "type": "bigint",
                "value": "1"
              }
            }
          ],
          "type": {
            "name": "Conv",
            "module": "ai.onnx",
            "version": 11,
            "description": "The convolution operator consumes an input tensor and a filter, and\ncomputes the output.",
            "attributes": [
              {
                "name": "auto_pad",
                "type": "string",
                "required": false,
                "default": "NOTSET",
                "description": "auto_pad must be either NOTSET, SAME_UPPER, SAME_LOWER or VALID. Where default value is NOTSET, which means explicit padding is used. SAME_UPPER or SAME_LOWER mean pad the input so that `output_shape[i] = ceil(input_shape[i] / strides[i])` for each axis `i`. The padding is split between the two sides equally or almost equally (depending on whether it is even or odd). In case the padding is an odd number, the extra padding is added at the end for SAME_UPPER and at the beginning for SAME_LOWER."
              },
              {
                "name": "dilations",
                "type": "int64[]",
                "required": false,
                "description": "dilation value along each spatial axis of the filter. If not present, the dilation defaults is 1 along each spatial axis."
              },
              {
                "name": "group",
                "type": "int64",
                "required": false,
                "default": 1,
                "description": "number of groups input channels and output channels are divided into."
              },
              {
                "name": "kernel_shape",
                "type": "int64[]",
                "required": false,
                "description": "The shape of the convolution kernel. If not present, should be inferred from input W."
              },
              {
                "name": "pads",
                "type": "int64[]",
                "required": false,
                "description": "Padding for the beginning and ending along each spatial axis, it can take any value greater than or equal to 0. The value represent the number of pixels added to the beginning and end part of the corresponding axis. `pads` format should be as follow [x1_begin, x2_begin...x1_end, x2_end,...], where xi_begin the number of pixels added at the beginning of axis `i` and xi_end, the number of pixels added at the end of axis `i`. This attribute cannot be used simultaneously with auto_pad attribute. If not present, the padding defaults to 0 along start and end of each spatial axis."
              },
              {
                "name": "strides",
                "type": "int64[]",
                "required": false,
                "description": "Stride along each spatial axis. If not present, the stride defaults is 1 along each spatial axis."
              }
            ],
            "inputs": [
              {
                "name": "X",
                "type": "T",
                "description": "Input data tensor from previous layer; has size (N x C x H x W), where N is the batch size, C is the number of channels, and H and W are the height and width. Note that this is for the 2D image. Otherwise the size is (N x C x D1 x D2 ... x Dn). Optionally, if dimension denotation is in effect, the operation expects input data tensor to arrive with the dimension denotation of [DATA_BATCH, DATA_CHANNEL, DATA_FEATURE, DATA_FEATURE ...]."
              },
              {
                "name": "W",
                "type": "T",
                "description": "The weight tensor that will be used in the convolutions; has size (M x C/group x kH x kW), where C is the number of channels, and kH and kW are the height and width of the kernel, and M is the number of feature maps. For more than 2 dimensions, the kernel shape will be (M x C/group x k1 x k2 x ... x kn), where (k1 x k2 x ... kn) is the dimension of the kernel. Optionally, if dimension denotation is in effect, the operation expects the weight tensor to arrive with the dimension denotation of [FILTER_OUT_CHANNEL, FILTER_IN_CHANNEL, FILTER_SPATIAL, FILTER_SPATIAL ...]. Assuming zero based indices for the shape array, X.shape[1] == (W.shape[1] * group) == C and W.shape[0] mod G == 0. Or in other words FILTER_IN_CHANNEL multiplied by the number of groups should be equal to DATA_CHANNEL and the number of feature maps M should be a multiple of the number of groups G."
              },
              {
                "name": "B",
                "type": "T",
                "option": "optional",
                "description": "Optional 1D bias to be added to the convolution, has size of M."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "Y",
                "type": "T",
                "description": "Output data tensor that contains the result of the convolution. The output dimensions are functions of the kernel size, stride size, and pad lengths."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain input and output types to float tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "conv",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[1, 1, 1, 1],\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 21.0, 27.0, 33.0, 24.0],  # (1, 1, 5, 5) output tensor\n                [33.0, 54.0, 63.0, 72.0, 51.0],\n                [63.0, 99.0, 108.0, 117.0, 81.0],\n                [93.0, 144.0, 153.0, 162.0, 111.0],\n                [72.0, 111.0, 117.0, 123.0, 84.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_basic_conv_with_padding\",\n)\n\n# Convolution without padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[0, 0, 0, 0],\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 63.0, 72.0],  # (1, 1, 3, 3) output tensor\n                [99.0, 108.0, 117.0],\n                [144.0, 153.0, 162.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_basic_conv_without_padding\",\n)"
              },
              {
                "summary": "conv_with_autopad_same",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with auto_pad='SAME_LOWER' and strides=2\nnode = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    auto_pad=\"SAME_LOWER\",\n    kernel_shape=[3, 3],\n    strides=[2, 2],\n)\ny = np.array(\n    [[[[12.0, 27.0, 24.0], [63.0, 108.0, 81.0], [72.0, 117.0, 84.0]]]]\n).astype(np.float32)\nexpect(node, inputs=[x, W], outputs=[y], name=\"test_conv_with_autopad_same\")"
              },
              {
                "summary": "conv_with_strides",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 7, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n                [25.0, 26.0, 27.0, 28.0, 29.0],\n                [30.0, 31.0, 32.0, 33.0, 34.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with strides=2 and padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 1, 1, 1],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 27.0, 24.0],  # (1, 1, 4, 3) output tensor\n                [63.0, 108.0, 81.0],\n                [123.0, 198.0, 141.0],\n                [112.0, 177.0, 124.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_conv_with_strides_padding\",\n)\n\n# Convolution with strides=2 and no padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[0, 0, 0, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 72.0],  # (1, 1, 3, 2) output tensor\n                [144.0, 162.0],\n                [234.0, 252.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_conv_with_strides_no_padding\",\n)\n\n# Convolution with strides=2 and padding only along one dimension (the H dimension in NxCxHxW tensor)\nnode_with_asymmetric_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 0, 1, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_asymmetric_padding = np.array(\n    [\n        [\n            [\n                [21.0, 33.0],  # (1, 1, 4, 2) output tensor\n                [99.0, 117.0],\n                [189.0, 207.0],\n                [171.0, 183.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_asymmetric_padding,\n    inputs=[x, W],\n    outputs=[y_with_asymmetric_padding],\n    name=\"test_conv_with_strides_and_asymmetric_padding\",\n)"
              }
            ],
            "category": "Layer"
          }
        },
        {
          "name": "re_lu_19",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "X",
              "value": [
                {
                  "name": "Conv__261:0",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        16,
                        1,
                        1
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "Y",
              "value": [
                {
                  "name": "re_lu_19:0",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        16,
                        1,
                        1
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "Relu",
            "module": "ai.onnx",
            "version": 14,
            "description": "Relu takes one input data (Tensor<T>) and produces one output data\n(Tensor<T>) where the rectified linear function, y = max(0, x), is applied to\nthe tensor elementwise.\n",
            "inputs": [
              {
                "name": "X",
                "type": "T",
                "description": "Input tensor"
              }
            ],
            "min_input": 1,
            "max_input": 1,
            "outputs": [
              {
                "name": "Y",
                "type": "T",
                "description": "Output tensor"
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "type_constraints": [
              {
                "description": "Constrain input and output types to signed numeric tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(float)",
                  "tensor(int32)",
                  "tensor(int8)",
                  "tensor(int16)",
                  "tensor(int64)",
                  "tensor(float16)",
                  "tensor(double)",
                  "tensor(bfloat16)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "relu",
                "code": "node = onnx.helper.make_node(\n    \"Relu\",\n    inputs=[\"x\"],\n    outputs=[\"y\"],\n)\nx = np.random.randn(3, 4, 5).astype(np.float32)\ny = np.clip(x, 0, np.inf)\n\nexpect(node, inputs=[x], outputs=[y], name=\"test_relu\")"
              }
            ],
            "category": "Activation"
          }
        },
        {
          "name": "Conv__262",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "X",
              "value": [
                {
                  "name": "re_lu_19:0",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        16,
                        1,
                        1
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "W",
              "value": [
                {
                  "name": "Conv2D_42/filter:0",
                  "initializer": {
                    "name": "Conv2D_42/filter:0",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float32",
                      "shape": {
                        "dimensions": [
                          16,
                          16,
                          1,
                          1
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        16,
                        16,
                        1,
                        1
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "B",
              "value": [
                {
                  "name": "conv2d_41_1/y:0",
                  "initializer": {
                    "name": "conv2d_41_1/y:0",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float32",
                      "shape": {
                        "dimensions": [
                          16
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        16
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "Y",
              "value": [
                {
                  "name": "Conv__262:0",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        16,
                        1,
                        1
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [
            {
              "name": "dilations",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "strides",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "kernel_shape",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "group",
              "type": "int64",
              "value": {
                "type": "bigint",
                "value": "1"
              }
            }
          ],
          "type": {
            "name": "Conv",
            "module": "ai.onnx",
            "version": 11,
            "description": "The convolution operator consumes an input tensor and a filter, and\ncomputes the output.",
            "attributes": [
              {
                "name": "auto_pad",
                "type": "string",
                "required": false,
                "default": "NOTSET",
                "description": "auto_pad must be either NOTSET, SAME_UPPER, SAME_LOWER or VALID. Where default value is NOTSET, which means explicit padding is used. SAME_UPPER or SAME_LOWER mean pad the input so that `output_shape[i] = ceil(input_shape[i] / strides[i])` for each axis `i`. The padding is split between the two sides equally or almost equally (depending on whether it is even or odd). In case the padding is an odd number, the extra padding is added at the end for SAME_UPPER and at the beginning for SAME_LOWER."
              },
              {
                "name": "dilations",
                "type": "int64[]",
                "required": false,
                "description": "dilation value along each spatial axis of the filter. If not present, the dilation defaults is 1 along each spatial axis."
              },
              {
                "name": "group",
                "type": "int64",
                "required": false,
                "default": 1,
                "description": "number of groups input channels and output channels are divided into."
              },
              {
                "name": "kernel_shape",
                "type": "int64[]",
                "required": false,
                "description": "The shape of the convolution kernel. If not present, should be inferred from input W."
              },
              {
                "name": "pads",
                "type": "int64[]",
                "required": false,
                "description": "Padding for the beginning and ending along each spatial axis, it can take any value greater than or equal to 0. The value represent the number of pixels added to the beginning and end part of the corresponding axis. `pads` format should be as follow [x1_begin, x2_begin...x1_end, x2_end,...], where xi_begin the number of pixels added at the beginning of axis `i` and xi_end, the number of pixels added at the end of axis `i`. This attribute cannot be used simultaneously with auto_pad attribute. If not present, the padding defaults to 0 along start and end of each spatial axis."
              },
              {
                "name": "strides",
                "type": "int64[]",
                "required": false,
                "description": "Stride along each spatial axis. If not present, the stride defaults is 1 along each spatial axis."
              }
            ],
            "inputs": [
              {
                "name": "X",
                "type": "T",
                "description": "Input data tensor from previous layer; has size (N x C x H x W), where N is the batch size, C is the number of channels, and H and W are the height and width. Note that this is for the 2D image. Otherwise the size is (N x C x D1 x D2 ... x Dn). Optionally, if dimension denotation is in effect, the operation expects input data tensor to arrive with the dimension denotation of [DATA_BATCH, DATA_CHANNEL, DATA_FEATURE, DATA_FEATURE ...]."
              },
              {
                "name": "W",
                "type": "T",
                "description": "The weight tensor that will be used in the convolutions; has size (M x C/group x kH x kW), where C is the number of channels, and kH and kW are the height and width of the kernel, and M is the number of feature maps. For more than 2 dimensions, the kernel shape will be (M x C/group x k1 x k2 x ... x kn), where (k1 x k2 x ... kn) is the dimension of the kernel. Optionally, if dimension denotation is in effect, the operation expects the weight tensor to arrive with the dimension denotation of [FILTER_OUT_CHANNEL, FILTER_IN_CHANNEL, FILTER_SPATIAL, FILTER_SPATIAL ...]. Assuming zero based indices for the shape array, X.shape[1] == (W.shape[1] * group) == C and W.shape[0] mod G == 0. Or in other words FILTER_IN_CHANNEL multiplied by the number of groups should be equal to DATA_CHANNEL and the number of feature maps M should be a multiple of the number of groups G."
              },
              {
                "name": "B",
                "type": "T",
                "option": "optional",
                "description": "Optional 1D bias to be added to the convolution, has size of M."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "Y",
                "type": "T",
                "description": "Output data tensor that contains the result of the convolution. The output dimensions are functions of the kernel size, stride size, and pad lengths."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain input and output types to float tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "conv",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[1, 1, 1, 1],\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 21.0, 27.0, 33.0, 24.0],  # (1, 1, 5, 5) output tensor\n                [33.0, 54.0, 63.0, 72.0, 51.0],\n                [63.0, 99.0, 108.0, 117.0, 81.0],\n                [93.0, 144.0, 153.0, 162.0, 111.0],\n                [72.0, 111.0, 117.0, 123.0, 84.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_basic_conv_with_padding\",\n)\n\n# Convolution without padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[0, 0, 0, 0],\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 63.0, 72.0],  # (1, 1, 3, 3) output tensor\n                [99.0, 108.0, 117.0],\n                [144.0, 153.0, 162.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_basic_conv_without_padding\",\n)"
              },
              {
                "summary": "conv_with_autopad_same",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with auto_pad='SAME_LOWER' and strides=2\nnode = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    auto_pad=\"SAME_LOWER\",\n    kernel_shape=[3, 3],\n    strides=[2, 2],\n)\ny = np.array(\n    [[[[12.0, 27.0, 24.0], [63.0, 108.0, 81.0], [72.0, 117.0, 84.0]]]]\n).astype(np.float32)\nexpect(node, inputs=[x, W], outputs=[y], name=\"test_conv_with_autopad_same\")"
              },
              {
                "summary": "conv_with_strides",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 7, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n                [25.0, 26.0, 27.0, 28.0, 29.0],\n                [30.0, 31.0, 32.0, 33.0, 34.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with strides=2 and padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 1, 1, 1],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 27.0, 24.0],  # (1, 1, 4, 3) output tensor\n                [63.0, 108.0, 81.0],\n                [123.0, 198.0, 141.0],\n                [112.0, 177.0, 124.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_conv_with_strides_padding\",\n)\n\n# Convolution with strides=2 and no padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[0, 0, 0, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 72.0],  # (1, 1, 3, 2) output tensor\n                [144.0, 162.0],\n                [234.0, 252.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_conv_with_strides_no_padding\",\n)\n\n# Convolution with strides=2 and padding only along one dimension (the H dimension in NxCxHxW tensor)\nnode_with_asymmetric_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 0, 1, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_asymmetric_padding = np.array(\n    [\n        [\n            [\n                [21.0, 33.0],  # (1, 1, 4, 2) output tensor\n                [99.0, 117.0],\n                [189.0, 207.0],\n                [171.0, 183.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_asymmetric_padding,\n    inputs=[x, W],\n    outputs=[y_with_asymmetric_padding],\n    name=\"test_conv_with_strides_and_asymmetric_padding\",\n)"
              }
            ],
            "category": "Layer"
          }
        },
        {
          "name": "activation_9",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "X",
              "value": [
                {
                  "name": "Conv__262:0",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        16,
                        1,
                        1
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "Y",
              "value": [
                {
                  "name": "activation_9:0",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        16,
                        1,
                        1
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "Sigmoid",
            "module": "ai.onnx",
            "version": 13,
            "description": "Sigmoid takes one input data (Tensor<T>) and produces one output data\n(Tensor<T>) where the sigmoid function, y = 1 / (1 + exp(-x)), is applied to the\ntensor elementwise.\n",
            "inputs": [
              {
                "name": "X",
                "type": "T",
                "description": "Input tensor"
              }
            ],
            "min_input": 1,
            "max_input": 1,
            "outputs": [
              {
                "name": "Y",
                "type": "T",
                "description": "Output tensor"
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "type_constraints": [
              {
                "description": "Constrain input and output types to float tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)",
                  "tensor(bfloat16)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "sigmoid",
                "code": "node = onnx.helper.make_node(\n    \"Sigmoid\",\n    inputs=[\"x\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([-1, 0, 1]).astype(np.float32)\ny = 1.0 / (\n    1.0 + np.exp(np.negative(x))\n)  # expected output [0.26894143, 0.5, 0.7310586]\nexpect(node, inputs=[x], outputs=[y], name=\"test_sigmoid_example\")\n\nx = np.random.randn(3, 4, 5).astype(np.float32)\ny = 1.0 / (1.0 + np.exp(np.negative(x)))\nexpect(node, inputs=[x], outputs=[y], name=\"test_sigmoid\")"
              }
            ],
            "category": "Activation"
          }
        },
        {
          "name": "multiply_9",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "A",
              "value": [
                {
                  "name": "mul_1:0",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        16,
                        72,
                        128
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "B",
              "value": [
                {
                  "name": "activation_9:0",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        16,
                        1,
                        1
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "C",
              "value": [
                {
                  "name": "multiply_9:0",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        16,
                        72,
                        128
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "Mul",
            "module": "ai.onnx",
            "version": 14,
            "description": "Performs element-wise binary multiplication (with Numpy-style broadcasting support).\n\nThis operator supports **multidirectional (i.e., Numpy-style) broadcasting**; for more details please check [the doc](https://github.com/onnx/onnx/blob/master/docs/Broadcasting.md).\n\n(Opset 14 change): Extend supported types to include uint8, int8, uint16, and int16.\n",
            "inputs": [
              {
                "name": "A",
                "type": "T",
                "description": "First operand."
              },
              {
                "name": "B",
                "type": "T",
                "description": "Second operand."
              }
            ],
            "min_input": 2,
            "max_input": 2,
            "outputs": [
              {
                "name": "C",
                "type": "T",
                "description": "Result, has same element type as two inputs"
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "type_constraints": [
              {
                "description": "Constrain input and output types to all numeric tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(uint8)",
                  "tensor(uint16)",
                  "tensor(uint32)",
                  "tensor(uint64)",
                  "tensor(int8)",
                  "tensor(int16)",
                  "tensor(int32)",
                  "tensor(int64)",
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)",
                  "tensor(bfloat16)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "mul",
                "code": "node = onnx.helper.make_node(\n    \"Mul\",\n    inputs=[\"x\", \"y\"],\n    outputs=[\"z\"],\n)\n\nx = np.array([1, 2, 3]).astype(np.float32)\ny = np.array([4, 5, 6]).astype(np.float32)\nz = x * y  # expected output [4., 10., 18.]\nexpect(node, inputs=[x, y], outputs=[z], name=\"test_mul_example\")\n\nx = np.random.randn(3, 4, 5).astype(np.float32)\ny = np.random.randn(3, 4, 5).astype(np.float32)\nz = x * y\nexpect(node, inputs=[x, y], outputs=[z], name=\"test_mul\")\n\nx = np.random.randint(4, size=(3, 4, 5), dtype=np.int8)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.int8)\nz = x * y\nexpect(node, inputs=[x, y], outputs=[z], name=\"test_mul_int8\")\n\nx = np.random.randint(4, size=(3, 4, 5), dtype=np.int16)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.int16)\nz = x * y\nexpect(node, inputs=[x, y], outputs=[z], name=\"test_mul_int16\")\n\nx = np.random.randint(4, size=(3, 4, 5), dtype=np.uint8)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.uint8)\nz = x * y\nexpect(node, inputs=[x, y], outputs=[z], name=\"test_mul_uint8\")\n\nx = np.random.randint(4, size=(3, 4, 5), dtype=np.uint16)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.uint16)\nz = x * y\nexpect(node, inputs=[x, y], outputs=[z], name=\"test_mul_uint16\")\n\nx = np.random.randint(4, size=(3, 4, 5), dtype=np.uint32)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.uint32)\nz = x * y\nexpect(node, inputs=[x, y], outputs=[z], name=\"test_mul_uint32\")\n\nx = np.random.randint(4, size=(3, 4, 5), dtype=np.uint64)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.uint64)\nz = x * y\nexpect(node, inputs=[x, y], outputs=[z], name=\"test_mul_uint64\")"
              },
              {
                "summary": "mul_broadcast",
                "code": "node = onnx.helper.make_node(\n    \"Mul\",\n    inputs=[\"x\", \"y\"],\n    outputs=[\"z\"],\n)\n\nx = np.random.randn(3, 4, 5).astype(np.float32)\ny = np.random.randn(5).astype(np.float32)\nz = x * y\nexpect(node, inputs=[x, y], outputs=[z], name=\"test_mul_bcast\")"
              }
            ]
          }
        },
        {
          "name": "add_12__xeno_compat__1",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "A",
              "value": [
                {
                  "name": "multiply_9:0",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        16,
                        72,
                        128
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "B",
              "value": [
                {
                  "name": "Conv__258:0",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        16,
                        72,
                        128
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "C",
              "value": [
                {
                  "name": "add_12__xeno_compat__1:0",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        16,
                        72,
                        128
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "Add",
            "module": "ai.onnx",
            "version": 14,
            "description": "Performs element-wise binary addition (with Numpy-style broadcasting support).\n\nThis operator supports **multidirectional (i.e., Numpy-style) broadcasting**; for more details please check [the doc](https://github.com/onnx/onnx/blob/master/docs/Broadcasting.md).\n\n(Opset 14 change): Extend supported types to include uint8, int8, uint16, and int16.\n",
            "inputs": [
              {
                "name": "A",
                "type": "T",
                "description": "First operand."
              },
              {
                "name": "B",
                "type": "T",
                "description": "Second operand."
              }
            ],
            "min_input": 2,
            "max_input": 2,
            "outputs": [
              {
                "name": "C",
                "type": "T",
                "description": "Result, has same element type as two inputs"
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "type_constraints": [
              {
                "description": "Constrain input and output types to all numeric tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(uint8)",
                  "tensor(uint16)",
                  "tensor(uint32)",
                  "tensor(uint64)",
                  "tensor(int8)",
                  "tensor(int16)",
                  "tensor(int32)",
                  "tensor(int64)",
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)",
                  "tensor(bfloat16)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "add",
                "code": "node = onnx.helper.make_node(\n    \"Add\",\n    inputs=[\"x\", \"y\"],\n    outputs=[\"sum\"],\n)\n\nx = np.random.randn(3, 4, 5).astype(np.float32)\ny = np.random.randn(3, 4, 5).astype(np.float32)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add\")\n\nx = np.random.randint(24, size=(3, 4, 5), dtype=np.int8)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.int8)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add_int8\")\n\nx = np.random.randint(24, size=(3, 4, 5), dtype=np.int16)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.int16)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add_int16\")\n\nx = np.random.randint(24, size=(3, 4, 5), dtype=np.uint8)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.uint8)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add_uint8\")\n\nx = np.random.randint(24, size=(3, 4, 5), dtype=np.uint16)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.uint16)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add_uint16\")\n\nx = np.random.randint(24, size=(3, 4, 5), dtype=np.uint32)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.uint32)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add_uint32\")\n\nx = np.random.randint(24, size=(3, 4, 5), dtype=np.uint64)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.uint64)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add_uint64\")"
              },
              {
                "summary": "add_broadcast",
                "code": "node = onnx.helper.make_node(\n    \"Add\",\n    inputs=[\"x\", \"y\"],\n    outputs=[\"sum\"],\n)\n\nx = np.random.randn(3, 4, 5).astype(np.float32)\ny = np.random.randn(5).astype(np.float32)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add_bcast\")"
              }
            ]
          }
        },
        {
          "name": "Conv__263",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "X",
              "value": [
                {
                  "name": "add_12__xeno_compat__1:0",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        16,
                        72,
                        128
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "W",
              "value": [
                {
                  "name": "Conv2D_43/filter:0",
                  "initializer": {
                    "name": "Conv2D_43/filter:0",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float32",
                      "shape": {
                        "dimensions": [
                          16,
                          16,
                          1,
                          1
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        16,
                        16,
                        1,
                        1
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "B",
              "value": [
                {
                  "name": "conv2d_42_1/y:0",
                  "initializer": {
                    "name": "conv2d_42_1/y:0",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float32",
                      "shape": {
                        "dimensions": [
                          16
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        16
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "Y",
              "value": [
                {
                  "name": "Conv__263:0",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        16,
                        72,
                        128
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [
            {
              "name": "dilations",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "strides",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "kernel_shape",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "group",
              "type": "int64",
              "value": {
                "type": "bigint",
                "value": "1"
              }
            }
          ],
          "type": {
            "name": "Conv",
            "module": "ai.onnx",
            "version": 11,
            "description": "The convolution operator consumes an input tensor and a filter, and\ncomputes the output.",
            "attributes": [
              {
                "name": "auto_pad",
                "type": "string",
                "required": false,
                "default": "NOTSET",
                "description": "auto_pad must be either NOTSET, SAME_UPPER, SAME_LOWER or VALID. Where default value is NOTSET, which means explicit padding is used. SAME_UPPER or SAME_LOWER mean pad the input so that `output_shape[i] = ceil(input_shape[i] / strides[i])` for each axis `i`. The padding is split between the two sides equally or almost equally (depending on whether it is even or odd). In case the padding is an odd number, the extra padding is added at the end for SAME_UPPER and at the beginning for SAME_LOWER."
              },
              {
                "name": "dilations",
                "type": "int64[]",
                "required": false,
                "description": "dilation value along each spatial axis of the filter. If not present, the dilation defaults is 1 along each spatial axis."
              },
              {
                "name": "group",
                "type": "int64",
                "required": false,
                "default": 1,
                "description": "number of groups input channels and output channels are divided into."
              },
              {
                "name": "kernel_shape",
                "type": "int64[]",
                "required": false,
                "description": "The shape of the convolution kernel. If not present, should be inferred from input W."
              },
              {
                "name": "pads",
                "type": "int64[]",
                "required": false,
                "description": "Padding for the beginning and ending along each spatial axis, it can take any value greater than or equal to 0. The value represent the number of pixels added to the beginning and end part of the corresponding axis. `pads` format should be as follow [x1_begin, x2_begin...x1_end, x2_end,...], where xi_begin the number of pixels added at the beginning of axis `i` and xi_end, the number of pixels added at the end of axis `i`. This attribute cannot be used simultaneously with auto_pad attribute. If not present, the padding defaults to 0 along start and end of each spatial axis."
              },
              {
                "name": "strides",
                "type": "int64[]",
                "required": false,
                "description": "Stride along each spatial axis. If not present, the stride defaults is 1 along each spatial axis."
              }
            ],
            "inputs": [
              {
                "name": "X",
                "type": "T",
                "description": "Input data tensor from previous layer; has size (N x C x H x W), where N is the batch size, C is the number of channels, and H and W are the height and width. Note that this is for the 2D image. Otherwise the size is (N x C x D1 x D2 ... x Dn). Optionally, if dimension denotation is in effect, the operation expects input data tensor to arrive with the dimension denotation of [DATA_BATCH, DATA_CHANNEL, DATA_FEATURE, DATA_FEATURE ...]."
              },
              {
                "name": "W",
                "type": "T",
                "description": "The weight tensor that will be used in the convolutions; has size (M x C/group x kH x kW), where C is the number of channels, and kH and kW are the height and width of the kernel, and M is the number of feature maps. For more than 2 dimensions, the kernel shape will be (M x C/group x k1 x k2 x ... x kn), where (k1 x k2 x ... kn) is the dimension of the kernel. Optionally, if dimension denotation is in effect, the operation expects the weight tensor to arrive with the dimension denotation of [FILTER_OUT_CHANNEL, FILTER_IN_CHANNEL, FILTER_SPATIAL, FILTER_SPATIAL ...]. Assuming zero based indices for the shape array, X.shape[1] == (W.shape[1] * group) == C and W.shape[0] mod G == 0. Or in other words FILTER_IN_CHANNEL multiplied by the number of groups should be equal to DATA_CHANNEL and the number of feature maps M should be a multiple of the number of groups G."
              },
              {
                "name": "B",
                "type": "T",
                "option": "optional",
                "description": "Optional 1D bias to be added to the convolution, has size of M."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "Y",
                "type": "T",
                "description": "Output data tensor that contains the result of the convolution. The output dimensions are functions of the kernel size, stride size, and pad lengths."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain input and output types to float tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "conv",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[1, 1, 1, 1],\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 21.0, 27.0, 33.0, 24.0],  # (1, 1, 5, 5) output tensor\n                [33.0, 54.0, 63.0, 72.0, 51.0],\n                [63.0, 99.0, 108.0, 117.0, 81.0],\n                [93.0, 144.0, 153.0, 162.0, 111.0],\n                [72.0, 111.0, 117.0, 123.0, 84.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_basic_conv_with_padding\",\n)\n\n# Convolution without padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[0, 0, 0, 0],\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 63.0, 72.0],  # (1, 1, 3, 3) output tensor\n                [99.0, 108.0, 117.0],\n                [144.0, 153.0, 162.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_basic_conv_without_padding\",\n)"
              },
              {
                "summary": "conv_with_autopad_same",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with auto_pad='SAME_LOWER' and strides=2\nnode = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    auto_pad=\"SAME_LOWER\",\n    kernel_shape=[3, 3],\n    strides=[2, 2],\n)\ny = np.array(\n    [[[[12.0, 27.0, 24.0], [63.0, 108.0, 81.0], [72.0, 117.0, 84.0]]]]\n).astype(np.float32)\nexpect(node, inputs=[x, W], outputs=[y], name=\"test_conv_with_autopad_same\")"
              },
              {
                "summary": "conv_with_strides",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 7, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n                [25.0, 26.0, 27.0, 28.0, 29.0],\n                [30.0, 31.0, 32.0, 33.0, 34.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with strides=2 and padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 1, 1, 1],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 27.0, 24.0],  # (1, 1, 4, 3) output tensor\n                [63.0, 108.0, 81.0],\n                [123.0, 198.0, 141.0],\n                [112.0, 177.0, 124.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_conv_with_strides_padding\",\n)\n\n# Convolution with strides=2 and no padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[0, 0, 0, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 72.0],  # (1, 1, 3, 2) output tensor\n                [144.0, 162.0],\n                [234.0, 252.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_conv_with_strides_no_padding\",\n)\n\n# Convolution with strides=2 and padding only along one dimension (the H dimension in NxCxHxW tensor)\nnode_with_asymmetric_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 0, 1, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_asymmetric_padding = np.array(\n    [\n        [\n            [\n                [21.0, 33.0],  # (1, 1, 4, 2) output tensor\n                [99.0, 117.0],\n                [189.0, 207.0],\n                [171.0, 183.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_asymmetric_padding,\n    inputs=[x, W],\n    outputs=[y_with_asymmetric_padding],\n    name=\"test_conv_with_strides_and_asymmetric_padding\",\n)"
              }
            ],
            "category": "Layer"
          }
        },
        {
          "name": "re_lu_20",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "X",
              "value": [
                {
                  "name": "Conv__263:0",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        16,
                        72,
                        128
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "Y",
              "value": [
                {
                  "name": "re_lu_20:0",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        16,
                        72,
                        128
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "Relu",
            "module": "ai.onnx",
            "version": 14,
            "description": "Relu takes one input data (Tensor<T>) and produces one output data\n(Tensor<T>) where the rectified linear function, y = max(0, x), is applied to\nthe tensor elementwise.\n",
            "inputs": [
              {
                "name": "X",
                "type": "T",
                "description": "Input tensor"
              }
            ],
            "min_input": 1,
            "max_input": 1,
            "outputs": [
              {
                "name": "Y",
                "type": "T",
                "description": "Output tensor"
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "type_constraints": [
              {
                "description": "Constrain input and output types to signed numeric tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(float)",
                  "tensor(int32)",
                  "tensor(int8)",
                  "tensor(int16)",
                  "tensor(int64)",
                  "tensor(float16)",
                  "tensor(double)",
                  "tensor(bfloat16)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "relu",
                "code": "node = onnx.helper.make_node(\n    \"Relu\",\n    inputs=[\"x\"],\n    outputs=[\"y\"],\n)\nx = np.random.randn(3, 4, 5).astype(np.float32)\ny = np.clip(x, 0, np.inf)\n\nexpect(node, inputs=[x], outputs=[y], name=\"test_relu\")"
              }
            ],
            "category": "Activation"
          }
        },
        {
          "name": "Conv__266",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "X",
              "value": [
                {
                  "name": "re_lu_20:0",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        16,
                        72,
                        128
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "W",
              "value": [
                {
                  "name": "const_fold_opt__389",
                  "initializer": {
                    "name": "const_fold_opt__389",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float32",
                      "shape": {
                        "dimensions": [
                          16,
                          1,
                          3,
                          3
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        16,
                        1,
                        3,
                        3
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "B",
              "value": [
                {
                  "name": "depthwise_conv2d_10/y:0",
                  "initializer": {
                    "name": "depthwise_conv2d_10/y:0",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float32",
                      "shape": {
                        "dimensions": [
                          16
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        16
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "Y",
              "value": [
                {
                  "name": "Conv__266:0",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        16,
                        72,
                        128
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [
            {
              "name": "dilations",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "strides",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "kernel_shape",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "3",
                  "3"
                ]
              }
            },
            {
              "name": "group",
              "type": "int64",
              "value": {
                "type": "bigint",
                "value": "16"
              }
            },
            {
              "name": "pads",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1",
                  "1",
                  "1"
                ]
              }
            }
          ],
          "type": {
            "name": "Conv",
            "module": "ai.onnx",
            "version": 11,
            "description": "The convolution operator consumes an input tensor and a filter, and\ncomputes the output.",
            "attributes": [
              {
                "name": "auto_pad",
                "type": "string",
                "required": false,
                "default": "NOTSET",
                "description": "auto_pad must be either NOTSET, SAME_UPPER, SAME_LOWER or VALID. Where default value is NOTSET, which means explicit padding is used. SAME_UPPER or SAME_LOWER mean pad the input so that `output_shape[i] = ceil(input_shape[i] / strides[i])` for each axis `i`. The padding is split between the two sides equally or almost equally (depending on whether it is even or odd). In case the padding is an odd number, the extra padding is added at the end for SAME_UPPER and at the beginning for SAME_LOWER."
              },
              {
                "name": "dilations",
                "type": "int64[]",
                "required": false,
                "description": "dilation value along each spatial axis of the filter. If not present, the dilation defaults is 1 along each spatial axis."
              },
              {
                "name": "group",
                "type": "int64",
                "required": false,
                "default": 1,
                "description": "number of groups input channels and output channels are divided into."
              },
              {
                "name": "kernel_shape",
                "type": "int64[]",
                "required": false,
                "description": "The shape of the convolution kernel. If not present, should be inferred from input W."
              },
              {
                "name": "pads",
                "type": "int64[]",
                "required": false,
                "description": "Padding for the beginning and ending along each spatial axis, it can take any value greater than or equal to 0. The value represent the number of pixels added to the beginning and end part of the corresponding axis. `pads` format should be as follow [x1_begin, x2_begin...x1_end, x2_end,...], where xi_begin the number of pixels added at the beginning of axis `i` and xi_end, the number of pixels added at the end of axis `i`. This attribute cannot be used simultaneously with auto_pad attribute. If not present, the padding defaults to 0 along start and end of each spatial axis."
              },
              {
                "name": "strides",
                "type": "int64[]",
                "required": false,
                "description": "Stride along each spatial axis. If not present, the stride defaults is 1 along each spatial axis."
              }
            ],
            "inputs": [
              {
                "name": "X",
                "type": "T",
                "description": "Input data tensor from previous layer; has size (N x C x H x W), where N is the batch size, C is the number of channels, and H and W are the height and width. Note that this is for the 2D image. Otherwise the size is (N x C x D1 x D2 ... x Dn). Optionally, if dimension denotation is in effect, the operation expects input data tensor to arrive with the dimension denotation of [DATA_BATCH, DATA_CHANNEL, DATA_FEATURE, DATA_FEATURE ...]."
              },
              {
                "name": "W",
                "type": "T",
                "description": "The weight tensor that will be used in the convolutions; has size (M x C/group x kH x kW), where C is the number of channels, and kH and kW are the height and width of the kernel, and M is the number of feature maps. For more than 2 dimensions, the kernel shape will be (M x C/group x k1 x k2 x ... x kn), where (k1 x k2 x ... kn) is the dimension of the kernel. Optionally, if dimension denotation is in effect, the operation expects the weight tensor to arrive with the dimension denotation of [FILTER_OUT_CHANNEL, FILTER_IN_CHANNEL, FILTER_SPATIAL, FILTER_SPATIAL ...]. Assuming zero based indices for the shape array, X.shape[1] == (W.shape[1] * group) == C and W.shape[0] mod G == 0. Or in other words FILTER_IN_CHANNEL multiplied by the number of groups should be equal to DATA_CHANNEL and the number of feature maps M should be a multiple of the number of groups G."
              },
              {
                "name": "B",
                "type": "T",
                "option": "optional",
                "description": "Optional 1D bias to be added to the convolution, has size of M."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "Y",
                "type": "T",
                "description": "Output data tensor that contains the result of the convolution. The output dimensions are functions of the kernel size, stride size, and pad lengths."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain input and output types to float tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "conv",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[1, 1, 1, 1],\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 21.0, 27.0, 33.0, 24.0],  # (1, 1, 5, 5) output tensor\n                [33.0, 54.0, 63.0, 72.0, 51.0],\n                [63.0, 99.0, 108.0, 117.0, 81.0],\n                [93.0, 144.0, 153.0, 162.0, 111.0],\n                [72.0, 111.0, 117.0, 123.0, 84.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_basic_conv_with_padding\",\n)\n\n# Convolution without padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    # Default values for other attributes: strides=[1, 1], dilations=[1, 1], groups=1\n    pads=[0, 0, 0, 0],\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 63.0, 72.0],  # (1, 1, 3, 3) output tensor\n                [99.0, 108.0, 117.0],\n                [144.0, 153.0, 162.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_basic_conv_without_padding\",\n)"
              },
              {
                "summary": "conv_with_autopad_same",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 5, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with auto_pad='SAME_LOWER' and strides=2\nnode = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    auto_pad=\"SAME_LOWER\",\n    kernel_shape=[3, 3],\n    strides=[2, 2],\n)\ny = np.array(\n    [[[[12.0, 27.0, 24.0], [63.0, 108.0, 81.0], [72.0, 117.0, 84.0]]]]\n).astype(np.float32)\nexpect(node, inputs=[x, W], outputs=[y], name=\"test_conv_with_autopad_same\")"
              },
              {
                "summary": "conv_with_strides",
                "code": "x = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 7, 5) input tensor\n                [5.0, 6.0, 7.0, 8.0, 9.0],\n                [10.0, 11.0, 12.0, 13.0, 14.0],\n                [15.0, 16.0, 17.0, 18.0, 19.0],\n                [20.0, 21.0, 22.0, 23.0, 24.0],\n                [25.0, 26.0, 27.0, 28.0, 29.0],\n                [30.0, 31.0, 32.0, 33.0, 34.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 1.0],  # (1, 1, 3, 3) tensor for convolution weights\n                [1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\n# Convolution with strides=2 and padding\nnode_with_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 1, 1, 1],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_padding = np.array(\n    [\n        [\n            [\n                [12.0, 27.0, 24.0],  # (1, 1, 4, 3) output tensor\n                [63.0, 108.0, 81.0],\n                [123.0, 198.0, 141.0],\n                [112.0, 177.0, 124.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_padding,\n    inputs=[x, W],\n    outputs=[y_with_padding],\n    name=\"test_conv_with_strides_padding\",\n)\n\n# Convolution with strides=2 and no padding\nnode_without_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[0, 0, 0, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_without_padding = np.array(\n    [\n        [\n            [\n                [54.0, 72.0],  # (1, 1, 3, 2) output tensor\n                [144.0, 162.0],\n                [234.0, 252.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_without_padding,\n    inputs=[x, W],\n    outputs=[y_without_padding],\n    name=\"test_conv_with_strides_no_padding\",\n)\n\n# Convolution with strides=2 and padding only along one dimension (the H dimension in NxCxHxW tensor)\nnode_with_asymmetric_padding = onnx.helper.make_node(\n    \"Conv\",\n    inputs=[\"x\", \"W\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[1, 0, 1, 0],\n    strides=[\n        2,\n        2,\n    ],  # Default values for other attributes: dilations=[1, 1], groups=1\n)\ny_with_asymmetric_padding = np.array(\n    [\n        [\n            [\n                [21.0, 33.0],  # (1, 1, 4, 2) output tensor\n                [99.0, 117.0],\n                [189.0, 207.0],\n                [171.0, 183.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\nexpect(\n    node_with_asymmetric_padding,\n    inputs=[x, W],\n    outputs=[y_with_asymmetric_padding],\n    name=\"test_conv_with_strides_and_asymmetric_padding\",\n)"
              }
            ],
            "category": "Layer"
          }
        },
        {
          "name": "re_lu_21",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "X",
              "value": [
                {
                  "name": "Conv__266:0",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        16,
                        72,
                        128
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "Y",
              "value": [
                {
                  "name": "re_lu_21:0",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        16,
                        72,
                        128
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "Relu",
            "module": "ai.onnx",
            "version": 14,
            "description": "Relu takes one input data (Tensor<T>) and produces one output data\n(Tensor<T>) where the rectified linear function, y = max(0, x), is applied to\nthe tensor elementwise.\n",
            "inputs": [
              {
                "name": "X",
                "type": "T",
                "description": "Input tensor"
              }
            ],
            "min_input": 1,
            "max_input": 1,
            "outputs": [
              {
                "name": "Y",
                "type": "T",
                "description": "Output tensor"
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "type_constraints": [
              {
                "description": "Constrain input and output types to signed numeric tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(float)",
                  "tensor(int32)",
                  "tensor(int8)",
                  "tensor(int16)",
                  "tensor(int64)",
                  "tensor(float16)",
                  "tensor(double)",
                  "tensor(bfloat16)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "relu",
                "code": "node = onnx.helper.make_node(\n    \"Relu\",\n    inputs=[\"x\"],\n    outputs=[\"y\"],\n)\nx = np.random.randn(3, 4, 5).astype(np.float32)\ny = np.clip(x, 0, np.inf)\n\nexpect(node, inputs=[x], outputs=[y], name=\"test_relu\")"
              }
            ],
            "category": "Activation"
          }
        },
        {
          "name": "add_13__xeno_compat__1",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "A",
              "value": [
                {
                  "name": "re_lu_20:0",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        16,
                        72,
                        128
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "B",
              "value": [
                {
                  "name": "re_lu_21:0",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        16,
                        72,
                        128
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "C",
              "value": [
                {
                  "name": "add_13__xeno_compat__1:0",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        16,
                        72,
                        128
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "Add",
            "module": "ai.onnx",
            "version": 14,
            "description": "Performs element-wise binary addition (with Numpy-style broadcasting support).\n\nThis operator supports **multidirectional (i.e., Numpy-style) broadcasting**; for more details please check [the doc](https://github.com/onnx/onnx/blob/master/docs/Broadcasting.md).\n\n(Opset 14 change): Extend supported types to include uint8, int8, uint16, and int16.\n",
            "inputs": [
              {
                "name": "A",
                "type": "T",
                "description": "First operand."
              },
              {
                "name": "B",
                "type": "T",
                "description": "Second operand."
              }
            ],
            "min_input": 2,
            "max_input": 2,
            "outputs": [
              {
                "name": "C",
                "type": "T",
                "description": "Result, has same element type as two inputs"
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "type_constraints": [
              {
                "description": "Constrain input and output types to all numeric tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(uint8)",
                  "tensor(uint16)",
                  "tensor(uint32)",
                  "tensor(uint64)",
                  "tensor(int8)",
                  "tensor(int16)",
                  "tensor(int32)",
                  "tensor(int64)",
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)",
                  "tensor(bfloat16)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "add",
                "code": "node = onnx.helper.make_node(\n    \"Add\",\n    inputs=[\"x\", \"y\"],\n    outputs=[\"sum\"],\n)\n\nx = np.random.randn(3, 4, 5).astype(np.float32)\ny = np.random.randn(3, 4, 5).astype(np.float32)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add\")\n\nx = np.random.randint(24, size=(3, 4, 5), dtype=np.int8)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.int8)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add_int8\")\n\nx = np.random.randint(24, size=(3, 4, 5), dtype=np.int16)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.int16)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add_int16\")\n\nx = np.random.randint(24, size=(3, 4, 5), dtype=np.uint8)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.uint8)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add_uint8\")\n\nx = np.random.randint(24, size=(3, 4, 5), dtype=np.uint16)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.uint16)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add_uint16\")\n\nx = np.random.randint(24, size=(3, 4, 5), dtype=np.uint32)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.uint32)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add_uint32\")\n\nx = np.random.randint(24, size=(3, 4, 5), dtype=np.uint64)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.uint64)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add_uint64\")"
              },
              {
                "summary": "add_broadcast",
                "code": "node = onnx.helper.make_node(\n    \"Add\",\n    inputs=[\"x\", \"y\"],\n    outputs=[\"sum\"],\n)\n\nx = np.random.randn(3, 4, 5).astype(np.float32)\ny = np.random.randn(5).astype(np.float32)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add_bcast\")"
              }
            ]
          }
        },
        {
          "name": "conv2d_transpose",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "X",
              "value": [
                {
                  "name": "add_13__xeno_compat__1:0",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        16,
                        72,
                        128
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "W",
              "value": [
                {
                  "name": "conv2d_transpose/filter:0",
                  "initializer": {
                    "name": "conv2d_transpose/filter:0",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float32",
                      "shape": {
                        "dimensions": [
                          16,
                          1,
                          2,
                          2
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        16,
                        1,
                        2,
                        2
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "Y",
              "value": [
                {
                  "name": "conv2d_transpose:0",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        1,
                        144,
                        256
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [
            {
              "name": "dilations",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "1",
                  "1"
                ]
              }
            },
            {
              "name": "strides",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "2",
                  "2"
                ]
              }
            },
            {
              "name": "kernel_shape",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "2",
                  "2"
                ]
              }
            },
            {
              "name": "output_shape",
              "type": "int64[]",
              "value": {
                "type": "bigint[]",
                "value": [
                  "144",
                  "256"
                ]
              }
            }
          ],
          "type": {
            "name": "ConvTranspose",
            "module": "ai.onnx",
            "version": 11,
            "description": "The convolution transpose operator consumes an input tensor and a filter,\nand computes the output.\n\nIf the pads parameter is provided the shape of the output is calculated via the following equation:\n\n  output_shape[i] = stride[i] * (input_size[i] - 1) + output_padding[i] + ((kernel_shape[i] - 1) * dilations[i] + 1) - pads[start_i] - pads[end_i]\n\noutput_shape can also be explicitly specified in which case pads values are auto generated using these equations:\n\n  total_padding[i] = stride[i] * (input_size[i] - 1) + output_padding[i] + ((kernel_shape[i] - 1) * dilations[i] + 1) - output_shape[i]\n  If (auto_pads == SAME_UPPER): pads[start_i] = total_padding[i]/2; pads[end_i] = total_padding[i] - (total_padding[i]/2)\n  Else: pads[start_i] = total_padding[i] - (total_padding[i]/2); pads[end_i] = (total_padding[i]/2).\n\n    ",
            "attributes": [
              {
                "name": "auto_pad",
                "type": "string",
                "required": false,
                "default": "NOTSET",
                "description": "auto_pad must be either NOTSET, SAME_UPPER, SAME_LOWER or VALID. Where default value is NOTSET, which means explicit padding is used. SAME_UPPER or SAME_LOWER mean pad the input so that `output_shape[i] = input_shape[i] * strides[i]` for each axis `i`. The padding is split between the two sides equally or almost equally (depending on whether it is even or odd). In case the padding is an odd number, the extra padding is added at the end for SAME_UPPER and at the beginning for SAME_LOWER."
              },
              {
                "name": "dilations",
                "type": "int64[]",
                "required": false,
                "description": "dilation value along each spatial axis of the filter. If not present, the dilation defaults to 1 along each spatial axis."
              },
              {
                "name": "group",
                "type": "int64",
                "required": false,
                "default": 1,
                "description": "number of groups input channels and output channels are divided into."
              },
              {
                "name": "kernel_shape",
                "type": "int64[]",
                "required": false,
                "description": "The shape of the convolution kernel. If not present, should be inferred from input W."
              },
              {
                "name": "output_padding",
                "type": "int64[]",
                "required": false,
                "description": "Additional elements added to the side with higher coordinate indices in the output. Each padding value in \"output_padding\" must be less than the corresponding stride/dilation dimension. By default, this attribute is a zero vector. Note that this attribute doesn't directly affect the computed output values. It only controls the selection of the computed values, so changing this attribute only adds or removes output elements. If \"output_shape\" is explicitly provided, \"output_padding\" does not contribute additional size to \"output_shape\" but participates in the computation of the needed padding amount. This is also called adjs or adjustment in some frameworks."
              },
              {
                "name": "output_shape",
                "type": "int64[]",
                "required": false,
                "description": "The shape of the output can be explicitly set which will cause pads values to be auto generated. If output_shape is specified pads values are ignored. See doc for details for equations to generate pads. Note that the output_shape attribute value should not include dimensions for batch size and channels, which are automatically inferred."
              },
              {
                "name": "pads",
                "type": "int64[]",
                "required": false,
                "description": "Padding for the beginning and ending along each spatial axis, it can take any value greater than or equal to 0. The value represent the number of pixels added to the beginning and end part of the corresponding axis. `pads` format should be as follow [x1_begin, x2_begin...x1_end, x2_end,...], where xi_begin the number of pixels added at the beginning of axis `i` and xi_end, the number of pixels added at the end of axis `i`. This attribute cannot be used simultaneously with auto_pad attribute. If not present, the padding defaults to 0 along start and end of each spatial axis."
              },
              {
                "name": "strides",
                "type": "int64[]",
                "required": false,
                "description": "Stride along each spatial axis. If not present, the stride defaults to 1 along each spatial axis."
              }
            ],
            "inputs": [
              {
                "name": "X",
                "type": "T",
                "description": "Input data tensor from previous layer; has size (N x C x H x W), where N is the batch size, C is the number of channels, and H and W are the height and width. Note that this is for the 2D image. Otherwise the size is (N x C x D1 x D2 ... x Dn)"
              },
              {
                "name": "W",
                "type": "T",
                "description": "The weight tensor that will be used in the convolutions; has size (C x M/group x kH x kW), where C is the number of channels, and kH and kW are the height and width of the kernel, and M is the number of feature maps. For more than 2 dimensions, the weight shape will be (C x M/group x k1 x k2 x ... x kn), where (k1 x k2 x ... x kn) is the dimension of the kernel. The number of channels in the output should be equal to W.shape[1] * group (assuming zero based indices of the shape array)"
              },
              {
                "name": "B",
                "type": "T",
                "option": "optional",
                "description": "Optional 1D bias to be added to the convolution, has size of M."
              }
            ],
            "min_input": 2,
            "max_input": 3,
            "outputs": [
              {
                "name": "Y",
                "type": "T",
                "description": "Output data tensor that contains the result of the convolution. The output dimensions are functions of the kernel size, stride size, pad lengths and group count. The number of channels in the output should be equal to W.shape[1] * group (assuming zero based indices of the shape array)"
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "inputs_range": "2 - 3",
            "type_constraints": [
              {
                "description": "Constrain input and output types to float tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "convtranspose",
                "code": "x = np.array(\n    [[[[0.0, 1.0, 2.0], [3.0, 4.0, 5.0], [6.0, 7.0, 8.0]]]]  # (1, 1, 3, 3)\n).astype(np.float32)\n\nW = np.array(\n    [\n        [\n            [[1.0, 1.0, 1.0], [1.0, 1.0, 1.0], [1.0, 1.0, 1.0]],  # (1, 2, 3, 3)\n            [[1.0, 1.0, 1.0], [1.0, 1.0, 1.0], [1.0, 1.0, 1.0]],\n        ]\n    ]\n).astype(np.float32)\n\nnode = onnx.helper.make_node(\"ConvTranspose\", [\"X\", \"W\"], [\"Y\"])\n\ny = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 3.0, 3.0, 2.0],  # (1, 2, 5, 5)\n                [3.0, 8.0, 15.0, 12.0, 7.0],\n                [9.0, 21.0, 36.0, 27.0, 15.0],\n                [9.0, 20.0, 33.0, 24.0, 13.0],\n                [6.0, 13.0, 21.0, 15.0, 8.0],\n            ],\n            [\n                [0.0, 1.0, 3.0, 3.0, 2.0],\n                [3.0, 8.0, 15.0, 12.0, 7.0],\n                [9.0, 21.0, 36.0, 27.0, 15.0],\n                [9.0, 20.0, 33.0, 24.0, 13.0],\n                [6.0, 13.0, 21.0, 15.0, 8.0],\n            ],\n        ]\n    ]\n).astype(np.float32)\n\nexpect(node, inputs=[x, W], outputs=[y], name=\"test_convtranspose\")"
              },
              {
                "summary": "convtranspose_1d",
                "code": "x = np.array([[[0.0, 1.0, 2.0]]]).astype(np.float32)  # (1, 1, 3)\n\nW = np.array([[[1.0, 1.0, 1.0], [1.0, 1.0, 1.0]]]).astype(  # (1, 2, 3)\n    np.float32\n)\n\nnode = onnx.helper.make_node(\"ConvTranspose\", [\"X\", \"W\"], [\"Y\"])\n\ny = np.array(\n    [[[0.0, 1.0, 3.0, 3.0, 2.0], [0.0, 1.0, 3.0, 3.0, 2.0]]]  # (1, 2, 5)\n).astype(np.float32)\n\nexpect(node, inputs=[x, W], outputs=[y], name=\"test_convtranspose_1d\")"
              },
              {
                "summary": "convtranspose_3d",
                "code": "x = np.array(\n    [\n        [\n            [\n                [\n                    [0.0, 1.0, 2.0, 3.0, 4.0],  # (1, 1, 3, 4, 5)\n                    [5.0, 6.0, 7.0, 8.0, 9.0],\n                    [10.0, 11.0, 12.0, 13.0, 14.0],\n                    [15.0, 16.0, 17.0, 18.0, 19.0],\n                ],\n                [\n                    [20.0, 21.0, 22.0, 23.0, 24.0],\n                    [25.0, 26.0, 27.0, 28.0, 29.0],\n                    [30.0, 31.0, 32.0, 33.0, 34.0],\n                    [35.0, 36.0, 37.0, 38.0, 39.0],\n                ],\n                [\n                    [40.0, 41.0, 42.0, 43.0, 44.0],\n                    [45.0, 46.0, 47.0, 48.0, 49.0],\n                    [50.0, 51.0, 52.0, 53.0, 54.0],\n                    [55.0, 56.0, 57.0, 58.0, 59.0],\n                ],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\nW = np.array(\n    [\n        [\n            [\n                [\n                    [1.0, 1.0, 1.0],  # (1, 2, 3, 3, 3)\n                    [1.0, 1.0, 1.0],\n                    [1.0, 1.0, 1.0],\n                ],\n                [[1.0, 1.0, 1.0], [1.0, 1.0, 1.0], [1.0, 1.0, 1.0]],\n                [[1.0, 1.0, 1.0], [1.0, 1.0, 1.0], [1.0, 1.0, 1.0]],\n            ],\n            [\n                [[1.0, 1.0, 1.0], [1.0, 1.0, 1.0], [1.0, 1.0, 1.0]],\n                [[1.0, 1.0, 1.0], [1.0, 1.0, 1.0], [1.0, 1.0, 1.0]],\n                [[1.0, 1.0, 1.0], [1.0, 1.0, 1.0], [1.0, 1.0, 1.0]],\n            ],\n        ]\n    ]\n).astype(np.float32)\n\nnode = onnx.helper.make_node(\"ConvTranspose\", [\"X\", \"W\"], [\"Y\"])\n\ny = np.array(\n    [\n        [\n            [\n                [\n                    [0.0, 1.0, 3.0, 6.0, 9.0, 7.0, 4.0],  # (1, 2, 5, 6, 7)\n                    [5.0, 12.0, 21.0, 27.0, 33.0, 24.0, 13.0],\n                    [15.0, 33.0, 54.0, 63.0, 72.0, 51.0, 27.0],\n                    [30.0, 63.0, 99.0, 108.0, 117.0, 81.0, 42.0],\n                    [25.0, 52.0, 81.0, 87.0, 93.0, 64.0, 33.0],\n                    [15.0, 31.0, 48.0, 51.0, 54.0, 37.0, 19.0],\n                ],\n                [\n                    [20.0, 42.0, 66.0, 72.0, 78.0, 54.0, 28.0],\n                    [50.0, 104.0, 162.0, 174.0, 186.0, 128.0, 66.0],\n                    [90.0, 186.0, 288.0, 306.0, 324.0, 222.0, 114.0],\n                    [120.0, 246.0, 378.0, 396.0, 414.0, 282.0, 144.0],\n                    [90.0, 184.0, 282.0, 294.0, 306.0, 208.0, 106.0],\n                    [50.0, 102.0, 156.0, 162.0, 168.0, 114.0, 58.0],\n                ],\n                [\n                    [60.0, 123.0, 189.0, 198.0, 207.0, 141.0, 72.0],\n                    [135.0, 276.0, 423.0, 441.0, 459.0, 312.0, 159.0],\n                    [225.0, 459.0, 702.0, 729.0, 756.0, 513.0, 261.0],\n                    [270.0, 549.0, 837.0, 864.0, 891.0, 603.0, 306.0],\n                    [195.0, 396.0, 603.0, 621.0, 639.0, 432.0, 219.0],\n                    [105.0, 213.0, 324.0, 333.0, 342.0, 231.0, 117.0],\n                ],\n                [\n                    [60.0, 122.0, 186.0, 192.0, 198.0, 134.0, 68.0],\n                    [130.0, 264.0, 402.0, 414.0, 426.0, 288.0, 146.0],\n                    [210.0, 426.0, 648.0, 666.0, 684.0, 462.0, 234.0],\n                    [240.0, 486.0, 738.0, 756.0, 774.0, 522.0, 264.0],\n                    [170.0, 344.0, 522.0, 534.0, 546.0, 368.0, 186.0],\n                    [90.0, 182.0, 276.0, 282.0, 288.0, 194.0, 98.0],\n                ],\n                [\n                    [40.0, 81.0, 123.0, 126.0, 129.0, 87.0, 44.0],\n                    [85.0, 172.0, 261.0, 267.0, 273.0, 184.0, 93.0],\n                    [135.0, 273.0, 414.0, 423.0, 432.0, 291.0, 147.0],\n                    [150.0, 303.0, 459.0, 468.0, 477.0, 321.0, 162.0],\n                    [105.0, 212.0, 321.0, 327.0, 333.0, 224.0, 113.0],\n                    [55.0, 111.0, 168.0, 171.0, 174.0, 117.0, 59.0],\n                ],\n            ],\n            [\n                [\n                    [0.0, 1.0, 3.0, 6.0, 9.0, 7.0, 4.0],\n                    [5.0, 12.0, 21.0, 27.0, 33.0, 24.0, 13.0],\n                    [15.0, 33.0, 54.0, 63.0, 72.0, 51.0, 27.0],\n                    [30.0, 63.0, 99.0, 108.0, 117.0, 81.0, 42.0],\n                    [25.0, 52.0, 81.0, 87.0, 93.0, 64.0, 33.0],\n                    [15.0, 31.0, 48.0, 51.0, 54.0, 37.0, 19.0],\n                ],\n                [\n                    [20.0, 42.0, 66.0, 72.0, 78.0, 54.0, 28.0],\n                    [50.0, 104.0, 162.0, 174.0, 186.0, 128.0, 66.0],\n                    [90.0, 186.0, 288.0, 306.0, 324.0, 222.0, 114.0],\n                    [120.0, 246.0, 378.0, 396.0, 414.0, 282.0, 144.0],\n                    [90.0, 184.0, 282.0, 294.0, 306.0, 208.0, 106.0],\n                    [50.0, 102.0, 156.0, 162.0, 168.0, 114.0, 58.0],\n                ],\n                [\n                    [60.0, 123.0, 189.0, 198.0, 207.0, 141.0, 72.0],\n                    [135.0, 276.0, 423.0, 441.0, 459.0, 312.0, 159.0],\n                    [225.0, 459.0, 702.0, 729.0, 756.0, 513.0, 261.0],\n                    [270.0, 549.0, 837.0, 864.0, 891.0, 603.0, 306.0],\n                    [195.0, 396.0, 603.0, 621.0, 639.0, 432.0, 219.0],\n                    [105.0, 213.0, 324.0, 333.0, 342.0, 231.0, 117.0],\n                ],\n                [\n                    [60.0, 122.0, 186.0, 192.0, 198.0, 134.0, 68.0],\n                    [130.0, 264.0, 402.0, 414.0, 426.0, 288.0, 146.0],\n                    [210.0, 426.0, 648.0, 666.0, 684.0, 462.0, 234.0],\n                    [240.0, 486.0, 738.0, 756.0, 774.0, 522.0, 264.0],\n                    [170.0, 344.0, 522.0, 534.0, 546.0, 368.0, 186.0],\n                    [90.0, 182.0, 276.0, 282.0, 288.0, 194.0, 98.0],\n                ],\n                [\n                    [40.0, 81.0, 123.0, 126.0, 129.0, 87.0, 44.0],\n                    [85.0, 172.0, 261.0, 267.0, 273.0, 184.0, 93.0],\n                    [135.0, 273.0, 414.0, 423.0, 432.0, 291.0, 147.0],\n                    [150.0, 303.0, 459.0, 468.0, 477.0, 321.0, 162.0],\n                    [105.0, 212.0, 321.0, 327.0, 333.0, 224.0, 113.0],\n                    [55.0, 111.0, 168.0, 171.0, 174.0, 117.0, 59.0],\n                ],\n            ],\n        ]\n    ]\n).astype(np.float32)\n\nexpect(node, inputs=[x, W], outputs=[y], name=\"test_convtranspose_3d\")"
              },
              {
                "summary": "convtranspose_attributes",
                "code": "x = np.array(\n    [[[[0.0, 1.0, 2.0], [3.0, 4.0, 5.0], [6.0, 7.0, 8.0]]]]  # (1, 1, 3, 3)\n).astype(np.float32)\n\nW = np.array(\n    [\n        [\n            [[1.0, 1.0, 1.0], [1.0, 1.0, 1.0], [1.0, 1.0, 1.0]],  # (1, 2, 3, 3)\n            [[1.0, 1.0, 1.0], [1.0, 1.0, 1.0], [1.0, 1.0, 1.0]],\n        ]\n    ]\n).astype(np.float32)\n\ny = np.array(\n    [\n        [\n            [\n                [0.0, 0.0, 1.0, 1.0, 3.0, 2.0, 2.0, 0.0],  # (1, 2, 10, 8)\n                [0.0, 0.0, 1.0, 1.0, 3.0, 2.0, 2.0, 0.0],\n                [0.0, 0.0, 1.0, 1.0, 3.0, 2.0, 2.0, 0.0],\n                [3.0, 3.0, 7.0, 4.0, 9.0, 5.0, 5.0, 0.0],\n                [3.0, 3.0, 7.0, 4.0, 9.0, 5.0, 5.0, 0.0],\n                [3.0, 3.0, 7.0, 4.0, 9.0, 5.0, 5.0, 0.0],\n                [6.0, 6.0, 13.0, 7.0, 15.0, 8.0, 8.0, 0.0],\n                [6.0, 6.0, 13.0, 7.0, 15.0, 8.0, 8.0, 0.0],\n                [6.0, 6.0, 13.0, 7.0, 15.0, 8.0, 8.0, 0.0],\n                [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n            ],\n            [\n                [0.0, 0.0, 1.0, 1.0, 3.0, 2.0, 2.0, 0.0],\n                [0.0, 0.0, 1.0, 1.0, 3.0, 2.0, 2.0, 0.0],\n                [0.0, 0.0, 1.0, 1.0, 3.0, 2.0, 2.0, 0.0],\n                [3.0, 3.0, 7.0, 4.0, 9.0, 5.0, 5.0, 0.0],\n                [3.0, 3.0, 7.0, 4.0, 9.0, 5.0, 5.0, 0.0],\n                [3.0, 3.0, 7.0, 4.0, 9.0, 5.0, 5.0, 0.0],\n                [6.0, 6.0, 13.0, 7.0, 15.0, 8.0, 8.0, 0.0],\n                [6.0, 6.0, 13.0, 7.0, 15.0, 8.0, 8.0, 0.0],\n                [6.0, 6.0, 13.0, 7.0, 15.0, 8.0, 8.0, 0.0],\n                [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n            ],\n        ]\n    ]\n).astype(np.float32)\n\nnode = onnx.helper.make_node(\n    \"ConvTranspose\", [\"X\", \"W\"], [\"Y\"], strides=[3, 2], output_shape=[10, 8]\n)\nexpect(node, inputs=[x, W], outputs=[y], name=\"test_convtranspose_output_shape\")\n\nnode = onnx.helper.make_node(\n    \"ConvTranspose\", [\"X\", \"W\"], [\"Y\"], strides=[3, 2], output_padding=[1, 1]\n)\nexpect(node, inputs=[x, W], outputs=[y], name=\"test_convtranspose_pad\")\n\nnode = onnx.helper.make_node(\n    \"ConvTranspose\",\n    [\"X\", \"W\"],\n    [\"Y\"],\n    name=\"test\",\n    strides=[3, 2],\n    output_shape=[10, 8],\n    kernel_shape=[3, 3],\n    output_padding=[1, 1],\n)\nexpect(node, inputs=[x, W], outputs=[y], name=\"test_convtranspose_kernel_shape\")"
              },
              {
                "summary": "convtranspose_autopad_same",
                "code": "x = np.array(\n    [[[[0.0, 1.0, 2.0], [3.0, 4.0, 5.0], [6.0, 7.0, 8.0]]]]  # (1, 1, 3, 3)\n).astype(np.float32)\n\nW = np.array(\n    [\n        [\n            [[1.0, 1.0, 1.0], [1.0, 1.0, 1.0], [1.0, 1.0, 1.0]],  # (1, 2, 3, 3)\n            [[1.0, 1.0, 1.0], [1.0, 1.0, 1.0], [1.0, 1.0, 1.0]],\n        ]\n    ]\n).astype(np.float32)\n\nnode = onnx.helper.make_node(\n    \"ConvTranspose\", [\"X\", \"W\"], [\"Y\"], auto_pad=\"SAME_UPPER\", strides=[2, 2]\n)\n\ny = np.array(\n    [\n        [\n            [\n                [0.0, 0.0, 1.0, 1.0, 3.0, 2.0],\n                [0.0, 0.0, 1.0, 1.0, 3.0, 2.0],\n                [3.0, 3.0, 8.0, 5.0, 12.0, 7.0],\n                [3.0, 3.0, 7.0, 4.0, 9.0, 5.0],\n                [9.0, 9.0, 20.0, 11.0, 24.0, 13.0],\n                [6.0, 6.0, 13.0, 7.0, 15.0, 8.0],\n            ],\n            [\n                [0.0, 0.0, 1.0, 1.0, 3.0, 2.0],\n                [0.0, 0.0, 1.0, 1.0, 3.0, 2.0],\n                [3.0, 3.0, 8.0, 5.0, 12.0, 7.0],\n                [3.0, 3.0, 7.0, 4.0, 9.0, 5.0],\n                [9.0, 9.0, 20.0, 11.0, 24.0, 13.0],\n                [6.0, 6.0, 13.0, 7.0, 15.0, 8.0],\n            ],\n        ]\n    ]\n).astype(np.float32)\n\nexpect(node, inputs=[x, W], outputs=[y], name=\"test_convtranspose_autopad_same\")"
              },
              {
                "summary": "convtranspose_dilations",
                "code": "x = np.array(\n    [[[[3.0, 8.0, 1.0], [9.0, 5.0, 7.0], [3.0, 2.0, 6.0]]]]  # (1, 1, 3, 3)\n).astype(np.float32)\nW = np.array([[[[7.0, 2.0], [1.0, 9.0]]]]).astype(np.float32)  # (1, 1, 2, 2)\n\nnode = onnx.helper.make_node(\n    \"ConvTranspose\", [\"X\", \"W\"], [\"Y\"], dilations=[2, 2]\n)\n\ny = np.array(\n    [\n        [\n            [\n                [21.0, 56.0, 13.0, 16.0, 2.0],  # [1, 1, 5, 5]\n                [63.0, 35.0, 67.0, 10.0, 14.0],\n                [24.0, 22.0, 76.0, 76.0, 21.0],\n                [9.0, 5.0, 88.0, 45.0, 63.0],\n                [3.0, 2.0, 33.0, 18.0, 54.0],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\nexpect(node, inputs=[x, W], outputs=[y], name=\"test_convtranspose_dilations\")"
              },
              {
                "summary": "convtranspose_group_2",
                "code": "x = np.array(\n    [\n        [\n            [[0.0, 1.0, 2.0], [3.0, 4.0, 5.0], [6.0, 7.0, 8.0]],\n            [[9.0, 10.0, 11.0], [12.0, 13.0, 14.0], [15.0, 16.0, 17.0]],\n        ]\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [[1.0, 1.0, 1.0], [1.0, 1.0, 1.0], [1.0, 1.0, 1.0]],\n        ],\n        [\n            [[1.0, 1.0, 1.0], [1.0, 1.0, 1.0], [1.0, 1.0, 1.0]],\n        ],\n    ]\n).astype(np.float32)\n\nnode = onnx.helper.make_node(\"ConvTranspose\", [\"X\", \"W\"], [\"Y\"], group=2)\n\ny = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 3.0, 3.0, 2.0],\n                [3.0, 8.0, 15.0, 12.0, 7.0],\n                [9.0, 21.0, 36.0, 27.0, 15.0],\n                [9.0, 20.0, 33.0, 24.0, 13.0],\n                [6.0, 13.0, 21.0, 15.0, 8.0],\n            ],\n            [\n                [9.0, 19.0, 30.0, 21.0, 11.0],\n                [21.0, 44.0, 69.0, 48.0, 25.0],\n                [36.0, 75.0, 117.0, 81.0, 42.0],\n                [27.0, 56.0, 87.0, 60.0, 31.0],\n                [15.0, 31.0, 48.0, 33.0, 17.0],\n            ],\n        ]\n    ]\n).astype(np.float32)\n\nexpect(node, inputs=[x, W], outputs=[y], name=\"test_convtranspose_group_2\")"
              },
              {
                "summary": "convtranspose_group_2_image_3",
                "code": "x = np.array(\n    [\n        [\n            [[0.0, 1.0, 2.0], [3.0, 4.0, 5.0], [6.0, 7.0, 8.0]],\n            [[9.0, 10.0, 11.0], [12.0, 13.0, 14.0], [15.0, 16.0, 17.0]],\n        ],\n        [\n            [[18.0, 19.0, 20.0], [21.0, 22.0, 23.0], [24.0, 25.0, 26.0]],\n            [[9.0, 10.0, 11.0], [12.0, 13.0, 14.0], [15.0, 16.0, 17.0]],\n        ],\n        [\n            [[0.0, 1.0, 2.0], [3.0, 4.0, 5.0], [6.0, 7.0, 8.0]],\n            [[9.0, 10.0, 11.0], [12.0, 13.0, 14.0], [15.0, 16.0, 17.0]],\n        ],\n    ]\n).astype(np.float32)\nW = np.array(\n    [\n        [\n            [[1.0, 1.0, 1.0], [1.0, 1.0, 1.0], [1.0, 1.0, 1.0]],\n        ],\n        [\n            [[1.0, 1.0, 1.0], [1.0, 1.0, 1.0], [1.0, 1.0, 1.0]],\n        ],\n    ]\n).astype(np.float32)\n\nnode = onnx.helper.make_node(\"ConvTranspose\", [\"X\", \"W\"], [\"Y\"], group=2)\n\ny = np.array(\n    [\n        [\n            [\n                [0.0, 1.0, 3.0, 3.0, 2.0],\n                [3.0, 8.0, 15.0, 12.0, 7.0],\n                [9.0, 21.0, 36.0, 27.0, 15.0],\n                [9.0, 20.0, 33.0, 24.0, 13.0],\n                [6.0, 13.0, 21.0, 15.0, 8.0],\n            ],\n            [\n                [9.0, 19.0, 30.0, 21.0, 11.0],\n                [21.0, 44.0, 69.0, 48.0, 25.0],\n                [36.0, 75.0, 117.0, 81.0, 42.0],\n                [27.0, 56.0, 87.0, 60.0, 31.0],\n                [15.0, 31.0, 48.0, 33.0, 17.0],\n            ],\n        ],\n        [\n            [\n                [18.0, 37.0, 57.0, 39.0, 20.0],\n                [39.0, 80.0, 123.0, 84.0, 43.0],\n                [63.0, 129.0, 198.0, 135.0, 69.0],\n                [45.0, 92.0, 141.0, 96.0, 49.0],\n                [24.0, 49.0, 75.0, 51.0, 26.0],\n            ],\n            [\n                [9.0, 19.0, 30.0, 21.0, 11.0],\n                [21.0, 44.0, 69.0, 48.0, 25.0],\n                [36.0, 75.0, 117.0, 81.0, 42.0],\n                [27.0, 56.0, 87.0, 60.0, 31.0],\n                [15.0, 31.0, 48.0, 33.0, 17.0],\n            ],\n        ],\n        [\n            [\n                [0.0, 1.0, 3.0, 3.0, 2.0],\n                [3.0, 8.0, 15.0, 12.0, 7.0],\n                [9.0, 21.0, 36.0, 27.0, 15.0],\n                [9.0, 20.0, 33.0, 24.0, 13.0],\n                [6.0, 13.0, 21.0, 15.0, 8.0],\n            ],\n            [\n                [9.0, 19.0, 30.0, 21.0, 11.0],\n                [21.0, 44.0, 69.0, 48.0, 25.0],\n                [36.0, 75.0, 117.0, 81.0, 42.0],\n                [27.0, 56.0, 87.0, 60.0, 31.0],\n                [15.0, 31.0, 48.0, 33.0, 17.0],\n            ],\n        ],\n    ]\n).astype(np.float32)\n\nexpect(\n    node, inputs=[x, W], outputs=[y], name=\"test_convtranspose_group_2_image_3\"\n)"
              },
              {
                "summary": "convtranspose_pads",
                "code": "x = np.array(\n    [[[[0.0, 1.0, 2.0], [3.0, 4.0, 5.0], [6.0, 7.0, 8.0]]]]  # (1, 1, 3, 3)\n).astype(np.float32)\n\nW = np.array(\n    [\n        [\n            [[1.0, 1.0, 1.0], [1.0, 1.0, 1.0], [1.0, 1.0, 1.0]],  # (1, 2, 3, 3)\n            [[1.0, 1.0, 1.0], [1.0, 1.0, 1.0], [1.0, 1.0, 1.0]],\n        ]\n    ]\n).astype(np.float32)\n\nnode = onnx.helper.make_node(\n    \"ConvTranspose\", [\"X\", \"W\"], [\"Y\"], strides=[3, 2], pads=[1, 2, 1, 2]\n)\n\ny = np.array(\n    [\n        [\n            [\n                [1.0, 1.0, 3.0],  # (1, 2, 7, 3)\n                [1.0, 1.0, 3.0],\n                [7.0, 4.0, 9.0],\n                [7.0, 4.0, 9.0],\n                [7.0, 4.0, 9.0],\n                [13.0, 7.0, 15.0],\n                [13.0, 7.0, 15.0],\n            ],\n            [\n                [1.0, 1.0, 3.0],\n                [1.0, 1.0, 3.0],\n                [7.0, 4.0, 9.0],\n                [7.0, 4.0, 9.0],\n                [7.0, 4.0, 9.0],\n                [13.0, 7.0, 15.0],\n                [13.0, 7.0, 15.0],\n            ],\n        ]\n    ]\n).astype(np.float32)\n\nexpect(node, inputs=[x, W], outputs=[y], name=\"test_convtranspose_pads\")"
              }
            ],
            "category": "Layer"
          }
        },
        {
          "name": "conv2d_transpose_add",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "A",
              "value": [
                {
                  "name": "conv2d_transpose:0",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        1,
                        144,
                        256
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "B",
              "value": [
                {
                  "name": "const_fold_opt__402",
                  "initializer": {
                    "name": "const_fold_opt__402",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "float32",
                      "shape": {
                        "dimensions": [
                          1,
                          1,
                          1,
                          1
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        1,
                        1,
                        1
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "C",
              "value": [
                {
                  "name": "conv2d_transpose_add:0",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        1,
                        144,
                        256
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "Add",
            "module": "ai.onnx",
            "version": 14,
            "description": "Performs element-wise binary addition (with Numpy-style broadcasting support).\n\nThis operator supports **multidirectional (i.e., Numpy-style) broadcasting**; for more details please check [the doc](https://github.com/onnx/onnx/blob/master/docs/Broadcasting.md).\n\n(Opset 14 change): Extend supported types to include uint8, int8, uint16, and int16.\n",
            "inputs": [
              {
                "name": "A",
                "type": "T",
                "description": "First operand."
              },
              {
                "name": "B",
                "type": "T",
                "description": "Second operand."
              }
            ],
            "min_input": 2,
            "max_input": 2,
            "outputs": [
              {
                "name": "C",
                "type": "T",
                "description": "Result, has same element type as two inputs"
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "type_constraints": [
              {
                "description": "Constrain input and output types to all numeric tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(uint8)",
                  "tensor(uint16)",
                  "tensor(uint32)",
                  "tensor(uint64)",
                  "tensor(int8)",
                  "tensor(int16)",
                  "tensor(int32)",
                  "tensor(int64)",
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)",
                  "tensor(bfloat16)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "add",
                "code": "node = onnx.helper.make_node(\n    \"Add\",\n    inputs=[\"x\", \"y\"],\n    outputs=[\"sum\"],\n)\n\nx = np.random.randn(3, 4, 5).astype(np.float32)\ny = np.random.randn(3, 4, 5).astype(np.float32)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add\")\n\nx = np.random.randint(24, size=(3, 4, 5), dtype=np.int8)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.int8)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add_int8\")\n\nx = np.random.randint(24, size=(3, 4, 5), dtype=np.int16)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.int16)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add_int16\")\n\nx = np.random.randint(24, size=(3, 4, 5), dtype=np.uint8)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.uint8)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add_uint8\")\n\nx = np.random.randint(24, size=(3, 4, 5), dtype=np.uint16)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.uint16)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add_uint16\")\n\nx = np.random.randint(24, size=(3, 4, 5), dtype=np.uint32)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.uint32)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add_uint32\")\n\nx = np.random.randint(24, size=(3, 4, 5), dtype=np.uint64)\ny = np.random.randint(24, size=(3, 4, 5), dtype=np.uint64)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add_uint64\")"
              },
              {
                "summary": "add_broadcast",
                "code": "node = onnx.helper.make_node(\n    \"Add\",\n    inputs=[\"x\", \"y\"],\n    outputs=[\"sum\"],\n)\n\nx = np.random.randn(3, 4, 5).astype(np.float32)\ny = np.random.randn(5).astype(np.float32)\nexpect(node, inputs=[x, y], outputs=[x + y], name=\"test_add_bcast\")"
              }
            ]
          }
        },
        {
          "name": "segment_back",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "X",
              "value": [
                {
                  "name": "conv2d_transpose_add:0",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        1,
                        144,
                        256
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "Y",
              "value": [
                {
                  "name": "segment_back_raw_output___4:0",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        1,
                        144,
                        256
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "Sigmoid",
            "module": "ai.onnx",
            "version": 13,
            "description": "Sigmoid takes one input data (Tensor<T>) and produces one output data\n(Tensor<T>) where the sigmoid function, y = 1 / (1 + exp(-x)), is applied to the\ntensor elementwise.\n",
            "inputs": [
              {
                "name": "X",
                "type": "T",
                "description": "Input tensor"
              }
            ],
            "min_input": 1,
            "max_input": 1,
            "outputs": [
              {
                "name": "Y",
                "type": "T",
                "description": "Output tensor"
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "type_constraints": [
              {
                "description": "Constrain input and output types to float tensors.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)",
                  "tensor(bfloat16)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "sigmoid",
                "code": "node = onnx.helper.make_node(\n    \"Sigmoid\",\n    inputs=[\"x\"],\n    outputs=[\"y\"],\n)\n\nx = np.array([-1, 0, 1]).astype(np.float32)\ny = 1.0 / (\n    1.0 + np.exp(np.negative(x))\n)  # expected output [0.26894143, 0.5, 0.7310586]\nexpect(node, inputs=[x], outputs=[y], name=\"test_sigmoid_example\")\n\nx = np.random.randn(3, 4, 5).astype(np.float32)\ny = 1.0 / (1.0 + np.exp(np.negative(x)))\nexpect(node, inputs=[x], outputs=[y], name=\"test_sigmoid\")"
              }
            ],
            "category": "Activation"
          }
        },
        {
          "name": "Transpose__272",
          "chain": [],
          "metadata": [],
          "inputs": [
            {
              "name": "data",
              "value": [
                {
                  "name": "segment_back_raw_output___4:0",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        1,
                        144,
                        256
                      ]
                    }
                  }
                }
              ]
            },
            {
              "name": "shape",
              "value": [
                {
                  "name": "new_shape__369",
                  "initializer": {
                    "name": "new_shape__369",
                    "category": "Initializer",
                    "encoding": "<",
                    "type": {
                      "dataType": "int64",
                      "shape": {
                        "dimensions": [
                          4
                        ]
                      }
                    }
                  },
                  "type": {
                    "dataType": "int64",
                    "shape": {
                      "dimensions": [
                        4
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "outputs": [
            {
              "name": "reshaped",
              "value": [
                {
                  "name": "segment_back",
                  "type": {
                    "dataType": "float32",
                    "shape": {
                      "dimensions": [
                        1,
                        144,
                        256,
                        1
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "attributes": [],
          "type": {
            "name": "Reshape",
            "module": "ai.onnx",
            "version": 19,
            "description": "Reshape the input tensor similar to numpy.reshape.\nFirst input is the data tensor, second input is a shape tensor which specifies the output shape. It outputs the reshaped tensor.\nAt most one dimension of the new shape can be -1. In this case, the value is\ninferred from the size of the tensor and the remaining dimensions. A dimension\ncould also be 0, in which case the actual dimension value is unchanged (i.e. taken\nfrom the input tensor). If 'allowzero' is set, and the new shape includes 0, the\ndimension will be set explicitly to zero (i.e. not taken from input tensor).\nShape (second input) could be an empty shape, which means converting to a scalar.\nThe input tensor's shape and the output tensor's shape are required to have the same number of elements.\n\nIf the attribute 'allowzero' is set, it is invalid for the specified shape to\ncontain both a zero value and -1, as the value of the dimension corresponding\nto -1 cannot be determined uniquely.\n",
            "attributes": [
              {
                "name": "allowzero",
                "type": "int64",
                "required": false,
                "description": "(Optional) By default, when any value in the 'shape' input is equal to zero the corresponding dimension value is copied from the input tensor dynamically. allowzero=1 indicates that if any value in the 'shape' input is set to zero, the zero value is honored, similar to NumPy."
              }
            ],
            "inputs": [
              {
                "name": "data",
                "type": "T",
                "description": "An input tensor."
              },
              {
                "name": "shape",
                "type": "tensor(int64)",
                "description": "Specified shape for output."
              }
            ],
            "min_input": 2,
            "max_input": 2,
            "outputs": [
              {
                "name": "reshaped",
                "type": "T",
                "description": "Reshaped data."
              }
            ],
            "min_output": 1,
            "max_output": 1,
            "type_constraints": [
              {
                "description": "Constrain input and output types to all tensor types.",
                "type_param_str": "T",
                "allowed_type_strs": [
                  "tensor(uint8)",
                  "tensor(uint16)",
                  "tensor(uint32)",
                  "tensor(uint64)",
                  "tensor(int8)",
                  "tensor(int16)",
                  "tensor(int32)",
                  "tensor(int64)",
                  "tensor(bfloat16)",
                  "tensor(float16)",
                  "tensor(float)",
                  "tensor(double)",
                  "tensor(string)",
                  "tensor(bool)",
                  "tensor(complex64)",
                  "tensor(complex128)",
                  "tensor(float8e4m3fn)",
                  "tensor(float8e4m3fnuz)",
                  "tensor(float8e5m2)",
                  "tensor(float8e5m2fnuz)"
                ]
              }
            ],
            "examples": [
              {
                "summary": "allowzero",
                "code": "original_shape = [0, 3, 4]\ntest_cases = {\n    \"allowzero_reordered\": np.array([3, 4, 0], dtype=np.int64),\n}\ndata = np.random.random_sample(original_shape).astype(np.float32)\n\nfor test_name, shape in test_cases.items():\n    node = onnx.helper.make_node(\n        \"Reshape\",\n        inputs=[\"data\", \"shape\"],\n        outputs=[\"reshaped\"],\n        allowzero=1,  # if allowzero=1, final shape = (3, 4, 0)\n        # if allowzero=0, final shape = (3, 4, 4)\n    )\n\n    reshaped = reshape_reference_implementation(data, shape, allowzero=1)\n\n    expect(\n        node,\n        inputs=[data, shape],\n        outputs=[reshaped],\n        name=\"test_reshape_\" + test_name,\n    )"
              },
              {
                "summary": "reshape",
                "code": "original_shape = [2, 3, 4]\ntest_cases = {\n    \"reordered_all_dims\": np.array([4, 2, 3], dtype=np.int64),\n    \"reordered_last_dims\": np.array([2, 4, 3], dtype=np.int64),\n    \"reduced_dims\": np.array([2, 12], dtype=np.int64),\n    \"extended_dims\": np.array([2, 3, 2, 2], dtype=np.int64),\n    \"one_dim\": np.array([24], dtype=np.int64),\n    \"negative_dim\": np.array([2, -1, 2], dtype=np.int64),\n    \"negative_extended_dims\": np.array([-1, 2, 3, 4], dtype=np.int64),\n    \"zero_dim\": np.array([2, 0, 4, 1], dtype=np.int64),\n    \"zero_and_negative_dim\": np.array([2, 0, 1, -1], dtype=np.int64),\n}\ndata = np.random.random_sample(original_shape).astype(np.float32)\n\nfor test_name, shape in test_cases.items():\n    node = onnx.helper.make_node(\n        \"Reshape\",\n        inputs=[\"data\", \"shape\"],\n        outputs=[\"reshaped\"],\n    )\n\n    reshaped = reshape_reference_implementation(data, shape)\n\n    expect(\n        node,\n        inputs=[data, shape],\n        outputs=[reshaped],\n        name=\"test_reshape_\" + test_name,\n    )"
              }
            ],
            "category": "Shape"
          }
        }
      ]
    }
  ]
}